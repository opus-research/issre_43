[
  {
    "_id": "6621d47aac254a19ac29dea9",
    "number": 3255,
    "body": "A small follow-up on https://github.com/geopandas/geopandas/pull/3237 to be consistent with our own new default and don't warn when user does `DataFrame.set_geometry(geoms)`.\r\n\r\nThis also gets emitted in `explode` with no way of silencing.\r\n\r\n```py\r\nimport geopandas as gpd\r\nfrom geodatasets import get_path\r\n\r\ndf = gpd.read_file(get_path('nybb'))\r\ndf.explode()\r\n/Users/martin/Git/geopandas/geopandas/geodataframe.py:2469: FutureWarning: The `drop` keyword argument is deprecated and in future the only supported behaviour will match drop=False. To silence this warning and adopt the future behaviour, stop providing `drop` as a keyword to `set_geometry`. To replicate the `drop=True` behaviour you should update your code to\r\n`geo_col_name = gdf.active_geometry_name; gdf.set_geometry(new_geo_col).drop(columns=geo_col_name).rename_geometry(geo_col_name)`.\r\n  return gf.set_geometry(col, drop=drop, inplace=False, crs=crs)\r\n```",
    "head_branch": "set-geometry-warning",
    "is_a_fork": true,
    "comments": [
      "> This also gets emitted in `explode` with no way of silencing.\r\n\r\nWe should do the same change and pass `drop=None` inside explode then I would think - since in the past this always was drop=False, and in future it will continue to behave as drop=False?\r\n",
      "> We should do the same change and pass drop=None inside explode\r\n\r\nThat uses the default. Do you think we need to be explicit there?",
      "> > We should do the same change and pass drop=None inside explode\n> \n> That uses the default. Do you think we need to be explicit there?\n\nAh sorry, confused myself, should be drop=False, no reason to have a warning in that case I think"
    ],
    "commit_messages": [
      "CLN: pass drop=None to DataFrame.set_geometry (#3255)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d47bac254a19ac29deaa",
    "number": 3254,
    "body": "This fixes some warnings in the dev build:\r\n\r\n```\r\ngeopandas/tests/test_geodataframe.py: 54 warnings\r\ngeopandas/tests/test_pandas_methods.py: 8 warnings\r\ngeopandas/tools/tests/test_sjoin.py: 250 warnings\r\n  /home/runner/work/geopandas/geopandas/geopandas/tools/sjoin.py:425: DeprecationWarning: The copy keyword is deprecated and will be removed in a future version. Copy-on-Write is active in pandas since 3.0 which utilizes a lazy copy mechanism that defers copies until necessary. Use .copy() to make an eager copy if necessary.\r\n    joined = pd.concat([left, right], axis=1, copy=False)\r\n\r\ngeopandas/tests/test_overlay.py: 12 warnings\r\n  /home/runner/work/geopandas/geopandas/geopandas/tools/overlay.py:19: DeprecationWarning: The copy keyword is deprecated and will be removed in a future version. Copy-on-Write is active in pandas since 3.0 which utilizes a lazy copy mechanism that defers copies until necessary. Use .copy() to make an eager copy if necessary.\r\n    df.rename(\r\n```",
    "head_branch": "compat-pandas-3",
    "is_a_fork": true,
    "comments": [
      "This is overlapping a fair bit with #3236, you might want to grab a version of the astype changes from there as well?",
      "@m-richards sorry, forgot about your PR! Will indeed add the relevant bits of your PR here, and then can keep your PR to suppress the alignment warnings (which don't need to be backported)"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d47bac254a19ac29deab",
    "number": 3251,
    "body": "This was inspired by the versioneer change to not run on forks. I would quite like to be able to run tests on my fork, but not have the scheduled tests trigger every day (and generate daily notifications when the dev build is broken). Currently I work around this by turning the tests workflow on and off globally under the actions tab:\r\n\r\n![image](https://github.com/geopandas/geopandas/assets/45483497/cad6fedb-f7e6-4c2b-8e74-58c454c7dcc8)\r\n\r\nSplitting the workflow conditions means these could be turned on and off individually. Happy though if we decide it's not worth the complexity - I had a quick look and can't see other projects doing this, so perhaps this is only an annoyance for me.",
    "head_branch": "try_separate_scheduled_test",
    "is_a_fork": true,
    "comments": [
      "Is there a way to run the scheduled tests only on geopandas/geopandas? I am not sure if the `if` can be outside jobs.",
      "https://github.com/orgs/community/discussions/26684 might be relevant\r\n\r\nIn the job itself you can detect that it was scheduled (https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#schedule), and so that way we can use the `if` inside the job to limit the scheduled runs to only the main repo",
      "Thanks both for the suggestions that's much cleaner"
    ],
    "commit_messages": [
      "GHA: Split scheduled tests into a seperate workflow (#3251)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d47cac254a19ac29deac",
    "number": 3250,
    "body": "In #3237 @jorisvandenbossche left the following comment re the new tests I added there:\r\n >I know this is copied from the notebook, but would prefer for new tests to use a small dummy geodataframe (to avoid having \r\n  > our tests depend too much on IO). Could reuse the `dfs` fixture and just use one of both dataframes.\r\n\r\n_Originally posted by @jorisvandenbossche in https://github.com/geopandas/geopandas/pull/3237#discussion_r1546244011_\r\n            \r\nI decided to have a look and see if it is possible to to this in a more generic way, since we use the nybb dataset quite a lot throughout the tests. (now it's also possible Joris meant this from a test runtime perspective as well, in which case I expect moving things from fiona / pyogrio to json will actually slow things down - but it could be possible to instead load files from an IO engine if present)\r\n\r\nHere I've looked at if we were to store a copy of nybb in geojson (which we can read without fiona/pyogrio) for usage in the the non IO tests. We also need to then pass down the CRS, and the data dtype schema of the columns since geojson is not strongly typed. Having a quick look, this seems fairly feasible - I've just converted the usages in `test_geodataframe` to get some thoughts.\r\n\r\nJust realised now, it may be better to target geoarrow instead of geojson? Pyarrow is currently an optional dependency, but pandas will make it required in 3.0 and thus it will transitively be required.\r\n\r\nOne thing I am not sure about is if this needs to handle platform specific int widths, not sure what shapefile does (I've generated the geojsons on windows, so if all the linux tests fail I expect that is why)",
    "head_branch": "reduce_test_io_dependence",
    "is_a_fork": true,
    "comments": [
      "I suppose there are two different cases where we may want to change the dependency on IO. One is to ensure that we don't need to skip stuff if GDAL is not available via pyogrio or Fiona. Your suggestion resolves that. The other is to speed up tests by depending on small data created on the fly in cases, where we don't need to use real-world geometries. From that perspective, this goes in the wrong direction. \n\nI think that we could eventually try to do both, with preference for the latter when we have a choice. ",
      ">The other is to speed up tests by depending on small data created on the fly in cases, where we don't need to use real-world geometries. From that perspective, this goes in the wrong direction.\r\n\r\nAgree that ideally we wouldn't use any real world data except where we absolutely have to. But there's a trade off between maintainer time to convert existing tests to use new data (and reviewer time to make sure the new data is suitably equivalent) and CI/ test runtime. If I compare the test time of this PR vs main on CI (just looking at 312-latest-conda-forge as a sample, it's not significantly different and if I run `test_geodataframe` locally it's between 1-3% slower from the few quick tests comparisons I've done - which aren't going to control for background cpu differences all that well. So if it's a step in the wrong direction in terms of performance it's hopefully not a very big one.\r\n",
      "Yeah, the trade-off needs to be taken into account. That is partially why I said we _could_ try to do that rather than _should_.  I don't feel strongly about the need to change how our tests currently work and would personally try to focus our attention on different things than that. "
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d47dac254a19ac29dead",
    "number": 3249,
    "body": "Follow up on #3237 to make these tests which don't rely on the nybb data structure use a toy dataset instead. Didn't managed to get to this in time for the original merge (https://github.com/geopandas/geopandas/pull/3237/files#r1546244011)",
    "head_branch": "set_geometry_api_tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: remove nybb usage in set geometry api tests (#3249)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d47eac254a19ac29deae",
    "number": 3248,
    "body": "Automatic update of Versioneer by the `versioneer.yml` workflow.",
    "head_branch": "update-versioneer",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d47fac254a19ac29deaf",
    "number": 3247,
    "body": "This should hopefully resolve void PRs like #3238. Instead of running the stable black, we run pre-commit with whatever version is set there. It should also resolve unnecessary PRs on forks.",
    "head_branch": "versioneer-gha",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "GHA: update versioneer GHA so it uses pre-commit and does not run on forks (#3247)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d480ac254a19ac29deb0",
    "number": 3246,
    "body": "Including the version information in the changelog + minor linting of markdown. \r\n\r\nOnce the 1.0 is fully out, I would rename the header to 1.0. But until then, it may help to be explicit when people are going to be testing against pre-releases.\r\n\r\n",
    "head_branch": "alpha-changelog",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "RLS: mark 1.0.0-alpha1 in the changelog (#3246)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d480ac254a19ac29deb1",
    "number": 3245,
    "body": "Fixing the issue caused by #3237. The set_geometry test was split to two, but the pyproj-related skip was added to the wrong part.",
    "head_branch": "pyproj-test-skip",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: properly skip set_geometry tests when pyproj is not available (#3245)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d481ac254a19ac29deb2",
    "number": 3242,
    "body": null,
    "head_branch": "doc/add-buckaroo-to-community",
    "is_a_fork": true,
    "comments": [
      "What is Buckaroo:\r\n\r\n[Buckaroo](https://github.com/paddymul/buckaroo) is a modern data table viewer for Jupyter notebooks, tailored for exploratory data analysis tasks, which provides useful, sensible views and hooks for everyday data analysis. \r\nIn addition to standard table viewing features, Buckaroo comes with existing built-in analysis that is extensible by users.  This works on Pandas, Polars, and now GeoPandas! \r\n![geopandas-buckaroo](https://github.com/geopandas/geopandas/assets/40453/3e24ddc0-7344-4eed-87b7-04eb1595f88f)\r\n\r\nHere is a video demonstrating Buckaroo and GeoPandas:\r\nhttps://www.youtube.com/watch?v=T39DrGFq46A\r\n\r\n",
      "I normally would post the above to a mailing list.  I wanted to announce to the GeoPandas community that my tool supports this library.  I would appreciate it if you could include a link in your docs.  Let me know about any feedback you have on buckaroo or this PR",
      "One note - I would be careful about using SVG as some geometries may be quite large and browsers may struggle to render it freezing the window.",
      "> One note - I would be careful about using SVG as some geometries may be quite large and browsers may struggle to render it freezing the window.\r\n\r\nThanks for the heads up.  Buckaroo has built in downsampling. The `GeopandasSVGBuckarooWidget` samples to no more than 2k rows vs 10k for all other renderers..  `GeopandasSVGBuckarooWidget` is also not enabled by default.",
      "Thanks for sharing this @paddymul, certainly looks like a useful library, will try and check it out sometime soon. "
    ],
    "commit_messages": [
      "DOC: Add buckaroo data table to the community docs (#3242)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d482ac254a19ac29deb3",
    "number": 3241,
    "body": "I have fixed the issue with numpy 2 and explore over in branca but realised we don't test against that. Fixing it.",
    "head_branch": "branca-dev",
    "is_a_fork": true,
    "comments": [
      "All green now :)."
    ],
    "commit_messages": [
      "CI: install branca from main in dev env (#3241)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d483ac254a19ac29deb4",
    "number": 3240,
    "body": "Closes #3239 \r\n\r\nMoving the sorting to the query so we don't have to deal with it later. I _think_ it does not brake anything else.",
    "head_branch": "within-sorting",
    "is_a_fork": true,
    "comments": [
      "I suppose ideally we may want to test sort order with a combination of predicates / left/right/inner/outer but I don't think needs to be this PR."
    ],
    "commit_messages": [
      "REGR: fix order of left sjoin with within predicate (#3240)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d484ac254a19ac29deb5",
    "number": 3238,
    "body": "Automatic update of Versioneer by the `versioneer.yml` workflow.",
    "head_branch": "update-versioneer",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d484ac254a19ac29deb6",
    "number": 3237,
    "body": "Closes #2770\r\nCloses #1038, #3160 (superceded PRs) \r\n\r\nThis originally started with trying to rebase #1038, but that solution was breaking some tests due to column sort order, and also doesn't seem to implement what is discussed in the thread. I think this is a faithful implementation of what is discussed in #1038 minus the `geometry_name` discussion except for \r\n\r\n>But if the values have a name, it can also be an option to keep the original geometry column intact (not necessarily the default, but people could do drop=False to keep the original one)\r\n\r\nas the default is drop=False as it would be quite odd to have drop=False the default for string like arguments and drop=True the default for Series like arguments.\r\n\r\n(maybe I've misinterpreted that though. If this does become not straightforward to resolve I certainly don't think it's a blocker for 1.0, just something that would be nice to tie off if possible.)\r\n\r\n----------------------------------\r\n\r\nThis is a breaking change, and I think is best done as a breaking change, there's no clean way to deprecate this. \r\n\r\nThe best options with deprecation warnings I could see  (besides the already mentioned extra geometry col argument) would be to either, do what pandas is doing now for some behaviour (which I think is arguably quite annoying) and warn the behaviour will change in future every time the method is called (or called with arguments that the behaviour change would affect), or to provide some kind of toplevel `geopandas.options.set_geometry_new_behaviour = False/True/None` defaulting to None, so there is at least some way to migrate / silence warnings.\r\n\r\nTo try and make the changes as clear as possible, I opted to add new tests, replicating the exploratory notebook Joris set up on the original thread.\r\n",
    "head_branch": "set_geometry_api",
    "is_a_fork": true,
    "comments": [
      "> This is a breaking change, and I think is best done as a breaking change, there's no clean way to deprecate this.\r\n\r\nOne of the two main breaking changes is the case of passing an existing column name with `drop=True`, for example `gdf.set_geometry(\"centroid\", drop=True)` in case there is both a \"geometry\" and \"centroid\" column. Right now the result has one geometry column with the name \"geometry\" (but with values from \"centroid\" column), in the future that will be \"centroid\". \r\n\r\nAnother option could also be to just deprecate the `drop=True` keyword (and the behaviour for the default `drop=False` doesn't change), and that way we do it essentially with a deprecation instead of as a hard break.\r\n\r\nAnd then the alternative for people currently doing that, using the same example as above:\r\n- If you want to preserve the current behaviour, you need to do `gdf.set_geometry(\"centroid\").drop(columns=\"geometry\").rename_geometry(\"geometry\")` \r\n- If you want what is the new behaviour in this PR, you need to do `gdf.set_geometry(\"centroid\").drop(columns=\"geometry\")`\r\n\r\nThe first one is quite verbose, but also with this PR you would need the rename call, like `gdf.set_geometry(\"centroid\", drop=True).rename_geometry(\"geometry\")`.\r\n\r\nIn any case, also when keeping it as a breaking change as the PR does right now, might be good to mention the alternative to keep the previous behaviour.\r\n\r\n",
      "> Another option could also be to just deprecate the `drop=True` keyword (and the behaviour for the default `drop=False` doesn't change), and that way we do it essentially with a deprecation instead of as a hard break.\r\n\r\nI did wonder about this as I was working on this (I would think drop=True isn't being used all that much, but it's very hard to know in practice). In that world, what do you suggest about the provide a (Geo)Series case? As I see, we could\r\n1. preserve the series name now (breaking) and treat drop as false always, and warn it does nothing if drop is True? \r\n2. preserve the series name now (breaking) and implement with drop True and False and wait until the deprecation expires to have consistency? \r\n3. Leave the (Geo)Series name case case until after the deprecation expires (but this would still be breaking, just at a later date) noting that might take quite some time before it can be fixed.\r\n\r\nI'm happy with deprecating drop, I think it's just as good as an outcome, but avoids the hard break in this situation. I'd probably lean towards (1), since `drop` was being ignored when a GeoSeries is passed anyway (though I suppose you might think about it being drop = True in the sense that the name of the previous active geometry column was being preserved)\r\n\r\n\r\n> In any case, also when keeping it as a breaking change as the PR does right now, might be good to mention the alternative to keep the previous behaviour.\r\n\r\nYeah that is a good idea - I thought about this too and wasn't sure if the changelog is the right place - I suppose it is as we probably don't have that many breaking changes to warrant a separate \"updating to geopandas 1.0\" guide.\r\n\r\n",
      "> 1. preserve the series name now (breaking) and treat drop as false always, and warn it does nothing if drop is True?\r\n\r\nI vote for this solution.",
      "I think that's enough of a lean for me to make a start, will update the PR to implement this and switch the tests over to not use nybb.\r\n\r\nEdit: behaviour now changed to implement 1, test data not yet changed.",
      "I've found a pathological case that needs fixing:\r\n\r\n```py\r\nimport geopandas as gpd\r\nfrom geodatasets import get_path\r\n\r\ngdf = gpd.read_file(get_path('nybb'))\r\ncentroid = gdf.centroid\r\ncentroid.name = 'centroid'\r\n\r\ngdf.set_geometry(centroid).drop(columns='geometry').set_geometry(gdf.exterior)\r\n\r\n   BoroCode       BoroName     Shape_Leng    Shape_Area centroid\r\n0         5  Staten Island  330470.010332  1.623820e+09     None\r\n1         4         Queens  896344.047763  3.045213e+09     None\r\n2         3       Brooklyn  741080.523166  1.937479e+09     None\r\n3         1      Manhattan  359299.096471  6.364715e+08     None\r\n4         2          Bronx  464392.991824  1.186925e+09     None\r\n```\r\n\r\nIn the case of an active geometry with a custom name, setting a geometry (does not matter if a named Series or array-like) results in the above. If it is named, the result looks like:\r\n\r\n```py\r\n   BoroCode       BoroName     Shape_Leng    Shape_Area  \\\r\n0         5  Staten Island  330470.010332  1.623820e+09   \r\n1         4         Queens  896344.047763  3.045213e+09   \r\n2         3       Brooklyn  741080.523166  1.937479e+09   \r\n3         1      Manhattan  359299.096471  6.364715e+08   \r\n4         2          Bronx  464392.991824  1.186925e+09   \r\n\r\n                         centroid exterior  \r\n0    POINT (941639.45 150931.991)     None  \r\n1  POINT (1034578.078 197116.604)     None  \r\n2   POINT (998769.115 174169.761)     None  \r\n3   POINT (993336.965 222451.437)     None  \r\n4    POINT (1021174.79 249937.98)     None \r\n```",
      "@m-richards do you want me to take a pass at this? I'd like to get this in and an alpha release out sooner than later. ",
      "I will try take a look tonight ",
      "> I've found a pathological case that needs fixing:\r\n@martinfleis sorry I missed the original notification on this so I'm only looking at it now and it's not clear to me what you think the bug is. Would you be able to clarify, think I'm missing something.\r\n\r\nYou say \"does not matter if a named Series or array-like\", but then later imply the result changes if it is named.\r\nI'm guessing for the second case, you have a snippet something like\r\n```python\r\nimport geopandas as gpd\r\nfrom geodatasets import get_path\r\ngdf = gpd.read_file(get_path('nybb'))\r\ncentroid = gdf.centroid\r\ncentroid.name = 'centroid'\r\n\r\nexterior = gdf.exterior\r\nexterior.name = \"exterior\"\r\n\r\nprint(gdf.set_geometry(centroid).drop(columns='geometry').set_geometry(exterior))\r\n```\r\nbut that's working as intended - at least as I understand the above discussion - and that's what I've currently written in the changelog. We are moving to a default of `drop=False` in `set_geometry`, when a Series/ arraylike is supplied, the behaviour has historically been replace the values in the existing geometry (an analogue of drop=True). Now, we are introducing a breaking change to preserve the name of the GeoSeries given to set_geometry. Given this is breaking, I think it makes sense to already implement the `drop=False` behaviour (noting that if users use gdf.geometry rather than a column name, then all this will mean is carry around an additional column), or otherwise we effectively have \"drop=True\" behaviour if a GeoSeries/ arraylike is provided, but drop=False if a column name is given.",
      "Ah, I am sorry, I confused myself. I meant to use `gdf.boundary` instead of `gdf.exterior` and the resulting array of None lead to thinking that there's something wrong with the `set_geometry`. After a second look, this indeed works as expected.",
      "> Ah, I am sorry, I confused myself. I meant to use `gdf.boundary` instead of `gdf.exterior` and the resulting array of None lead to thinking that there's something wrong with the `set_geometry`. After a second look, this indeed works as expected.\r\n\r\nno worries!",
      "> Let's move forward here! I had a remaining comment on the tests, that can be done later as well\r\n\r\nyep sorry haven't had as much time, happy to follow up on a new branch",
      "Thanks @m-richards !"
    ],
    "commit_messages": [
      "BUG/API: Set geometry api where `col` is named / with `drop=True` (#3237)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d485ac254a19ac29deb7",
    "number": 3236,
    "body": "Cleaning deprecation warnings which are showing up.\r\nThere are some cases which could be simplified by conditionally defining kwargs - but I think that'd add overhead, so have just added similar code in each block.",
    "head_branch": "pandas_3_warning_cleanup",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d486ac254a19ac29deb8",
    "number": 3235,
    "body": "This should fix the one failing test for `astype` in the dev build",
    "head_branch": "compat-numpy-2-copy",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "COMPAT: adjust for new `copy`  behaviour of numpy.array / __array__ (#3235)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d487ac254a19ac29deb9",
    "number": 3234,
    "body": "From pandas' changelog for 3.0:\r\n\r\n> Enforce deprecation in [testing.assert_series_equal()](https://pandas.pydata.org/docs/dev/reference/api/pandas.testing.assert_series_equal.html#pandas.testing.assert_series_equal) and [testing.assert_frame_equal()](https://pandas.pydata.org/docs/dev/reference/api/pandas.testing.assert_frame_equal.html#pandas.testing.assert_frame_equal) with object dtype and mismatched null-like values, which are now considered not-equal ([GH 18463](https://github.com/pandas-dev/pandas/issues/18463))\r\n\r\nI commented earlier about that it would be nice to have a keyword for this (https://github.com/pandas-dev/pandas/pull/52081#issuecomment-1620648937), although I think that would not actually have helped in this case for us to avoid the `test_unstack` changes.\r\n\r\nThis are test-only changes, nothing critical for users.",
    "head_branch": "compat-pandas-testing-strict-null",
    "is_a_fork": true,
    "comments": [
      "The final failure in the dev build is in `explore`, so unrelated."
    ],
    "commit_messages": [
      "TST: compat with pandas 3.0 for strict null check in assert_frame_equal (#3234)\n\nCo-authored-by: Matt Richards <mrichards7@outlook.com.au>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d488ac254a19ac29deba",
    "number": 3233,
    "body": "Resolves #2937 \r\n\r\nExposes the existing sorting keywork in sindex.query to clip geodataframes and geoseries",
    "head_branch": "issue2937",
    "is_a_fork": true,
    "comments": [
      "> Doesn't 100% address the request as they requested preservation of the input order, but I imagine sorting would achieve the same outcome 9/10 times.\r\n\r\nCan you elaborate on that? In which case this does not work as expected?",
      "> > Doesn't 100% address the request as they requested preservation of the input order, but I imagine sorting would achieve the same outcome 9/10 times.\n> \n> \n> \n> Can you elaborate on that? In which case this does not work as expected?\n\nThe poster requested preservation of the input order. In the case where the input dataframe is not sorted, but clip is run with sort=True, it will return a sorted dataframe. If run with sort=False, it may return with a different unsorted order from the input.\n\nI can't think of any cases where a user would want to maintain the order of an unsorted dataframe though.",
      "> The poster requested preservation of the input order. In the case where the input dataframe is not sorted, but clip is run with sort=True, it will return a sorted dataframe. If run with sort=False, it may return with a different unsorted order from the input.\r\n> \r\n> I can't think of any cases where a user would want to maintain the order of an unsorted dataframe though.\r\n\r\nI don't think that is correct. The indices coming from `sindex.query` are integer positions of geometries in the original GeoSeries, it does not matter how their index looks like. So even if the GeoSeries to be clipped has a custom, unsorted index, with `sort=True`, the original order is fully preserved. Taking an example from your tests:\r\n\r\n```py\r\ncities = gpd.read_file(naturalearth_cities)\r\nworld = gpd.read_file(naturalearth_lowres)\r\nsouth_america = world[world[\"continent\"] == \"South America\"]\r\ncities.reset_index().set_index(\"name\").clip(south_america, sort=True)\r\n\r\n                index                     geometry\r\nname                                              \r\nGeorgetown         55    POINT (-58.16703 6.80197)\r\nParamaribo         59    POINT (-55.16703 5.83503)\r\nAsunción           62  POINT (-57.62583 -25.29067)\r\nQuito              88     POINT (-78.502 -0.21304)\r\nValparaíso        101  POINT (-71.61703 -33.04774)\r\nSucre             114  POINT (-65.25952 -19.04097)\r\nLa Paz            122  POINT (-68.15193 -16.49603)\r\nBrasília          169    POINT (-47.918 -15.78139)\r\nCaracas           181   POINT (-66.91898 10.50294)\r\nLima              189  POINT (-77.05201 -12.04607)\r\nBuenos Aires      210  POINT (-58.43251 -34.61071)\r\nBogota            230    POINT (-74.08529 4.59837)\r\nSantiago          236   POINT (-70.6505 -33.44021)\r\nRio de Janeiro    238  POINT (-43.21212 -22.90731)\r\nSão Paulo         239  POINT (-46.62697 -23.55673)\r\n```\r\n\r\nNotice that the original `index` is sorted even though the actual index is not, hence the order is correctly preserved. I suppose that we could improve the docstring within `sindex` to be a bit clearer about what we mean by \"index\" there.",
      "> > The poster requested preservation of the input order. In the case where the input dataframe is not sorted, but clip is run with sort=True, it will return a sorted dataframe. If run with sort=False, it may return with a different unsorted order from the input.\r\n> > I can't think of any cases where a user would want to maintain the order of an unsorted dataframe though.\r\n> \r\n> I don't think that is correct. The indices coming from `sindex.query` are integer positions of geometries in the original GeoSeries, it does not matter how their index looks like. So even if the GeoSeries to be clipped has a custom, unsorted index, with `sort=True`, the original order is fully preserved. Taking an example from your tests:\r\n> \r\n> ```python\r\n> cities = gpd.read_file(naturalearth_cities)\r\n> world = gpd.read_file(naturalearth_lowres)\r\n> south_america = world[world[\"continent\"] == \"South America\"]\r\n> cities.reset_index().set_index(\"name\").clip(south_america, sort=True)\r\n> \r\n>                 index                     geometry\r\n> name                                              \r\n> Georgetown         55    POINT (-58.16703 6.80197)\r\n> Paramaribo         59    POINT (-55.16703 5.83503)\r\n> Asunción           62  POINT (-57.62583 -25.29067)\r\n> Quito              88     POINT (-78.502 -0.21304)\r\n> Valparaíso        101  POINT (-71.61703 -33.04774)\r\n> Sucre             114  POINT (-65.25952 -19.04097)\r\n> La Paz            122  POINT (-68.15193 -16.49603)\r\n> Brasília          169    POINT (-47.918 -15.78139)\r\n> Caracas           181   POINT (-66.91898 10.50294)\r\n> Lima              189  POINT (-77.05201 -12.04607)\r\n> Buenos Aires      210  POINT (-58.43251 -34.61071)\r\n> Bogota            230    POINT (-74.08529 4.59837)\r\n> Santiago          236   POINT (-70.6505 -33.44021)\r\n> Rio de Janeiro    238  POINT (-43.21212 -22.90731)\r\n> São Paulo         239  POINT (-46.62697 -23.55673)\r\n> ```\r\n> \r\n> Notice that the original `index` is sorted even though the actual index is not, hence the order is correctly preserved. I suppose that we could improve the docstring within `sindex` to be a bit clearer about what we mean by \"index\" there.\r\n\r\nThank you for taking the time to explain, that makes sense "
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d489ac254a19ac29debb",
    "number": 3232,
    "body": "Closes #3207. It's worth looking at the diff before 12393dc773bc5213538ee3751fa53a72ec353180. I was originally intending to just fix the zipfile case and still depend on the internal details to push down the road until fiona 1.11/  fiona 2 for a future break. But I was looking into how we could replace this, and it actually seemed simpler to pinch the pyogrio logic for this, than to work out how to come up with a minimal equivalent of the fiona path classes - which we only want specifically for this purpose.\r\n\r\nNot sure how we feel about introducing the new code / duplication.\r\n\r\n",
    "head_branch": "fiona_1.10_compat",
    "is_a_fork": true,
    "comments": [
      "> Not sure how we feel about introducing the new code / duplication.\r\n\r\nI am personally fine with doing that. It's indeed some duplication, but then we also are more robust against future Fiona changes (and most of the effort of re-writing this outside of Fiona was already done in pyogrio)\r\n\r\nTo what extent did you cut down the pyogrio code? Would it be easier to just copy-paste it verbatim, even if that includes some features we don't need, so it's easier to update it later in case pyogrio would update / fix things?",
      "> To what extent did you cut down the pyogrio code? Would it be easier to just copy-paste it verbatim, even if that includes some features we don't need, so it's easier to update it later in case pyogrio would update / fix things?\r\n\r\nAh, looking at the code in pyogrio, I suppose it's mostly the `buffer_to_virtual_file` call, that's indeed something we have to remove here (and some completely unrelated helpers like `_preprocess_options_key_value`, that's of course fine to leave out)",
      "> > To what extent did you cut down the pyogrio code? Would it be easier to just copy-paste it verbatim, even if that includes some features we don't need, so it's easier to update it later in case pyogrio would update / fix things?\r\n> \r\n> Ah, looking at the code in pyogrio, I suppose it's mostly the `buffer_to_virtual_file` call, that's indeed something we have to remove here (and some completely unrelated helpers like `_preprocess_options_key_value`, that's of course fine to leave out)\r\n\r\nThe functions that we use are unchanged, it was just the imports and other unused stuff\r\n\r\n> (and most of the effort of re-writing this outside of Fiona was already done in pyogrio)\r\n\r\nThat's what made me think to look at pyogrio, since it necesasrily needed a solution to this zip situation without the fiona path classes.\r\n",
      "Yeah, I essentially wrote that piece of code in pyogrio by taking fiona's code (at the time) and simplifying it for just what we needed (eg we didn't need to class structure for just the internal usage)",
      "Can you re-enable that test path we limited to pyogrio in #3209? To test the original issue."
    ],
    "commit_messages": [
      "MAINT: Fiona 1.10 compat for zip files (#3232)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d489ac254a19ac29debc",
    "number": 3231,
    "body": "Addresses #3049 \r\n\r\nProposed approach to do a spatial join when both geometry and an attribute column are equal. Thought I'd get some eyes on it before I progress further as I'm new to contributing to this repo.\r\n\r\nThings left to do:\r\n- more tests\r\n- changelog\r\n- don't add suffix to the `sharedAttribute`\r\n- consider if sharedAttribute should allow more than one attribute column, i.e. accept list and force all attributes in listed columns to be equal\r\n- more details in docstring",
    "head_branch": "issue3049",
    "is_a_fork": true,
    "comments": [
      "Thanks! We should probably get #2353 in before touching sjoin code elsewhere. \r\n\r\nOne minor nit - please use snake_case in the code, not camelCase. Thanks!",
      "Thanks Martin,\r\n\r\nI noted #2353 has been merged. I've since re-based and resolved conflicts.\r\n\r\nI've made further updates so it can take lists and tuples too - similar to the ``merge()`` function in pandas. Renamed ``shared_attribute`` (corrected to snake case) to ``on_attribute`` - to be a bit more similar to kwarg `on` used in pandas. Happy to change to any argument you think is preferable. Have also updated to the \"_left\", \"_right\" suffix does not get appended to the ``on_attribute`` columns. \r\n",
      "> Can you also update the docstring of GeoDataFrame.sjoin in geodataframe.py?\r\n> \r\n> Otherwise this looks good to my eyes. Thanks!\r\n\r\nI've added to the docstring, I also noted the `distance` kwarg wasn't added to the `GeoDataFrame.sjoin` docstring, I've added that here (though wasn't sure if it really should be a separate commit)",
      "@nicholas-ys-tan can you merge main here to resolve conflicts?",
      "> For `sjoin` this looks good! I was wondering what the best approach would be, though, but I can imagine that this will depend on the characteristics of your data. But in general you could either first evaluate the spatial predicate and then the attribute match (as you did here), or either first perform the attribute merge (as a way to reduce the set of geometries for which to evaluate the spatial predicate?) and then the spatial predicate. Before I looked at the code in this PR, I was assuming this PR was for the latter, but of course for `sjoin` this should give identical results. So for a first version this is probably just fine. But I do think it might be interesting to explore performance characteristics of both on some example datasets in the future.\r\n\r\nI will confess I was not engaging with this PR and the original issue precisely because of this, I would think the best order of operations depends quite a bit of the data in question, and for that reason was wondering if this actually belongs in geopandas. But I can still see value in providing a convenience utility for this for the general case, even if it's not necessarily the most performant in all circumstances.",
      "> For `sjoin` this looks good! I was wondering what the best approach would be, though, but I can imagine that this will depend on the characteristics of your data. But in general you could either first evaluate the spatial predicate and then the attribute match (as you did here), or either first perform the attribute merge (as a way to reduce the set of geometries for which to evaluate the spatial predicate?) and then the spatial predicate. Before I looked at the code in this PR, I was assuming this PR was for the latter, but of course for `sjoin` this should give identical results. So for a first version this is probably just fine. But I do think it might be interesting to explore performance characteristics of both on some example datasets in the future.\r\n> \r\n> However, that also made me wonder if this approach is correct for the `sjoin_nearest`? Because in that case it _does_ matter in which order you do those operations, I think? I would assume that I get \"the closest geometry among those with a matching attribute\", but in practice it will give \"the overall closest geometry _if_ that closest geometry has a matching attribute\". That seems an important difference in expected behaviour, which I am not sure has been discussed?\r\n> \r\n> I would maybe suggest to focus this first PR on the `sjoin` function (where the behaviour is clearer), and leave out `sjoin_nearest` for later.\r\n\r\nThank you @jorisvandenbossche , that's great food for thought re performance and I will do some investigation into that.\r\n\r\nAlso thank you for pointing out the implications on `sjoin_nearest`, the sequence and its impact on the output was not something that had crossed my mind. I've since removed all `on_attribute` joins from `sjoin_nearest`.\r\n\r\nI will open up a new issue for discussion on the ordering of operations how `on_attribute` behaves in `sjoin_nearest`.",
      "> I was wondering what the best approach would be, though, but I can imagine that this will depend on the characteristics of your data. But in general you could either first evaluate the spatial predicate and then the attribute match (as you did here), or either first perform the attribute merge (as a way to reduce the set of geometries for which to evaluate the spatial predicate?) and then the spatial predicate.\r\n\r\n@jorisvandenbossche , is this sort of what you had in mind in terms of evaluating the characteristics first, then the spatial predicate? I'm essentially passing in smaller dataframes into that already have the attribute filtered to have geometries evaluated separately. I haven't yet done any performance testing as I am not sure if this is the optimal approach - it feels a bit naive at the moment and wanted to run it by you first.\r\n\r\nAn initial test with `test_sjoin_shared_attribute` in this PR suggests this approach (~0.045 secs) would be slower than the approach currently in the PR (~0.025 secs). But, this may not be a great example with the dataset being relatively small. I imagine maybe the batched processing of geometry joins may become more preferable on larger datasets (pure speculation).\r\n\r\nAdditionally, this does not currently work for multiple `on_attributes` yet.\r\n\r\n```python\r\ndef _geom_predicate_query_on_attribute_wrapper(left_df, right_df, predicate, distance, on_attribute):\r\n\r\n    unique_attrs = left_df[on_attribute[0]].unique()\r\n    l_idx = []\r\n    r_idx = []\r\n    for attr in unique_attrs:\r\n        right_attr_index = right_df[on_attribute[0]]==attr\r\n        left_attr_index = left_df[on_attribute[0]]==attr\r\n        right_df_attr = right_df[right_attr_index]\r\n        left_df_attr = left_df[left_attr_index]\r\n\r\n        left_df_idx, right_df_idx = _geom_predicate_query(left_df_attr, \r\n                                                          right_df_attr,\r\n                                                          predicate, \r\n                                                          distance)\r\n\r\n        l_idx += left_df_attr.index[left_df_idx].to_list()\r\n        r_idx += right_df_attr.index[right_df_idx].to_list()\r\n\r\n\r\n    return l_idx, r_idx\r\n```",
      "Thanks @nicholas-ys-tan "
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d48aac254a19ac29debd",
    "number": 3229,
    "body": "Resolves #3028.\r\n\r\nA proposed approach to do an area averaged mean (specific aggfunc argument TBD).\r\n\r\nThis approach allows us to use the existing pandas aggfunc so the kwargs still take effect.\r\n\r\nHave refactored to process geometries first, allowing processing of spatial_average_mean in one `if` statement, instead of having one at the start during non-geometry processing, and one after geometry processing (ref first commit before refactoring).\r\n\r\nHaven't fully tested the kwargs, nor written unit testing yet, nor documentation. Seeking prelim feedback before progressing further.",
    "head_branch": "issue3028",
    "is_a_fork": true,
    "comments": [
      "Have a question on desired behaviour. In the event a polygon and a 1-dimensional geometry type (Point or LineString) are dissolved together. Would we want the area weighted mean to:\r\n\r\n1. raise an error\r\n2. ignore the point data and just operate on the 2d data\r\n3. return nan in any rows that involved a 1-dimensional geometry (current behaviour)\r\n",
      "I would raise an error as area-weighted mean is not defined for other than polygonal geometries.",
      "Latest update greatly improves readability by using a user-defined function for aggfunc but have run into some issues around the `numeric_only` keyword when running with a dataframe that has non-numeric columns. Using `numeric_only` argument gets fed into the UDF for area-weighted mean.\r\n\r\nSeems to be a well-documented but perhaps an incompletely resolved issue at this time - https://github.com/pandas-dev/pandas/issues/50538. Continuing to look into it to determine best approach.\r\n",
      "I seem to have opened a can of worms by opting to feed a function to `aggfunc` to get the area-weighted-mean. I'm summarising below to keep track of the relevant information and where it stands today.\r\n\r\n- This is an existing issue on pandas side where the behaviour of `numeric_only` seems to work, it works fine when using pandas functions: 'first', 'last', 'min', 'max', 'sum', 'mean', 'median'. But not when fed with a function e.g. `np.mean`. It tries to feed the kwarg `numeric_only` into the function `np.mean`.\r\n- Feeding a function works fine if we don't use any kwargs. The issue with this arises if using a dataframe with non-numeric datatypes. An error will raise when trying the find the `np.mean` of strings for example. \r\n- This makes my current set-up untenable if trying to find the area-weighted-mean of a dataframe with non-numeric datatypes. I can make the area-weighted lambda function take in `**kwargs**` but then it will still error out when trying to operate on the string data.\r\n- There seems to have been a PR merged to 1.5.x-dev on pandas that would have provided more informative error messages but for some reason don't seem to be able to find it in the main branch. https://github.com/pandas-dev/pandas/pull/50627\r\n- As it stands it is currently on the pandas to do list: https://github.com/pandas-dev/pandas/issues/56946\r\n\r\nMy view on what we can do next:\r\n\r\n- Put this ticket on ice until `numeric_only` compatibility with user-defined functions is addressed upstream (We would continue to have issues when feeding UDF aggfuncs to `dissolve` where non-numeric dtypes exist.\r\n- Address with an \"ugly patch\" - something like what @jorisvandenbossche put forward: https://github.com/pandas-dev/pandas/issues/50538#issuecomment-1369803068 but on geopandas end in `dissolve`. So if `numeric_only` has been fed as a kwarg, we can pop it and filter out the non-numeric columns in our end before passing through to the `dataframe.groupby().agg()` function.\r\n- Put in an error message if the user is trying to run `area_weighted_mean` with a dataframe with non-numeric datatypes that they would need to manually drop the non-numeric columns first. Can also be done more generally where it should be used if a UDF and `numeric_only` are supplied.\r\n- By default, always operate only on numeric columns regardless of `numeric_only` kwarg\r\n\r\nIt may be worth noting the existing docstring may cause some confusion as it suggests `numeric_only` may be needed in pandas 2.0 for certain agg functions, but what is not noted is that it would also cause issues for other agg functions (UDFs in particular).\r\n\r\nApologies if I am off the mark in my investigation in this and wasted your time reading this wall of text.",
      "@nicholas-ys-tan is this ready for review? Asking given the draft status of the PR.",
      "I have submitted this PR to support using `area_weighted_mean` as an aggregate function in `dissolve`.\r\n\r\nThere is a major limitation to this in that the GeoDataFrame must be numeric only (with the exception of the geometry column and any columns listed in `by` for grouping.\r\n\r\nIn theory, we should have been able to get around this by using the `numeric_only` kwarg. However, there is an upstream bug in pandas where the `numeric_only` kwarg gets passed into any user-definied functions (UDF). This kwarg only works with the built-in methods such as 'sum', 'mean' etc. This is an existing issue where aggfunctions such as `np.sum` and np.mean` may cause issues.\r\n\r\nI attempted to submit a PR to address this upstream, but ran into further bugs that made this challenging. I have suspended work there as it was interfering with the work they are already putting in to fix.\r\nhttps://github.com/pandas-dev/pandas/issues/58146\r\n\r\nSupport of `numeric_only` for UDF is on their radar too.\r\nhttps://github.com/pandas-dev/pandas/issues/56946\r\n\r\nIn the mean time, if we wanted to proceed with this, I have added error catching to disallow any dataframes with non-numeric columns (except geometry and those listed in `by`) to be used with `area_weighted_mean`. Alternatively we can wait for the bugs to be fixed and remove those checks.\r\n",
      "> @nicholas-ys-tan is this ready for review? Asking given the draft status of the PR.\r\n\r\nThanks, yes, it is, I was just writing a comment to where this is now. Some upstream bugs detailed in the comments have enforced some limitations on what dataframes this can be used for, not sure if this is something we would still want to introduce at this time. But perhaps there is a better way to do this which I haven't thought of yet.",
      "One way around these limitations is to ensure that we intercept `\"area_weighted_mean\"` in the dict input, so users can specify which columns shall be aggregated using `area_weighted_mean` and which shall use some other method. Then we can revise as soon as pandas provides better support.\r\n\r\nIntercepting list input would also be useful but that won't solve any of the `numeric_only` issues.",
      "> One way around these limitations is to ensure that we intercept `\"area_weighted_mean\"` in the dict input, so users can specify which columns shall be aggregated using `area_weighted_mean` and which shall use some other method. Then we can revise as soon as pandas provides better support.\r\n> \r\n> Intercepting list input would also be useful but that won't solve any of the `numeric_only` issues.\r\n\r\nThanks @martinfleis , I had actually missed that `aggfunc` also accepts list and dictionary inputs.  I have updated with the latest commit to process list and dict inputs for aggfuncs."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d48bac254a19ac29debe",
    "number": 3228,
    "body": "This is the last PR exposing shapely functionality as GeoSeries methods outlined in #2010. One last that is there is `symmetric_difference_all`, but that seems to be wrong in shapely - https://github.com/shapely/shapely/issues/2027.\r\n\r\n",
    "head_branch": "all",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d48cac254a19ac29debf",
    "number": 3226,
    "body": "Closes #3199 using existing functions in GeoDataFrame.\r\n\r\nHave not included `na` as an attribute as Properties aren't used in GeoSeries as far as I understand.\r\n\r\nI noted default of `GeoDataFrame.to_json` show_bbox is False, but the existing code defaults to True, hence have explicitly left default as True.",
    "head_branch": "issue3199",
    "is_a_fork": true,
    "comments": [
      "Hello, have been looking to contribute to geopandas as a user of this repository - this seemed like a good low hanging fruit to get my feet wet with my first PR.\r\n\r\nI've read through the contribution guide and hope I have not violated any of the conventions. Kindly let me know if I did.\r\n\r\nThanks.",
      "Thank you for taking the time to review and provide detailed feedback @m-richards \r\n\r\nAgreed with both of your comments and have updated accordingly. Using the `to_json` method directly from geodataframe certainly addresses both of your comments without replicating the code for crs transformations.\r\n\r\nRegarding your more general comment on structure, I had a look at putting the function in `geopandas/base.py::GeoPandasBase` but the functions currently in the base class seem to be more on properties and geometric functions. The other GeoSeries i/o functions `to_file`, `from_file` inherit from `geodataframe` so I was seeking to mimic that structure in the latest commit. I am happy to move it to the base class if you think that is where it belongs though.\r\n\r\nThat said, I was thinking about moving the `to_json` method into a new file in `geopandas/io/json.py` as `_to_json` to facilitate working on this issue: https://github.com/geopandas/geopandas/issues/3187 in the future, it would also mimic the structure of `to_file`, but thought maybe that's best done as part of issue 3187, if I look at working on that down the road being a more complex one.\r\n\r\nAgain, appreciate your time and feedback.\r\n\r\nNoted there's a failing test - I'll keep looking into it"
    ],
    "commit_messages": [
      "ENH: show_bbox and drop_id added to geoseries.to_json (#3226)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d48dac254a19ac29dec0",
    "number": 3225,
    "body": "This should use intersphinx mapping and render as a link to https://arrow.apache.org/docs/python/generated/pyarrow.parquet.read_table.html\r\nsee also https://github.com/geopandas/geopandas/pull/2016\r\n\r\n",
    "head_branch": "doc-link-pyarrow-parquet-read_time",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: link to pyarrow.parquet.read_table (#3225)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d48dac254a19ac29dec1",
    "number": 3224,
    "body": "Closes #2837\r\n\r\nMarking it as a draft for now as before I'll start touching the docs, I'd like to get #3223 in to avoid unnecessary conflicts.\r\n\r\nThe only thing this does is to wrap `pyogrio.list_layers` and return it as a DataFrame instead of an array to avoid confusion like the one in https://github.com/geopandas/pyogrio/issues/275/. I was also considering returning a Series indexed by a layer name but DataFrame _feels_ more right in this case.\r\n\r\nTo-do:\r\n- [x] documentation",
    "head_branch": "list-layers",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: add geopandas.list_layers wrapping pyogrio (#3224)\n\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d48eac254a19ac29dec2",
    "number": 3223,
    "body": "Still need to figure out the minimal pin, 0.4.0 may not be it.\r\n\r\nXref #3201",
    "head_branch": "io-default",
    "is_a_fork": true,
    "comments": [
      "> Still need to figure out the minimal pin, 0.4.0 may not be it.\r\n\r\nI think we can definitely go for a newer version, especially for a geopandas 1.0 where it is a new dependency anyway (0.4.0 is almost two years old, i.e. older than shapely 2.0). \r\n\r\nIf we go for 1 year old, it's somewhere between 0.5 and 0.6. But I would personally even consider going for 0.7",
      "> If we go for 1 year old, it's somewhere between 0.5 and 0.6. But I would personally even consider going for 0.7\r\n\r\nI went with 0.5.0 in the end, which seems to work fine in our CI. 0.5.1 is what comes from anaconda defaults channel at the moment so it may be good to try and support it if there's no strict reason not to.\r\n",
      "Bumped minimal version to 0.7.0. I think this will not resolve with defaults. Will wait for CI and install pyogrio from PyPI if needed.",
      "Needs a merge of main",
      "Now that pyogrio 0.8 has been released, are you planning to update the write side to default to pyogrio as well?",
      "@kylebarron it should already default to pyogrio for writing. Or have I messed this PR?",
      "I suppose @kylebarron is referring to the new flavour of writing introduced in pyogrio 0.8 that uses the arrow interface of GDAL (`write_dataframe` with `use_arrow=True`)?\r\n\r\nI think it is too soon though to switch to it as default. It is a very new feature in GDAL as well as in pyogrio that didn't have any serious real-life testing yet in either project...",
      "Indeed, I conflated \"pyogrio engine\" with \"arrow interface\". So on both the read side and the write side, users will need to pass `use_arrow=True` to use the arrow interface, right? This is unfortunate (at least on the read side where it's better tested) but unavoidable unless pyarrow becomes a required dependency of pandas, I suppose.",
      "> Indeed, I conflated \"pyogrio engine\" with \"arrow interface\". So on both the read side and the write side, users will need to pass `use_arrow=True` to use the arrow interface, right? This is unfortunate (at least on the read side where it's better tested) but unavoidable unless pyarrow becomes a required dependency of pandas, I suppose.\r\n\r\nYes, for the read side I definitely agree it is unfortunate, but it is indeed to avoid pyarrow becoming a ~required dependency for geopandas...",
      "We've been discussing whether we should use arrow automatically if pyarrow is installed in a similar way we used pygeos over shapely before. But until we know that there is no difference between the resulting files and the way they are read, it is a bit trickier and can be confusing for users. The chance that pyarrow is in some of your envs and not in the other without you knowing is much higher these days than it was with pygeos back then. So it is a recipe for surprises.",
      ">We've been discussing whether we should use arrow automatically if pyarrow is installed in a similar way we used pygeos over shapely before\r\n\r\nI wonder if to avoid potential confusion but still be convenient we could expose a toplevel `geopandas.options` flag + environment variable. Or let the existing `geopandas.options.io_engine` accept `pyogrio_arrow` as an option, which would feed through use_arrow on read and write?"
    ],
    "commit_messages": [
      "Change the default IO engine to pyogrio (#3223)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>\r\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>\r\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d48fac254a19ac29dec3",
    "number": 3222,
    "body": "ffill/ bfill methods are to be used instead, neither of which are implemented on a GeoSeries",
    "head_branch": "pandas_3_fillna_method_removed",
    "is_a_fork": true,
    "comments": [
      "> We may want to do this conditionally depending on pandas\r\n\r\nIf a user explicitly sets it, it should still be passed through with the `kwargs`, I assume, and then you should still get the error about it not being supported when being on older pandas versions."
    ],
    "commit_messages": [
      "COMPAT: pandas 3 removes `method` kwarg to fillna (#3222)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d490ac254a19ac29dec4",
    "number": 3221,
    "body": "Closes #3103",
    "head_branch": "geoplot",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: remove dysfunctional geoplot example (#3221)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d491ac254a19ac29dec5",
    "number": 3219,
    "body": "Partial implementation of https://github.com/geopandas/geopandas/issues/3156. Adds a `to_arrow` method to export to GeoArrow.\r\n\r\nAdds a `geometry_encoding` parameter for either WKB or GeoArrow, defaulting to GeoArrow. Adds PROJJSON-encoded CRS, which is the current standard pending https://github.com/geoarrow/geoarrow/pull/40.\r\n\r\nNotes:\r\n\r\n- Right now this isn't totally separate from the `to_geoparquet` path, so GeoParquet metadata still gets set on the table metadata, even though that isn't required for GeoArrow.\r\n- If there are multiple geometry columns, are they guaranteed to have the same CRS? It seems like there's a CRS on the table but not a GeoSeries.",
    "head_branch": "kyle/geoarrow",
    "is_a_fork": true,
    "comments": [
      "How does this benchmark against https://github.com/shapely/shapely/pull/1953 ? The export half of that is currently fine (the import half is where I'm running into a lifecycle constraint).",
      "I think that PR should be an implementation detail. It seems that we should be able to switch from `to_ragged_array` to your implementation when it's stable/merged without changing the user facing API here. Or maybe I am missing something?\n\nI suppose one question is whether the GeoPandas export creates extension arrays or not. ",
      "Got it! I missed that detail 😳 . I'll more actively poke away at that PR since I think it does speed things up a bit.\r\n\r\nI think extension arrays would be nice (and would increase the chance that the CRS is not dropped), although that would require `geoarrow.pyarrow` for the extension type registration.",
      "hmm, you're right that does complicate this a bit. I'm guessing that if the extension type isn't registered the field is dropped through the c data interface?\n\nI'm not sure if geopandas should have a hard dependency on geoarrow-pyarrow (I assume that in 1.0 it'll still have an optional dep on pyarrow). Is there some way we can do this that'll work the same whether the user has geoarrow-pyarrow installed or not?",
      "The registration system causes a similar problem in R, where `as_nanoarrow_array()` or `arrow::as_arrow_array()` will do the wrong thing if the geoarrow package hasn't been loaded. For `to_arrow()` it seems pretty straightforward (`pyarrow` is loaded anyway and `geoarrow.pyarrow` is tiny compared to that)...for `__arrow_c_xxx__` it would take some workshopping.\r\n\r\nIt seems strange, but I wonder if geoarrow-pyarrow should not depend on pyarrow (such that it could be hard dependency with a minimal module that registers an import hook after `pyarrow` is loaded to also load its non-minimal module). (Just spitballing here).",
      "> If there are multiple geometry columns, are they guaranteed to have the same CRS? It seems like there's a CRS on the table but not a GeoSeries.\r\n\r\nNot at all. CRS is stored at the GeometryArray level and each column can have its own. `GeoDataFrame.crs` retrieves CRS of the active geometry column only.",
      "> It seems strange, but I wonder if geoarrow-pyarrow should not depend on pyarrow (such that it could be hard dependency with a minimal module that registers an import hook after `pyarrow` is loaded to also load its non-minimal module). (Just spitballing here).\r\n\r\nHmm, that's interesting. As long as it's ok for the registration to happen multiple times, then geopandas could strictly depend on geoarrow-pyarrow and always register the extension types? I figure that geopandas would also need to construct classes exported from geoarrow-pyarrow?",
      "> I'm guessing that if the extension type isn't registered the field is dropped through the c data interface?\r\n\r\nFor RecordBatches, that shouldn't be the case (or if so, that sounds as a bug). But pyarrow.Array objects (not part of an object with a Schema), that will indeed not preserve that information ..\r\n\r\n---\r\n\r\nI kind of like the idea of returning non-extension type data but just with the field annotations. However, if we return pyarrow objects and add a similar method for GeoSeries / GeometryArray, that's an issue ..\r\n\r\nThis might also be a reason to _not_ return pyarrow objects, but a generic wrapper object with the dunder methods. Then it is up to the user to decide which Arrow implementation or which extension types to use when importing that data.\r\n\r\nAnother problem with the extension types, even if we would add `geoarrow-pyarrow` as a dependency to geopandas, is that eventually we might want to control that extension type in geopandas itself .. For example, we will eventually want to add a pandas ExtensionArray backed by (Py)Arrow memory (instead of GEOS objects), and at that point, we might to have a pyarrow extension type that maps to that pandas extension instead of `geoarrow-pandas`.\r\n",
      "> Another problem with the extension types, even if we would add geoarrow-pyarrow as a dependency to geopandas, is that eventually we might want to control that extension type in geopandas itself \r\n\r\nIf you support GeoArrow as a storage type for a `GeoSeries`, there's no need for `geoarrow-pandas` to exist!\r\n\r\nYou could try it and see if there are problems, but really think that we not want randomly dropped extension type metadata depending on the user's runtime and/or which order (or if) they imported `geoarrow.pyarrow`. I'm pretty happy to update (or review any update) to `geoarrow-pyarrow` that makes it easier to depend on; however, I don't think it is productive to duplicate `geoarrow-pyarrow`.",
      "> If you support GeoArrow as a storage type for a `GeoSeries`, there's no need for `geoarrow-pandas` to exist!\r\n\r\nUnless you just want support for preserving the geoarrow data in conversion to pandas, but don't have the whole geo stack installed.. Although we are making geopandas leaner to install, and the core just depends on pandas and shapely, which is quite small (the default install still comes with GDAL, PROJ, and its bindings, though, you have do some effort to only get the minimal install)\r\n\r\n\r\nBut yes, I see how ideally, when dealing with and passing around _pyarrow_ objects, we only have a single canonical `geoarrow` pyarrow extension type implementation that gets reused. \r\nWe could start with adding `geoarrow-pyarrow` as an optional dependency here\r\n\r\nAnd I have to re-read our thoughts in https://github.com/geoarrow/geoarrow-python/issues/38. Ideally geopandas could also depend on something just for the extension types (while `geoarrow-pyarrow` is already having other (compute) functionality as well)",
      "This is good discussion!\r\n\r\nIf we do want to go down a path of exposing capsule-based objects, I wonder if it would be easiest to describe to users a two-step process of \"exporting\" to Arrow and then \"importing\" into the destination library. Maybe that informs the API here?\r\n\r\n\r\n\r\n> I kind of like the idea of returning non-extension type data but just with the field annotations\r\n\r\nSo this would be something like this? (pseudocode)\r\n\r\n```\r\n@dataclass\r\nclass GeoPandasArrowArray:\r\n\tarray: pyarrow.Array\r\n    field: pyarrow.Field\r\n\r\n    def __arrow_c_array__(self, requested_schema):\r\n\t\tschema_capsule = self.field.__arrow_c_schema__()\r\n\t\tarray_capsule = self.array.__arrow_c_array__()[1]\r\n\t\treturn (schema_capsule, array_capsule)\r\n```\r\n\r\nI like the minimalism of it, where it doesn't need a new dependency (besides pyarrow) but presumably would work with geoarrow-c, geoarrow-pyarrow, and geoarrow-rust.\r\n\r\nSo `to_arrow` on a `GeoSeries` would return this `GeoPandasArrowArray`? Then would `to_arrow` on the `GeoDataFrame` return a pyarrow table or a similar wrapper class? Calling `__arrow_c_stream__` on the `Table` object would maintain the data type, but once you get the geometry column as a `ChunkedArray` you'd have lost the extension types, right?",
      "> Unless you just want support for preserving the geoarrow data in conversion to pandas, but don't have the whole geo stack installed\r\n\r\nAny temporary gripes about the number of dependencies required to `some_arrow_array.to_pandas()` I think are massively outweighed by having it return a `GeoSeries` and having that be the canonical and only route. The role of geoarrow-pandas could still be to provide the extension array implementation, which could avoid a pyarrow dependency via nanoarrow or geoarrow-c or geoarrow-rust.\r\n\r\n> So to_arrow on a GeoSeries would return this GeoPandasArrowArray? \r\n\r\nCould the `GeoSeries` implement `__arrow_c_array__` and/or `__arrow_c_stream__` for C consumers and `__arrow_array__` for pyarrow consumers? That would ensure that pyarrow users get an extension array with the extension type registered but C consumers (who might care less about registration) just get a schema with metadata.",
      "> Could the `GeoSeries` implement `__arrow_c_array__` and/or `__arrow_c_stream__` for C consumers and `__arrow_array__` for pyarrow consumers? That would ensure that pyarrow users get an extension array with the extension type registered but C consumers (who might care less about registration) just get a schema with metadata.\r\n\r\nThis does sound nice (I'm guessing that pyarrow will always prefer `__arrow_array__`?) though we were considering starting with `GeoSeries.to_arrow` to allow the user to choose between WKB and native geometry encoding.",
      "> to allow the user to choose between WKB and native geometry encoding.\r\n\r\nOne could use `requested_schema` (for the C protocol) or `type` (for the `__arrow_array__` protocol)? Maybe defaulting to (inferred) GeoArrow native encoding but allowing a type request of `wkb()`? That would also let a caller opt out of extension types via `pa.array(some_geoseries, pa.binary())`.\r\n",
      "> One could use `requested_schema` (for the C protocol) or `type` (for the `__arrow_array__` protocol)? Maybe defaulting to (inferred) GeoArrow native encoding but allowing a type request of `wkb()`? That would also let a caller opt out of extension types via `pa.array(some_geoseries, pa.binary())`.\r\n\r\nYes, that's potentially an option, but it's hard to handle that schema negotiation without extra information about the set of geometry types in the source data, and that isn't known without a scan through the data. ",
      "> Yes, that's potentially an option, but it's hard to handle that schema negotiation without extra information about the set of geometry types in the source data, and that isn't known without a scan through the data.\r\n\r\nIt could be WKB by default then? That would be more stable since it would be guaranteed to be the same type each time and has generally wider support.",
      "> It could be WKB by default then? That would be more stable since it would be guaranteed to be the same type each time and has generally wider support.\r\n\r\nYes but in the future when GeoArrow-native support is more widespread, we may want to default to exporting GeoArrow-native geometries, and changing that from WKB would be a breaking change. That's why I'm more inclined to not yet define PyCapsule methods on the GeoSeries directly. For now, let the user decide which output format to use.",
      "Proposal to move forward with this on the short term with an initial version that returns Arrow data with the metadata (and so not registered extension types):\r\n\r\n- I would like to get this in something quickly (ideally in the next two weeks for geopandas 1.0), and so on the short term I don't think we can rely on geoarrow-pyarrow. My feeling is that would need a bit more time to become a dependency of geopandas. We can still later see how we can deduplicate code that might exist in both geopandas and geoarrow-pyarrow. \r\n- In addition, I think for quite some use cases, at least the ones we are now thinking about ourselves (Kyle for lonboard / geoarrow-rust, geopandas itself for writing to geoparquet), you might actually only need the metadata. So for those use cases, this initial version will work fine. And I think the initial priority is to enable those use cases.\r\n\r\nFor what to actually return, we have two options:\r\n\r\n- Return pyarrow objects, but with just the field metadata for extension types and not registered types. \r\n  - Advantage is that this is a more usable object to work with for users and will be supported by more libraries, but disadvantage is that it ties us to pyarrow\r\n  - The main problem is that right now it's a bit difficult to actually convert columns with metadata to the custom (registered) extension type. So for people that _do_ use geoarrow-pyarrow, you can't easily get what you want AFAIK.\r\n  - If we want to return the extension types in the future, we could add an option for it now and make that required to specify (though this is a bit cumbersome ..), to avoid a breaking change in the future. Because switching to extension types would make the metadata go away, which other consumers of the data might rely upon\r\n- Don't return pyarrow objects but some wrapper that only exposes the dunder methods of the capsule interface\r\n  - Disadvantage is that users always have to do an additional call to turn the object into something usable, but advantages is that this doesn't tie us to pyarrow (e.g. we would be free to in the future replace this piece of code with nanoarrow, or with the capsule that shapely might give us directly, or ..), i.e. we are free to change that under the hood without breaking user code assuming the return value is a pyarrow object.\r\n  - The second point is also a disadvantage _right now_, because pyarrow tables are more widespread supported compared to Arrow PyCapsule interface (for example, polars will be able to convert the pyarrow table, but not yet the wrapper object)\r\n  - This gives a clearer option for someone who wants the extension types (which we can then document), because they can do:\r\n\r\n    ```python\r\n    import pyarrow as pa\r\n    import geoarrow.pyarrow  # this registers the extension types\r\n    \r\n    table = pa.table(gdf.to_arrow(encoding=\"geoarrow\"))\r\n    ```\r\n    and the step through the C Data Interface back to pyarrow will ensure it sees the metadata and uses the registered extension types.\r\n\r\nI would propose to go with the second option for now. This is a bit more cumbersome to use right now for end users, but gives us more freedom for the future (i.e. we can still decide to return pyarrow objects later (eg if pandas makes that a required dependency) without breaking user code, but not the other way around)",
      "I agree that geoarrow-pyarrow is not a good fit right now (and won't be until I or somebody else has time to focus efforts there and give it the requisite number of releases to iron out bugs to a level suitable for geopandas), and that exposing a \"dummy\" array object with the right dunder methods is the best solution. Even if this is a little more cumbersome, the workaround is compact (as you noted). \r\n\r\nI also am an obvious fan of extension types: I love the possibility that Geospatial data can be a first-class citizen in Arrow-based libraries (that support extension types) without dropping CRS metadata. I doubt there will be significant geoarrow-pyarrow usage until it is ready to be a candidate for geopandas dependency, at which point we can engineer a workaround (`nanoarrow.c_schema(type).metadata` should work everywhere).",
      "I concur that geoarrow-pyarrow is not stable enough to be used by geopandas, especially as geopandas moves to 1.0. \r\n\r\n> might actually only need the metadata\r\n\r\nHow so? It seems all these cases need the actual data as well.\r\n\r\n> some use cases\r\n\r\nI think showing how the integration _just works_ with writing to GDAL would be an impressive example. E.g. both this:\r\n\r\n```py\r\ngdf = gpd.GeoDataFrame(...)\r\npyogrio.write_arrow(gdf.to_arrow())\r\n```\r\n\r\nand _also_ through the OGR Python bindings support for Arrow, is quite cool.\r\n\r\n> * Don't return pyarrow objects but some wrapper that only exposes the dunder methods of the capsule interface\r\n\r\nI'm +1 on this. This also gives us more time to see if other libraries like Polars adopt the PyCapsule API directly, where `pl.from_arrow(gdf.to_arrow())` would work out of the box. But I think the benefits of allowing us freedom to move in the future without making backwards-incompatible changes are quite valuable. And for now it's only one extra line of code for users.\r\n\r\n> return pyarrow objects later (eg if pandas makes that a required dependency)\r\n\r\noff topic but I thought that was already decided?",
      "> > might actually only need the metadata\r\n> \r\n> How so? It seems all these cases need the actual data as well.\r\n\r\nSorry, I meant only the metadata and not as a registered extension type. Of course everyone wants the actual data as well ;) \r\nBut so essentially what you did here, i.e. create data with field metadata, not using a pyarrow extension type.\r\n",
      "> > return pyarrow objects later (eg if pandas makes that a required dependency)\r\n> \r\n> off topic but I thought that was already decided?\r\n\r\nYes, but then there were second thoughts .. ;) (https://github.com/pandas-dev/pandas/issues/54466, https://github.com/pandas-dev/pandas/issues/57073)\r\n(I just wrote a PDEP last week for pandas 3.0 to keep a fallback for the \"string\" dtype in case pyarrow is not installed)",
      "FWIW I also have a draft PR on top of this to add GeoParquet support (https://github.com/geopandas/geopandas/pull/3275). It does need a bit ore, like the option to have separated instead of interleaved coordinates.",
      "> Sorry, I meant only the metadata and not as a registered extension type. Of course everyone wants the actual data as well ;) But so essentially what you did here, i.e. create data with field metadata, not using a pyarrow extension type.\r\n\r\nOh I see. Yeah, I got used to maintaining extension metadata on the field separately from the arrays because arrow-rs doesn't have the concept of extension arrays.",
      "I pushed a few updates that I needed for my GeoParquet PR (support for separated coords in addition to interleaved), and also added some basic tests.\r\n\r\nThe tests are right now based on comparing the output with the generated example data we have at https://github.com/geoarrow/geoarrow-data. A few notes:\r\n\r\n- It's generally super annoying to assert equality for pyarrow objects (something we should improve on that side), eg to specifically check field metadata but ignore schema metadata, or ignore the nullable flag, consider NaNs as equal, ... (and that combined with basically not visual message or output about which aspect might not be equal ..)\r\n- In addition to that, @paleolimbot I noticed that the generated example data don't set the nullable flag to False for everything but the top-level list. \r\n  Also, the type of the row_number column is inconsistent between the gpkg and arrow files (int32 vs int64)",
      "I think this should be mostly ready.\r\n\r\nThere are a few small remaining TODOs (making fields non-nullable, removing empty crs metadata), but for those I first need to fix the test data.\r\n\r\nThen there is the remaining API question:\r\n\r\n- how to specify interleaved vs separated coordinates? In the `geometry_encoding` keyword? As a separate flag? See https://github.com/geopandas/geopandas/pull/3219#discussion_r1594035520",
      "I keep trying to find time to review this. I'll try to get to this in the next couple of days",
      "@kylebarron I suppose we should also add a similar method to GeoSeries (just returning the geometry array and not as a tabular struct array)?",
      "> @kylebarron I suppose we should also add a similar method to GeoSeries (just returning the geometry array and not as a tabular struct array)?\r\n\r\nyeah absolutely",
      "I am going to merge this now, to make it easier to finish the dependent PRs (import, parquet writing), but let's further tweak the interface in follow-ups if needed!\r\n\r\nThanks Kyle for getting this started and all for the feedback.",
      "I'm particularly good at starting PRs that others finish 😆 🫣 . Thanks for all the effort pushing this over the line! 🙏 "
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d491ac254a19ac29dec6",
    "number": 3215,
    "body": "xref #2010 \r\n\r\nOne thing I was considering here was if to explode the collection to two GeoSeries but if a user does not care about the direction then the original GeometryCollection that comes from GEOS is probably better and they can explode it later if needed.",
    "head_branch": "shared_paths",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d492ac254a19ac29dec7",
    "number": 3214,
    "body": "xref #2010\n\nCloses #1711",
    "head_branch": "line_merge",
    "is_a_fork": true,
    "comments": [
      "resolves #1711"
    ],
    "commit_messages": [
      "ENH: add line_merge method (#3214)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d493ac254a19ac29dec8",
    "number": 3212,
    "body": "Closes #1832 \r\n\r\nOne question here - do we want to test if the warning is emitted in every single binary method, since they all use the same `_delegate_binary_method` under the hood. I opted for _no_ but can potentially include those.",
    "head_branch": "align",
    "is_a_fork": true,
    "comments": [
      "I am certainly fine with not exhaustively testing this for every single method"
    ],
    "commit_messages": [
      "API: change the align default to None allowing silencing alignment warning in binary ops (#3212)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d494ac254a19ac29dec9",
    "number": 3211,
    "body": "xref #2010",
    "head_branch": "relate_pattern",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d495ac254a19ac29deca",
    "number": 3209,
    "body": "Replaces broken usage with deprecated usage. Disentangling GeoPandas from fiona's path module is left as a TODO.\r\n\r\nResolves #3207\r\n\r\n@m-richards @jorisvandenbossche I think this should get the project back in green.",
    "head_branch": "sgillies-patch-1",
    "is_a_fork": false,
    "comments": [
      "We will have to enable fiona main again to actually test it (in ci/envs/311-dev.yml, need to remove the pin)",
      "Not passing on dev - https://github.com/geopandas/geopandas/actions/runs/8185403536/job/22381724635?pr=3209",
      "There is one remaining failure that is specifically testing something related to zipped files:\r\n\r\n```\r\n =================================== FAILURES ===================================\r\n________________________ test_infer_zipped_file[fiona] _________________________\r\n[gw2] linux -- Python 3.11.8 /home/runner/micromamba/envs/test/bin/python3.11\r\n\r\n>   ???\r\n\r\nfiona/ogrext.pyx:135: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\n>   ???\r\nE   fiona._err.CPLE_OpenFailedError: /home/runner/work/geopandas/geopandas/geopandas/tests/data/nybb_16a.zip!nybb.shp: No such file or directory\r\n\r\nfiona/_err.pyx:289: CPLE_OpenFailedError\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nengine = 'fiona'\r\nnybb_filename = 'zip:///home/runner/work/geopandas/geopandas/geopandas/tests/data/nybb_16a.zip'\r\n\r\n    def test_infer_zipped_file(engine, nybb_filename):\r\n        # Remove the zip scheme so that the test for a zipped file can\r\n        # check it and add it back.\r\n        path = nybb_filename[6:]\r\n        gdf = read_file(path, engine=engine)\r\n        assert isinstance(gdf, geopandas.GeoDataFrame)\r\n    \r\n        # Check that it can successfully add a zip scheme to a path that already has a\r\n        # scheme\r\n        gdf = read_file(\"file+file://\" + path, engine=engine)\r\n        assert isinstance(gdf, geopandas.GeoDataFrame)\r\n    \r\n        # Check that it can add a zip scheme for a path that includes a subpath\r\n        # within the archive.\r\n>       gdf = read_file(path + \"!nybb.shp\", engine=engine)\r\n\r\ngeopandas/io/tests/test_file.py:692: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\ngeopandas/io/file.py:308: in _read_file\r\n    return _read_file_fiona(\r\ngeopandas/io/file.py:354: in _read_file_fiona\r\n    with reader(path_or_bytes, **kwargs) as features:\r\n../../../micromamba/envs/test/lib/python3.11/site-packages/fiona/env.py:457: in wrapper\r\n    return f(*args, **kwds)\r\n../../../micromamba/envs/test/lib/python3.11/site-packages/fiona/__init__.py:321: in open\r\n    colxn = Collection(\r\n../../../micromamba/envs/test/lib/python3.11/site-packages/fiona/collection.py:233: in __init__\r\n    self.session.start(self, **kwargs)\r\nfiona/ogrext.pyx:588: in fiona.ogrext.Session.start\r\n    ???\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\n>   ???\r\nE   fiona.errors.DriverError: /home/runner/work/geopandas/geopandas/geopandas/tests/data/nybb_16a.zip!nybb.shp: No such file or directory\r\n\r\nfiona/ogrext.pyx:143: DriverError\r\n------------------------------ Captured log call -------------------------------\r\nERROR    fiona._env:collection.py:233 /home/runner/work/geopandas/geopandas/geopandas/tests/data/nybb_16a.zip!nybb.shp: No such file or directory\r\n```",
      "The failure is caused by the change at https://github.com/Toblerity/Fiona/blame/master/fiona/_path.py#L82. To fiona, `!` means nothing without an archive type URI scheme (zip, tar, gzip). But in 1.9, we did parse it no matter what https://github.com/Toblerity/Fiona/blob/maint-1.9/fiona/path.py#L68. That wasn't intended behavior and was the source of a rasterio bug: https://github.com/rasterio/rasterio/commit/dce1c75880d09d7da83b8d7d966c7da2f4faa448.\r\n\r\nI recommend deleting that particular assertion. I'll do so in this PR.\r\n\r\n \r\n\r\n"
    ],
    "commit_messages": [
      "COMPAT: Update import of parse_path from fiona (#3209)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d496ac254a19ac29decb",
    "number": 3208,
    "body": "See https://github.com/geopandas/geopandas/issues/3207",
    "head_branch": "tmp-pin-fiona",
    "is_a_fork": true,
    "comments": [
      "And pinning pytest for https://github.com/scientific-python/pytest-doctestplus/issues/239",
      "Going to merge this to unblock other PRs / have green CI"
    ],
    "commit_messages": [
      "TEMP pin fiona to 1.9 in dev build (#3208)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d496ac254a19ac29decc",
    "number": 3206,
    "body": "As mentioned in the community meeting... a first step in documenting some differences between Fiona and Pyogrio.",
    "head_branch": "DOC-add-migration-guide-for-fiona-to-pyogrio",
    "is_a_fork": true,
    "comments": [
      "@theroggy can we try to finish and merge this before the alpha release hits so we can point people at the migration guide when needed?",
      "> @theroggy can we try to finish and merge this before the alpha release hits so we can point people at the migration guide when needed?\r\n\r\nOK, I'll apply the feedback this weekend...",
      "> Thanks @theroggy for starting on this!\r\n> \r\n> You probably know better than me, is there also a difference with the handling of nulls worth mentioning? (from memory pyogrio will handle writing nullable ints, but fiona would turn these into floats? but this may only be with use_arrow=True) I recall checking something about this on an issue, but I can't find it now.\r\n\r\nI'm not aware (anymore) of a difference regarding this...",
      "The docstring tests are failing on a pyarrow issue... but I don't import pyarrow in the new docs, and don't really understand what is going wrong?",
      "> but I don't import pyarrow in the new docs, and don't really understand what is going wrong?\r\n\r\nIgnore that - https://github.com/apache/arrow/issues/41058",
      "Merging to have it available during the alpha pre-release testing. We can iterate further in follow-up PRs if someone wants to see some changes here."
    ],
    "commit_messages": [
      "DOC: add migration guide for fiona to pyogrio (#3206)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d497ac254a19ac29decd",
    "number": 3205,
    "body": null,
    "head_branch": "enable-pyscopg3_test_edits",
    "is_a_fork": true,
    "comments": [
      "Sorry for the noise, this was supposed to be a PR against my fork."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d498ac254a19ac29dece",
    "number": 3204,
    "body": "Automatic update of Versioneer by the `versioneer.yml` workflow.",
    "head_branch": "update-versioneer",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d499ac254a19ac29decf",
    "number": 3203,
    "body": "Closes #2077\r\n\r\nWhen pyproj is not available and a user tries to set a CRS, it currently falls back to `None` and warns about the situation. It may be cleaner to raise an error to avoid potential issues with that though but you wouldn't be able to read a file in such a case. Now you can read it but you won't get CRS support.\r\n\r\nAlso, raising would require a ton of skips in our tests. Warnings can just be silenced.",
    "head_branch": "optional-crs",
    "is_a_fork": true,
    "comments": [
      "I think that implementation-wise, this is now ready for a review. It will need a changelog and some documentation but I'd like to get an agreement on behaviour first."
    ],
    "commit_messages": [
      "ENH: make pyproj a soft-dependency (#3203)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d499ac254a19ac29ded0",
    "number": 3202,
    "body": "xref #2010\ncloses #2916\ncloses #2949",
    "head_branch": "build_area",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d49aac254a19ac29ded1",
    "number": 3197,
    "body": "Updating to the new 2024 stable style (mostly some changes in the inline if/else formatting)",
    "head_branch": "bump-black",
    "is_a_fork": true,
    "comments": [
      "Already going to merge this, in the hope it stops the unnecessary versioneer updates.\r\n\r\n> Any thoughts on adopting ruff format instead? I've been using it quite happily in some other projects.\r\n\r\nI won't object if someone does a PR switching, although I also kind of like keeping black (and it's not that I ever had problems with black, with its speed, or with the combo of running black and ruff, or that it feels an annoyance to have both)"
    ],
    "commit_messages": [
      "MAINT: bump black (#3197)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d49bac254a19ac29ded2",
    "number": 3195,
    "body": "Updates the copyright year in `conf.py` to \"2013-2024\".",
    "head_branch": "patch-2",
    "is_a_fork": true,
    "comments": [
      "Thanks!"
    ],
    "commit_messages": [
      "DOC: remove copyright year (#3195)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d49cac254a19ac29ded3",
    "number": 3193,
    "body": null,
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Update mergingdata.rst to mention the correct pandas method (#3193)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d49dac254a19ac29ded4",
    "number": 3191,
    "body": "Two fixes\r\n* the deprecated convert_dtypes has been removed\r\n* In dissolve, the value for geometry in non observed categorical groups has changed (due to https://github.com/pandas-dev/pandas/pull/55738). We also should deprecated the default of observed from false to true to match pandas (created #3192 for this).",
    "head_branch": "pandas_main_compat",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "COMPAT: pandas 3 related test updates (#3191)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d49eac254a19ac29ded5",
    "number": 3190,
    "body": "xref #2263, removing some of the plotting related warnings.",
    "head_branch": "more_warnings",
    "is_a_fork": true,
    "comments": [
      "@m-richards I have rebased this and would like to merge it ahead of 1.0-alpha1. Is there anything stopping us? Asking since ou marked it only as a draft PR.",
      "> @m-richards I have rebased this and would like to merge it ahead of 1.0-alpha1. Is there anything stopping us? Asking since ou marked it only as a draft PR.\r\n\r\nNo, it should be ready - I had it as draft since there's been test failures when I pushed it, but they were coincidental and unrelated",
      "Thanks!"
    ],
    "commit_messages": [
      "CLN: remove plotting compatibility aliases (#3190)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d49fac254a19ac29ded6",
    "number": 3188,
    "body": "This sets vmin and vmax to the 2nd and 98th percentile of the values similar to xarray's robust keyword.\r\ncolourbar is extended in both directions same as xarray\r\noverwrites user defined vmin and vmax if provided.",
    "head_branch": "main",
    "is_a_fork": true,
    "comments": [
      "Can someone please point me in the right direction? Im looking at the failed lint and im not sure what exactly is wrong!",
      "Hey @leonfoks generally it is a good idea to first open an issue to discuss the feature you would like to add before jumping in and creating a PR. As a generic library we have to be careful not to add everything possible to our plotting functions, or we end up with an unwieldy API. So it's good to get to get support from maintainers before going to the trouble of creating a whole PR. \r\n\r\nIn this case though, I think `robust` is probably a worthwhile inclusion. \r\n\r\nIn terms of the linting specifically, you might want to have a look here: https://geopandas.org/en/latest/community/contributing.html#style-guide-linting,\r\nin particular, the step for installing pre-commit - as it's the easiest way to make sure the linting is in sync with our requirements (but you can also invoke black and ruff directly)."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d49fac254a19ac29ded7",
    "number": 3186,
    "body": "Closes https://github.com/geopandas/geopandas/issues/3169",
    "head_branch": "pytest-xfails",
    "is_a_fork": true,
    "comments": [
      "I'm also a bit perplexed on how this is best configured. Another option, we could also pin to pytest <8 in the short term?",
      "Just going to merge for now. We can revisit if we need to"
    ],
    "commit_messages": [
      "TST/CI: decrease verbosity for xfails in pytest 8+ output (#3186)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4a0ac254a19ac29ded8",
    "number": 3185,
    "body": "Bumps [pre-commit/action](https://github.com/pre-commit/action) from 3.0.0 to 3.0.1.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/pre-commit/action/releases\">pre-commit/action's releases</a>.</em></p>\n<blockquote>\n<h2>pre-commit/action@v3.0.1</h2>\n<h3>Misc</h3>\n<ul>\n<li>Update actions/cache to v4\n<ul>\n<li><a href=\"https://redirect.github.com/pre-commit/action/issues/190\">#190</a> PR by <a href=\"https://github.com/SukiCZ\"><code>@​SukiCZ</code></a>.</li>\n<li><a href=\"https://redirect.github.com/pre-commit/action/issues/189\">#189</a> issue by <a href=\"https://github.com/bakerkj\"><code>@​bakerkj</code></a>.</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/pre-commit/action/commit/2c7b3805fd2a0fd8c1884dcaebf91fc102a13ecd\"><code>2c7b380</code></a> v3.0.1</li>\n<li><a href=\"https://github.com/pre-commit/action/commit/8e2deebc7918860122d0968e9e4fb73161fedbe2\"><code>8e2deeb</code></a> Merge pull request <a href=\"https://redirect.github.com/pre-commit/action/issues/190\">#190</a> from SukiCZ/upgrade-action/cache-v4</li>\n<li><a href=\"https://github.com/pre-commit/action/commit/0dbc303468d9ee1ae3a4cddd9b697c1424c73522\"><code>0dbc303</code></a> Upgrade action/cache to v4. Fixes: <a href=\"https://redirect.github.com/pre-commit/action/issues/189\">#189</a></li>\n<li><a href=\"https://github.com/pre-commit/action/commit/c7d159c2092cbfaab7352e2d8211ab536aa2267c\"><code>c7d159c</code></a> Merge pull request <a href=\"https://redirect.github.com/pre-commit/action/issues/185\">#185</a> from pre-commit/asottile-patch-1</li>\n<li><a href=\"https://github.com/pre-commit/action/commit/9dd42377a1725fb44b57b6a17501d984852f8ad9\"><code>9dd4237</code></a> fix main badge</li>\n<li><a href=\"https://github.com/pre-commit/action/commit/37faf8a587e18fa3a3f78f600c9edbfd0691c3c3\"><code>37faf8a</code></a> Merge pull request <a href=\"https://redirect.github.com/pre-commit/action/issues/184\">#184</a> from pre-commit/pre-commit-ci-update-config</li>\n<li><a href=\"https://github.com/pre-commit/action/commit/049686ec527b5f1785b9cafcb3258821878466b1\"><code>049686e</code></a> [pre-commit.ci] pre-commit autoupdate</li>\n<li><a href=\"https://github.com/pre-commit/action/commit/5f528da5c95691c4cf42ff76a4d10854b62cbb82\"><code>5f528da</code></a> move back to maintenance-only</li>\n<li><a href=\"https://github.com/pre-commit/action/commit/efd3bcfec120bd343786e46318186153b7bc8c68\"><code>efd3bcf</code></a> Merge pull request <a href=\"https://redirect.github.com/pre-commit/action/issues/170\">#170</a> from pre-commit/pre-commit-ci-update-config</li>\n<li><a href=\"https://github.com/pre-commit/action/commit/df308c7f46bfa147cdec6c9795d030dc13431d35\"><code>df308c7</code></a> [pre-commit.ci] pre-commit autoupdate</li>\n<li>Additional commits viewable in <a href=\"https://github.com/pre-commit/action/compare/v3.0.0...v3.0.1\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pre-commit/action&package-manager=github_actions&previous-version=3.0.0&new-version=3.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
    "head_branch": "dependabot/github_actions/pre-commit/action-3.0.1",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "CI: Bump pre-commit/action from 3.0.0 to 3.0.1 (#3185)\n\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4a1ac254a19ac29ded9",
    "number": 3184,
    "body": "For some reasons, RTD does not pick tags and uses 0+untagged. An attempt to fix that though it is unclear to me why it happens.\n",
    "head_branch": "docs_version",
    "is_a_fork": true,
    "comments": [
      "Where RTD in xyzservices pulls recent tags while doing \r\n\r\n```\r\ngit fetch origin --force --prune --prune-tags --depth 50 pull/160/head:external-160\r\n```\r\n\r\nit does not pull them using the same command in geopandas...",
      "It seems that the main reason is that we're too far from the last tag. `--depth 50` does not fetch tags, while `--depth 150` does. 0.14.3 was picked correctly as well as all the other released versions. But `stable`, which should be an alias of 0.14.3 does not show a correct version.",
      "I give up. We just need to release more often to avoid the issue apparently :D",
      "I did something similar in shapely, and there I put it in `post_checkout` instead of `pre_install` (https://github.com/shapely/shapely/pull/1914). Not sure if that would matter ...\r\n\r\nhttps://github.com/shapely/shapely/blob/b44ed66b277e8f51de8db5314204527682f961aa/.readthedocs.yml#L13-L15",
      "Ah, but I see that is also not working anymore on the latest docs version ... (it again shows \"shapely 0\")\r\n\r\nAlthough at the same time, the build output _does_ show that the tags were fetched: https://readthedocs.org/projects/shapely/builds/23358414/ (is it because the commit that a tag points to isn't in the history (with a depth of 50) that it does not use the tag?)",
      "> I put it in post_checkout instead of pre_install \r\n\r\nThat should not matter.\r\n\r\nI managed to fetch the tags and got to the same point where shapely is now.\r\n\r\n> is it because the commit that a tag points to isn't in the history (with a depth of 50) that it does not use the tag\r\n\r\nI guess? I am no git wizard but since it will work once we cut 1.0, I kind of gave it low priority after the simple solution did not work.",
      "If we want this to work, the readthedocs have this: https://docs.readthedocs.io/en/stable/build-customization.html#unshallow-git-clone  (that fetches the full history)",
      "https://github.com/shapely/shapely/pull/1985 seems to have worked as well for shapely",
      "It worked here as well https://readthedocs.org/projects/geopandas/builds/23415092/"
    ],
    "commit_messages": [
      "RTD: update readthedocs setup (#3184)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4a2ac254a19ac29deda",
    "number": 3183,
    "body": "We currently have a whole bunch of failures in the dev build with pandas main because of a change in the `.names` attribute of an Index no longer returning a list-like (FrozenList) but a tuple. This small fix will ensure it works in either case.\r\n(https://github.com/pandas-dev/pandas/pull/57042#issuecomment-1935700777)\r\n",
    "head_branch": "compat-pandas-get-parts",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "COMPAT: fix _get_index_for_parts (explode, etc) for future pandas (#3183)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4a3ac254a19ac29dedb",
    "number": 3180,
    "body": "Closes https://github.com/geopandas/geopandas/issues/3178",
    "head_branch": "ufunc-cow-issue",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "COMPAT: ensure GeoSeries returns writeable array with pandas Copy-on-Write (#3180)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4a3ac254a19ac29dedc",
    "number": 3177,
    "body": "xref #2010",
    "head_branch": "voronoi",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4a4ac254a19ac29dedd",
    "number": 3176,
    "body": "xref #2010",
    "head_branch": "reason",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4a5ac254a19ac29dede",
    "number": 3175,
    "body": "xref #2010",
    "head_branch": "precision",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: `set_precision` and `get_precision` methods (#3175)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4a6ac254a19ac29dedf",
    "number": 3174,
    "body": "xref #2263. This definitely needs a changelog, haven't done that yet.",
    "head_branch": "expire_deprecations",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "MAINT: Expire deprecations (#3174)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4a7ac254a19ac29dee0",
    "number": 3173,
    "body": "Closes #3165 (in the specific case of `_geometry_column_name==\"geometry\"` - which is also the case which previously worked prior to the regression",
    "head_branch": "constructor_from_mgr_regression_again",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4a8ac254a19ac29dee1",
    "number": 3172,
    "body": "Automatic update of Versioneer by the `versioneer.yml` workflow.",
    "head_branch": "update-versioneer",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4a8ac254a19ac29dee2",
    "number": 3171,
    "body": "Bumps [codecov/codecov-action](https://github.com/codecov/codecov-action) from 3 to 4.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/codecov/codecov-action/releases\">codecov/codecov-action's releases</a>.</em></p>\n<blockquote>\n<h2>v4.0.0</h2>\n<p>v4 of the Codecov Action uses the <a href=\"https://docs.codecov.com/docs/the-codecov-cli\">CLI</a> as the underlying upload. The CLI has helped to power new features including local upload, the global upload token, and new upcoming features.</p>\n<h2>Breaking Changes</h2>\n<ul>\n<li>The Codecov Action runs as a <code>node20</code> action due to <code>node16</code> deprecation. See <a href=\"https://github.blog/changelog/2023-09-22-github-actions-transitioning-from-node-16-to-node-20/\">this post from GitHub</a> on how to migrate.</li>\n<li>Tokenless uploading is unsupported. However, PRs made from forks to the upstream public repos will support tokenless (e.g. contributors to OS projects do not need the upstream repo's Codecov token). This <a href=\"https://docs.codecov.com/docs/adding-the-codecov-token#github-actions\">doc</a> shows instructions on how to add the Codecov token.</li>\n<li>OS platforms have been added, though some may not be automatically detected. To see a list of platforms, see our <a href=\"https://cli.codecov.io\">CLI download page</a></li>\n<li>Various arguments to the Action have been changed. Please be aware that the arguments match with the CLI's needs</li>\n</ul>\n<p><code>v3</code> versions and below will not have access to CLI features (e.g. global upload token, ATS).</p>\n<h2>What's Changed</h2>\n<ul>\n<li>build(deps): bump openpgp from 5.8.0 to 5.9.0 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/985\">codecov/codecov-action#985</a></li>\n<li>build(deps): bump actions/checkout from 3.0.0 to 3.5.3 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1000\">codecov/codecov-action#1000</a></li>\n<li>build(deps): bump ossf/scorecard-action from 2.1.3 to 2.2.0 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1006\">codecov/codecov-action#1006</a></li>\n<li>build(deps): bump tough-cookie from 4.0.0 to 4.1.3 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1013\">codecov/codecov-action#1013</a></li>\n<li>build(deps-dev): bump word-wrap from 1.2.3 to 1.2.4 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1024\">codecov/codecov-action#1024</a></li>\n<li>build(deps): bump node-fetch from 3.3.1 to 3.3.2 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1031\">codecov/codecov-action#1031</a></li>\n<li>build(deps-dev): bump <code>@​types/node</code> from 20.1.4 to 20.4.5 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1032\">codecov/codecov-action#1032</a></li>\n<li>build(deps): bump github/codeql-action from 1.0.26 to 2.21.2 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1033\">codecov/codecov-action#1033</a></li>\n<li>build commit,report and upload args based on codecovcli by <a href=\"https://github.com/dana-yaish\"><code>@​dana-yaish</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/943\">codecov/codecov-action#943</a></li>\n<li>build(deps-dev): bump <code>@​types/node</code> from 20.4.5 to 20.5.3 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1055\">codecov/codecov-action#1055</a></li>\n<li>build(deps): bump github/codeql-action from 2.21.2 to 2.21.4 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1051\">codecov/codecov-action#1051</a></li>\n<li>build(deps-dev): bump <code>@​types/node</code> from 20.5.3 to 20.5.4 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1058\">codecov/codecov-action#1058</a></li>\n<li>chore(deps): update outdated deps by <a href=\"https://github.com/thomasrockhu-codecov\"><code>@​thomasrockhu-codecov</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1059\">codecov/codecov-action#1059</a></li>\n<li>build(deps-dev): bump <code>@​types/node</code> from 20.5.4 to 20.5.6 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1060\">codecov/codecov-action#1060</a></li>\n<li>build(deps-dev): bump <code>@​typescript-eslint/parser</code> from 6.4.1 to 6.5.0 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1065\">codecov/codecov-action#1065</a></li>\n<li>build(deps-dev): bump <code>@​typescript-eslint/eslint-plugin</code> from 6.4.1 to 6.5.0 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1064\">codecov/codecov-action#1064</a></li>\n<li>build(deps): bump actions/checkout from 3.5.3 to 3.6.0 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1063\">codecov/codecov-action#1063</a></li>\n<li>build(deps-dev): bump eslint from 8.47.0 to 8.48.0 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1061\">codecov/codecov-action#1061</a></li>\n<li>build(deps-dev): bump <code>@​types/node</code> from 20.5.6 to 20.5.7 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1062\">codecov/codecov-action#1062</a></li>\n<li>build(deps): bump openpgp from 5.9.0 to 5.10.1 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1066\">codecov/codecov-action#1066</a></li>\n<li>build(deps-dev): bump <code>@​types/node</code> from 20.5.7 to 20.5.9 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1070\">codecov/codecov-action#1070</a></li>\n<li>build(deps): bump github/codeql-action from 2.21.4 to 2.21.5 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1069\">codecov/codecov-action#1069</a></li>\n<li>build(deps-dev): bump <code>@​typescript-eslint/eslint-plugin</code> from 6.5.0 to 6.6.0 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1072\">codecov/codecov-action#1072</a></li>\n<li>Update README.md by <a href=\"https://github.com/thomasrockhu-codecov\"><code>@​thomasrockhu-codecov</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1073\">codecov/codecov-action#1073</a></li>\n<li>build(deps-dev): bump <code>@​typescript-eslint/parser</code> from 6.5.0 to 6.6.0 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1071\">codecov/codecov-action#1071</a></li>\n<li>build(deps-dev): bump <code>@​vercel/ncc</code> from 0.36.1 to 0.38.0 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1074\">codecov/codecov-action#1074</a></li>\n<li>build(deps): bump <code>@​actions/core</code> from 1.10.0 to 1.10.1 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1081\">codecov/codecov-action#1081</a></li>\n<li>build(deps-dev): bump <code>@​typescript-eslint/eslint-plugin</code> from 6.6.0 to 6.7.0 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1080\">codecov/codecov-action#1080</a></li>\n<li>build(deps): bump actions/checkout from 3.6.0 to 4.0.0 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1078\">codecov/codecov-action#1078</a></li>\n<li>build(deps): bump actions/upload-artifact from 3.1.2 to 3.1.3 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1077\">codecov/codecov-action#1077</a></li>\n<li>build(deps-dev): bump <code>@​types/node</code> from 20.5.9 to 20.6.0 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1075\">codecov/codecov-action#1075</a></li>\n<li>build(deps-dev): bump <code>@​typescript-eslint/parser</code> from 6.6.0 to 6.7.0 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1079\">codecov/codecov-action#1079</a></li>\n<li>build(deps-dev): bump eslint from 8.48.0 to 8.49.0 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1076\">codecov/codecov-action#1076</a></li>\n<li>use cli instead of node uploader by <a href=\"https://github.com/dana-yaish\"><code>@​dana-yaish</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1068\">codecov/codecov-action#1068</a></li>\n<li>chore(release): 4.0.0-beta.1 by <a href=\"https://github.com/thomasrockhu-codecov\"><code>@​thomasrockhu-codecov</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1084\">codecov/codecov-action#1084</a></li>\n<li>not adding -n if empty to do-upload command by <a href=\"https://github.com/dana-yaish\"><code>@​dana-yaish</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1085\">codecov/codecov-action#1085</a></li>\n<li>4.0.0-beta.2 by <a href=\"https://github.com/thomasrockhu-codecov\"><code>@​thomasrockhu-codecov</code></a> in <a href=\"https://redirect.github.com/codecov/codecov-action/pull/1086\">codecov/codecov-action#1086</a></li>\n</ul>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/codecov/codecov-action/blob/main/CHANGELOG.md\">codecov/codecov-action's changelog</a>.</em></p>\n<blockquote>\n<h2>4.0.0-beta.2</h2>\n<h3>Fixes</h3>\n<ul>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/1085\">#1085</a> not adding -n if empty to do-upload command</li>\n</ul>\n<h2>4.0.0-beta.1</h2>\n<p><code>v4</code> represents a move from the <a href=\"https://github.com/codecov/uploader\">universal uploader</a> to the <a href=\"https://github.com/codecov/codecov-cli\">Codecov CLI</a>. Although this will unlock new features for our users, the CLI is not yet at feature parity with the universal uploader.</p>\n<h3>Breaking Changes</h3>\n<ul>\n<li>No current support for <code>aarch64</code> and <code>alpine</code> architectures.</li>\n<li>Tokenless uploading is unsuported</li>\n<li>Various arguments to the Action have been removed</li>\n</ul>\n<h2>3.1.4</h2>\n<h3>Fixes</h3>\n<ul>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/967\">#967</a> Fix typo in README.md</li>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/971\">#971</a> fix: add back in working dir</li>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/969\">#969</a> fix: CLI option names for uploader</li>\n</ul>\n<h3>Dependencies</h3>\n<ul>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/970\">#970</a> build(deps-dev): bump <code>@​types/node</code> from 18.15.12 to 18.16.3</li>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/979\">#979</a> build(deps-dev): bump <code>@​types/node</code> from 20.1.0 to 20.1.2</li>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/981\">#981</a> build(deps-dev): bump <code>@​types/node</code> from 20.1.2 to 20.1.4</li>\n</ul>\n<h2>3.1.3</h2>\n<h3>Fixes</h3>\n<ul>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/960\">#960</a> fix: allow for aarch64 build</li>\n</ul>\n<h3>Dependencies</h3>\n<ul>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/957\">#957</a> build(deps-dev): bump jest-junit from 15.0.0 to 16.0.0</li>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/958\">#958</a> build(deps): bump openpgp from 5.7.0 to 5.8.0</li>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/959\">#959</a> build(deps-dev): bump <code>@​types/node</code> from 18.15.10 to 18.15.12</li>\n</ul>\n<h2>3.1.2</h2>\n<h3>Fixes</h3>\n<ul>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/718\">#718</a> Update README.md</li>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/851\">#851</a> Remove unsupported path_to_write_report argument</li>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/898\">#898</a> codeql-analysis.yml</li>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/901\">#901</a> Update README to contain correct information - inputs and negate feature</li>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/955\">#955</a> fix: add in all the extra arguments for uploader</li>\n</ul>\n<h3>Dependencies</h3>\n<ul>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/819\">#819</a> build(deps): bump openpgp from 5.4.0 to 5.5.0</li>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/835\">#835</a> build(deps): bump node-fetch from 3.2.4 to 3.2.10</li>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/840\">#840</a> build(deps): bump ossf/scorecard-action from 1.1.1 to 2.0.4</li>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/841\">#841</a> build(deps): bump <code>@​actions/core</code> from 1.9.1 to 1.10.0</li>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/843\">#843</a> build(deps): bump <code>@​actions/github</code> from 5.0.3 to 5.1.1</li>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/869\">#869</a> build(deps): bump node-fetch from 3.2.10 to 3.3.0</li>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/872\">#872</a> build(deps-dev): bump jest-junit from 13.2.0 to 15.0.0</li>\n<li><a href=\"https://redirect.github.com/codecov/codecov-action/issues/879\">#879</a> build(deps): bump decode-uri-component from 0.2.0 to 0.2.2</li>\n</ul>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/codecov/codecov-action/commit/e0b68c6749509c5f83f984dd99a76a1c1a231044\"><code>e0b68c6</code></a> fix: show both token uses in readme (<a href=\"https://redirect.github.com/codecov/codecov-action/issues/1250\">#1250</a>)</li>\n<li><a href=\"https://github.com/codecov/codecov-action/commit/1f9f5573d12d0967fe14551018a4b25610226551\"><code>1f9f557</code></a> Add all args (<a href=\"https://redirect.github.com/codecov/codecov-action/issues/1245\">#1245</a>)</li>\n<li><a href=\"https://github.com/codecov/codecov-action/commit/09686fcfcb6453414a5acd7f3a939670a7a77826\"><code>09686fc</code></a> Update README.md (<a href=\"https://redirect.github.com/codecov/codecov-action/issues/1243\">#1243</a>)</li>\n<li><a href=\"https://github.com/codecov/codecov-action/commit/f30e4959ba63075080d4f7f90cacc18d9f3fafd7\"><code>f30e495</code></a> fix: update action.yml (<a href=\"https://redirect.github.com/codecov/codecov-action/issues/1240\">#1240</a>)</li>\n<li><a href=\"https://github.com/codecov/codecov-action/commit/a7b945cea47ad44d8340fae2b004cb982191264f\"><code>a7b945c</code></a> fix: allow for other archs (<a href=\"https://redirect.github.com/codecov/codecov-action/issues/1239\">#1239</a>)</li>\n<li><a href=\"https://github.com/codecov/codecov-action/commit/98ab2c591b94478f4c3606d68ff73601df85ec43\"><code>98ab2c5</code></a> Update package.json (<a href=\"https://redirect.github.com/codecov/codecov-action/issues/1238\">#1238</a>)</li>\n<li><a href=\"https://github.com/codecov/codecov-action/commit/43235cc5aeeafd8aeb836fe7d647599acead161c\"><code>43235cc</code></a> Update README.md (<a href=\"https://redirect.github.com/codecov/codecov-action/issues/1237\">#1237</a>)</li>\n<li><a href=\"https://github.com/codecov/codecov-action/commit/0cf8684c821546a4e0c8c9a4cf4f21a7a0c5014b\"><code>0cf8684</code></a> chore(ci): bump to node20 (<a href=\"https://redirect.github.com/codecov/codecov-action/issues/1236\">#1236</a>)</li>\n<li><a href=\"https://github.com/codecov/codecov-action/commit/8e1e730371bf82c744e8ca9aa469e2b7011542ce\"><code>8e1e730</code></a> build(deps-dev): bump <code>@​typescript-eslint/eslint-plugin</code> from 6.19.1 to 6.20.0 ...</li>\n<li><a href=\"https://github.com/codecov/codecov-action/commit/61293af0e8288c75266030376a088c781ec81c18\"><code>61293af</code></a> build(deps-dev): bump <code>@​typescript-eslint/parser</code> from 6.19.1 to 6.20.0 (<a href=\"https://redirect.github.com/codecov/codecov-action/issues/1235\">#1235</a>)</li>\n<li>Additional commits viewable in <a href=\"https://github.com/codecov/codecov-action/compare/v3...v4\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=codecov/codecov-action&package-manager=github_actions&previous-version=3&new-version=4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
    "head_branch": "dependabot/github_actions/codecov/codecov-action-4",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Bump codecov/codecov-action from 3 to 4 (#3171)\n\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4a9ac254a19ac29dee3",
    "number": 3170,
    "body": "Bumps [peter-evans/create-pull-request](https://github.com/peter-evans/create-pull-request) from 5 to 6.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/peter-evans/create-pull-request/releases\">peter-evans/create-pull-request's releases</a>.</em></p>\n<blockquote>\n<h2>Create Pull Request v6.0.0</h2>\n<h2>Behaviour changes</h2>\n<ul>\n<li>The default values for <code>author</code> and <code>committer</code> have changed. See &quot;What's new&quot; below for details. If you are overriding the default values you will not be affected by this change.</li>\n<li>On completion, the action now removes the temporary git remote configuration it adds when using <code>push-to-fork</code>. This should not affect you unless you were using the temporary configuration for some other purpose after the action completes.</li>\n</ul>\n<h2>What's new</h2>\n<ul>\n<li>Updated runtime to Node.js 20\n<ul>\n<li>The action now requires a minimum version of <a href=\"https://github.com/actions/runner/releases/tag/v2.308.0\">v2.308.0</a> for the Actions runner. Update self-hosted runners to v2.308.0 or later to ensure compatibility.</li>\n</ul>\n</li>\n<li>The default value for <code>author</code> has been changed to <code>${{ github.actor }} &lt;${{ github.actor_id }}+${{ github.actor }}@users.noreply.github.com&gt;</code>. The change adds the <code>${{ github.actor_id }}+</code> prefix to the email address to align with GitHub's standard format for the author email address.</li>\n<li>The default value for <code>committer</code> has been changed to <code>github-actions[bot] &lt;41898282+github-actions[bot]@users.noreply.github.com&gt;</code>. This is to align with the default GitHub Actions bot user account.</li>\n<li>Adds input <code>git-token</code>, the <a href=\"https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token\">Personal Access Token (PAT)</a> that the action will use for git operations. This input defaults to the value of <code>token</code>. Use this input if you would like the action to use a different token for git operations than the one used for the GitHub API.</li>\n<li><code>push-to-fork</code> now supports pushing to sibling repositories in the same network.</li>\n<li>Previously, when using <code>push-to-fork</code>, the action did not remove temporary git remote configuration it adds during execution. This has been fixed and the configuration is now removed when the action completes.</li>\n<li>If the pull request body is truncated due to exceeding the maximum length, the action will now suffix the body with the message &quot;...<em>[Pull request body truncated]</em>&quot; to indicate that the body has been truncated.</li>\n<li>The action now uses <code>--unshallow</code> only when necessary, rather than as a default argument of <code>git fetch</code>. This should improve performance, particularly for large git repositories with extensive commit history.</li>\n<li>The action can now be executed on one GitHub server and create pull requests on a <em>different</em> GitHub server. Server products include GitHub hosted (github.com), GitHub Enterprise Server (GHES), and GitHub Enterprise Cloud (GHEC). For example, the action can be executed on GitHub hosted and create pull requests on a GHES or GHEC instance.</li>\n</ul>\n<h2>What's Changed</h2>\n<ul>\n<li>Update distribution by <a href=\"https://github.com/actions-bot\"><code>@​actions-bot</code></a> in <a href=\"https://redirect.github.com/peter-evans/create-pull-request/pull/2086\">peter-evans/create-pull-request#2086</a></li>\n<li>fix crazy-max/ghaction-import-gp parameters by <a href=\"https://github.com/fharper\"><code>@​fharper</code></a> in <a href=\"https://redirect.github.com/peter-evans/create-pull-request/pull/2177\">peter-evans/create-pull-request#2177</a></li>\n<li>Update distribution by <a href=\"https://github.com/actions-bot\"><code>@​actions-bot</code></a> in <a href=\"https://redirect.github.com/peter-evans/create-pull-request/pull/2364\">peter-evans/create-pull-request#2364</a></li>\n<li>Use checkout v4 by <a href=\"https://github.com/okuramasafumi\"><code>@​okuramasafumi</code></a> in <a href=\"https://redirect.github.com/peter-evans/create-pull-request/pull/2521\">peter-evans/create-pull-request#2521</a></li>\n<li>Note about <code>delete-branch</code> by <a href=\"https://github.com/dezren39\"><code>@​dezren39</code></a> in <a href=\"https://redirect.github.com/peter-evans/create-pull-request/pull/2631\">peter-evans/create-pull-request#2631</a></li>\n<li>98 dependency updates by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a></li>\n</ul>\n<h2>New Contributors</h2>\n<ul>\n<li><a href=\"https://github.com/fharper\"><code>@​fharper</code></a> made their first contribution in <a href=\"https://redirect.github.com/peter-evans/create-pull-request/pull/2177\">peter-evans/create-pull-request#2177</a></li>\n<li><a href=\"https://github.com/okuramasafumi\"><code>@​okuramasafumi</code></a> made their first contribution in <a href=\"https://redirect.github.com/peter-evans/create-pull-request/pull/2521\">peter-evans/create-pull-request#2521</a></li>\n<li><a href=\"https://github.com/dezren39\"><code>@​dezren39</code></a> made their first contribution in <a href=\"https://redirect.github.com/peter-evans/create-pull-request/pull/2631\">peter-evans/create-pull-request#2631</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/peter-evans/create-pull-request/compare/v5.0.2...v6.0.0\">https://github.com/peter-evans/create-pull-request/compare/v5.0.2...v6.0.0</a></p>\n<h2>Create Pull Request v5.0.2</h2>\n<p>⚙️ Fixes an issue that occurs when using <code>push-to-fork</code> and both base and head repositories are in the same org/user account.</p>\n<h2>What's Changed</h2>\n<ul>\n<li>fix: specify head repo by <a href=\"https://github.com/peter-evans\"><code>@​peter-evans</code></a> in <a href=\"https://redirect.github.com/peter-evans/create-pull-request/pull/2044\">peter-evans/create-pull-request#2044</a></li>\n<li>20 dependency updates by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/peter-evans/create-pull-request/compare/v5.0.1...v5.0.2\">https://github.com/peter-evans/create-pull-request/compare/v5.0.1...v5.0.2</a></p>\n<h2>Create Pull Request v5.0.1</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>fix: truncate body if exceeds max length by <a href=\"https://github.com/peter-evans\"><code>@​peter-evans</code></a> in <a href=\"https://redirect.github.com/peter-evans/create-pull-request/pull/1915\">peter-evans/create-pull-request#1915</a></li>\n<li>12 dependency updates by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/peter-evans/create-pull-request/compare/v5.0.0...v5.0.1\">https://github.com/peter-evans/create-pull-request/compare/v5.0.0...v5.0.1</a></p>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/peter-evans/create-pull-request/commit/b1ddad2c994a25fbc81a28b3ec0e368bb2021c50\"><code>b1ddad2</code></a> feat: v6 (<a href=\"https://redirect.github.com/peter-evans/create-pull-request/issues/2717\">#2717</a>)</li>\n<li><a href=\"https://github.com/peter-evans/create-pull-request/commit/bb809027fda03cc267431a7d36a88148eb9f3846\"><code>bb80902</code></a> build(deps-dev): bump <code>@​types/node</code> from 18.19.8 to 18.19.10 (<a href=\"https://redirect.github.com/peter-evans/create-pull-request/issues/2712\">#2712</a>)</li>\n<li><a href=\"https://github.com/peter-evans/create-pull-request/commit/e0037d470cdeb1c8133acfba89af08639bb69eb3\"><code>e0037d4</code></a> build(deps): bump peter-evans/create-or-update-comment from 3 to 4 (<a href=\"https://redirect.github.com/peter-evans/create-pull-request/issues/2702\">#2702</a>)</li>\n<li><a href=\"https://github.com/peter-evans/create-pull-request/commit/94b1f99e3a73880074d0e669c3b69d376cc8ceae\"><code>94b1f99</code></a> build(deps): bump peter-evans/find-comment from 2 to 3 (<a href=\"https://redirect.github.com/peter-evans/create-pull-request/issues/2703\">#2703</a>)</li>\n<li><a href=\"https://github.com/peter-evans/create-pull-request/commit/69c27eaf4a14a67b5362a51e681f83d3d5e0f96b\"><code>69c27ea</code></a> build(deps-dev): bump ts-jest from 29.1.1 to 29.1.2 (<a href=\"https://redirect.github.com/peter-evans/create-pull-request/issues/2685\">#2685</a>)</li>\n<li><a href=\"https://github.com/peter-evans/create-pull-request/commit/7ea722a0f6286a45eb3005280d83575a74bc8fef\"><code>7ea722a</code></a> build(deps-dev): bump prettier from 3.2.2 to 3.2.4 (<a href=\"https://redirect.github.com/peter-evans/create-pull-request/issues/2684\">#2684</a>)</li>\n<li><a href=\"https://github.com/peter-evans/create-pull-request/commit/5ee839affd4c87811108724370a2819a40e2e5d3\"><code>5ee839a</code></a> build(deps-dev): bump <code>@​types/node</code> from 18.19.7 to 18.19.8 (<a href=\"https://redirect.github.com/peter-evans/create-pull-request/issues/2683\">#2683</a>)</li>\n<li><a href=\"https://github.com/peter-evans/create-pull-request/commit/60fc256c678e6ed78d0d42e09675c9beba09cb94\"><code>60fc256</code></a> build(deps-dev): bump eslint-plugin-prettier from 5.1.2 to 5.1.3 (<a href=\"https://redirect.github.com/peter-evans/create-pull-request/issues/2660\">#2660</a>)</li>\n<li><a href=\"https://github.com/peter-evans/create-pull-request/commit/0c677233614c017442253060c74fd2cb7ff349fc\"><code>0c67723</code></a> build(deps-dev): bump <code>@​types/node</code> from 18.19.5 to 18.19.7 (<a href=\"https://redirect.github.com/peter-evans/create-pull-request/issues/2661\">#2661</a>)</li>\n<li><a href=\"https://github.com/peter-evans/create-pull-request/commit/4e288e851b95bd1362e281a255094fcc47ada675\"><code>4e288e8</code></a> build(deps-dev): bump prettier from 3.1.1 to 3.2.2 (<a href=\"https://redirect.github.com/peter-evans/create-pull-request/issues/2659\">#2659</a>)</li>\n<li>Additional commits viewable in <a href=\"https://github.com/peter-evans/create-pull-request/compare/v5...v6\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=peter-evans/create-pull-request&package-manager=github_actions&previous-version=5&new-version=6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
    "head_branch": "dependabot/github_actions/peter-evans/create-pull-request-6",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Bump peter-evans/create-pull-request from 5 to 6 (#3170)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4aaac254a19ac29dee4",
    "number": 3168,
    "body": "I just made some small cosmetic additions to the landing page. \r\n\r\n1. remove the secondary sidebar as there are no real sections here, simply titles\r\n2. remove the indices that are generated by sphinx-quickstart and are no longer supported by modern sphinx-build. ",
    "head_branch": "documentation",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: improve landing page (#3168)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4abac254a19ac29dee5",
    "number": 3167,
    "body": "Closes #3061, which found that `.to_postgis()` uses `copy_expert`, which is a method specific to psycopg2. Some users may want to use the more recent psycopg (also known as psycopg3) package instead. A reply to the issue report asked for a pull request adding psycopg support, so I've put this one together as I've been encountering the same problem. \r\n\r\n\r\n## Changes\r\n\r\nThis pull request makes `.to_postgis()` use either `.copy()` (psycopg) or `copy_expert()` depending on which is available on the cursor object. It does this by adding an attribute check to `._psql_insert_copy()`, which is passed to `.to_sql` as the 'method' argument.\r\n\r\nThe biggest changes are to the tests for `io/sql`, where it parameterises all tests to run with both psycopg and psycopg2 to ensure compatibility for both. \r\n\r\nIt also adds psycopg to the docs and test builds. \r\n\r\n## Questions\r\n\r\nI'm not sure if you'd prefer to keep one out of psycopg2/psycopg as the 'main' protocol. I've treated them pretty much evenly but put psycopg first in the `to_postgis()` check as it's the more recent package. ",
    "head_branch": "enable-psycopg3",
    "is_a_fork": true,
    "comments": [
      "I'm having some difficulty with the test runners and things failing that shouldn't have been affected by the changes. But I see this is also happening on pull requests that only change, say, documentation. \r\n\r\nSo I'm going to reopen this in case it is ready for feedback despite the failures. Hope it looks vaguely useful and appropriate. \r\n\r\nEDIT: by reopening I've accidentally circumvented the main bulk of the tests - they aren't actually all passing yet on these runners. I'm still working on them, but finding it hard to work out what's something environmental and what's my bad code.",
      "Problems with test runners seem largely resolved, but there's still a couple I haven't got my head round. Will leave in draft till I can get back to this and work out what's going wrong",
      "@MrAlecJohnson I haven't looked through your PR in detail, but it might be handy to know\r\n* the 3.11 dev enviroment builds against dev versions of packages, and if you see failures that look unrelated to what you're working on, they probably are (and we can clarify if they are and you are unsure)\r\n* The tests.yaml handles postgis separately (you may have already seen this), so the postgis tests actually only run in `310-pd20-conda-forge.yaml` and `311-latest-conda-forge.yaml`.\r\nThanks for the draft contribution, I'll have a look in some detail hopefully soon.",
      "> @MrAlecJohnson I haven't looked through your PR in detail, but it might be handy to know\r\n> \r\n>     * the 3.11 dev enviroment builds against dev versions of packages, and if you see failures that look unrelated to what you're working on, they probably are (and we can clarify if they are and you are unsure)\r\n> \r\n>     * The tests.yaml handles postgis separately (you may have already seen this), so the postgis tests actually only run in `310-pd20-conda-forge.yaml` and `311-latest-conda-forge.yaml`.\r\n>       Thanks for the draft contribution, I'll have a look in some detail hopefully soon.\r\n\r\nThank you! That's really useful to know.\r\n\r\nAm I right in thinking the failures on `3.11-dev.yaml` are unconnected to my changes? I'm still getting those on a branch where I don't make any substantive code changes. \r\n\r\nBut the failure and skipping on `310-pd20-conda-forge.yaml` I can see does seem to be from my pull request, so I'll get those sorted...",
      "Ah, okay, I see the issue - it's about dependency versions, so @m-richards it would be great to get your (or anyone else's!) views on how I should approach this. I don't want to mess with the builds unnecessarily.  \r\n\r\n1. there's a tiny error in the Pandas compatibility xfails on [test_duplicate_geometry_column_fails](https://github.com/geopandas/geopandas/blob/e996129c5f77fb7aae1d7bbf76dee3c7678a8ecb/geopandas/io/tests/test_sql.py#L743) - this will xfail on 2.0.0 and 2.0.1, but xpass on 2.0.2 and 2.0.3 - and `310-pd20-conda-forge` pins to 2.0 without specifying minor version. I think the easiest fix here is to pin a specific minor version in this build - does that sound reasonable? Or would you rather I make the pandas compatbility checks more specific?\r\n\r\n2. I failed to account for psycopg3 requiring sqlalchemy>=2.0. Rather than changing any of the sqlalchemy versions in the builds, I suspect I should just only include psycopg3 when there's already a sqlalchemy above 2.0. Does that also sound sensible? The new psycopg3 postgis tests run nicely on 311-latest-conda-forge, where sqlalchemy>=2.0",
      "> 1. there's a tiny error in the Pandas compatibility xfails on [test_duplicate_geometry_column_fails](https://github.com/geopandas/geopandas/blob/e996129c5f77fb7aae1d7bbf76dee3c7678a8ecb/geopandas/io/tests/test_sql.py#L743) - this will xfail on 2.0.0 and 2.0.1, but xpass on 2.0.2 and 2.0.3 - and `310-pd20-conda-forge` pins to 2.0 without specifying minor version. I think the easiest fix here is to pin a specific minor version in this build - does that sound reasonable? Or would you rather I make the pandas compatbility checks more specific?\r\n\r\nI would prefer to fix in in the code than in the build deps - you'll notice this is only failing on this branch and not on main, and I presume that's because adding psycopg3 to the yml is causing conda to resolve to a different version of pandas. I think you could define a compat.PANDAS_GE_202 analogous to the others and update the guard in the test (https://github.com/pandas-dev/pandas/pull/53118 is where this was fixed on the pandas side and it lines up with the versions you have checked xfail/ xpass)\r\n\r\n> 2. I failed to account for psycopg3 requiring sqlalchemy>=2.0. Rather than changing any of the sqlalchemy versions in the builds, I suspect I should just only include psycopg3 when there's already a sqlalchemy above 2.0. Does that also sound sensible? The new psycopg3 postgis tests run nicely on 311-latest-conda-forge, where sqlalchemy>=2.0\r\n\r\nI agree this makes sense - at least for this PR. We only have two dev builds running the postgres tests, so it's good to keep one on sqlalchemy <2 and one on 2+. (Although I think this point 1. of yours will be resolved without you needing to make any code changes, so I supose that's fine too :))\r\n\r\nWe are at the point where we can probably consider dropping sqlalchemy 1.4 support - but I think thats a separate topic, because pandas didn't support sql 2 until pandas 2.\r\n",
      "Those approaches sound great, thank you. \r\n\r\nBelatedly realised my 'skip tests for packages not installed' approach won't work with the 'TESTS SKIPPED, FAILING' in the test workflow, so I'll have to come back to that, hopefully soon!",
      "I think this is now ready for review. There are still 2 runners failing, but as far as I can tell the failures are unconnected to these changes. Apologies if I've got that wrong! \r\n\r\nFor the `test_sql` tests I've set them to only run on versions of psycopg that are installed, so if only one package is installed only one set of tests is run. If neither psycopg nor psycopg2 is installed, no sql-based tests run, but there are still skips, so they will still set off the 'Fail if tests are skipped' condition in the workflow.",
      "@m-richards Thank you for those suggestions. All incorporated now, along with a much cleaner test setup and much smaller diff. I've managed to get rid of those unnecessary extra fixtures now. I hope this looks more useful! \r\n\r\n",
      "> Shall we maybe switch from psycopg2 to psycopg in optional-dependencies in pyproject.toml? this psycopg->psycopg2->psycopg versioning is so confusing I am not sure what is the proper dependency.\r\n\r\nYeah I suppose it should be `psycopg` now.",
      "Thanks @MrAlecJohnson!",
      "How comes that this is still not in the pip package (0.14.4) although merged in main?",
      "@rs-kersten  main is targeted for 1.0, 0.14.x lives in a branch and this was not back ported when doing 0.14.4 release.",
      "Oh okay, thanks for the clarification"
    ],
    "commit_messages": [
      "BUG: support psycopg3 in .to_postgis() (#3167)\n\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4acac254a19ac29dee6",
    "number": 3166,
    "body": "Automatic update of Versioneer by the `versioneer.yml` workflow.",
    "head_branch": "update-versioneer",
    "is_a_fork": false,
    "comments": [
      "Does not touch versioneer files but reformats stuff all around...",
      "I think this is black 24 styling that's all the other formatting.",
      "We should probably update that action to use the pre-commit rather than pulling latest black."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4acac254a19ac29dee7",
    "number": 3164,
    "body": "Draft until I've found where this is currently tested",
    "head_branch": "enable-psycopg3",
    "is_a_fork": true,
    "comments": [
      "Here https://github.com/geopandas/geopandas/blob/main/geopandas/io/tests/test_sql.py",
      "Oh gosh, sorry, I hadn't meant to open this here, I'd meant to do it all on my fork till I had something more complete. Sorry about that - my first try at open source contribution and I've already got it wrong! Will close for now but hopefully come back with this soon...\r\n\r\n(though thank you for the test locations!)"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4adac254a19ac29dee8",
    "number": 3163,
    "body": "## What\n\nThe specification for `optional-dependencies` is part of PEP 621\n<https://peps.python.org/pep-0621/>. See\n<https://packaging.python.org/en/latest/specifications/pyproject-toml/#pyproject-toml-spec>\nfor latest specification.\n\nI added the dependencies to `optional-dependencies` based on\n`./requirements-dev.txt`, `./environment.yml` and #2990.\n\n## Why?\n\nThis would be useful for defining the optional dependencies when packaging\n`geopandas` for e.g. `nixpkgs`\n(<https://github.com/NixOS/nixpkgs/blob/master/pkgs/development/python-modules/geopandas/default.nix>)\nas it is better for them to be defined here in the main repository than\ndownstream. As there is already code in `./geopandas/` that use these optional\ndependencies, I believe they should be documented somewhere.\n\n## Misc\n\nI did not update `requirements-dev.txt` as I do not know if it is currently\nup-to-date (<https://github.com/geopandas/geopandas/pull/2438#issuecomment-1205268708>)\nor being maintained.\n\nMarked as draft as no feedback yet given from maintainers. Hopefully this sounds good!\n",
    "head_branch": "2990-add-optional-dependencies",
    "is_a_fork": true,
    "comments": [
      "Thanks for the review!\r\n\r\nTook a look at some other packages and I am actually wondering if it would be simpler to just define two optional dependency groups: `all` and `dev`. `all` includes all dependencies except the development ones. `dev` contains `pytest` and others needed for testing and development.`all` is used by well-known packages, such as `pandas` and `typer`, to indicate all optional dependencies for features.\r\n\r\nIf `all` could be defined by pointing to the already defined groups (`postgis`, `plot`, etc.), that would be the best way to define `all`. But that is not possible without introducing a possible circular dependency issue. E.g. `pandas` defines `all` by redefining all the dependencies of all other groups in `all` (<https://github.com/pandas-dev/pandas/blob/56b5979f136e72ce78e5221392739481c025d5e7/pyproject.toml#L88>). This is not nice to maintain.\r\n\r\nThe grouping feature is not apparent to users and writing e.g. `pip install geopandas[postgis,postgis-write,plot]` is demanding a lot from any casual installer of `geopandas`. I would also wager that either a) an user wants to minimize dependencies, in which case they can add the optional dependencies as they run into errors as they run `geopandas` code or b) just want all functionality of `geopandas` quickly. For a) the groupings are not much better than just manually installing the required packages. For b) the `all` group gives a simple way to install all optionals.",
      "I just want to say that I believe it is nice to have optional dependencies defined in some way in pyproject. However, I don't think I've ever used it a as a conda/mamba user myself so don't really care if it is split in groups of just `all` and `dev`. The latter seems more maintainable.",
      "I also don't have a strong leaning on all & dev vs split out. I use pip rather than conda for work, but I don't tend to use extras, I'll just install the base package. Even if I know and extra exists I usually have to double check what it's called  - and the most reliable way of doing that is looking at the pyproject.toml, at which point I no longer need the extra because I can see the packages underneath it. ",
      "Updated the pull request to use the two groups discussed above, `all` and `dev`. Also updated documentation to inform users and developers of these options. One change, that I do not know if is appropriate, is the use of `psycopg2-binary` instead of `psycopg2`. Using this package is easier as it contains binary components of `psycopg2` directly (<https://github.com/psycopg/psycopg2#installation>).",
      "Ready for (full) review, sorry for slight delay!"
    ],
    "commit_messages": [
      "MAINT: Add optional-dependencies to pyproject.toml (#3163)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4aeac254a19ac29dee9",
    "number": 3162,
    "body": "Starting a whatsnew entry for 0.14.3 (so this can be backported in https://github.com/geopandas/geopandas/pull/3161)",
    "head_branch": "changelog-0.14.3",
    "is_a_fork": true,
    "comments": [
      "Going to merge this so I can include it in https://github.com/geopandas/geopandas/pull/3161"
    ],
    "commit_messages": [
      "DOC/RLS: start changelog for 0.14.3 (#3162)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4afac254a19ac29deea",
    "number": 3161,
    "body": "Initial set of backports for 0.14.3\r\n\r\n* #3023\r\n* #3046\r\n* #3095\r\n* #3131\r\n* #3128\r\n* #3148\r\n* #3144 (but without the error for old GEOS, because on 0.14.x we still had a warning about it when not supported)\r\n* #3080\r\n* #3159\r\n\r\nplus some test fixes to get things green ",
    "head_branch": "0.14.2-backports",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REGR: directly fix _constructor_from_mgr regression (#3159)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4b0ac254a19ac29deeb",
    "number": 3160,
    "body": "Closes #2770. Edit: While this does deal with that particular issue, it doesn't deal with the associated inconsistency of `set_geometry` behaviour -see #1038 - I missed the coupling when I first looked at this. Probably not ideally to fix this in the constructor only and not in `set_geometry`",
    "head_branch": "preserve_geoseries_name_in_gdf_constructor",
    "is_a_fork": true,
    "comments": [
      "Superceded by https://github.com/geopandas/geopandas/pull/3237"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4b0ac254a19ac29deec",
    "number": 3159,
    "body": "Testing to see if we can directly solve the regression without extra complications. Tests seem to be fine - remaining fails are the missing backports for the pandas 2.2 EA changes.\r\n\r\nEdit: Took Joris' suggestion below and merged with main, so this is now able to be applied to main and backported.",
    "head_branch": "test_constructor_from_mgr_regression",
    "is_a_fork": true,
    "comments": [
      "After merging https://github.com/geopandas/geopandas/pull/3161, this should be easier to have things green (there are also a few TEMP commits in that PR that will need to be reverted here, I think)",
      "The commit https://github.com/geopandas/geopandas/pull/3159/commits/a424b1f37381cbae0afb9b48c5293aba47e37fe0 looks good to me!\r\n\r\nIf it's easier, I think we can also first target this to main and backport it later (then the test also already exists, and your other PRs can just fixup the test for non-default names)",
      "> The commit [a424b1f](https://github.com/geopandas/geopandas/commit/a424b1f37381cbae0afb9b48c5293aba47e37fe0) looks good to me!\r\n> \r\n> If it's easier, I think we can also first target this to main and backport it later (then the test also already exists, and your other PRs can just fixup the test for non-default names)\r\n\r\n@jorisvandenbossche I took your suggestion, this now should be ready to commit to main. When you backport, the test will need to be updated to use `geopandas.datasets.get_path(\"nybb\")` because the conftest.py changes are only on main.\r\n\r\n(no changelog entry since I think this is covered by the collective pandas 2.2 compatibility entry)",
      "Added both the original compat commit and this one to the backports in https://github.com/geopandas/geopandas/pull/3161 now. seems to be good!"
    ],
    "commit_messages": [
      "REGR: directly fix _constructor_from_mgr regression (#3159)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4b1ac254a19ac29deed",
    "number": 3154,
    "body": "Exposing `get_num_geometries` as `count_geometries`, `get_num_interior_rings` as `count_interior_rings` and replacing the implementation of `count_coordinates` with `get_num_coordinates` to avoid the loop.",
    "head_branch": "get_",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4b2ac254a19ac29deee",
    "number": 3153,
    "body": "Adding `dwithin` as a predicate. It may be better to rename it to `within_distance` but since we're using `dwithin` to specify predicates in sindex.query and elsewhere, I'd keep `dwithin`.\r\n\r\nxref #2010",
    "head_branch": "dwithin",
    "is_a_fork": true,
    "comments": [
      "While \"dwithin\" is not the best name, it's what shapely, postgis, etc all use, so that's probably also a good reason to keep it"
    ],
    "commit_messages": [
      "ENH: add GeoSeries.dwithin (#3153)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4b3ac254a19ac29deef",
    "number": 3151,
    "body": "Xref #2010\r\n\r\nI was surprised how faster this actually is. On geodatasets' `geoda.south` it goes from 121 ms to 4.43 ms. It will likely depend on the data but it is impressive nonetheless. \r\n\r\nThe formulations in the docstring feel a bit sloppy so I'd appreciate some native speaker to check if it makes sense.",
    "head_branch": "coverage_all",
    "is_a_fork": true,
    "comments": [
      "Change the keyword to `method` with string options to allow `GEOSDisjointSubsetUnion` to be exposed in future. "
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4b4ac254a19ac29def0",
    "number": 3150,
    "body": "I enabled a few more `ruff` rules, separating each rule into a commit.",
    "head_branch": "fix-lint",
    "is_a_fork": true,
    "comments": [
      "I would personally keep RUF002 disabled. Those changed it caused lead to worse typography in docstrings and I don't see how that is an improvement. I don't mind the rest but also have no strong opinion about them. We mostly copied the list of disabled rules form pandas in the first place so didn't put a ton of thought into that.",
      "@martinfleis I can revert RUF002 if you think it causes more harm than good, but now that `pandas` also enables RUF002, do you think `geopandas` can follow suit?\r\n\r\nHere's the latest `pandas` config: https://github.com/pandas-dev/pandas/blob/main/pyproject.toml#L328",
      "I don't care much to be honest. Let's wait for some of the other maintainers to weigh in.",
      "This is going to become subjective ;)\r\n\r\nI would personally keep [PLR5501](https://github.com/geopandas/geopandas/pull/3150/commits/818d5a45499500bacbc3ee49a95c6be4dbf33545) disabled .. It's often a good idea to flatten those levels, but in some of the cases it changed, there is a code logic about having if/else, and each block in that having another if/else. Changing that to if/elif/else changes the flow of the code, and can potentially make it harder to follow the logic. I think this is a case where the person writing the code can make a better judgment than a linter with a fixed rule.",
      "> This is going to become subjective ;)\r\n\r\nMy proposal is not to touch the rules exceptions we have now. Our capacity to deal with GeoPandas stuff is limited and this is super low on priority but can turn into a long discussion that is not worth it/we can't afford.",
      "In general I don't care about things that are just stylistic (like in general black's formatting), that's just less things to think about. So if there are some stylistic rules that can be enabled (and auto-fixed, like black), I am OK with that. \r\nBut PLR5501 is not just stylistic, it changes the structure of the code. For those I agree it might not be worth the debate at the moment.",
      "If it avoids us talking round in circles I am happy to keep the lint rules as they are right now. \r\n\r\nIf forced to make a decision on these, I'd enable RUF001,2,3 (but don't really care) and keep PLR5501 disabled, while in certain situations it might make the code clearer, I don't think it universally does.",
      "Hello all, \r\n\r\nI understood from the discussion that changing the list of ignored rules is not a priority now, will close this PR."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4b5ac254a19ac29def1",
    "number": 3149,
    "body": "This PR bumps `ruff` to the latest version, which is a stable one and has a lot more checks. \r\n\r\nI fixed all the new linting errors, apart from `RUF012` and `PYI024`, which I'm unsure about the fix.",
    "head_branch": "bump-ruff",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "MAINT: Bump ruff (#3149)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4b5ac254a19ac29def2",
    "number": 3148,
    "body": "Closes #3147\r\n\r\nI want to point out that this is not a bug on our side but knowing Esri, this is the easiest way how to fix the issue geopandas users face when working within ArcPro environment. There's probably no way to test this though.\r\n\r\n@remi-braun can you test this?",
    "head_branch": "esri_bug",
    "is_a_fork": true,
    "comments": [
      "This seems to work 💪 \r\n\r\nThank your for doing support and maintenance for Esri 🙄 "
    ],
    "commit_messages": [
      "COMPAT: fix compatibility with Esri-shipped GDAL (#3148)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4b6ac254a19ac29def3",
    "number": 3146,
    "body": "Closes #3119. Alternative to #3125 which I think will not go anywhere. \r\n\r\nThis is also not an ideal solution.",
    "head_branch": "fix_loc_regression2",
    "is_a_fork": true,
    "comments": [
      "Also not ideal, the \"upcast by default\" assumption is not great for astype(object), and potentially other things."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4b7ac254a19ac29def4",
    "number": 3145,
    "body": "Closes https://github.com/geopandas/geopandas/issues/3143",
    "head_branch": "tst-skip-old-geos",
    "is_a_fork": true,
    "comments": [
      "Is the error in `test_frechet_distance` also related to GEOS version? I would suppose so. Can we skip that one as well?",
      "Yes, just added a skip for the frechet test as well. Not going to put the effort to figure out why it's failing for old GEOS."
    ],
    "commit_messages": [
      "TST/CI: skip some tests for older GEOS (#3145)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4b8ac254a19ac29def5",
    "number": 3144,
    "body": "Related to https://github.com/geopandas/geopandas/issues/3143. \r\n\r\nDo we want to warn if not using ISO?",
    "head_branch": "compat-parquet-old-geos",
    "is_a_fork": true,
    "comments": [
      "> Do we want to warn if not using ISO?\r\n\r\nMaybe even raise? If you specify to get ISO and we can't provide it, it may be the best not to produce formally invalid data.",
      "I wouldn't raise always, because often it doesn't matter. In practice, I think it's only for 3D data. So will add a check for the dimensionality, and then when 3D and old GEOS, then we can raise an error.",
      "That's a while ago! All green ;)"
    ],
    "commit_messages": [
      "COMPAT: only use ISO WKB flavor in to_parquet for GEOS that supports it (#3144)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4b9ac254a19ac29def6",
    "number": 3142,
    "body": null,
    "head_branch": "tst-extension-array",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: update extension array tests for upstream pandas changes (#3142)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4b9ac254a19ac29def7",
    "number": 3141,
    "body": "resolves #2901",
    "head_branch": "TST-Add-test-on-reading-None-values",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Add test on reading None values (#3141)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4baac254a19ac29def8",
    "number": 3139,
    "body": "A next batch of warning fixes. This ignores a few external warnings we can't do anything about.",
    "head_branch": "maint-ci-reduce-warnings-2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "MAINT: reduce warnings in the tests (#3139)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4bbac254a19ac29def9",
    "number": 3134,
    "body": "After merging https://github.com/geopandas/geopandas/pull/3084, the nybb zip file changed directory, but we were using that url for testing reading from url. ",
    "head_branch": "tst-fix-url",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: update new url for nybb dataset (#3134)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4bcac254a19ac29defa",
    "number": 3133,
    "body": "A couple of changes related to selecting columns in `read_file`:\r\n\r\n- Publicize to use `columns` (which I think the nicest API): explicitly add to the docstring (and will update the docs to mention it as well)\r\n- Translate `columns` to `incude_fields` for the fiona engine, so `columns` is always supported.\r\n- For the pyogrio engine, translate both `include_fields` and `ignore_fields` keywords that are supported by fiona to the `columns` keyword of pyogrio. This ensures a smooth upgrade when we switch the default for people that were using those keywords.\r\n  - I did add a warning pointing to use `columns` instead, we can discuss whether we want to keep this warning (or make it stronger).\r\n\r\n",
    "head_branch": "read-file-columns",
    "is_a_fork": true,
    "comments": [
      "+1 on keeping only `columns` in future. ",
      "Probably a tangential issue but we should use column specification in `GeoSeries.from_file` to avoid reading attributes when we drop them anyway. Should be done once this is in.",
      "Updated the PR. Fixed the failing test (remaining failure is the dev build, failing for other reasons). And changed the UserWarning into a DeprecationWarning with the intent that eventually we only keep the `columns` keyword."
    ],
    "commit_messages": [
      "ENH: harmonize read_file column selection keywords (support `columns` for fiona, support `ignore_fields`/`include_fields` for pyogrio for back compat) (#3133)\n\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4bdac254a19ac29defb",
    "number": 3132,
    "body": "Closes #1320",
    "head_branch": "make-GeoDataFrame-to-geo-public",
    "is_a_fork": true,
    "comments": [
      "Thanks for the suggestions.  And I trust you more than me for the GeoJSON wording :)"
    ],
    "commit_messages": [
      "ENH: make _to_geo public as to_geo_dict (#3132)\n\nCo-authored-by: Remy FRANSEN <remy.fransen@artal.fr>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Matt Richards <mrichards7@outlook.com.au>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4bdac254a19ac29defc",
    "number": 3131,
    "body": "Small follow-up on https://github.com/geopandas/geopandas/pull/2966, fixing the warning in `overlay` more at the root, instead of silencing it with filterwarnings.",
    "head_branch": "compat-pandas-empty-concat",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "COMPAT: avoid concat with empty object dtype column in overlay() (#3131)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4beac254a19ac29defd",
    "number": 3130,
    "body": "Follow-up on https://github.com/geopandas/geopandas/pull/2966#issuecomment-1878816712:\r\n\r\n- Fixes the warning in our tests (by passing the `include_groups=False` keyword if needed instead of selecting the columns)\r\n- Adds an additional test case explicitly selecting columns, and parametrized that with different geometry name (see the mentioned issue, this should fail with latest pandas)",
    "head_branch": "test-pandas-groupby-column-selection",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: update groupby test to handle included group columns with pandas >= 2.2 + test with non-default geometry name (#3130)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4bfac254a19ac29defe",
    "number": 3128,
    "body": "Passing `errors=\"ignore\"` is deprecated and will raise an error in the future. So removed this usage and already put it in a try/except block. We need this twice though, because we have a fallback with trying `utc=True` in case the error was from mixed timezones.",
    "head_branch": "read-file-to_datetime",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "COMPAT: remove usage of pd.to_datetime errors=ignore option (#3128)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4c0ac254a19ac29deff",
    "number": 3127,
    "body": "Testing to see how much difference this actually gives.",
    "head_branch": "ci-remove-xdist",
    "is_a_fork": true,
    "comments": [
      "So it does give a considerable speed-up, even on CI, so closing (will hide the warnings from xdist separately then)"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4c1ac254a19ac29df00",
    "number": 3126,
    "body": "Follow up on https://github.com/geopandas/geopandas/pull/2966",
    "head_branch": "maint-ci-reduce-warnings",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "MAINT: reduce warnings in the tests (#3126)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4c1ac254a19ac29df01",
    "number": 3125,
    "body": "Potential ideas for solving this. As implemented, `_constructor_from_mgr` stays nice and clean, but relies too heavily on the pandas internals for my liking (though in an ideal world pandas would expose some way to handle less straightforward dtype concatenation cases). \r\n\r\nEdit: This kind of approach is not going to work because of this if else in compat compat:\r\nhttps://github.com/pandas-dev/pandas/blob/612823e824805b97a2dbe258ba808dc572083d49/pandas/core/dtypes/concat.py#L128-L144\r\nThis block assumes `to_concat` shares a common dtype, and with this trick that's not true\r\n\r\n\r\nI expect we'll end up using something along the lines of the update to `_constructor_from_mgr` which is commented out at the moment.",
    "head_branch": "fix_loc_regression",
    "is_a_fork": true,
    "comments": [
      "Interesting! That's a nice workaround on our side. I will try to think tomorrow a bit more about how this ideally would be tackled on the pandas side. But on the shorter term, I think this common_dtype trick is an interesting avenue to explore."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4c2ac254a19ac29df02",
    "number": 3124,
    "body": "Sorry for the notification spam, meant to run this on my fork, but forgot to update the base branch.",
    "head_branch": "remove_dataset_test",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4c3ac254a19ac29df03",
    "number": 3123,
    "body": "This is the changelog entry as it exists on the 0.14.x branch (from merging https://github.com/geopandas/geopandas/pull/3074, cherry-picking https://github.com/geopandas/geopandas/pull/3094 (https://github.com/geopandas/geopandas/commit/7c8fa85963273a17dee76a7d19b7a3c8a6b8aeee), and the release commit). \r\nAdding it to the main branch as well (for this specific case where we merged directly to the release branch)so we correctly keep track of it in the main branch / stable docs.",
    "head_branch": "doc-changelog-0142",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC/RLS: add 0.14.2 changelog to main branch as well (#3123)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4c4ac254a19ac29df04",
    "number": 3121,
    "body": "xref https://github.com/pandas-dev/pandas/pull/56583#issuecomment-1875964373",
    "head_branch": "tst/pandas_ea_testing",
    "is_a_fork": true,
    "comments": [
      "Thanks! I am fine with this right now but I'm wondering if it is a right solution. Assuming there's a number of downstream packages implementing EAs, this would need to be done in every one of them. Wouldn't it be better to ensure that EA tests just work without a need to define generic fixtures for every EA implementation? I would assume that you only override those that are affected by the specifics of your EA and inherit the rest but that is not the case at the moment.",
      "Yes, we have always ensured on the pandas side that the base extension array tests don't use other fixtures than the ones defined in those tests itself. I think we should continue on that path (otherwise it is very hard to know as downstream user which fixtures should be implemented).\r\n\r\nI think we can simply revert the small part of https://github.com/pandas-dev/pandas/pull/56583 that touches the extension tests. Ideally we would have a better test on the pandas side to remind us of this contract, so we don't easily break that with such \"cleaning\" PRs.",
      "Yeah agreed a better long term solution is needed on the pandas side to avoid this. Opened up https://github.com/pandas-dev/pandas/issues/56735 to track this",
      "I did a PR to pandas to fix it there, and we have the issue to add better testing for this. That resolves this for now on the geopandas side, so closing this PR."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4c5ac254a19ac29df05",
    "number": 3116,
    "body": "This is just a minor change aimed at visibility and understandability of all the options `buffer` has. It is all supported via `kwargs` for some time already but explicitly adding keywords to our buffer seems to be better. I am also switching from numbers for join and cap styles to explicit strings (although both options are supported on shapely side). `shapely.BufferCapStyle` and `shapely.BufferJoinStyle` are omitted from the docstring as they are just enums with a limited practical value.\r\n\r\nxref #2010",
    "head_branch": "buffer",
    "is_a_fork": true,
    "comments": [
      "> Do you think it warrants a changelog entry? I don't mind either way since we're just making existing behaviour more obvious.\r\n\r\nIt does not change any behaviour of anything, it is more of a documentation I'd say. So I'm fine without one."
    ],
    "commit_messages": [
      "ENH: buffer signature parity with shapely (#3116)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4c5ac254a19ac29df06",
    "number": 3114,
    "body": "xref #2010\r\n\r\n",
    "head_branch": "predicate_xy",
    "is_a_fork": true,
    "comments": [
      "I am wondering a bit how useful this is to add as a method in geopandas. The reason you typically use this is because you have *lots* of points that are not yet converted to geometries (like x/y columns in your dataframe), and compare this to a few or one polygon. But that pattern doesn't map to a geoseries/dataframe _method_ if your columns are x/y coordinates.  \r\nAnd if you have a column of polygons and provide a matching length arrays/columns of points, I am not sure how much benefit this actually gives (if the polygon is not reused and prepared)\r\n",
      "It has a limited use indeed but there was an explicit request to add this one in https://github.com/geopandas/geopandas/issues/2010#issuecomment-1817475119. Also, once we finally manage to get beyond row-wise predicate checks with some version of #1674, it may be more useful.",
      "Agreed not to implement during the last dev call."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4c6ac254a19ac29df07",
    "number": 3113,
    "body": "Resolves #3073 \r\n\r\nRemark: Not described in the issue, but the function `test_overlap_make_valid()` was also still testing on `buffer(0)` for the fixed bowtie. From what I read online, `buffer(0)` was an old workaround from when `make_valid()` function from Shapely didn't exist yet that slightly changes the geometry and thus makes this test fail on:\r\n\r\n```python\r\n    if should_make_valid:\r\n        df_overlay_bowtie = overlay(df1, df_bowtie, make_valid=should_make_valid)\r\n        assert df_overlay_bowtie.at[0, \"geometry\"].equals(fixed_bowtie)\r\n        assert df_overlay_bowtie.at[1, \"geometry\"].equals(fixed_bowtie)\r\n```\r\n\r\nI thus also changed it to also use the more recent `make_valid()` function from Shapely here.",
    "head_branch": "Issue-3073",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REF: Replace the usage of buffer(0) with make_valid (#3113)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4c7ac254a19ac29df08",
    "number": 3112,
    "body": "Bumps [actions/upload-artifact](https://github.com/actions/upload-artifact) from 3 to 4.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/actions/upload-artifact/releases\">actions/upload-artifact's releases</a>.</em></p>\n<blockquote>\n<h2>v4.0.0</h2>\n<h2>What's Changed</h2>\n<p>The release of upload-artifact@v4 and download-artifact@v4 are major changes to the backend architecture of Artifacts. They have numerous performance and behavioral improvements.</p>\n<p>For more information, see the <a href=\"https://github.com/actions/toolkit/tree/main/packages/artifact\"><code>@​actions/artifact</code></a> documentation.</p>\n<h2>New Contributors</h2>\n<ul>\n<li><a href=\"https://github.com/vmjoseph\"><code>@​vmjoseph</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/upload-artifact/pull/464\">actions/upload-artifact#464</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/upload-artifact/compare/v3...v4.0.0\">https://github.com/actions/upload-artifact/compare/v3...v4.0.0</a></p>\n<h2>v3.1.3</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>chore(github): remove trailing whitespaces by <a href=\"https://github.com/ljmf00\"><code>@​ljmf00</code></a> in <a href=\"https://redirect.github.com/actions/upload-artifact/pull/313\">actions/upload-artifact#313</a></li>\n<li>Bump <code>@​actions/artifact</code> version to v1.1.2 by <a href=\"https://github.com/bethanyj28\"><code>@​bethanyj28</code></a> in <a href=\"https://redirect.github.com/actions/upload-artifact/pull/436\">actions/upload-artifact#436</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/upload-artifact/compare/v3...v3.1.3\">https://github.com/actions/upload-artifact/compare/v3...v3.1.3</a></p>\n<h2>v3.1.2</h2>\n<ul>\n<li>Update all <code>@actions/*</code> NPM packages to their latest versions- <a href=\"https://redirect.github.com/actions/upload-artifact/issues/374\">#374</a></li>\n<li>Update all dev dependencies to their most recent versions - <a href=\"https://redirect.github.com/actions/upload-artifact/issues/375\">#375</a></li>\n</ul>\n<h2>v3.1.1</h2>\n<ul>\n<li>Update actions/core package to latest version to remove <code>set-output</code> deprecation warning <a href=\"https://redirect.github.com/actions/upload-artifact/issues/351\">#351</a></li>\n</ul>\n<h2>v3.1.0</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Bump <code>@​actions/artifact</code> to v1.1.0 (<a href=\"https://redirect.github.com/actions/upload-artifact/pull/327\">actions/upload-artifact#327</a>)\n<ul>\n<li>Adds checksum headers on artifact upload (<a href=\"https://redirect.github.com/actions/toolkit/pull/1095\">actions/toolkit#1095</a>) (<a href=\"https://redirect.github.com/actions/toolkit/pull/1063\">actions/toolkit#1063</a>)</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/actions/upload-artifact/commit/c7d193f32edcb7bfad88892161225aeda64e9392\"><code>c7d193f</code></a> Merge pull request <a href=\"https://redirect.github.com/actions/upload-artifact/issues/466\">#466</a> from actions/v4-beta</li>\n<li><a href=\"https://github.com/actions/upload-artifact/commit/13131bb095770b4070a7477c3cd2d96e1c16d9f4\"><code>13131bb</code></a> licensed cache</li>\n<li><a href=\"https://github.com/actions/upload-artifact/commit/4a6c273b9834f66a1d05c170dc3f80f9cdb9def1\"><code>4a6c273</code></a> Merge branch 'main' into v4-beta</li>\n<li><a href=\"https://github.com/actions/upload-artifact/commit/f391bb91a3d3118aeca171c365bb319ece276b37\"><code>f391bb9</code></a> Merge pull request <a href=\"https://redirect.github.com/actions/upload-artifact/issues/465\">#465</a> from actions/robherley/v4-documentation</li>\n<li><a href=\"https://github.com/actions/upload-artifact/commit/9653d03c4b74c32144e02dae644fea70e079d4b3\"><code>9653d03</code></a> Apply suggestions from code review</li>\n<li><a href=\"https://github.com/actions/upload-artifact/commit/875b63076402f25ef9d52c294c86ba4f97810575\"><code>875b630</code></a> add limitations section</li>\n<li><a href=\"https://github.com/actions/upload-artifact/commit/ecb21463e93740a6be75c3116242169bfdbcb15a\"><code>ecb2146</code></a> add compression example</li>\n<li><a href=\"https://github.com/actions/upload-artifact/commit/5e7604f84a055838f64ed68bb9904751523081ae\"><code>5e7604f</code></a> trim some repeated info</li>\n<li><a href=\"https://github.com/actions/upload-artifact/commit/d6437d07581fe318a364512e6cf6b1dca6b4f92c\"><code>d6437d0</code></a> naming</li>\n<li><a href=\"https://github.com/actions/upload-artifact/commit/1b561557037b4957d7d184e9aac02bec86c771eb\"><code>1b56155</code></a> s/v4-beta/v4/g</li>\n<li>Additional commits viewable in <a href=\"https://github.com/actions/upload-artifact/compare/v3...v4\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/upload-artifact&package-manager=github_actions&previous-version=3&new-version=4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
    "head_branch": "dependabot/github_actions/actions/upload-artifact-4",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Bump actions/upload-artifact from 3 to 4 (#3112)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4c8ac254a19ac29df09",
    "number": 3111,
    "body": null,
    "head_branch": "fix_dead_link",
    "is_a_fork": true,
    "comments": [
      "This link was broken for me earlier, but there appears to be a redirect now/  redirect temporarily wasn't working?\r\n\r\nEdit: I suppose there's no harm to updating the link."
    ],
    "commit_messages": [
      "DOC/ MAINT: fix link in bug report form (#3111)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4c9ac254a19ac29df0a",
    "number": 3110,
    "body": "Resolves #2962\r\n\r\nReference #2791\r\n\r\nRemark: I noticed a method called `_from_wkb_or_wkb` in `GeoSeries`, I suppose this should be `_from_wkb_or_wkt`? If this is the case, shall I change this in this PR or in a seperate one?",
    "head_branch": "ENH-add-on_invalid-parameter-to-from_wkt-and-from_wkb",
    "is_a_fork": true,
    "comments": [
      "`_from_wkb_or_wkb` in GeoSeries has been renamed to `_from_wkb_or_wkt`.",
      "Pushed a small commit to address my one comment, and also removed the parametrization (then the if/elif/else wasn't needed, that felt a bit simpler to me)"
    ],
    "commit_messages": [
      "ENH: add on_invalid parameter to from_wkt and from_wkb (#3110)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4caac254a19ac29df0b",
    "number": 3108,
    "body": "Bumps [actions/setup-python](https://github.com/actions/setup-python) from 4 to 5.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/actions/setup-python/releases\">actions/setup-python's releases</a>.</em></p>\n<blockquote>\n<h2>v5.0.0</h2>\n<h2>What's Changed</h2>\n<p>In scope of this release, we update node version runtime from node16 to node20 (<a href=\"https://redirect.github.com/actions/setup-python/pull/772\">actions/setup-python#772</a>). Besides, we update dependencies to the latest versions.</p>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/setup-python/compare/v4.8.0...v5.0.0\">https://github.com/actions/setup-python/compare/v4.8.0...v5.0.0</a></p>\n<h2>v4.8.0</h2>\n<h2>What's Changed</h2>\n<p>In scope of this release we added support for GraalPy (<a href=\"https://redirect.github.com/actions/setup-python/pull/694\">actions/setup-python#694</a>). You can use this snippet to set up GraalPy:</p>\n<pre lang=\"yaml\"><code>steps:\n- uses: actions/checkout@v4\n- uses: actions/setup-python@v4 \n  with:\n    python-version: 'graalpy-22.3' \n- run: python my_script.py\n</code></pre>\n<p>Besides, the release contains such changes as:</p>\n<ul>\n<li>Trim python version when reading from file by <a href=\"https://github.com/FerranPares\"><code>@​FerranPares</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/628\">actions/setup-python#628</a></li>\n<li>Use non-deprecated versions in examples by <a href=\"https://github.com/jeffwidman\"><code>@​jeffwidman</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/724\">actions/setup-python#724</a></li>\n<li>Change deprecation comment to past tense by <a href=\"https://github.com/jeffwidman\"><code>@​jeffwidman</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/723\">actions/setup-python#723</a></li>\n<li>Bump <code>@​babel/traverse</code> from 7.9.0 to 7.23.2 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/743\">actions/setup-python#743</a></li>\n<li>advanced-usage.md: Encourage the use actions/checkout@v4 by <a href=\"https://github.com/cclauss\"><code>@​cclauss</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/729\">actions/setup-python#729</a></li>\n<li>Examples now use checkout@v4 by <a href=\"https://github.com/simonw\"><code>@​simonw</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/738\">actions/setup-python#738</a></li>\n<li>Update actions/checkout to v4 by <a href=\"https://github.com/dmitry-shibanov\"><code>@​dmitry-shibanov</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/761\">actions/setup-python#761</a></li>\n</ul>\n<h2>New Contributors</h2>\n<ul>\n<li><a href=\"https://github.com/FerranPares\"><code>@​FerranPares</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/setup-python/pull/628\">actions/setup-python#628</a></li>\n<li><a href=\"https://github.com/timfel\"><code>@​timfel</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/setup-python/pull/694\">actions/setup-python#694</a></li>\n<li><a href=\"https://github.com/jeffwidman\"><code>@​jeffwidman</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/setup-python/pull/724\">actions/setup-python#724</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/setup-python/compare/v4...v4.8.0\">https://github.com/actions/setup-python/compare/v4...v4.8.0</a></p>\n<h2>v4.7.1</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Bump word-wrap from 1.2.3 to 1.2.4 by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/702\">actions/setup-python#702</a></li>\n<li>Add range validation for toml files by <a href=\"https://github.com/dmitry-shibanov\"><code>@​dmitry-shibanov</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/726\">actions/setup-python#726</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/setup-python/compare/v4...v4.7.1\">https://github.com/actions/setup-python/compare/v4...v4.7.1</a></p>\n<h2>v4.7.0</h2>\n<p>In scope of this release, the support for reading python version from pyproject.toml was added (<a href=\"https://redirect.github.com/actions/setup-python/pull/669\">actions/setup-python#669</a>).</p>\n<pre lang=\"yaml\"><code>      - name: Setup Python\n        uses: actions/setup-python@v4\n&lt;/tr&gt;&lt;/table&gt; \n</code></pre>\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/actions/setup-python/commit/0a5c61591373683505ea898e09a3ea4f39ef2b9c\"><code>0a5c615</code></a> Update action to node20 (<a href=\"https://redirect.github.com/actions/setup-python/issues/772\">#772</a>)</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/0ae58361cdfd39e2950bed97a1e26aa20c3d8955\"><code>0ae5836</code></a> Add example of GraalPy to docs (<a href=\"https://redirect.github.com/actions/setup-python/issues/773\">#773</a>)</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/b64ffcaf5b410884ad320a9cfac8866006a109aa\"><code>b64ffca</code></a> update actions/checkout to v4 (<a href=\"https://redirect.github.com/actions/setup-python/issues/761\">#761</a>)</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/8d2896179abf658742de432b3f203d2c2d86a587\"><code>8d28961</code></a> Examples now use checkout@v4 (<a href=\"https://redirect.github.com/actions/setup-python/issues/738\">#738</a>)</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/7bc6abb01e0555719edc2dbca70a2fde309e5e56\"><code>7bc6abb</code></a> advanced-usage.md: Encourage the use actions/checkout@v4 (<a href=\"https://redirect.github.com/actions/setup-python/issues/729\">#729</a>)</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/e8111cec9d3dc15220d8a3b638f08419f57b906a\"><code>e8111ce</code></a> Bump <code>@​babel/traverse</code> from 7.9.0 to 7.23.2 (<a href=\"https://redirect.github.com/actions/setup-python/issues/743\">#743</a>)</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/a00ea43da65e7c04d2bdae58b3afecd77057eb9e\"><code>a00ea43</code></a> add fix for graalpy ci (<a href=\"https://redirect.github.com/actions/setup-python/issues/741\">#741</a>)</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/8635b1ccc5934e73ed3510980fd2e7790b85839b\"><code>8635b1c</code></a> Change deprecation comment to past tense (<a href=\"https://redirect.github.com/actions/setup-python/issues/723\">#723</a>)</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/f6cc428f535856f9c23558d01765a42a4d6cf758\"><code>f6cc428</code></a> Use non-deprecated versions in examples (<a href=\"https://redirect.github.com/actions/setup-python/issues/724\">#724</a>)</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/5f2af211d616f86005883b44826180b21abb4060\"><code>5f2af21</code></a> Add GraalPy support (<a href=\"https://redirect.github.com/actions/setup-python/issues/694\">#694</a>)</li>\n<li>Additional commits viewable in <a href=\"https://github.com/actions/setup-python/compare/v4...v5\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/setup-python&package-manager=github_actions&previous-version=4&new-version=5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
    "head_branch": "dependabot/github_actions/actions/setup-python-5",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Bump actions/setup-python from 4 to 5 (#3108)\n\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4caac254a19ac29df0c",
    "number": 3107,
    "body": "Current plotting methods simply call `plt.draw()`  at the end. \r\nThis assumes that the figure to which the plot-axes belongs to is managed by `pyplot` and that it is also the currently active figure. \r\n\r\nIf a custom axes is provided (e.g. using `gdf.plot(ax=ax)`) and the associated figure is not properly recognized by `pyplot`, then the final call to `plt.draw()` will trigger the creation **of a new figure** rather than drawing the figure to which the axes belong to.\r\n\r\nSince `plt.draw()` defaults to `plt.gcf().canvas.draw_idle()`, I suggest replacing it with `ax.figure.canvas.draw_idle()` to ensure that the correct figure is triggered.\r\n\r\n\r\nTo give a quick example where the current implementation can cause problems: If you initialize a figure in a jupyter-notebook cell and call `gdf.plot()` in a subsequent cell.\r\n\r\n![grafik](https://github.com/geopandas/geopandas/assets/22773387/79a14b89-44bd-4446-a871-9bd3b0b2e850)\r\n\r\n\r\n\r\n\r\n\r\n",
    "head_branch": "patch-3",
    "is_a_fork": true,
    "comments": [
      "This all sounds very sensible to me but I know little of these matplotlib internals to review it. \r\n\r\n@ksunden would you consider this an optimal solution?",
      "Taking one step back: do we know _why_ we are calling the `plt.draw()` here to start with? (and maybe it can just be left out entirely?) \r\n\r\nI was thinking it might be to ensure the axes' view are updated (eg when plotting something to an existing ax that falls outside of the extent). But we already have a `ax.autoscale_view()` call in the helper functions that add the actual collections to the ax.\r\n\r\nThis call was added in https://github.com/geopandas/geopandas/pull/40/commits/b0d0b5382d1e8e8fbdbc4cc75762207a7e56682b",
      "But in any case, besides my question above, this change certainly seems good and at least (even if we might not strictly need it) benign, given it just preserves the current behaviour of triggering a draw, but using the OO API.",
      "Hey all, sorry for responding a bit too late... \r\n\r\nI'm also not 100% sure whether the `draw`-call is really needed or not (I guess it ultimately depends on the used backend and whether or not matplotlibs interactive-mode is activated) but I'd also vote for keeping it since users are very much used to this behavior and it should not cause any problems if it is called unnecessarily.\r\n\r\nThanks for merging! ",
      "`canvas.draw_idle` is certainly better in this context than `plt.draw`, though I do also wonder if the explicit draw here is truly required at all.\r\n\r\nBut in any case certainly better (sorry for the slow response, I was away from dev work last week)."
    ],
    "commit_messages": [
      "Make sure gdf.plot() triggers drawing the figure of the used plot-axes (#3107)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4cbac254a19ac29df0d",
    "number": 3105,
    "body": "We have contains_properly already in sindex as an allowed predicate but did not have one explicitly exposed.\r\n\r\nPart of #2010",
    "head_branch": "contains_properly",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: add contains_properly predicate method (#3105)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4ccac254a19ac29df0e",
    "number": 3102,
    "body": "Pandas main has a regression with using `check_dtype=False`, which will probably be fixed on the pandas side. But, looking at the test where the failure was showing up, we can also easily make the test more explicit.\r\n\r\nCloses #3093",
    "head_branch": "fix-test-read_file-int",
    "is_a_fork": true,
    "comments": [
      "This reduced the number of failures on the dev build, so seems to be working fine"
    ],
    "commit_messages": [
      "TST: update read_file test to be more specific about expected dtype (#3102)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4cdac254a19ac29df0f",
    "number": 3101,
    "body": "Closes #3099.\r\n\r\nLike `_from_sequence` right above, I minimally edited the abstract base function to give the desired behavior.\r\n\r\n@martinfleis think this warrants its own test since it's more or less an alias of `from_wkt`...?",
    "head_branch": "main",
    "is_a_fork": true,
    "comments": [
      "I think it would be good to add a small test that reading from CSV with specifying the dtype works (essentially what you did in the issue). While we indeed don't need to test the details of what kind of strings work for `from_wkt`, it's good to have some test to avoid accidentally removing this feature.",
      "Makes sense, added!",
      "@jorisvandenbossche believe this is ready, I think the test failure is unrelated",
      "Looks good to me! Can you also add a short line to the changelog?",
      "@martinfleis done!"
    ],
    "commit_messages": [
      "ENH: Add GeometryArray._from_sequence_of_strings (#3101)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4ceac254a19ac29df10",
    "number": 3100,
    "body": "This was recommended by @martinfleis in #3098.\r\n\r\nIt currently contains a tip on dropping duplicate geometries using normalize() before drop_duplicates(). It can be used as an appropriate place in the future for other How To/Hints and Tips content later.",
    "head_branch": "add-how-to-docs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4ceac254a19ac29df11",
    "number": 3095,
    "body": "Follow-up on #3067.\r\n\r\nxref https://github.com/geopandas/geopandas/pull/3067#issuecomment-1837949013 (thanks @zaneselvans!)",
    "head_branch": "gpqspec",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: update note on GeoParquet support (#3095)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4cfac254a19ac29df12",
    "number": 3094,
    "body": "As pointed out by @anitagraser on Mastodon, `explore()` raises an error when there is a missing or an empty geometry in the active column. This drops affected rows prior generating a JSON for Folium, as there's nothing to show.",
    "head_branch": "explore_none",
    "is_a_fork": true,
    "comments": [
      "The generation of the HTML is lazy, so if you call `explore` inside tests, nearly nothing is actually tested. Surely not this case. ",
      "> The generation of the HTML is lazy, so if you call `explore` inside tests, nearly nothing is actually tested. Surely not this case.\r\n\r\nAh yes you're right, it's the rendering which triggers the crash, separate to the `.explore()`"
    ],
    "commit_messages": [
      "BUG: allow None and empty geoms in explore (#3094)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4d0ac254a19ac29df13",
    "number": 3092,
    "body": "Somehow `is_closed` was already implemented on a `GeometryArray` level, but not exposed to GeoPandasBase. Doing that now as part of #2010.",
    "head_branch": "is_closed_doc",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: explose is_closed on a base level (#3092)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4d1ac254a19ac29df14",
    "number": 3090,
    "body": "xref #2010 ",
    "head_branch": "force_d",
    "is_a_fork": true,
    "comments": [
      "Thanks!"
    ],
    "commit_messages": [
      "ENH: add force_2d and force_3d (#3090)\n\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4d2ac254a19ac29df15",
    "number": 3088,
    "body": "Refs: #3085 \r\nFor the current version: Warn the user that tries to manually change a GeoSeries' **existing** CRS by the property setter (ex. `gs.crs = \"new crs\"`), that the setter will be deprecated in future versions and that the `set_crs` method should be used instead.",
    "head_branch": "3085_raise",
    "is_a_fork": true,
    "comments": [
      "As noted in https://github.com/geopandas/geopandas/issues/3085, we'll need to cover both GeoSeries and GeoDataFrame here.",
      "There seems to be an issue with `GeoDataFrame.dissolve` trying to set `crs` through the setter but I cannot wrap my head around were this is happening.\r\nAny suggestions?",
      "@JohnMoutafis would you have time to update for the comments of @martinfleis ?",
      "@jorisvandenbossche I will try to find some (hopefully soon)",
      "@JohnMoutafis given we'd like to have this included in 1.0 which shall be released hopefully soon, I have pushed some commits myself, mostly resolving my own comments. ",
      "@martinfleis sorry for not finding the time to handle the requested changes.\r\nDoes the PR need anything atm to be merged?\r\nWhat about the coverage?",
      "I think it is ready to be merged, just want to wait for another review.\r\n\r\nThe coverage can be ignored I suppose, given the patch has 100%. It tends to be flaky from time to time.",
      "> I also see in the dev env that the warnings are getting triggered by pandas code in certain tests, which we may want to look into, but I suppose there's still quite a bit of time before the deprecation is enforced.\r\n\r\nI think they are being triggered in general in our tests. Looking at the ones in test_geodataframe.py, it seems this comes from doing `df.crs = None` (i.e. to remove the crs from a df for the test). But replacing that with `df = df.set_crs(None, allow_override=True)` doesn't work, because we don't accept None.\r\n\r\nDo we want to accept `None` in that method, or do we not raise the warning for the case of assigning `None` ? (we are not silently _replacing_ a crs, so less need to warn about that)",
      "Yeah, I noted that in https://github.com/geopandas/geopandas/pull/3088#pullrequestreview-2009085413 and then forgot about it.\r\n\r\n> Do we want to accept None in that method, or do we not raise the warning for the case of assigning None ?\r\n\r\nI think that we should have a canonical way of removing crs and `set_crs(None, allow_override=True)` feels like the best way.\r\n\r\nIn the tests, we can potentially replace that by assigning to the `GeometryArray.crs` but allowing None in `set_crs` might be the best."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4d3ac254a19ac29df16",
    "number": 3087,
    "body": "I am always annoyed when geopandas `__repr__` shows all those unnecessary zeros when plotting coordinates. See our docstrings for example. \r\n\r\nIf we use `shapely.to_wkt` instead of `shapely.wkt.dump`, we get _smart_ precision. i.e. coordinates are shown in using a set precision but only when that makes sense. No additional zeros are added.\r\n\r\nExample of current behaviour:\r\n\r\n```py\r\n>>> geopandas.GeoSeries([LineString([(5, 5.333436425673), (0, 0)])])\r\n0    LINESTRING (5.00000 5.33344, 0.00000 0.00000)\r\ndtype: geometry\r\n```\r\n\r\nAfter the one line change in 5c6b8ac2751fb9e1d087580f5988adf35e6c7abe\r\n\r\n```py\r\n0    LINESTRING (5 5.33344, 0 0)\r\ndtype: geometry\r\n```\r\n\r\nI am even willing to change all those hard-coded values in our docstrings because this is imo infinitely better way of printing the coordinates.\r\n\r\nAny objections?",
    "head_branch": "repr_rounding",
    "is_a_fork": true,
    "comments": [
      "As I was expecting a ton of docstring tests failures that did not come, I realised that since the last CI update, we don't test docstrings at all...",
      "This is ready for review. I'd like to merge this soon to ensure that new examples created as part of the shapely parity project which will come with an increasing intensity can be generated only once.\r\n\r\nThe only code change is 5c6b8ac.",
      "Maybe just add a small whatsnew note about it?"
    ],
    "commit_messages": [
      "REF: trim trailing zeros in WKT to generate __repr__ (#3087)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4d3ac254a19ac29df17",
    "number": 3086,
    "body": "xref #2010\r\n\r\nI have also noticed that the changelog is not properly linted and did that while adding a note for the PR.",
    "head_branch": "snap",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: expose snap (#3086)\n\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4d4ac254a19ac29df18",
    "number": 3084,
    "body": "Closes #3079 \r\nCloses #2751 ",
    "head_branch": "remove_datasets",
    "is_a_fork": true,
    "comments": [
      "> Thanks a lot for looking into that!\r\n> \r\n> I suppose that the files won't be shipped in the wheel, correct?\r\n\r\nAt present, for this PR nybb is included, and naturalearth is excluded - that's not by design, it's just that I haven't updated the existing rules in `pyproject.toml::[tool.setuptools.package-data]`. I'm not sure what the \"right thing\" is to do here - I could see the argument we should include these so the test suite in the wheel/sdist works, but I could also see an argument that directing a downstream consumer to github for this would be fine too. I don't know but I'd imagine system linux package managers are working with source code from github rather than sdists/ wheels from pypi.\r\n\r\nEdit: We already are missing tests/data/overlay/** in our wheel and are not hearing about issues because of this, so perhaps we are fine to leave out.",
      "I think this is ready to go now - contrary to what I said at the meeting today, I had already updated the pyproject.toml so that datasets are excluded from the wheel. I've built it locally and confirmed they aren't present. \r\n\r\nI went ahead and added pytest skips into the fixtures, I've checked that the skips work locally, and also that they do not skip when run on github actions: https://github.com/geopandas/geopandas/actions/runs/7415769532/job/20179553948?pr=3124",
      "In its current form, I think this also resolves #2751.",
      "> Thanks a lot! I think this is ready. Can you just add a changelog note?\r\n\r\nWhoops, forgot to push it yesterday, should be there now.",
      "Thanks Matt!"
    ],
    "commit_messages": [
      "MAINT: Remove geopandas.datasets (#3084)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4d5ac254a19ac29df19",
    "number": 3083,
    "body": "Removing some dead code paths which are no longer executed / required. This started looking at the indirect coverage changes from #3001, but I also had a quick scan at coverage a bit more widely to pick up a few places with redundant lines.",
    "head_branch": "coverage_related_cleanups",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "MAINT: Coverage related cleanups (#3083)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4d6ac254a19ac29df1a",
    "number": 3080,
    "body": "xref #3060\r\n\r\nWith [6b4857e](https://github.com/geopandas/geopandas/pull/3080/commits/6b4857ec8d1bcccb52984d2af1b9685349d37ed7) we are down to a mere 34992 warnings (commits after are fixes for old pandas).\r\n\r\nWith [5d7d146](https://github.com/geopandas/geopandas/pull/3080/commits/5d7d14672255a6fdededc1b92416f8011adfd450) we are down to 346\r\n\r\n[482c989](https://github.com/geopandas/geopandas/pull/3080/commits/482c98926c37d6d2dab7c4c4fd950815a81a50d0) is a bit more convoluted than the others. Originally I didn't think we needed this, but there are warnings about this in e.g. test_clip.py (and with it we are down to 311). Since we have quite some logic for `GeoSeries._constructor_expanddim`, I opted to directly construct the dataframe (and fortunately we can actually do this in the DataFrame case as the `Series._name` being undefined as part of `from_mgr` is not an issue)\r\n\r\nWould not surprise me if this is not the 'right' way of doing some of this, I've kept some tabs on some of the relevant pandas PRs but not across it all.",
    "head_branch": "pandas_constructor_apis",
    "is_a_fork": true,
    "comments": [
      "Thanks @m-richards! I believe that all of the @jorisvandenbossche's comments were resolved so merging to get it all green again.",
      "@m-richards we should evaluate how safe it is to backport to this to release in 0.14.x. \r\n\r\nIt probably then also requires to backport one of your open PRs to address the regression?",
      "I created https://github.com/geopandas/geopandas/pull/3159 to have a look at how safely this could be done (I imagine we don't want to merge that PR though because it might be confusing since it's a collection of PRs on main). But if it looks good I'll split out the relevant commit to add."
    ],
    "commit_messages": [
      "COMPAT: add pandas blockmanager alternative apis for _constructor like things (#3080)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4d7ac254a19ac29df1b",
    "number": 3078,
    "body": "With CoW enabled, the index is not necessarily an identical object (in python `is` sence), but it's still identical from pandas' point of view, and pandas has a `Index.is_()` method to check for this. \r\n\r\nThis fixes a few of the failures on the dev build (where we test with CoW enabled)",
    "head_branch": "fix-cow-constructor-sliced",
    "is_a_fork": true,
    "comments": [
      "Yeah, me neither ;) My intention with `continue-on-error` was the same, but that's apparently not how it works. But some googling pointed to `always()` as alternative that actually does what you want."
    ],
    "commit_messages": [
      "BUG: fix getting row as Series for CoW (#3078)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4d8ac254a19ac29df1c",
    "number": 3075,
    "body": "Exposes Shapely's `transform` function according to ENH: #2010  ",
    "head_branch": "ENH_2010_expose_shapely_transform_function_to_geopandas",
    "is_a_fork": true,
    "comments": [
      "@martinfleis I have updated my branch according to your suggestions!"
    ],
    "commit_messages": [
      "ENH: Expose transform (#3075)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4d8ac254a19ac29df1d",
    "number": 3074,
    "body": "Closes #3069\r\n\r\nI suppose ideally this would have a regression test as part of the commit, but I'm not exactly sure how to produce some minimal test where the `buffer(0)` vs `make_valid` difference is present\r\n\r\n(and I suppose the changelog for 0.14.2 needs to be added to main as well, I'm not sure how I should have done this best, since the regression is already solved on main)",
    "head_branch": "overlay_regression",
    "is_a_fork": true,
    "comments": [
      "> I think it is fine as is. I am also unsure how to produce a minimal example that is affected by this. On the changelog, if we keep that under 0.14.2, we're fine, no?\r\n\r\nYep - just that it will need another pull request once this is merged, because this will put it in the changelog for 0.14.2 on the 0.14.x branch",
      "> Yep - just that it will need another pull request once this is merged, because this will put it in the changelog for 0.14.2 on the 0.14.x branch\r\n\r\nWill do that as a follow-up after making the release",
      "Dealing with the changelog on main here: https://github.com/geopandas/geopandas/pull/3123"
    ],
    "commit_messages": [
      "BUG: Overlay regression from incorrect refactor (#3074)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": true,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4d9ac254a19ac29df1e",
    "number": 3072,
    "body": null,
    "head_branch": "rls-0.14.1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "RLS/DOC: update changelog for 0.14.1 (#3072)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4daac254a19ac29df1f",
    "number": 3071,
    "body": "Backported:\r\n\r\n- https://github.com/geopandas/geopandas/pull/3066\r\n- https://github.com/geopandas/geopandas/pull/3057\r\n- https://github.com/geopandas/geopandas/pull/3067\r\n- https://github.com/geopandas/geopandas/pull/3070\r\n\r\nAnd in addition backported a few of the TST commits in the hope this gives a greener CI here.",
    "head_branch": "0.14.1-backports",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "RLS/DOC: update changelog for 0.14.1 (#3072)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": true,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4dbac254a19ac29df20",
    "number": 3070,
    "body": "Similar to https://github.com/apache/arrow/pull/38608, but doing it on our side as well for people that use latest geopandas with older pyarrow. \r\n(using a similar approach as https://github.com/pitrou/pyarrow-hotfix, without adding a required dependency on that package)\r\n\r\nI did a similar fix in pandas, but since geopandas uses pyarrow directly, instead of through pd.read_parquet, I thought I could add the same here.",
    "head_branch": "pyarrow-hotfix",
    "is_a_fork": true,
    "comments": [
      "Yes, I think that's a correct analysis."
    ],
    "commit_messages": [
      "Parquet/Feather IO: disable PyExtensionType autoload (#3070)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4dcac254a19ac29df21",
    "number": 3067,
    "body": "There are no spec changes between 1.0.0-b1 and 1.0.0, so it's just updating the used number for writing.",
    "head_branch": "geoparquet-1.0",
    "is_a_fork": true,
    "comments": [
      "Do you want to cut a patch with this soon?",
      "Yes, just opened https://github.com/geopandas/geopandas/issues/3068",
      "@jorisvandenbossche It looks like [the docstring for GeoDataframe.to_parquet()](https://geopandas.org/en/v0.14.1/docs/reference/api/geopandas.GeoDataFrame.to_parquet.html) might have missed being updated when this PR was merged? There's still a warning about [only tracking v0.4.0](https://github.com/geopandas/geopandas/blob/main/geopandas/geodataframe.py#L1042-L1109) and the allowed values for `schema_version` don't include 1.0.0."
    ],
    "commit_messages": [
      "ENH: support GeoParquet 1.0.0 spec (#3067)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4ddac254a19ac29df22",
    "number": 3066,
    "body": "Addressing https://github.com/geopandas/geopandas/issues/3065",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [
      "Actually, could you maybe use CartoDB Positron tiles rather than DarkMatter? I think it will look better.",
      "Can you use the \"OpenStreetMap HOT\" string instead of HOTOSM? The former resolvers to tiles, the latter will not. ",
      "@martinfleis It should be all set there.",
      "Thanks!"
    ],
    "commit_messages": [
      "Remove Stamen references from  plotting_basemap_background.ipynb (#3066)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4ddac254a19ac29df23",
    "number": 3062,
    "body": "Resolves #3043\r\n\r\nSomewhat different approach than #3044 (thanks @Jaapel for getting that started!).",
    "head_branch": "add_pyogrio_mask",
    "is_a_fork": true,
    "comments": [
      "I also renamed some of the test cases of bbox / mask for clarity"
    ],
    "commit_messages": [
      "ENH: Add support for mask keyword with pyogrio >= 0.7.0 (#3062)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4deac254a19ac29df24",
    "number": 3058,
    "body": "Resolves #3055 \r\n\r\nThis makes reading a data source that lacks geometry the same between the Fiona and Pyogrio engines by returning a Pandas DataFrame instead of a GeoDataFrame; this is also the same as the result when using the `ignore_geometry` keyword.\r\n\r\nI have this listed as an API change; should this be a potentially-breaking change instead?",
    "head_branch": "issue3055",
    "is_a_fork": true,
    "comments": [
      "> I have this listed as an API change; should this be a potentially-breaking change instead?\r\n\r\nYeah, I think it make sense to give it a tiny bit more visibility.",
      ">I have this listed as an API change; should this be a potentially-breaking change instead?\r\nI feel like this should probably be potentially-breaking, as someone might rely on the existence of the column called geometry, say if they populated it via `df.geometry = GeoSeries(...)` (even though set_geometry would be preferable as it is monkey patched onto pd.DataFrame).\r\n\r\nRelated edge case, what happens if there is a geometry field but there is all None values (i.e. a CSV with a column called geometry but all NaNs). Or does gdal work out that this is not actually geometry",
      "> Related edge case, what happens if there is a geometry field but there is all None values (i.e. a CSV with a column called geometry but all NaNs). Or does gdal work out that this is not actually geometry\r\n\r\nGDAL expects the geometry column in a CSV to be called [WKT](https://gdal.org/drivers/vector/csv.html#vector-csv) by default and expects WKT-encoded values.\r\n\r\nIf a column called \"geometry\" is present in the CSV (and GDAL isn't given an override to use it), whatever values are present in that column are preserved as-is when you read it, but it is returned as a DataFrame.  i.e., \"geometry\" does not have special meaning to GDAL as a column name in a CSV.\r\n\r\nIf a column called \"WKT\" is present (and GDAL is using this as default), GDAL detects this as a geo-enabled file, returns `{..., \"geometry\": \"Unknown\"}` for Fiona's schema, and both Fiona and Pyogrio return this as a GeoDataFrame with a `geometry` GeoSeries column, even if all values in the WKT column are missing / empty strings.  The raw WKT column is also included in the resulting GeoDataFrame.  If values in the WKT column cannot be parsed to geometries, they are returned as `None`.\r\n\r\nSo I think the key thing here is whether the data source includes a geometry field according to the way that GDAL detects geometry fields; if so - even if empty - this will return a GeoDataFrame.  Otherwise, if the data source does not include a geometry field in whatever way GDAL expects for that format, this will return a DataFrame.  I think that is the behavior we want in this case, rather than doing a secondary check that the detected geometry field is non-empty.\r\n\r\n",
      ">I think that is the behavior we want in this case, rather than doing a secondary check that the detected geometry field is non-empty.\r\n\r\nThanks for the detailed explanation, agree that the behaviour makes sense as is."
    ],
    "commit_messages": [
      "API: Fiona engine: return a Pandas DataFrame when no geometry available (#3058)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4dfac254a19ac29df25",
    "number": 3057,
    "body": "Stamen will no longer work in a few days and folium will directly depend on xyzservices. Removing the mention of Stamen for now and will update again once the implementation in folium is merged.",
    "head_branch": "stamen_doc",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: remove Stamen from explore docstring (#3057)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4e0ac254a19ac29df26",
    "number": 3056,
    "body": "No need for pip install of pointpats and matplotlib anymore (at least on a macOS).",
    "head_branch": "py312",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: install whole 3.12 env from conda-forge (#3056)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4e1ac254a19ac29df27",
    "number": 3052,
    "body": "Follow-up on #3026",
    "head_branch": "count",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "API: make count_coordinates a method (#3052)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4e1ac254a19ac29df28",
    "number": 3051,
    "body": null,
    "head_branch": "matt/test_pyogrio_datetime_support",
    "is_a_fork": true,
    "comments": [
      "Some unit (ms vs ns) differences that need to be taken into account, it seems",
      "Thanks!"
    ],
    "commit_messages": [
      "TST: enable pyogrio datetime tz tests (#3051)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4e2ac254a19ac29df29",
    "number": 3048,
    "body": "Before this fix, when the user tries to write a non CRS geometry on a PostGIS database, the action fails because the SRID was converted to -1 (Geopandas pattern), not 0 (PostGIS pattern).\r\n\r\nWell, one important observation: I also think that the test related to the last commit on this issue was not executed, because the test was correctly implemented and it must fail on the previous implementation.",
    "head_branch": "fix-topostgis-no-crs",
    "is_a_fork": true,
    "comments": [
      "Do you mean `test_write_postgis_without_crs`? This is run on CI - see here: https://github.com/geopandas/geopandas/actions/runs/6601942151/job/17933478854\r\nSo it seems there is something conditional about your situation that the existing test currently doesn't catch.\r\n\r\nEdit: looking at the code, are you using `if_exists==\"append\"`? I believe this case is not covered by that test. If that is the case, could you contribute a test/  extend the existing test covering the \"append\" case?",
      "Hi @m-richards ! Thanks for your response. I did'nt notice that the existing test \"test_write_postgis_without_crs\" doesn't catch the if_exists conditional.\r\n\r\nI will review and submit a new PR.",
      "You can submit changes as new commits directly on this PR",
      "@m-richards , just added \"append\" on the test. Now we try to save on PostGIS twice: first replacing, second appending. \r\n\r\nOne thing: somehow, CI/CD pre-commit is failing after linting my changes. Do you know why?",
      "> One thing: somehow, CI/CD pre-commit is failing after linting my changes. Do you know why?\r\n\r\nThis is due to the code formatting and linting rules we have as part of geopandas to keep things consistent. You might like to have a look at https://geopandas.org/en/latest/community/contributing.html#style-guide-linting, in particular the bit about `pre-commit` to keep your commits in sync with the style conventions. But for now, I've just pushed a commit which should resolve the linting, so the tests will run.",
      "@igorVinicius @m-richards might this have been fixed by https://github.com/geopandas/geopandas/pull/3328 in the meantime? (I see that PR changes -1 to 0 as well)",
      "> @igorVinicius @m-richards might this have been fixed by #3328 in the meantime? (I see that PR changes -1 to 0 as well)\r\n\r\nYep, and `test_append_without_crs` added there also covers the behaviour here, so we can close this. Nonetheless thanks @igorVinicius  for your initial efforts here."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4e3ac254a19ac29df2a",
    "number": 3047,
    "body": "When doing #3013, when @m-richards pointed out that we may need to keep the allocation of an empty array and then its population, we thought we don't since we thought it is shapely 1.8 related. Well, it was not :D. When there is no actual interior, this is now failing on main.\r\n\r\nFixed. No need for changelog as it fixed unreleased #3013.",
    "head_branch": "interiors_no_ints",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix interiors when no interior is present (#3047)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4e4ac254a19ac29df2b",
    "number": 3046,
    "body": "Addresses https://github.com/geopandas/geopandas/issues/2948\r\n\r\nIn recent pandas, internal construction from a Manager object no longer goes through `_constructor`, but there is now a `_constructor_from_mgr`. Overriding this so we can implement our \"_geoseries_constructor_with_fallback\" logic that we have for `_constructor` there as well.\r\n\r\nOur `GeoSeries._constructor` is `_geoseries_constructor_with_fallback`, which does:\r\n\r\nhttps://github.com/geopandas/geopandas/blob/49c208ab95fa7cebd8553cba264ea3dc65e272fd/geopandas/geoseries.py#L40-L51\r\n\r\nand currently the `GeoSeries(..)` init will raise that TypeError if being passed a manager that is not of geometry dtype.\r\n",
    "head_branch": "constructor-from-mgr",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "COMPAT: ensure GeoSeries fallback to Series for construction from mgr (#3046)\n\nCo-authored-by: Matt Richards <mrichards7@outlook.com.au>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4e5ac254a19ac29df2c",
    "number": 3044,
    "body": "Tested using: `pyogrio @ git+https://github.com/geopandas/pyogrio.git@4fe4abe1ab31fa05ec44df04a0a4677f56c57749`, should probably wait until the next release.",
    "head_branch": "main",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4e6ac254a19ac29df2d",
    "number": 3042,
    "body": null,
    "head_branch": "ci_numpy_dev",
    "is_a_fork": true,
    "comments": [
      "This is failing because shapely will use an older numpy in its isolated build environment, even when installing from git (or maybe we can pass the `--no-build-isolation` flag?). \r\nIt's on my todo list to fix this in shapely, will try to get to that this weekend!",
      "See https://github.com/shapely/shapely/issues/1972 for the details",
      "It seems that this finally works, resolves the matplotlib issues we see on main and uncovers two issues to be solved on our side.",
      "It's indeed good to test with numpy nightly on our side as well! (as it uncovers an issue for which we should do a release before numpy 2.0 hits ..) \r\nIt's a bit bizarre that scipy nightly (called through the pandas/matplotlib plotting code) was failing with released numpy, though. That shouldn't happen AFAIU. Opened an upstream issue about that -> https://github.com/scipy/scipy/issues/20286",
      "The failure with `explore` we see here is an upstream issue - https://github.com/python-visualization/folium/issues/1905. "
    ],
    "commit_messages": [
      "CI: include numpy nightlies in CI dev build (#3042)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4e6ac254a19ac29df2e",
    "number": 3041,
    "body": "I think that matplotlib is breaking it but let's give it a go and get it temporarily from pip if needed.",
    "head_branch": "312",
    "is_a_fork": true,
    "comments": [
      "Getting matplotlib from PyPI works. We also need to load pointpats from PyPI because it tries to pull matplotlib itself but that is okay. \r\n\r\nIt seems that the issue there lies in both pillow and GDAL are depending on libjpeg-turbo but there is no resolvable combination yet. Not sure if that is something to report or if should just wait until conda-forge migration is over.\r\n\r\nI'll keep matplotlib and pointpats commented out to remind us to change it once it resolves.",
      "Thanks for this effort! It's really nice to see how quickly the adoption of Python 3.12 is going in the geospatial stack, with [Fiona](https://github.com/Toblerity/Fiona/releases/tag/1.9.5), [rasterio](https://github.com/rasterio/rasterio/releases/tag/1.3.8.post2), [shapely](https://github.com/shapely/shapely/releases/tag/2.0.2) all having uploaded Python 3.12 wheels in the last week, and [rtree](https://github.com/Toblerity/rtree/pull/286) only needing to tag a release!"
    ],
    "commit_messages": [
      "CI: include Python 3.12 in the matrix (#3041)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4e7ac254a19ac29df2f",
    "number": 3040,
    "body": "The tests show a bunch of warnings from `test_file.py` coming from pyogrio.",
    "head_branch": "pyogrio-warnings",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: fix/suppress some warnings for the pyogrio tests (#3040)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4e8ac254a19ac29df30",
    "number": 3039,
    "body": "The latest dev version of pyogrio now supports `skip_features` that are not between 0 and the feature count (truncating larger values to the feature count, i.e. skipping all rows). This PR updates the test to follow that change.\r\n\r\nNegative values for `skip_features` are right now also interpreted as \"skip everything\", while here we allow a negative slice start to mean counting from the end. That's something we should decide what to do with this on the pyogrio side (if allowing negative skip_features, just letting it skip everything is also a bit confusing?) \r\nFor this PR, for now raising an error on our side about negative slice start in case of pyogrio.",
    "head_branch": "fix-pyogrio-rows",
    "is_a_fork": true,
    "comments": [
      "Per [pyogrio #312](https://github.com/geopandas/pyogrio/pull/312), it will now again raise an error on negative values (though a different error message than before).  Intercepting that and raising a different error on the GeoPandas side seems reasonable, since the keyword passed to pyogrio is different.",
      "Indeed, keeping the error message specific about the slice start as I did here seems good to keep.\r\n\r\nIn theory, we could also decide to support the negative slice on the geopandas side, by first querying the number of features. Of course, doing that in pyogrio can be slightly (or a lot, if the format doesn't support cheap feature count) more efficient, but on the other hand it doesn't really fit in pyogrio to support negative values, and I think it's also not the most important case to be as optimal as possible (I would assume it's typically used when exploring a dataset)"
    ],
    "commit_messages": [
      "TST: fix bbox test for latest pyogrio (#3039)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4e9ac254a19ac29df31",
    "number": 3038,
    "body": null,
    "head_branch": "fix-ci",
    "is_a_fork": true,
    "comments": [
      "Going to merge this, to get some greener CI"
    ],
    "commit_messages": [
      "TST/CI: correct pandas skip and ensure up to date matplotlib (#3038)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4eaac254a19ac29df32",
    "number": 3036,
    "body": "This was a bit out of date",
    "head_branch": "doc-install-wheel-update",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: update warning note about dependencies with pip (#3036)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4eaac254a19ac29df33",
    "number": 3032,
    "body": "Fixes #3031",
    "head_branch": "main",
    "is_a_fork": true,
    "comments": [
      "@BartoszBiernacki Thanks a lot for the PR, and our apologies for the slow follow-up.\r\n\r\nCould you add a test for this? (check `geopandas/tests/test_explore.py`)\r\n\r\nYou also have a linter failure because of some trailing whitespace. To avoid this kind of issues, I would personally recommend installing the pre-commit hook we have included in the repo which will check and fix those lint issues automatically. See https://geopandas.org/en/latest/community/contributing.html#style-guide-linting"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4ebac254a19ac29df34",
    "number": 3027,
    "body": "adding is_ccw from shapely",
    "head_branch": "add_is_ccw",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Add is_ccw from shapely (#3027)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Matt Richards <mrichards7@outlook.com.au>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4ecac254a19ac29df35",
    "number": 3026,
    "body": "Adding count coordinates from shapely",
    "head_branch": "add_count_coordinates",
    "is_a_fork": true,
    "comments": [
      "Missed this before, but shouldn't we make this a method instead of attribute? Especially the \"count\" in the name is really an action, and feels strange for an attribute (even though it is a relatively cheap \"characteristic\" of the geometries)",
      "> Missed this before, but shouldn't we make this a method instead of attribute\r\n\r\nI completely missed that... yes, it should've been a method."
    ],
    "commit_messages": [
      "ENH: Add count coordinates (#3026)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4edac254a19ac29df36",
    "number": 3025,
    "body": null,
    "head_branch": "issue_2818",
    "is_a_fork": true,
    "comments": [
      "@martinfleis could you please have a look at this? Issue: 2818 https://github.com/geopandas/geopandas/issues/2818",
      "Going to close this as there is nothing substantial included in the PR. Future contributions on this are welcome as comments on #2856 or #2818 though."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4eeac254a19ac29df37",
    "number": 3024,
    "body": null,
    "head_branch": "issue_2818",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4efac254a19ac29df38",
    "number": 3023,
    "body": "quick test to fix issue discussed in #326 which probably should be its own issue.",
    "head_branch": "crs_concat_set_issue",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Don't use set in concat CRS checking (#3023)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4efac254a19ac29df39",
    "number": 3022,
    "body": "xref https://github.com/geopandas/geopandas/discussions/3021",
    "head_branch": "typo",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: minor grammar fix (#3022)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4f0ac254a19ac29df3a",
    "number": 3018,
    "body": "Now we are on minimum pandas 1.4, `convert dtypes` should not longer need to be overloaded as https://github.com/pandas-dev/pandas/pull/44249 would always be included. Not sure about astype, but it looks like it could be removed too.\r\n\r\nEdit. Astype will have to wait until pandas 1.4 is dropped.",
    "head_branch": "remove_overloads",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CLN: Remove convert dtypes overload (#3018)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4f1ac254a19ac29df3b",
    "number": 3017,
    "body": "Continuation of #2604",
    "head_branch": "darshanip/main",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DEP: GeoSeries.geom_almost_equals (#3017)\n\nCo-authored-by: darshanpatidar1 <darshancoding@gmail.com>\r\nCo-authored-by: Darshan <36774606+darshanip@users.noreply.github.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4f2ac254a19ac29df3c",
    "number": 3013,
    "body": "Still WIP. A few notes:\r\n\r\n- it is a beast of a PR but it is mostly removal and only very minor changes in tests. It may help following individual commits. I also think that it is better to survive one large PR cleaning it all that having a series of smaller PRs in this specific case.\r\n- I have completely removed `_vectorized.py` and moved the code to `array.py`. In most cases a method is a single line calling shapely function now, so there is no point in having it separately. I assume that with spherely, we won't be wrapping it in existing `GeometryArray`  so it is not useful to have the file around in case spherely code will land there.\r\n- What do we want to do with the spatial index class? Shall we just have one `SpatialIndex` instead of `PyGEOSSTRTreeIndex` subclassing `BaseSpatialIndex`? Would a rename be considered too hard of a break (I don't think so)?\r\n- There are still some follow-ups, like the behavior of unary_union but those can be done later.\r\n- I haven't touched docs yet. \r\n- I haven't touched CI and min requirements either so minimal will likely fail.\r\n\r\nxref https://github.com/geopandas/geopandas/issues/2691",
    "head_branch": "future",
    "is_a_fork": true,
    "comments": [
      "This is now complete. The pygeos pickle testing will be a follow up (#3035).",
      "Let's merge?",
      "Thanks a lot Martin!\r\n\r\n> have been through the CI failures, test failures are from astype, matplotlib dev, geopandas/io/tests/test_file.py::test_read_file_filtered__rows_bbox[pyogrio], which is presumably pyogrio dev since it's not in the fiona version and pandas 2.2 dev stuff, so not related. \r\n\r\nHave opened PRs for the matplotlib and astype failures, and one for pyogrio\r\n\r\n> The project overall codecov is now failing (at a quite look __setstate__ pygeos is part of this, plus some exceptions are no longer being hit, but I think this is okay to leave as a follow up.\r\n\r\nThe pickling will be covered by the follow-up. And we also removed a lot of code, so the uncovered lines have become relatively speaking a bigger percentage ;)"
    ],
    "commit_messages": [
      "REF: remove support of PyGEOS and Shapely<2 (#3013)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>\r\nCo-authored-by: Matt Richards <mrichards7@outlook.com.au>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4f3ac254a19ac29df3d",
    "number": 3012,
    "body": "I just sorted the list of changes, added missing PR number and fixed formatting. I also went through the list of commits since 0.13.2 and it seems that we have it all included (when relevant).",
    "head_branch": "014",
    "is_a_fork": true,
    "comments": [
      "@jorisvandenbossche do you want to cut the release or shall I?",
      "Feel free to do so if you have time, otherwise I can do it during one of the next talks ;)",
      "Thanks for the release!"
    ],
    "commit_messages": [
      "RLS: prepare changelog for 0.14 (#3012)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4f4ac254a19ac29df3e",
    "number": 3011,
    "body": "I didn't realise this is not explore code that would pull data from xyzservices...",
    "head_branch": "fix_explore_guide",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: use included tilelayer in explore guide (#3011)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4f4ac254a19ac29df3f",
    "number": 3010,
    "body": "Few commits broken off from https://github.com/geopandas/geopandas/pull/2966 that have the actual code changes that are important to have in the release",
    "head_branch": "pandas-compat",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "COMPAT: fix warnings for latest pandas (#3010)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4f5ac254a19ac29df40",
    "number": 3008,
    "body": "Closes https://github.com/geopandas/geopandas/issues/2995",
    "head_branch": "pyogrio-docs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: update io user guide to mention pyogrio (#3008)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4f6ac254a19ac29df41",
    "number": 3007,
    "body": "`unary_union` should not be an attribute. There is no good way of deprecating an attribute and turning it into a method, so as discussed in person with @jorisvandenbossche, it may be the best to have a new method and deprecate an attribute. We can have a longer deprecation here, `unary_union` does not need to be removed in 1.0.",
    "head_branch": "union_all",
    "is_a_fork": true,
    "comments": [
      "The dev is passing because there's been a timeout error when fetching pandas nightly wheel https://github.com/geopandas/geopandas/actions/runs/6169793856/job/16744795666?pr=3007#step:3:307",
      "It is properly failing now :)",
      "@jorisvandenbossche are we fine with this? I would like to expose `coverage_union_all` via a keyword in here as a follow-up.",
      "Is it correct that `union_all()` isn't available in current stable GeoPandas? If so, would it make sense to backport it to 0.14, to make sure it's replacement is available before deprecating `unary_union` in 1.0.0?",
      "> Is it correct that union_all() isn't available in current stable GeoPandas?\r\n\r\nYes\r\n\r\n>  If so, would it make sense to backport it to 0.14, to make sure it's replacement is available before deprecating unary_union in 1.0.0?\r\n\r\nI don't think so. The behaviour does not change, there's only a warning popping up at the moment.\r\n",
      "Thanks!\r\n\r\nA 1.0.0 version is just a bit of a strange version to start introducing new warnings, so that threw me of. Most of the time you need to resolve warnings to be compatible with a major new version.",
      "Yeah, ideally we had _enforced_ the deprecation in 1.0.0, but we were to late with introducing the warning.\r\n\r\nGiven this is an often-used attribute, we should maybe start with a DeprecationWarning instead of a FutureWarning, though (so you don't see it as user if downstream libraries are still using it, but only when using it yourself directly)",
      "> we should maybe start with a DeprecationWarning instead of a FutureWarning\r\n\r\n+1 on that",
      "Thanks for picking this up, sounds like a good idea!\r\n\r\nFor context, this is how my notebook now looks:\r\n\r\n![image](https://github.com/geopandas/geopandas/assets/15776622/334fd322-8556-4640-afba-37570e0f34c2)\r\n\r\n(a few thousands of those)",
      "I suppose that with #3313, this should clear up and hopefully osmnx will cut a release adapting the code to union_all before the e switch to FutureWarning again. "
    ],
    "commit_messages": [
      "API: use union_all() and deprecate unary_union (#3007)\n\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4f7ac254a19ac29df42",
    "number": 3006,
    "body": "Stamen is [deprecating](https://stamen.com/here-comes-the-future-of-stamen-maps/) they're tiles. Removing their usage from our docs. \r\n\r\nThey are further mention in `explore` as a reference to folium. There I would wait for https://github.com/python-visualization/folium/issues/1803 to be resolved.\r\n\r\nThe same issue is in the notebook describing contextily, where we should first resolve https://github.com/geopandas/contextily/issues/220.",
    "head_branch": "stamen",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: remove Stamen tiles from docs (#3006)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4f8ac254a19ac29df43",
    "number": 3005,
    "body": "Bumps [actions/checkout](https://github.com/actions/checkout) from 3 to 4.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/actions/checkout/releases\">actions/checkout's releases</a>.</em></p>\n<blockquote>\n<h2>v4.0.0</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Update default runtime to node20 by <a href=\"https://github.com/takost\"><code>@​takost</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1436\">actions/checkout#1436</a></li>\n<li>Support fetching without the --progress option by <a href=\"https://github.com/simonbaird\"><code>@​simonbaird</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1067\">actions/checkout#1067</a></li>\n<li>Release 4.0.0 by <a href=\"https://github.com/takost\"><code>@​takost</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1447\">actions/checkout#1447</a></li>\n</ul>\n<h2>New Contributors</h2>\n<ul>\n<li><a href=\"https://github.com/takost\"><code>@​takost</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/checkout/pull/1436\">actions/checkout#1436</a></li>\n<li><a href=\"https://github.com/simonbaird\"><code>@​simonbaird</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/checkout/pull/1067\">actions/checkout#1067</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/checkout/compare/v3...v4.0.0\">https://github.com/actions/checkout/compare/v3...v4.0.0</a></p>\n<h2>v3.6.0</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Mark test scripts with Bash'isms to be run via Bash by <a href=\"https://github.com/dscho\"><code>@​dscho</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1377\">actions/checkout#1377</a></li>\n<li>Add option to fetch tags even if fetch-depth &gt; 0 by <a href=\"https://github.com/RobertWieczoreck\"><code>@​RobertWieczoreck</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/579\">actions/checkout#579</a></li>\n<li>Release 3.6.0 by <a href=\"https://github.com/luketomlinson\"><code>@​luketomlinson</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1437\">actions/checkout#1437</a></li>\n</ul>\n<h2>New Contributors</h2>\n<ul>\n<li><a href=\"https://github.com/RobertWieczoreck\"><code>@​RobertWieczoreck</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/checkout/pull/579\">actions/checkout#579</a></li>\n<li><a href=\"https://github.com/luketomlinson\"><code>@​luketomlinson</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/checkout/pull/1437\">actions/checkout#1437</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/checkout/compare/v3.5.3...v3.6.0\">https://github.com/actions/checkout/compare/v3.5.3...v3.6.0</a></p>\n<h2>v3.5.3</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Fix: Checkout Issue in self hosted runner due to faulty submodule check-ins by <a href=\"https://github.com/megamanics\"><code>@​megamanics</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1196\">actions/checkout#1196</a></li>\n<li>Fix typos found by codespell by <a href=\"https://github.com/DimitriPapadopoulos\"><code>@​DimitriPapadopoulos</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1287\">actions/checkout#1287</a></li>\n<li>Add support for sparse checkouts by <a href=\"https://github.com/dscho\"><code>@​dscho</code></a> and <a href=\"https://github.com/dfdez\"><code>@​dfdez</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1369\">actions/checkout#1369</a></li>\n<li>Release v3.5.3 by <a href=\"https://github.com/TingluoHuang\"><code>@​TingluoHuang</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1376\">actions/checkout#1376</a></li>\n</ul>\n<h2>New Contributors</h2>\n<ul>\n<li><a href=\"https://github.com/megamanics\"><code>@​megamanics</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/checkout/pull/1196\">actions/checkout#1196</a></li>\n<li><a href=\"https://github.com/DimitriPapadopoulos\"><code>@​DimitriPapadopoulos</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/checkout/pull/1287\">actions/checkout#1287</a></li>\n<li><a href=\"https://github.com/dfdez\"><code>@​dfdez</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/checkout/pull/1369\">actions/checkout#1369</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/checkout/compare/v3...v3.5.3\">https://github.com/actions/checkout/compare/v3...v3.5.3</a></p>\n<h2>v3.5.2</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Fix: Use correct API url / endpoint in GHES by <a href=\"https://github.com/fhammerl\"><code>@​fhammerl</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1289\">actions/checkout#1289</a> based on <a href=\"https://redirect.github.com/actions/checkout/issues/1286\">#1286</a> by <a href=\"https://github.com/1newsr\"><code>@​1newsr</code></a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/checkout/compare/v3.5.1...v3.5.2\">https://github.com/actions/checkout/compare/v3.5.1...v3.5.2</a></p>\n<h2>v3.5.1</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Improve checkout performance on Windows runners by upgrading <code>@​actions/github</code> dependency by <a href=\"https://github.com/BrettDong\"><code>@​BrettDong</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1246\">actions/checkout#1246</a></li>\n</ul>\n<h2>New Contributors</h2>\n<ul>\n<li><a href=\"https://github.com/BrettDong\"><code>@​BrettDong</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/checkout/pull/1246\">actions/checkout#1246</a></li>\n</ul>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/actions/checkout/blob/main/CHANGELOG.md\">actions/checkout's changelog</a>.</em></p>\n<blockquote>\n<h1>Changelog</h1>\n<h2>v4.0.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1067\">Support fetching without the --progress option</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1436\">Update to node20</a></li>\n</ul>\n<h2>v3.6.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1377\">Fix: Mark test scripts with Bash'isms to be run via Bash</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/579\">Add option to fetch tags even if fetch-depth &gt; 0</a></li>\n</ul>\n<h2>v3.5.3</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1196\">Fix: Checkout fail in self-hosted runners when faulty submodule are checked-in</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1287\">Fix typos found by codespell</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1369\">Add support for sparse checkouts</a></li>\n</ul>\n<h2>v3.5.2</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1289\">Fix api endpoint for GHES</a></li>\n</ul>\n<h2>v3.5.1</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1246\">Fix slow checkout on Windows</a></li>\n</ul>\n<h2>v3.5.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1237\">Add new public key for known_hosts</a></li>\n</ul>\n<h2>v3.4.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1209\">Upgrade codeql actions to v2</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1210\">Upgrade dependencies</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1225\">Upgrade <code>@​actions/io</code></a></li>\n</ul>\n<h2>v3.3.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1045\">Implement branch list using callbacks from exec function</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1050\">Add in explicit reference to private checkout options</a></li>\n<li>[Fix comment typos (that got added in <a href=\"https://redirect.github.com/actions/checkout/issues/770\">#770</a>)](<a href=\"https://redirect.github.com/actions/checkout/pull/1057\">actions/checkout#1057</a>)</li>\n</ul>\n<h2>v3.2.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/942\">Add GitHub Action to perform release</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/967\">Fix status badge</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1002\">Replace datadog/squid with ubuntu/squid Docker image</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/964\">Wrap pipeline commands for submoduleForeach in quotes</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1029\">Update <code>@​actions/io</code> to 1.1.2</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1039\">Upgrading version to 3.2.0</a></li>\n</ul>\n<h2>v3.1.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/939\">Use <code>@​actions/core</code> <code>saveState</code> and <code>getState</code></a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/922\">Add <code>github-server-url</code> input</a></li>\n</ul>\n<h2>v3.0.2</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/770\">Add input <code>set-safe-directory</code></a></li>\n</ul>\n<h2>v3.0.1</h2>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/actions/checkout/commit/3df4ab11eba7bda6032a0b82a6bb43b11571feac\"><code>3df4ab1</code></a> Release 4.0.0 (<a href=\"https://redirect.github.com/actions/checkout/issues/1447\">#1447</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/8b5e8b768746b50394015010d25e690bfab9dfbc\"><code>8b5e8b7</code></a> Support fetching without the --progress option (<a href=\"https://redirect.github.com/actions/checkout/issues/1067\">#1067</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/97a652b80035363df47baee5031ec8670b8878ac\"><code>97a652b</code></a> Update default runtime to node20 (<a href=\"https://redirect.github.com/actions/checkout/issues/1436\">#1436</a>)</li>\n<li>See full diff in <a href=\"https://github.com/actions/checkout/compare/v3...v4\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/checkout&package-manager=github_actions&previous-version=3&new-version=4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
    "head_branch": "dependabot/github_actions/actions/checkout-4",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "CI: Bump actions/checkout from 3 to 4 (#3005)\n\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4f9ac254a19ac29df44",
    "number": 3004,
    "body": "Our custom equals implementation uses `_data` which is deprecated and triggers a warning on pandas >=2.1, but it looks like we only have this to work around a pandas issue. Just running on CI to see what removing this does.\r\n\r\nSeems not to cause any issues.",
    "head_branch": "remove_equals_override",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "COMPAT: Remove base.equals override (#3004)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4f9ac254a19ac29df45",
    "number": 3002,
    "body": "Just adding in the fact that when we use shapely over pygeos when pygeos is the selected engine, we need to convert the result back to pygeos (as originally noted here). This will all go away in 1.0 anyway, but still a bug for now.\r\nhttps://github.com/geopandas/geopandas/pull/2940#discussion_r1273415232\r\n",
    "head_branch": "fix_concave_hull_pygeos",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix pygeos compat for concave hull (#3002)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4faac254a19ac29df46",
    "number": 3001,
    "body": "Thought it might be a good idea to update our dependencies if we're aiming to do a release soonish. This is based on the [SPEC 0](https://scientific-python.org/specs/spec-0000/) time windows, and I used a modified version of the included code snippet (https://gist.github.com/m-richards/ea4a156b702b27641d81c32d195dfc98) to work out the package ranges. Note that it's not perfect (fiona 1.8.20 is missing for some reason) but it's certainly easier than manually checking pypi for everything.\r\n\r\nThe only variation I've made is for fiona, where I've updated the dependency range taking into account micro releases, since there were so many 1.8.x releases.\r\n\r\nI just touched the dependencies which affect our code and those specified in the CI envs, except I left pyarrow, mapclassify and the sql related dependencies.\r\n\r\nWe can also potentially reduce the number of CI envs, as we have a lot of 3.9 environments after this, but I think that would be easier to review as a separate pull request.",
    "head_branch": "update_min_deps",
    "is_a_fork": true,
    "comments": [
      "Thanks both!"
    ],
    "commit_messages": [
      "Update minimum package dependencies (#3001)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4fbac254a19ac29df47",
    "number": 3000,
    "body": null,
    "head_branch": "fix_sjoin_test",
    "is_a_fork": true,
    "comments": [
      "Thanks! \r\nI think `geopandas/tools/tests/test_sjoin.py::TestNearest::test_sjoin_nearest_exclusive[None-expected0]` will need a similar change?",
      "I think this now works, final dev failures are just astype and the EA null dtype tests",
      "Thanks!"
    ],
    "commit_messages": [
      "TST: update groupby metadata test for pandas 2.1 (#3000)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4fcac254a19ac29df48",
    "number": 2999,
    "body": "The title says it all.",
    "head_branch": "default_engine",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Switch the default geometry engine to Shapely (#2999)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4fdac254a19ac29df49",
    "number": 2997,
    "body": "The `GeometryDtype.na_value` in practice is `None` (this is being returned when accessing a missing value), but the attribute itself it set to NaN. \r\n\r\nIn the past I remember that it gave some test failures, but let's see what it does now.",
    "head_branch": "dtype-na_value",
    "is_a_fork": true,
    "comments": [
      "And indeed, it gives a whole bunch of errors, it seems up to pandas 2.0. So we might be able to change this in the future when supporting pandas >= 2.0",
      "> And indeed, it gives a whole bunch of errors, it seems up to pandas 2.0. So we might be able to change this in the future when supporting pandas >= 2.0\r\n\r\nI imagine defining `na_value` conditionally based on pandas version would be bad?  (I could imagine this might be a problem for pickling but not sure)",
      "It might not be too bad to make `na_value` dependent on the pandas version, but I would personally like to avoid that I think",
      "With https://github.com/pandas-dev/pandas/pull/54930 this is no longer needed, and I suppose we can close this. (Though longer term it's perhaps still worth looking at setting the NA value to None for consistency once we only support pandas >=2)",
      "Merged this with main again now that we support pandas >=2 only. Seems we may as well just do this for consistency, since the behaviour is that the na_value is None in practice (and maybe that let's the pandas side simplify tests if they want to)",
      "I'd say let's go ahead and merge this.",
      "> I'd say let's go ahead and merge this.\r\n\r\nAgree, easy to revert if there's some unforseen consequence down the line."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4fdac254a19ac29df4a",
    "number": 2996,
    "body": "Nightlies of core scientific python projects are now on https://pypi.anaconda.org/scientific-python-nightly-wheels not on https://pypi.anaconda.org/scipy-wheels-nightly/. Changing the repository and switching pandas and matplotlib to install from that nightly wheel rather than building from source.",
    "head_branch": "nightly",
    "is_a_fork": true,
    "comments": [
      "It looks like the whole anaconda.org is currently down, so all our dev builds hang now, but I promise this will work once they're up again :D",
      "This currently doesn't currently do what I would expect it to, it's not pulling in the numpy latest - it looks like it's being installed by mamba, because pyarrow depends on it. It's also pulling in matplotlib 3.8.0rc1 from regular pypi, rather than 3.8.0.dev from the anaconda pypi",
      "> it's not pulling in the numpy latest - it looks like it's being installed by mamba, because pyarrow depends on it\r\n\r\nthat seems to be the case on main as well. do you know if there is a way to force reinstall without doing that as a manual step later in the action? \r\n\r\n> It's also pulling in matplotlib 3.8.0rc1 from regular pypi, rather than 3.8.0.dev from the anaconda pypi\r\n\r\nhmm, that is a result of including `--extra-index-url https://pypi.org/simple`. I can drop that but it is recommended by the Scientific Python to keep it there to ensure pip knows where to pull potential dependencies from.",
      "> > it's not pulling in the numpy latest - it looks like it's being installed by mamba, because pyarrow depends on it\r\n> \r\n> that seems to be the case on main as well. do you know if there is a way to force reinstall without doing that as a manual step later in the action?\r\n\r\nNot that I'm aware of, although we may be able to just install pyarrow with pip as well? (and avoid needing numpy at the mamba stage)\r\n\r\n> > It's also pulling in matplotlib 3.8.0rc1 from regular pypi, rather than 3.8.0.dev from the anaconda pypi\r\n> \r\n> hmm, that is a result of including `--extra-index-url https://pypi.org/simple`. I can drop that but it is recommended by the Scientific Python to keep it there to ensure pip knows where to pull potential dependencies from.\r\n\r\npretty sure we need to keep the extra index url, otherwise fiona won't be able to be installed. Ideally the conda pypi would be set up to forward missed packages to pypi, as gitlab does (https://docs.gitlab.com/ee/user/packages/pypi_repository/#install-from-the-project-level) in which case you only need to use `index-url` and there is no ambiguity, I think at least. \r\n\r\nIn this particular case I wonder if the `rc` is treated as \"newer\" when it's looked up and it may not be an issue in general (regardless, this is still a step forward from pointing at the old outdated location).\r\n\r\n",
      "> install pyarrow with pip as well\r\n\r\nlet's try that.\r\n\r\n> In this particular case I wonder if the rc is treated as \"newer\" when it's looked up and it may not be an issue in general \r\n\r\nI think so. This is likely an issue that will occasionally come and go.",
      "Gettin `pyarrow` via pip did resolve the numpy installation.",
      "There are a lot of failures due to incompatibility between stable pyarrow and the latest numpy... \r\n\r\nI've opened an issue to solve those in mapclassify here https://github.com/pysal/mapclassify/pull/186. \r\n\r\nNot sure what to do about the pyarrow issues. Maybe dropping pyarrow from this env for now?",
      "> Not sure what to do about the pyarrow issues. Maybe dropping pyarrow from this env for now?\r\n\r\nI suppose the question is whether we think we are more likely to have issues from numpy 2.0 or pyarrow specific issues related to dev versions of pandas. At a guess I think the latter is more likely? Also at some point presumably pyarrow will actually become a required dependency for pandas and we'll be back to this issue (that will happen for pandas 3.0, but it's not currently declared in the pyproject.toml) Happy to go either way for now.\r\n\r\n",
      "I hoped that pulling the pyarrow nightly would resolve the numpy compatibility but they did not catch up yet (https://github.com/apache/arrow/issues/37574).\r\n\r\nI would like to have both in the dev build. Maybe we could temporarily xfail those? I am not sure what is the best solution as these things will likely happen.",
      "I switched to numpy from conda as the 2.0 is causing too much noise right now. That seems to work okay."
    ],
    "commit_messages": [
      "CI: use the new nightly repo (#2996)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4feac254a19ac29df4b",
    "number": 2994,
    "body": "Failure with latest pandas release, as described in https://github.com/geopandas/geopandas/issues/2948. I am skipping that part of the test just for pandas 2.1.0, assuming we will fix it by pandas 2.1.1.",
    "head_branch": "skip-astype-failure",
    "is_a_fork": true,
    "comments": [
      "Thanks @jorisvandenbossche!",
      "> assuming we will fix it by pandas 2.1.1\r\n\r\npandas 2.1.1 is now in Debian experimental, and geopandas still fails with it as reported in [Debian Bug #1053941](https://bugs.debian.org/1053941):\r\n```\r\n151s =================================== FAILURES ===================================\r\n151s _________________________________ test_astype __________________________________\r\n151s \r\n151s s = 0    POINT (0.000000000 0.000000000)\r\n151s 1    POINT (1.000000000 1.000000000)\r\n151s 2    POINT (2.000000000 2.000000000)\r\n151s dtype: geometry\r\n151s df =                           geometry  value1  value2\r\n151s 0  POINT (0.000000000 0.000000000)       0       1\r\n151s 1  POINT (1.000000000 1.000000000)       1       2\r\n151s 2  POINT (2.000000000 2.000000000)       2       1\r\n151s \r\n151s     def test_astype(s, df):\r\n151s         # check geoseries functionality\r\n151s         with pytest.raises(TypeError):\r\n151s             s.astype(int)\r\n151s     \r\n151s         assert s.astype(str)[0] == \"POINT (0 0)\"\r\n151s     \r\n151s         res = s.astype(object)\r\n151s         if not Version(pd.__version__) == Version(\"2.1.0\"):\r\n151s             # https://github.com/geopandas/geopandas/issues/2948 - bug in pandas 2.1.0\r\n151s >           assert isinstance(res, pd.Series) and not isinstance(res, GeoSeries)\r\n151s E           AssertionError: assert (True and not True)\r\n151s E            +  where True = isinstance(0    POINT (0.000000000 0.000000000)\\n1    POINT (1.000000000 1.000000000)\\n2    POINT (2.000000000 2.000000000)\\ndtype: geometry, <class 'pandas.core.series.Series'>)\r\n151s E            +    where <class 'pandas.core.series.Series'> = pd.Series\r\n151s E            +  and   True = isinstance(0    POINT (0.000000000 0.000000000)\\n1    POINT (1.000000000 1.000000000)\\n2    POINT (2.000000000 2.000000000)\\ndtype: geometry, GeoSeries)\r\n151s \r\n151s geopandas/tests/test_pandas_methods.py:256: AssertionError\r\n```\r\nhttps://ci.debian.net/data/autopkgtest/unstable/amd64/p/python-geopandas/38997837/log.gz",
      "Yes, indeed, and so we updated the version check in the test: https://github.com/geopandas/geopandas/pull/3038 (that's not in the released version though, so hopefully you can add a skip/xfail in the debian testing for it)"
    ],
    "commit_messages": [
      "TST: skip astype(object) check in test for pandas 2.1.0 (#2994)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d4ffac254a19ac29df4c",
    "number": 2993,
    "body": "It's a bit a specific corner case, but so when having all your center points for the Hilbert curve calculation on a horizontal or vertical line (i.e. with constant x values or constant y values), we would do a division by zero (from the range of x or y values).\r\n\r\nI added a check for a width of zero to avoid this warning. \r\nBut also updated the extension array test to use different data, to avoid this brittleness in the tests we inherit from pandas, and added a dedicated test.\r\n\r\nThis should fix the current failure for `test_extension_array.py::TestMethods::test_argsort_missing` (which was failing because pandas upstream added a `assert_produces_warning` that isn't expecting additional warnings from numpy).",
    "head_branch": "hilbert-warning",
    "is_a_fork": true,
    "comments": [
      "The non-dev CI builds that are failing now only have a single remaining failure for `test_astype`, which is being silenced in https://github.com/geopandas/geopandas/pull/2994, so with those two PRs, the CI should be green again except for the dev build."
    ],
    "commit_messages": [
      "BUG: Avoid numpy invalid warning in Hilbert distance for points with constant x or y values (#2993)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d500ac254a19ac29df4d",
    "number": 2992,
    "body": null,
    "head_branch": "dev-test-cow-strings",
    "is_a_fork": true,
    "comments": [
      "With the one fix to `iterfeatures`, all tests seem to be passing: all failures are known ones happening on main as well (https://github.com/geopandas/geopandas/issues/2998), and the one remaining failure `test_rebuild_on_multiple_col_selection` just needs an update (it's specifically testing that a multi-column getitem is copying the underlying arrays)"
    ],
    "commit_messages": [
      "CI: test pandas future options (CoW and strings) in dev build (#2992)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d501ac254a19ac29df4e",
    "number": 2989,
    "body": "adding minimum_clearance from shapely",
    "head_branch": "add_minimum_clearance",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: add minimum_clearance to geopandas from shapely (#2989)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d501ac254a19ac29df4f",
    "number": 2988,
    "body": "xref #2010",
    "head_branch": "reverse",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: expose reverse (#2988)\n\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d502ac254a19ac29df50",
    "number": 2986,
    "body": "Fixing some of the warnings we have on the dev build:\r\n\r\n```\r\n geopandas/tests/test_extension_array.py::TestMissing::test_fillna_series\r\n  /home/runner/work/geopandas/geopandas/geopandas/tests/test_extension_array.py:372: FutureWarning: ExtensionArray.fillna added a 'copy' keyword in pandas 2.1.0. In a future version, ExtensionArray subclasses will need to implement this keyword or an exception will be raised. In the interim, the keyword is ignored by GeometryArray.\r\n    result = ser.fillna(fill_value)\r\n```\r\n\r\nI have to check if this is properly tested in the upstream tests we inherit (maybe not since they were not failing before, only warning)",
    "head_branch": "fillna-copy",
    "is_a_fork": true,
    "comments": [
      "Added to the docstring and added a small dedicated test.\r\n\r\nRemaining failures are unrelated."
    ],
    "commit_messages": [
      "COMPAT: add fillna copy keyword for pandas 2.1 (#2986)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d503ac254a19ac29df51",
    "number": 2985,
    "body": "- Added support to geometry sindex attribute for query() function by predicate \"dwithin\".  \r\n- Also enabled similar functionality for \"sjoin\" function, both with new optional parameter \"distance\".  \r\n- Added \"dwithin\" predicate support with distance parameter for benchmark.sjoin.Bench.time_sjoin().\r\n- Added pytest case for executing this function.  Can be executed with `pytest geopandas\\tests\\test_sindex.py -k test_dwithin_predicate`\r\n- Did not add dwithin predicate to query_bulk() method due to deprecation.\r\n- _PYGEOS_PREDICATES sourced from shapely.strtree.BinaryPredicates do NOT include value for dwithin predicate, so predicate check includes additional comparison operation against string \"dwithin\", along with other keys from BinaryPredicates (overlaps, contains, etc.).\r\n\r\n[SOURCE ISSUE](https://github.com/geopandas/geopandas/issues/2882)\r\n",
    "head_branch": "issue_2882",
    "is_a_fork": true,
    "comments": [
      "@aleczoeller thanks for your contribution!  This looks similar in intent but is presently smaller in scope than #2900 which also adds this functionality and has undergone review and approval by at least one maintainer.  I don't mean to sound dismissive of your efforts here, but I'm curious if you were aware of that PR and if there was some other angle unique to your PR that hasn't already been addressed by #2900?",
      "Hi @brendan-ward - thanks for the feedback, no I was unaware of the other issue!  If this is covered that's no problem.  If any element might be helpful, like the test, just let me know.  For now I'll close the PR. "
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d504ac254a19ac29df52",
    "number": 2984,
    "body": "When writing to PostGIS, I want the option to allow mixed geometries in a table. The current behaviour of `to_postgis` implicitly disallows this by setting the geometry type to whatever the first dataframe type is to populate that table.\r\n\r\nThis change simply looks to see if the user has defined the geometry dtype first. If not then it continues with the original behaviour of setting the geometry type to the dataframe, otherwise it leaves the dtype untouched and allows the user to specify the target table geometry type.\r\n\r\n\r\n```python\r\ndf.to_postgis(\r\n    con=engine, name=name, if_exists=\"append\",\r\n    dtype={\"geometry\": Geometry(geometry_type='GEOMETRY', srid=4326)})  # <-- This config persists on table creation and population\r\n```\r\n\r\nAddresses:\r\nhttps://github.com/geopandas/geopandas/issues/2612\r\nhttps://github.com/geopandas/geopandas/issues/2661\r\n",
    "head_branch": "main",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d505ac254a19ac29df53",
    "number": 2982,
    "body": "This make the geodatasets package more discoverable.\r\n\r\nWorks as expected:\r\n\r\n![Screen Shot 2023-08-21 at 12 56 20 PM](https://github.com/geopandas/geopandas/assets/17162724/e5542d29-b828-491f-9c17-cceda0b731df)\r\n",
    "head_branch": "raybellwaves-patch-1",
    "is_a_fork": true,
    "comments": [
      "Shall we maybe link to https://geodatasets.readthedocs.io/en/latest/ instead of the repo?"
    ],
    "commit_messages": [
      "DOC: hyperlink geodatasets in README.md (#2982)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d505ac254a19ac29df54",
    "number": 2981,
    "body": "Closes #2979",
    "head_branch": "pytz",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: compat with tzdata (2023c-8) (#2981)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d506ac254a19ac29df55",
    "number": 2978,
    "body": "Looks like pandas decided to change how these extension array tests work (https://github.com/pandas-dev/pandas/pull/54355)",
    "head_branch": "update_ea_tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "MAINT: Update EA tests to use assert series equal directly. (#2978)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d507ac254a19ac29df56",
    "number": 2971,
    "body": "Based on [issue 2378](https://github.com/geopandas/geopandas/issues/2378) not so much [pr 1920](https://github.com/geopandas/geopandas/pull/1920)",
    "head_branch": "main-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d508ac254a19ac29df57",
    "number": 2970,
    "body": "Previously, when plotting GeoDataFrames and NaNs or None values are in the column to be plotted and a numpy array of marker sizes is provided, the alignment between non-NaN column values and marker sizes is ensured by [masking](https://github.com/geopandas/geopandas/blob/b4b10313ab57bf2c55592a28fb99687c9a538fc2/geopandas/plotting.py#L879) the markersize array (as introduced in 6ac19052c811b39fea88b40625c69246f733709d). However, only numpy arrays are supported resulting in unexpectedly different behavior when passing another list-like markersize argument such as a pandas Series or plain list.\r\n\r\nTo ensure a consistent user experience, this PR adds support for any list-like markersize argument.\r\n\r\nSnippet to reproduce the issue:\r\n```\r\nimport numpy as np\r\nimport pandas as pd\r\nimport geopandas as gpd\r\n\r\nmarkercolor = [1, np.nan, None, 4]\r\nmarkersize = [100, 300, 900, 2700]\r\n\r\ndf = pd.DataFrame(data={'markercolor': markercolor})\r\ngeo = gpd.points_from_xy([1, 2, 3, 4], [1, 2, 3, 4])\r\ngdf = gpd.GeoDataFrame(df, geometry=geo, crs='EPSG:3035')\r\n\r\ngdf.plot(markersize=markersize)\r\ngdf.plot(column='markercolor', markersize=markersize)\r\ngdf.plot(column='markercolor', markersize=np.array(markersize))\r\ngdf.plot(column='markercolor', markersize=pd.Series(markersize))\r\n```",
    "head_branch": "fix-missing-data-plotting",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d509ac254a19ac29df58",
    "number": 2969,
    "body": "Automatic update of Versioneer by the `versioneer.yml` workflow.",
    "head_branch": "update-versioneer",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Update Versioneer (#2969)\n\nCo-authored-by: martinfleis <martinfleis@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d50aac254a19ac29df59",
    "number": 2966,
    "body": null,
    "head_branch": "reduce_warnings",
    "is_a_fork": true,
    "comments": [
      "@m-richards what is the state of this? With pandas 2.1, some of the warnings are propagated to a user (categorical dtype checks). Would be good to resolve that in 0.14.",
      "> @m-richards what is the state of this? With pandas 2.1, some of the warnings are propagated to a user (categorical dtype checks). Would be good to resolve that in 0.14.\r\n\r\nI'll have another look, I think it's left as draft as there was more that could be done, but there's probably enough changes in this PR as is already.\r\n\r\nEdit: I think this is fine to review as is, although I can add to it if there are other warnings that are missing and particularly noisy.",
      "> I pushed the same change of categorical dtype from plot to explore but the rest looks great! Thanks for this!\r\n\r\nThanks, that's a good one to add. I've just pushed 4 more commits, which are all fairly simple warning catching in the tests.",
      "In the last commit (https://github.com/geopandas/geopandas/pull/2966/commits/09189ce7350993b2740c9ed48fa0f91bb70faf67), I reverted a change to silence a warning in a groupby test. Because with this change, the test is now failing with latest geopandas (maybe related to the _constructor changes?). In any case something to further investigate, but let's do that in a follow-up such that this PR can be merged (I also want to do a general follow-up for fixing more warnings).",
      "Related to that last commit, a reproducer from that test:\r\n\r\n```python\r\nfrom shapely.geometry import Point\r\nfrom geopandas import GeoDataFrame\r\n\r\ncrs = \"EPSG:4326\"\r\n\r\ndf = GeoDataFrame(\r\n    {\r\n        \"geometry\": [Point(0, 0), Point(1, 1), Point(0, 0)],\r\n        \"value1\": np.arange(3, dtype=\"int64\"),\r\n        \"value2\": np.array([1, 2, 1], dtype=\"int64\"),\r\n    },\r\n    crs=crs,\r\n)\r\n\r\n# dummy test asserting we can access the crs\r\ndef func(group):\r\n    assert isinstance(group, GeoDataFrame)\r\n    assert group.crs == crs\r\n\r\n# original code, warning with latest pandas about group key being included in applied group\r\ndf.groupby(\"value2\").apply(func)\r\n# proposed fix to avoid the warning, now failing\r\ndf.groupby(\"value2\")[df.columns].apply(func)\r\n```\r\n\r\nThis is failing since #3080, but I think this is rather a bug on the pandas side (not calling finalize when doing the column selection, and thus the active geometry name is not passed on), and essentially similar as the other follow-up issue from #3080: this was previously only working because of passing the data to GeoDataFrame which then defaults to \"geometry\" column. If changing the above example to use a different column name, it was already failing before #3080"
    ],
    "commit_messages": [
      "MAINT: Reduce warnings in CI (#2966)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d50aac254a19ac29df5a",
    "number": 2965,
    "body": "I've found that in my newest local dev environment I still get the windows specific dtype errrors that caused a selection of tests to be skipped in #2862. \r\nThis is with python 3.11 and\r\n```\r\nPYTHON DEPENDENCIES\r\n-------------------\r\ngeopandas  : 0.13.2+19.g27c48cf\r\nnumpy      : 1.25.1\r\npandas     : 2.1.0.dev0+1237.gc92b3701ef\r\npyproj     : 3.6.0\r\nshapely    : 2.0.1\r\n```\r\nso it's not somehow related to python 3.8.\r\n\r\nFix seems to be straightforward, in our index_parts code we do a cumsum over a boolean array which then is implicitly converted to the numpy platform default dtype (int32 on windows). ",
    "head_branch": "fix_windows_disabled_tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: resolve windows specific dtype test failures (#2965)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d50bac254a19ac29df5b",
    "number": 2964,
    "body": "The GeoPandas docs installation page references the pointpats package and links to https://pointpats.readthedocs.io/en/latest/, which doesn't exist. This trivial PR fixes the link by pointing to the homepage https://pysal.org/pointpats/ instead.",
    "head_branch": "main",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: broken pointpats link in docs (#2964)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d50cac254a19ac29df5c",
    "number": 2963,
    "body": "Exposing `polygonize` on the GeoPandasBase level. In the end, I have opted to expose both `polygonize` and `polygonize_full` within a single method as it was easy enough and especially dangles can be quite useful even when you are not debugging the result.\r\n\r\nUnlike shapely, we also include the noding step but not through `node` but using `unary_union` which has the same effect but is faster and more robust according to https://github.com/libgeos/geos/issues/877#issuecomment-1521056559.",
    "head_branch": "polygonize",
    "is_a_fork": true,
    "comments": [
      "@jorisvandenbossche good points, all in."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d50dac254a19ac29df5d",
    "number": 2961,
    "body": "Description: This pull request updates the docstring for the dissolve function in the geopandas package to accurately document the options for the by parameter.\r\n\r\nChanges Made: Modified the docstring to indicate that the by parameter can accept either a string or a list-like object.\r\n\r\nPlease review and merge this pull request. Thank you for your attention to this matter.",
    "head_branch": "update-docstring-for-dissolve",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Update dissolve docstring to document options for the \"by\" parameter (#2961)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d50eac254a19ac29df5e",
    "number": 2960,
    "body": null,
    "head_branch": "shortest_line",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: add shortest_line from shapely (#2960)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d50fac254a19ac29df5f",
    "number": 2959,
    "body": "Closes #2889",
    "head_branch": "apply_edge_case",
    "is_a_fork": true,
    "comments": [
      "> This is a weird pattern...\r\n> \r\n> The fix is okay I guess, I would just suggest users not to get there :).\r\n\r\nAgree and Agree, but we can still fix it regardless. "
    ],
    "commit_messages": [
      "BUG: fix apply axis=1 edge case for nested data (#2959)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d50fac254a19ac29df60",
    "number": 2958,
    "body": "Files with .fgb extension will now use the FlatGeobuf driver by default in `GeoDataFrame.to_file()`.\r\n\r\nCloses #2957",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Link files with .fgb extension to FlatGeobuf driver (#2958)\n\nCo-authored-by: Matt Richards <mrichards7@outlook.com.au>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d510ac254a19ac29df61",
    "number": 2956,
    "body": "This PR aims to enable reading geoalchemy WKTs and WKBs with SRID information in them. See documentation here: https://geoalchemy-2.readthedocs.io/en/latest/elements.html",
    "head_branch": "read_geoalchemy_WKBElement",
    "is_a_fork": true,
    "comments": [
      "@martinfleis We have a dilemma here: either we have to devise a way to read the SRID from the raw data (hex or string), or convert the WKBElements into strings before passing them off to lib.from_wkb. Should an attempt be made to convert the elements to strings or bytes?\r\n\r\nI solved it now by converting elements to string when needed. It's not very clean, though.",
      "Now I've used the shapely get_srid method as suggested in https://github.com/geopandas/geopandas/issues/2952. EWKT reading is not working, with the following:\r\n\r\n```\r\nFAILED geopandas/tests/test_geoseries.py::TestSeries::test_from_ewkt - pygeos.GEOSException: ParseException: Unknown type: 'SRID=4326;POLYGON'\r\nFAILED geopandas/tests/test_geoseries.py::TestSeries::test_from_ewkt_series - pygeos.GEOSException: ParseException: Unknown type: 'SRID=4326;POLYGON'\r\n```\r\nIt seems GEOS is not able to read this format.\r\nOne option is to not do EWKT at all. Another is to remove the SRID header manually, which is slow and requires geopandas to keep track of possible changes to the standard.\r\n\r\nWhat do you think?",
      "Could you also check what is the performance hit on this one? I.e. how long does it take to get srids compared to the geometry decoding. We may want to add an option to completely avoid that path, even for `crs=None`."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d511ac254a19ac29df62",
    "number": 2953,
    "body": "Added integer_object_nulls parameter to table.to_pandas() call, since table is of type pyarrow.parquet and can process columns this way.\r\n\r\nI added a test that recreates this entire possible situation - a null value Object type series concatenated with an integer, written to parquet and then checked to ensure the original int64 type doesn't default to Object. This is added as test_read_parquet_int() method to test_pandas_methods.py.\r\n\r\nChange to accommodate [issue 2951](https://github.com/geopandas/geopandas/issues/2951)\r\n\r\n",
    "head_branch": "issue_2951",
    "is_a_fork": true,
    "comments": [
      "Hi @aleczoeller, thanks for the pull request on this. Please have a look at the comment I've just left in #2951 - I don't think this approach is the best way forward to solve that issue. But please feel free to join the discussion on that issue if you see otherwise, or update this pull request to accomodate.\r\n\r\nGenerally, it is always good to add a test when changing behaviour - even if the code path is well covered by existing tests - clearly our existing tests did not catch the issue that was created. Explicit tests are also very useful for us in order to prevent regressions in the code.",
      "Hi @m-richards , thanks for your feedback on the issue thread (I'll respond there as well).  This makes perfect sense, so I added a test that recreates this entire possible situation - a null value Object type series concatenated with an integer, written to parquet and then checked to ensure the original int64 type doesn't default to Object.  This is added as test_read_parquet_int() method to test_pandas_methods.py.\r\n\r\nI left the to_pandas() kwarg use_nullable_dtypes in (for now at least) because based on my reading geopandas is using pyarrow.parquet.read_table() instead of pandas.read_parquet(). "
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d512ac254a19ac29df63",
    "number": 2950,
    "body": "Let columns of dtype `np.int32` (non-nullable) and `pandas.Int32Dtype()` (nullable) be inferred as int32 columns instead of int(64). Needed for the `OGR_GMT` driver.\r\n\r\nRelated:\r\n- https://github.com/GenericMappingTools/pygmt/pull/2592\r\n- https://github.com/geopandas/geopandas/issues/967#issuecomment-842999302\r\n\r\nSimilar PRs in the past:\r\n- https://github.com/geopandas/geopandas/pull/2265\r\n- https://github.com/geopandas/geopandas/pull/2464",
    "head_branch": "infer_int32_schema",
    "is_a_fork": true,
    "comments": [
      "Just to add some context, a fix to allow writing int32s as int32s (pandas nullable dtype or otherwise) is certainly welcome. #2464 stalled because it also tried to adjust the schema for tab files such that all integer fields were written as int32s - which is not ideal if you have int64 values outside the int32 range (this auto converting is something that could be revisited as a follow up). It doesn't seem like that is a problem for your use case, I understand from the linked issue OGR_GMT only supports 32 bit dtypes.",
      "> a fix to allow writing int32s as int32s (pandas nullable dtype or otherwise) is certainly welcome\r\n\r\nThanks @m-richards for the context! Done in 6859d6c1ebc2410d6e44141eb0b04ff1476c8a49, so I'll mark this PR ready for review. Happy to add more unit tests if needed :smiley:\r\n\r\nYou're right that we just need the auto-schema detection to output int32 when either a nullable or non-nullable int32 column is used. It doesn't look like the [`_to_file`](https://github.com/geopandas/geopandas/blob/55fa5134dd0e74388209641807ee1c4aa572967d/geopandas/io/file.py#L452-L549) function does much in terms of driver-specific dtype casting, and it's probably best not to introduce too much driver-specific logic there, so we'll probably workaround the int64 cast to int32 separately in PyGMT at https://github.com/GenericMappingTools/pygmt/pull/2592.",
      "> You're right that we just need the auto-schema detection to output int32 when either a nullable or non-nullable int32 column is used. It doesn't look like the [`_to_file`](https://github.com/geopandas/geopandas/blob/55fa5134dd0e74388209641807ee1c4aa572967d/geopandas/io/file.py#L452-L549) function does much in terms of driver-specific dtype casting, and it's probably best not to introduce too much driver-specific logic there, so we'll probably workaround the int64 cast to int32 separately in PyGMT at [GenericMappingTools/pygmt#2592](https://github.com/GenericMappingTools/pygmt/pull/2592).\r\n\r\nAs I understand it, Fiona is the low-level library that supports different drivers? Does it makes more sense that Fiona should do driver-specific casting (e.g., `int64` to `int32` for OGR_GMT)?",
      "> > You're right that we just need the auto-schema detection to output int32 when either a nullable or non-nullable int32 column is used. It doesn't look like the [`_to_file`](https://github.com/geopandas/geopandas/blob/55fa5134dd0e74388209641807ee1c4aa572967d/geopandas/io/file.py#L452-L549) function does much in terms of driver-specific dtype casting, and it's probably best not to introduce too much driver-specific logic there, so we'll probably workaround the int64 cast to int32 separately in PyGMT at [GenericMappingTools/pygmt#2592](https://github.com/GenericMappingTools/pygmt/pull/2592).\r\n> \r\n> As I understand it, Fiona is the low-level library that supports different drivers? Does it makes more sense that Fiona should do driver-specific casting (e.g., `int64` to `int32` for OGR_GMT)?\r\n\r\nFrom https://github.com/Toblerity/Fiona/issues/1277#issuecomment-1613427767, it seems that fiona will only follow what GDAL is doing, so we might need to make the change in GDAL instead? Or upstream in GMT itself?",
      "> so we might need to make the change in GDAL instead?\r\n\r\nCasting int64 to int32 may cause problems if the data is out of the int32 range, so what GDAL does (converting int64 to string) makes sense to me. Maybe we can ask GDAL to make OGR_GMT support int64 types.\r\n\r\n",
      "> > so we might need to make the change in GDAL instead?\r\n> \r\n> Casting int64 to int32 may cause problems if the data is out of the int32 range, so what GDAL does (converting int64 to string) makes sense to me. Maybe we can ask GDAL to make OGR_GMT support int64 types.\r\n\r\nOk, do we need to add support in GDAL for integer64 before GMT C can handle int64 columns from OGR_GMT files, or the other way round? I see this sentence at https://github.com/GenericMappingTools/gmt/blob/6.4.0/doc/rst/source/cookbook/ogrgmt-format.rst#declaration-of-aspatial-fields:\r\n\r\n> Available datatypes should largely follow the shapefile (DB3) specification, including string, integer, double, datetime, and logical (boolean). In OGR/GMT vector files, they will be stored as appropriately formatted text strings.\r\n>\r\n> An example header record containing all these is\r\n>\r\n> ```\r\n> # @VGMT1.0 @GPOLYGON @Nname|depth|id @Tstring|double|integer\r\n> ```\r\n\r\nReferring back to https://github.com/OSGeo/gdal/blob/6e9103bd5acb1ff8da305c4e77fa30335ffa3b70/ogr/ogrsf_frmts/gmt/ogrgmtlayer.cpp#L754-L773, the 'double' refers to Real values (floating point), whereas 'integer' is int32 only, we would need to use 'integer64' instead in GDAL.\r\n\r\nAlternatively, I saw at https://github.com/GenericMappingTools/gmt/pull/3296#discussion_r422554772 that there was a warning like this:\r\n\r\n```\r\nWarning 1: The output driver does not seem to natively support Integer64 type for field FID. Converting it to Real instead. -mapFieldType can be used to control field type conversion.\r\n```\r\nSo maybe we could also convert int64 values to float64 in GMT?\r\n\r\nEIther way, this PR should still be helpful for other drivers like Mapinfo TAB files.",
      "> I think it would be good to add a test to `test_file` to write a file and see how the int32 dtypes are round-tripped for a couple of drivers (perhaps, gpkg, geojson, gmt).\n> \n> I don't think it's necessary that the round trip is one-to-one (that would be ideal), but it would be nice to still have a test showing the current limitations if any.\n\nSorry for the late reply, got caught up with some other stuff. I've added a test for writing to/from shp/gpkg/geojson/gmt files at dd6d5ad69c8b62a3d5aebb8ed0b2bf9482a4a2c1, see if that's ok.",
      "> Sorry for the late reply, got caught up with some other stuff. \r\n\r\nNo worries at all, thanks for coming back to revisit this!\r\n\r\n>I've added a test for writing to/from shp/gpkg/geojson/gmt files at [dd6d5ad](https://github.com/geopandas/geopandas/commit/dd6d5ad69c8b62a3d5aebb8ed0b2bf9482a4a2c1), see if that's ok.\r\n\r\nLooks great, thanks for that. I hope you don't mind, I'm just going to push a small change - I've just checked locally and can see that we should be able to enable pyogrio for these tests, and moreover pyogrio will route trip the int32 dtype if there are no nulls.\r\n\r\n"
    ],
    "commit_messages": [
      "BUG: Infer schema for np.int32 and pd.Int32Dtype columns properly (#2950)\n\nCo-authored-by: Matt Richards <mrichards7@outlook.com.au>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d513ac254a19ac29df64",
    "number": 2947,
    "body": "We didn't merge main in before merging #2027 which made ruff unhappy on main. ",
    "head_branch": "fix_linting",
    "is_a_fork": true,
    "comments": [
      "Thanks a bunch! Sorry for the extra work",
      "We see some `urllib.error.URLError: <urlopen error [Errno -3] Temporary failure in name resolution>` but since they suggest temporality and are for sure not caused by this, I'll merge this."
    ],
    "commit_messages": [
      "MAINT: fix linting issue caused by a merge of #2027 (#2947)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d514ac254a19ac29df65",
    "number": 2944,
    "body": "Closes #2942 ",
    "head_branch": "fix_crs_colname",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Fix crash on constructing gdf with colname `crs` (#2944)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d514ac254a19ac29df66",
    "number": 2943,
    "body": "Closes #2941 \r\n\r\nAdding a simple property allowing a user to safely check if there is an active geometry column set or not.",
    "head_branch": "has_geom",
    "is_a_fork": true,
    "comments": [
      "We don't want a user to be able to do\r\n```py\r\ngdf.active_geometry_name = \"my_other_column\"\r\n```\r\ninstead of calling `set_geometry`, I suppose, so we would need to have some kind of a similar logic of private-public attribute or a different way of dealing with that anyway. So it may be just fine to keep it as is?\r\n",
      "> We don't want a user to be able to do\r\n> \r\n> ```python\r\n> gdf.active_geometry_name = \"my_other_column\"\r\n> ```\r\n> \r\n> instead of calling `set_geometry`, I suppose, so we would need to have some kind of a similar logic of private-public attribute or a different way of dealing with that anyway. So it may be just fine to keep it as is?\r\n\r\nYep, thanks a good reason to keep as a property.",
      "Thoughts on the exact name of the property: `active_geometry_name` vs `active_geometry_column` vs `active_geometry_column_name` ? \r\n(I like the \"column\" in there, as that is how you typically speak about this, but then the full \"column name\" gets a bit long, and just \"column\" might be interpreted as the actual column)",
      "> Thoughts on the exact name of the property: `active_geometry_name` vs `active_geometry_column` vs `active_geometry_column_name` ? \n> (I like the \"column\" in there, as that is how you typically speak about this, but then the full \"column name\" gets a bit long, and just \"column\" might be interpreted as the actual column)\n\nI think name needs to be in there, or otherwise it seems likely to be confused with `.geometry`.  \n\nI don't mind `active_geometry_column_name` being verbose given it's explicit and I expect it's not going to be used super often. While I think it's good the property name lines up with how the active geometry column name might be described in text, I don't feel 'column' necessarily needs to be there - for other geodataframe methods that operate on the qctive geometry column we don't bake 'column' into the name. ",
      "I don't think we need to include \"column\" in there, while I do think \"name\" should be there. What is here now doesn't seem to be ambiguous in my eyes so I would use it as is. "
    ],
    "commit_messages": [
      "ENH: add GeoDataFrame.active_geometry_name (#2943)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d515ac254a19ac29df67",
    "number": 2940,
    "body": "Implements the shapely remove_repeated_points method as part of https://github.com/geopandas/geopandas/issues/2010",
    "head_branch": "remove_repeated_points",
    "is_a_fork": true,
    "comments": [
      "@JamesGardiner is this ready for review?",
      "@martinfleis not yet - I've been caught up with other activities the last few weeks. I'll look to get it out of draft over the weekend",
      "@martinfleis I'm getting an odd failure in CI for this that I haven't had time to get to the bottom of yet. The issue is that in `Tests / ubuntu-latest, ci/envs/39-pd13-conda-forge.yaml` I get an error `TypeError: One of the arguments is of incorrect type. Please provide only Geometry objects.` - this only occurs in that specific test env and from what I can see the geometry is valid",
      "@JamesGardiner That looks like some weird mismatch between shapely and pygeos when testing docstrings. I'll have a look. ",
      "Thanks @martinfleis - I did some testing and it looks like it's isolated to the Linestring in the docstring",
      "Looks like that worked @m-richards - thanks!",
      "Thanks @JamesGardiner!"
    ],
    "commit_messages": [
      "ENH: add remove_repeated_points as a GeoSeries method (#2940)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d516ac254a19ac29df68",
    "number": 2939,
    "body": "On L96 of `tools.overlay._overlay_difference` there is currently a call to `GeoSeries.buffer(0)` that is made on a set of geometries that, based on the code on L95, is guaranteed to consist of only Polygons and MultiPolyons. My presumption is that the intent of this line is to ensure that all these geometries are valid and `buffer(0)` was used for historical reasons. `make_valid` is a more efficient way of accomplishing this.\r\n\r\nIn testing a [new feature for the censusdis project](https://github.com/vengroff/censusdis/pull/121#discussion_r1241221117) we found that the current use of `buffer(0)` in the code mentioned above caused roughly a 15x performance degradation over using `make_valid`.\r\n\r\nThis is my first PR to geopandas, but I ran tests locally as the [Contributing Guide](https://geopandas.org/en/stable/community/contributing.html) suggested and saw no regressions. So I am hopeful that this change has no negative effects but improves performance both for us and for other users of geopandas.",
    "head_branch": "dev/overlay-difference-make-valid",
    "is_a_fork": true,
    "comments": [
      "Based on a few test failures it looks like we need to handle older versions of shapely with the old `buffer(0)` approach. Will try to add that within the next 24h or so."
    ],
    "commit_messages": [
      "PERF: replace buffer(0) with make_valid() in _overlay_difference (#2939)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d517ac254a19ac29df69",
    "number": 2938,
    "body": null,
    "head_branch": "main",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Spelling errata (#2938)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d518ac254a19ac29df6a",
    "number": 2934,
    "body": null,
    "head_branch": "read-postgis-infer-geom",
    "is_a_fork": true,
    "comments": [
      "Going to work on this a bit more before submitting."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d518ac254a19ac29df6b",
    "number": 2933,
    "body": "Closes #2932. Due to the constructor changes we don't seem to need to overload merge anymore. This has the side benefit that args and kwargs are not obvuscated, users can directly see the pandas parameters.",
    "head_branch": "fix_dataframe_return_type",
    "is_a_fork": true,
    "comments": [
      "Can you update the changelog to include this under dev?",
      "Thanks!"
    ],
    "commit_messages": [
      "BUG: fix merge return type for colname collision (#2933)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d519ac254a19ac29df6c",
    "number": 2929,
    "body": "adding frechet distance method for geopandas from shapely",
    "head_branch": "frechet_distance",
    "is_a_fork": true,
    "comments": [
      "Thanks @kaushiksrini!"
    ],
    "commit_messages": [
      "ENH: add frechet_distance method (#2929)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d51aac254a19ac29df6d",
    "number": 2926,
    "body": "Fixes #2899",
    "head_branch": "test-sjoin",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Fixed conditions on test_sjoin in test_geodataframe, so that test is not unnecessarily skipped (#2926)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d51bac254a19ac29df6e",
    "number": 2925,
    "body": "Implements the shapely node method as part of https://github.com/geopandas/geopandas/issues/2010",
    "head_branch": "node",
    "is_a_fork": true,
    "comments": [
      "This is another one that requires an API discussion first. I am not certain what we want to do here. Try focusing on easy cases first (1-1 relationship between input geom and output geom like concave_hull) before tackling not so clear functions.",
      "A typical use case for `node` is a street network. You have individual LineStrings, with names, speed etc. You notice that the topology is broken and you need to include additional nodes, eg. prior calling a polygonize or doing anything else. I suppose that the expectation of the outcome would be to get back the same GeoDataFrame with LineStrings that now have additional nodes where they meet with other LineStrings.\r\n\r\nThe current implementation in this PR does not do that.\r\n\r\nMy suggestion would be to try to merge all geometries to a single GeometryCollection, call `node`, and explode it back to the original state, so we can preserve all the attributes.\r\n\r\n@JamesGardiner I will put this on the agenda for the next dev call on Thursday.",
      "This was discussed during the dev call and we decided to postpone the implementation of the method until GEOS exposes noding as a window function (discussed in https://github.com/libgeos/geos/issues/877). With the current API, we would not be able to create the API a user would expect from us.",
      "Great, thanks for the update @martinfleis - I'll close this for now."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d51cac254a19ac29df6f",
    "number": 2923,
    "body": "Closes #2922\r\n\r\nWe need to pass `k` from `binning`, not the one passed as an argument as `mapclassify.classify` may result in different number of bins (esp. with `UserDefined` scheme).",
    "head_branch": "userdefined_bins",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix a color assignment in ``explore`` when using ``UserDefined`` bins (#2923)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d51dac254a19ac29df70",
    "number": 2921,
    "body": "Setting up `ruff` as a linter alongside `black`, replacing `flake8` and extending the amount of rules we shall follow. \r\n\r\nruff settings is copied from pandas at the moment. The first commit just switches (and pre-commit will fail). I'll push fixes in subsequent commits to keep better track of changes.",
    "head_branch": "ruff",
    "is_a_fork": true,
    "comments": [
      "I suppose we can merge?",
      "Thanks!"
    ],
    "commit_messages": [
      "MAINT: use ruff instead of flake8 (#2921)\n\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>\r\nCo-authored-by: Matt Richards <mrichards7@outlook.com.au>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d51eac254a19ac29df71",
    "number": 2919,
    "body": "Closes #2918",
    "head_branch": "regr-file-uri",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REGR: fix read_file with file:// URIs (#2919)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d51eac254a19ac29df72",
    "number": 2916,
    "body": "Implements the shapely build_area method as part of https://github.com/geopandas/geopandas/issues/2010",
    "head_branch": "build_area",
    "is_a_fork": true,
    "comments": [
      "Thinking about this a bit further from the API perspective - the result coming from shapely is always a geometry, never an array, right? Therefore it is similar to `unary_union` that does not return GeoSeries but the geometry. We should probably first think about the best way of exposing it as I am not sure a single-geometry GeoSeries is a right solution.\r\n\r\nWe will have a similar discussion on `polygonize` and a couple of other functions (I'll open issues for that).",
      "That's right, it always returns the Geometry rather than an array. I'll hold off on any further changes pending the outcome of that discussion.",
      "The optimal API for `build_area` and `polygonize` has been [discussed](https://hackmd.io/pq8MqmtxTFqqaiayFuuEYQ?view#2023-07-06) during the last dev meeting and we agreed that given a GeoSeries of (Multi)LineStrings, the method should combine all geometries in a single GeometryCollection, call the function of the collection and return a GeoSeries composed of individual parts of the results (i.e. exploded geometry).\r\n\r\nWe should thoroughly test if creating a GeometryCollection is enough or of we need to do the union to ensure proper topology (important esp. for polygonize). Potentially, there could be a keyword controlling the behaviour.\r\n\r\nIf someone wants to do the element-wise `build_area`, they can always use `shapely.build_area` on a GeoSeries.",
      "@martinfleis that makes sense - I'll look to update this PR ASAP"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d51fac254a19ac29df73",
    "number": 2915,
    "body": "Implements the shapely extract_unique_points method as part of https://github.com/geopandas/geopandas/issues/2010",
    "head_branch": "extract_unique_points",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: add extract_unique_points as a GeoSeries property (#2915)\n\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d520ac254a19ac29df74",
    "number": 2914,
    "body": "Fixes https://github.com/geopandas/geopandas/issues/2908\r\n\r\nAlternative for https://github.com/geopandas/geopandas/pull/2912, since that didn't fix all cases of urls that no longer work. \r\nThe approach in this PR is to only _not_ download the data ourselves ~if the url has an extension~ if the url indicates to support reading ranges (and in that case we assume the /vsicurl/ filesystem will work), and in all other cases still download the data as we did before, passing the raw bytes to pyogrio/fiona. \r\nIf later pyogrio/fiona have better support for urls, we could again consider passing through all urls.\r\n",
    "head_branch": "fix-read-url",
    "is_a_fork": true,
    "comments": [
      "Given that there are also urls with extension that don't work out of the box with `/vsicurl`, I switched the approach here to check whether the URL supports partial reads (https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Ranges). \r\nThe idea is that `/vsicurl` is mostly (only?) useful in those cases, as it is especially important to be able read parts of large files. I verified that the original driving use case from https://github.com/geopandas/geopandas/issues/2795 (reading from large gpkg with spatial filter) works with this approach."
    ],
    "commit_messages": [
      "REGR: fix read_file from urls (#2914)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d521ac254a19ac29df75",
    "number": 2913,
    "body": "Renaming the keyword to follow the ecosystem-wide discussion outlined in https://github.com/scientific-python/specs/pull/180",
    "head_branch": "rng",
    "is_a_fork": true,
    "comments": [
      "@jorisvandenbossche didn't you want this in 0.13.1?"
    ],
    "commit_messages": [
      "REF: deprecate seed keyword to rng in sample_points (#2913)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d522ac254a19ac29df76",
    "number": 2912,
    "body": "Handles (part of?) https://github.com/geopandas/geopandas/issues/2908",
    "head_branch": "fix-read-url-without-zip-extension",
    "is_a_fork": true,
    "comments": [
      "This doesn't solve all cases (also other urls that are not \"zip files without extension\" are failing now), so closing in favor of https://github.com/geopandas/geopandas/pull/2914"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d522ac254a19ac29df77",
    "number": 2910,
    "body": "Implements the shapely segmentize method as part of https://github.com/geopandas/geopandas/issues/2010",
    "head_branch": "segmentize",
    "is_a_fork": true,
    "comments": [
      "Thanks @JamesGardiner!"
    ],
    "commit_messages": [
      "ENH: add segmentize as a GeoSeries method (#2910)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d523ac254a19ac29df78",
    "number": 2909,
    "body": "implements hausdorff distance, from #2010 ",
    "head_branch": "hausdorff_distance",
    "is_a_fork": true,
    "comments": [
      "~~it looks like a test is timing out and failing despite only changelog change. is there a way to rerun the checks?~~ \r\n\r\nit passed!",
      "Thanks @kaushiksrini!"
    ],
    "commit_messages": [
      "ENH: add hausdorff distance method (#2909)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d524ac254a19ac29df79",
    "number": 2907,
    "body": "Implements the shapely delaunay_triangles method as part of https://github.com/geopandas/geopandas/issues/2010",
    "head_branch": "delaunay_triangles",
    "is_a_fork": true,
    "comments": [
      "Thanks @JamesGardiner! And @m-richards for review!"
    ],
    "commit_messages": [
      "ENH: add delaunay_triangles as GeoSeries method (#2907)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d525ac254a19ac29df7a",
    "number": 2906,
    "body": "`mamba-org/provision-with-micromamba` is [deprecated](https://github.com/mamba-org/provision-with-micromamba) and it is recommended to use `setup-micromamba` instead. \r\n\r\nI will self-merge this once the CI gets green.",
    "head_branch": "mamba",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: use mamba-org/setup-micromamba action (#2906)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d527ac254a19ac29df7b",
    "number": 2903,
    "body": "Implements the shapely concave_hull method as part of https://github.com/geopandas/geopandas/issues/2010.\r\n\r\nCloses #1739 ",
    "head_branch": "concave_hull",
    "is_a_fork": true,
    "comments": [
      "Thanks @JamesGardiner! (and I saw you fixed one of the changelog numbers I think perhaps I added with an error, good spot)"
    ],
    "commit_messages": [
      "ENH: add concave_hull as GeoSeries method (#2903)\n\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d527ac254a19ac29df7c",
    "number": 2902,
    "body": "Implements the shapely offset_curve method as part of #2010",
    "head_branch": "offset_curve",
    "is_a_fork": true,
    "comments": [
      "@martinfleis do you want the new methods to explicitly add shapely parameters to the Geopandas methods, or would you prefer passing them through as kwargs and pointing users to the shapely docs?",
      "Better ton be explicit. We risk getting out of sync but it is easier for a user to see the whole signature rather that fishing in shapely docs which kwargs are allowed.",
      "Thanks for the second review @m-richards - no rush on my end to get these merged"
    ],
    "commit_messages": [
      "ENH: add offset_curve as GeoSeries method (#2902)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d528ac254a19ac29df7d",
    "number": 2900,
    "body": "This is my first pull request and a response to #2882, feedback very welcome. I have incorporated the ``predicate=\"dwithin\"`` and `distance` arugment into sindex, also for rtree structures, and written corresponding tests into test_sindex.py and test_geodataframe. I'm not 100% sure about version compatibility for 'dwithin' but have specified either:\r\n\r\nUSE_SHAPELY_20 or \r\nUSE_PYGEOS and PyGEOS >=0.12.0 and GEOS >= 3.10.0\r\n\r\nsince dwithin requires GEOS 3.10.0 and PyGEOS only [added this feature in 0.12.0 ](https://pygeos.readthedocs.io/en/latest/changelog.html)\r\n\r\nModification of __compat.py was necessary to track these version requirements.\r\n\r\nDocstring for query in sindex has been updated to include 'dwithin' in predicates and to include examples using 'dwithin'.\r\n\r\nNB: All tests passed when using shapely. Using PyGEOS, 9 failed tests are related to pandas version and not the enhancement, the 9 failed tests with PyGEOS also occur in the main branch.",
    "head_branch": "dwithin-predicate",
    "is_a_fork": true,
    "comments": [
      "The codecov test is failing due to error handling for outdated versions of pyGEOS and Shapely that aren't used in the tests. I could remove the dwithin functionality for rtree data types... Can someone please help me over the finish line?",
      "@brendan-ward thanks for the feedback! I've implemented everything. I'm still failing on the codecov/patch test since `test_dwithin_requirements()` is never tested. Everything else seems OK.",
      "@brendan-ward thanks for the finishing touches! I tried to apply the same concepts to my other edits as well. I also realised that I didn't build in the array-like capability for the distance parameter in Rtree. Might as well, since we were already 90% of the way there for enabling dwithin for Rtree geometries. I hope everything is up to scratch now! ",
      "Ah I see, thanks! I've now adapted the code from shapely, but with some differences: \r\n\r\n- making geometry into an array only happens for Rtree geometries when predicate = \"dwithin\". This is because the minimal build (no PyGEOS, shapely=1.7.1) was doing odd things with geometries like `MultiPolygon` and  `LineString` when trying to convert them to arrays. The minimal build cannot use \"dwithin\" and so a clash is avoided.\r\n- if the geometry is scalar, it's reverted to its original form, to keep the original conditions for looping: \r\n```python\r\nif hasattr(geometry, \"__array__\") and not isinstance(\r\n    geometry, BaseGeometry\r\n):\r\n    # Iterates over geometry, applying query\r\n``` \r\nThis means that geometries passed as lists still fail unless predicate=\"dwithin\", but it preserves the original logic for other predicates while solving the broadcasting issue. I hope that fixes the issue.",
      "Hi @chris-hedemann, I've just merged this back up to date with main. There were a decent amount of conflicts as the next release will require shapely 2.0 (please let me know if something doesn't look right!). Unfortunately this means that Rtree is also no longer a dependency, and so the parts of this pull request to add rtree support are no longer needed (appologies for the long timescales between this being drafted, first review and then merging). \r\n\r\nWhilst joris is probably better placed to review, I'd like to try and move this forward again, so I will aim to do a review myself in the next little while.",
      "@chris-hedemann again apologies for our slow review cycle .. I merged with the latest main branch and fixed the test for the changed error message.\r\n\r\nI think we still need to update the sjoin() docstring to include an entry for the new distance parameter. And I think we might also need some actual test for sjoin in `test_sjoin.py` (currently it's only tested for the sindex.query() method). \r\n\r\n",
      "@jorisvandenbossche yes, absolutely. My time resources have significantly reduced since the PR last May and the learning curve for getting back in is steeper than I thought. I'm currently unsure whether the distance parameter can be an array in the sjoin. It can in the query. I'll have a look on the weekend and try to solve this. If you already know the answer, let me know, that would save me some time.",
      "I think for `sjoin`, for now we can simply pass through whatever is specified by the user to `sindex.query`, and thus also be a scalar or array-like, like you allowed it to be in `query`. \r\nIn theory we could also do something like allow specifying a column name, but that is convenience that can be considered later.\r\n\r\nNow, while writing this: if a user would pass an array like, it's not necessarily obvious to the user which length this can be (since your left and right dataframe typically has a different length, and it's not super clear which is used for the index and which is passed. This is also something we should generally document better). \r\nAnyway, I think we can still just pass it through, and for now rely on the checking in `sindex.query` and this method erroring when a wrong shaped array is passed.",
      "Thanks @jorisvandenbossche. So I've edited the docstring to explain that the distance parameter can be a 1D array with length = len(left_geoDataFrame). I've put some simple tests into test_sjoin.py too, just to make sure that predicate=dwithin is working. The GeoDataFrame that is returned has \"how\"-dependent sorting, as you probably know. \r\n\r\nIt would be good to finish up this PR soon. Let me know what I can do, and I will try to respond quickly.",
      "@jorisvandenbossche I think this is ready. Last week I also relaxed the order of the resulting dataframe for sjoin tests, since this appears to be environment-dependent, and I am not updating sjoin in this PR...",
      "The remaining failing builds are being tackled in other PRs, so going to merge this!\r\n\r\nThanks again @chris-hedemann, and sorry it took such a long time!",
      "You're welcome @jorisvandenbossche and thanks for your help over the finish line!",
      "Would it be possible to add the distances values in the geodataframe when using the distance argument in GeoDataFrame.sjoin() ?",
      "@ShootingStarD That should not be too complicated. Can you open a new issue outlining that? I'll get lost here. ",
      "> @ShootingStarD That should not be too complicated. Can you open a new issue outlining that? I'll get lost here.\r\n\r\ni made it here : #3270 ",
      "Nice. Do you want to tackle the issue @ShootingStarD? I’d be happy to help. \r\n#3270 "
    ],
    "commit_messages": [
      "ENH: dwithin predicate and distance argument for query and sjoin (#2900)\n\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>\r\nCo-authored-by: Matt Richards <mrichards7@outlook.com.au>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d529ac254a19ac29df7e",
    "number": 2896,
    "body": "The `explore` method already has a `docstring`.  Decorating the `explore` methods with `@doc` docerator is causing the documentation to show the docstring twice (here: https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.explore.html)",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [
      "I'm not sure what do you mean that it is there twice. I see only one docstring, the one coming from the decorator. This method does not have its docstring defined here, only a small comment. ",
      "Hello Martin. Sorry for my late response.\r\n\r\nRight now, the sentence `Interactive map based on folium/leaflet.js` is repeated twice because it's a docstring in the `explore` function, and also part of the `_explore` docstring. Therefore, in the `doc` decorator it's being appended.\r\n\r\n![image](https://github.com/geopandas/geopandas/assets/9997649/9c503703-7f4e-4bbf-a75a-776e34eec895)\r\n\r\nI fixed my PR. I only deleted the redundant sentence from `explore` function and kept calling the `@doc`.",
      "Minor question: why does it take so long to create conda environment? It took me 20 minutes to create the dev environment. I know this has nothing to do with `geopandas`, but I just want to learn.",
      "The default conda resolver is written in Python and is very slow when it needs to resolve geospatial environment with many compiled dependencies. I recommend switching to `mamba`, which is a drop-in replacement of conda with resolver written in C++ making the whole process take seconds instead."
    ],
    "commit_messages": [
      "DOC: Remove redundant sentence in documentation of the `explore` method (#2896)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d52aac254a19ac29df7f",
    "number": 2891,
    "body": "See https://github.com/geopandas/geopandas/pull/2849#issuecomment-1537099850",
    "head_branch": "tst-skip-duplicate-columns-pd2",
    "is_a_fork": true,
    "comments": [
      "Not entirely sure where the failure comes from.",
      "> Not entirely sure where the failure comes from.\r\n\r\nLooking at the failures, it's like `PANDAS_GE_20` isn't set correctly, we're getting pandas 2 error messages but not hitting our compat blocks for them. Actually looking in more detail, the environment is still running against pip installed pandas 2.0.0rc which is probably not ideal. I'll push a commit bumping that and see what happens.\r\n\r\nEdit: I should have looked at the diff `PANDAS_GE_20` was changed to not include dev versions, so hopefully this should fix.",
      "Now it behaves as expected. Though we have `if grep SKIPPED >/dev/null;then echo \"TESTS SKIPPED, FAILING\" && exit 1` in the action for this part so it fails. Maybe we can use `xfail/xpass` instead here?",
      "Ah, yes, thanks for the fixup!",
      "Yes, and will make it xfail"
    ],
    "commit_messages": [
      "TST: skip postgis duplicate column test for pandas 2.0.x (#2891)\n\nCo-authored-by: Matt Richards <mrichards7@outlook.com.au>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d52bac254a19ac29df80",
    "number": 2890,
    "body": "xref https://github.com/geopandas/geopandas/issues/2692",
    "head_branch": "rls-doc-0.13",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "RLS/DOC: update to changelog for 0.13 (#2890)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d52bac254a19ac29df81",
    "number": 2887,
    "body": "I merged #2886 without a changelog note, so adding it here.",
    "head_branch": "missing_changelog",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add missing changelog for #2886 (#2887)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d52cac254a19ac29df82",
    "number": 2886,
    "body": "It seems we are getting tripped up by ax.legend's rather complex calling convention, resulting in an error: \"You have mixed positional and keyword arguments, some input may be discarded.\"\r\n\r\nSimplify the call by integrating all arguments into kwargs.",
    "head_branch": "wnavarre-patch-1",
    "is_a_fork": true,
    "comments": [
      "Tests failed, but it seems possible they weren't caused by my commit since the master branch is also failing. \r\n\r\nI rebased off of the commit described  below. This seems to be the most recent commit that passed CI on master.  \r\n\r\ncommit e32573db55eef05705618de29ae5c66b4ef8803a\r\nAuthor: NoharaMasato <38820014+NoharaMasato@users.noreply.github.com>\r\nDate:   Tue Apr 25 11:30:59 2023 +0900\r\n",
      "> It seems we are getting tripped up by ax.legend's rather complex calling convention, resulting in an error: \"You have mixed positional and keyword arguments, some input may be discarded.\"\r\n\r\nWhere do you see this error? Do you have a reproducible example?\r\n\r\nThe fix looks okay to me but I'd like to see the bug first :).",
      "Yes. Bug occurs with when using \"labels\" in the `legend_kwds` dict argument to `plot`. Example code below.\r\n\r\nThe output in the terminal for this code is: \r\n\r\n```\r\n/home/navarre/micromamba/envs/geo_env/lib/python3.8/site-packages/geopandas/plotting.py:944: UserWarning: You have mixed positional and keyword arguments, some input may be discarded.\r\n  ax.legend(patches, categories, **legend_kwds)\r\nSee the problem?\r\nBetter?\r\n```\r\n\r\nAnd the failing and succeding maps (note the weird little box in the upper left of the failing map):\r\n ![failing](https://user-images.githubusercontent.com/12436443/235767411-1979c351-8370-4a93-8554-92cf3c149128.png)\r\n![succeeding](https://user-images.githubusercontent.com/12436443/235767413-338bce4b-1076-409b-ad28-956b06c6eaaa.png)\r\n\r\n\r\n```py\r\nimport geopandas\r\nimport matplotlib.pyplot as plt\r\n\r\npath_to_data = geopandas.datasets.get_path(\"nybb\")\r\ngdf = geopandas.read_file(path_to_data)\r\n\r\ndef go(ax):\r\n    gdf.plot(column=\"BoroName\",\r\n             ax=ax,\r\n             categorical=True,\r\n             categories=[\"Manhattan\",\r\n                         \"Bronx\",\r\n                         \"Staten Island\",\r\n                         \"Brooklyn\",\r\n                         \"Queens\"],\r\n             legend=True,\r\n             legend_kwds= {\r\n                 \"labels\":[\"New York County\",\r\n                           \"Bronx County\",\r\n                           \"Richmond County\",\r\n                           \"Kings County\",\r\n                           \"Queens County\"],\r\n                 \"loc\": \"upper left\"\r\n             })\r\n\r\nfig, ax = plt.subplots(figsize = (10,10))\r\ngo(ax)\r\nfig.show()\r\ninput(\"See the problem?\")\r\n\r\n# You've seen the problem. Now for demonstrating the solution:\r\n    \r\ndef make_custom_legend_method(ax):\r\n    normal_method = ax.legend\r\n    def proposed_fix(*args, **kwargs):\r\n        if len(args) != 2:\r\n            # The proposed fix is on a callsite where args always equaled two...\r\n            # Just behave as normal.\r\n            return normal_method(*args, **kwargs)\r\n        handles, labels = args\r\n        kwargs.setdefault(\"handles\", handles)\r\n        kwargs.setdefault(\"labels\", labels)\r\n        normal_method(**kwargs)\r\n    return proposed_fix\r\n\r\nfig, ax = plt.subplots(figsize = (10,10))\r\nax.legend = make_custom_legend_method(ax)\r\ngo(ax)\r\nfig.show()\r\ninput(\"Better?\")\r\n\r\n# Better?\r\n```",
      "Ah! Great, thanks! \r\n\r\nWe should probably also add a test for this case as this apparent failure was not caught by our current test suite. Could you add one? There'll be some other testing the legend, so you can mirror the implementation.",
      "Ok. Edited a test case to hit this problem. "
    ],
    "commit_messages": [
      "BUG: Fix broken call to ax.legend (#2886)\n\nCo-authored-by: William Navarre <navarre@dimins.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d52dac254a19ac29df83",
    "number": 2883,
    "body": "This PR contains a few improvements of the comments in the code examples for [Geometric Manipulations](https://geopandas.org/en/latest/docs/user_guide/geometric_manipulations.html#examples-of-geometric-manipulations). Partly, this is also relevant for the main README:\r\n- Fix typo \"object\" to \"objects\"\r\n- Add highlighting of `geopandas.GeoSeries` \r\n- Add change \"our\" to \"a\" corresponding to PR #2650",
    "head_branch": "fix-typo-geomanipulation",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Fix typos in comments of code examples for \"Geometric Manipulations\" (#2883)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d52eac254a19ac29df84",
    "number": 2881,
    "body": "GeoPandas has been accepted as a NumFOCUS Sponsored project. As part of the onboarding, we were given a checklist of things to update and mention either in the ReadMe or in the documentation. This PR includes them all.\r\n\r\nThe [guide](https://github.com/numfocus/templates/blob/master/fiscal-sponsor-readme-attribution.md) says that we should have a `GOVERNANCE.md` file in the root but I am linking directly to the document as it lives in its own repository to cover all of the GeoPandas projects, not only the main repo. I suppose it is okay.\r\n\r\nThe links to geopandas project page and donation page do not work yet but I suppose this is how they'll look like. ",
    "head_branch": "numfocus",
    "is_a_fork": true,
    "comments": [
      "All the links now correctly lead to respective NumFOCUS pages.",
      "Thanks!"
    ],
    "commit_messages": [
      "DOC: update documentation for the NumFOCUS Sponsored project status (#2881)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d52fac254a19ac29df85",
    "number": 2880,
    "body": "Super small fix of error message of `_to_file` method.",
    "head_branch": "fix-error-message-of-to-file",
    "is_a_fork": true,
    "comments": [
      "Thanks @NoharaMasato!"
    ],
    "commit_messages": [
      "CLN: Fix ValueError message in _to_file (#2880)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d530ac254a19ac29df86",
    "number": 2879,
    "body": "This PR adds the `use_geography` parameter to `write_postgis`, which when set to true (false by default), use the `geography` PostGIS type instead of `geometry`.\r\n\r\nIt also contains a slight refactor of `tests.util.create_postgis` for readability's sake: `geometry(MULTIPOLYGON, 0)` and `geometry(MULTIPOLYGON)` are equivalent, as well as `ST_SetSRID(ST_GeometryFromText(%s), 0)` and `ST_GeometryFromText(%s)`",
    "head_branch": "postgis_geography",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d530ac254a19ac29df87",
    "number": 2878,
    "body": "Add document for #2357",
    "head_branch": "add-note-for-to-file",
    "is_a_fork": true,
    "comments": [
      "This is a good start @NoharaMasato! It would be great if you could extend this and add a code example of how to do this, perhaps by adding a section below `Apache Parquet and Feather file formats`?, say `WritingGeoDataFrames with multiple geometry columns`\r\n\r\nThen we could also mention that for mutli-layer formats such as geopackage, additional geometry columns can be written to separate layers as another option.",
      "Thanks @m-richards for the comment. I added an example in the `Writing spatial data` section.\r\nPlease take a look when you have time. Thank you.\r\n",
      "Thanks @m-richards for the review and suggestion. I incorporated your suggestion.",
      "@martinfleis\r\nThank you for the suggestion. I committed all of them."
    ],
    "commit_messages": [
      "DOC: add note for to_file method when saving multiple GeoSeries (#2878)\n\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d531ac254a19ac29df88",
    "number": 2877,
    "body": "**Description:**\r\nAt the moment `sjoin_nearest` cannot be used to identify the closest neigbour of a set of points since each geometry is matched to itself. However in Shapely2.0 `shapely.query_nearest` exposes the `exclusive` parameter to exclude identical geometries from the join. This PR adds the `exclusive` parameter in `sjoin_nearest` so that the join excludes identical geometries\r\n\r\n**Example:**\r\n```python\r\ncities = read_file(geopandas.datasets.get_path(\"naturalearth_cities\"))\r\nsjoin = gpd.sjoin_nearest(cities, cities) \r\n```\r\njoins each city with itself\r\n\r\nHowever,\r\n```python\r\ncities = read_file(geopandas.datasets.get_path(\"naturalearth_cities\"))\r\nsjoin = gpd.sjoin_nearest(cities, cities, exclusive=True) \r\n```\r\nreturns the actual closest city pairs (e.g. Rome with Vatican City)\r\n \r\n**Remarks**\r\nI am still unsure how to enable this functionality for pygeos and whether this would be required. At the moment the `exclusive` parameter is only available if the backend is using Shapely >= 2.0.",
    "head_branch": "join_nearest_exclude_identical",
    "is_a_fork": true,
    "comments": [
      "I can't figure out why sjoin fails the codecov..",
      "Everything is failing on codecov now. Ignore that. ",
      "> Everything is failing on codecov now. Ignore that.\r\n\r\nThen we are ready to merge :)",
      "> @harisbal apologies for the slow re-review!\r\n> \r\n> Can you please revert the changes to the `CHANGELOG.md`; it looks like the vast majority of those are due to auto-formatting, which isn't desirable in this case (I think we need to retain the double back-ticks due to how this gets embedded into the docs). Then disable your autoformatter for this file, and manually add `` Added `exclusive` parameter to `sjoin_nearest` method for Shapely >= 2.0 (#2877) `` under the development version (not 0.13.1) without running the autoformatter on the file. Sorry for the extra work there - that file has had the most updates of those that you've touched.\r\n\r\nI believe this time I got it right. Thank you for the patience and the support!"
    ],
    "commit_messages": [
      "ENH: add exclusive parameter to sjoin_nearest (#2877)\n\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d532ac254a19ac29df89",
    "number": 2876,
    "body": "I personnaly use GADM dataset a lot when it comes to administrative boundaries and I was always copy/pasting the same script to load data from their server as Geodataframe. \r\n\r\nI ended-up created a lightweight package that loads these data with just the name of the admin area and deals with some simple issues such as:\r\n-loading to GEE \r\n- manage duplicate names\r\n- download specific administrative subdivisions within a requested country\r\n\r\nI thought (maybe naively) that this package could be included in the \"data retreival\" section of your documentation.  ",
    "head_branch": "pygadm",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add the pygadm package to geopandas ecosystem (#2876)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d533ac254a19ac29df8a",
    "number": 2873,
    "body": "Closes #1604\r\n\r\n```python\r\n>>> import geopandas\r\n>>> from shapely.geometry import Polygon\r\n>>> s = geopandas.GeoSeries(\r\n...     [\r\n...         Polygon([(0, 0), (1, 1), (0, 1)]),\r\n...         None,\r\n...         Polygon([(0, 0), (-1, 1), (0, -1)]),\r\n...     ]\r\n... )\r\n>>> s.fillna(method='ffill')\r\n0    POLYGON ((0.00000 0.00000, 1.00000 1.00000, 0....\r\n1    POLYGON ((0.00000 0.00000, 1.00000 1.00000, 0....\r\n2    POLYGON ((0.00000 0.00000, -1.00000 1.00000, 0...\r\ndtype: geometry\r\n```",
    "head_branch": "fillna/method-working",
    "is_a_fork": true,
    "comments": [
      "What result of the following case?\r\n\r\n```python\r\nimport geopandas\r\nfrom shapely.geometry import Polygon\r\n\r\ns = geopandas.GeoSeries(\r\n    [\r\n        None,\r\n        Polygon([(0, 0), (-1, 1), (0, -1)]),\r\n    ]\r\n)\r\ns.fillna(method='ffill')\r\n```\r\n\r\nShould it return `None`?\r\n\r\n```python\r\n0                                                 None\r\n1    POLYGON ((0.00000 0.00000, -1.00000 1.00000, 0...\r\ndtype: geometry\r\n```\r\n\r\nOr `BaseGeometry/GeometryCollection`?\r\n\r\n```python\r\n0                             GEOMETRYCOLLECTION EMPTY\r\n1    POLYGON ((0.00000 0.00000, -1.00000 1.00000, 0...\r\ndtype: geometry\r\n```",
      "> What result of the following case? ..\r\n> Should it return None? Or BaseGeometry/GeometryCollection?\r\n\r\nI think ideally, it should preserve the None, since we are forward filling, None's at the start shouldn't change.",
      "Ready to go.",
      "@Zeroto521 apologies for the very slow follow-up here!\r\n\r\nHowever, in the meantime, pandas has actually deprecated and removed this `method` keyword from `fillna`, pointing users to use the `ffill()` and `bfill()` methods directly (the keyword will be removed in pandas 3.0). See also https://github.com/geopandas/geopandas/pull/3222\r\n\r\nThose methods work out of the box with the upstream pandas implementation, and so that makes this PR obsolete if we directly go with the future pandas behaviour (in theory we could still add it for the users of geopandas on pandas 2.x, but given that the pandas 3.0 release is planned shortly, I don't think that is worth doing)"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d534ac254a19ac29df8b",
    "number": 2868,
    "body": "Closes #2867 ",
    "head_branch": "cols_via_index_regr",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REGR: fix regression in assignment of multiple columns using pandas.Index (#2868)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d534ac254a19ac29df8c",
    "number": 2866,
    "body": "The GeoParquet spec allows this, but we currently don't check for this, and will also just ignore it (since we can't handle spherical edges). If a user explicitly has data with this optional flag set, it seems best to issue a warning (so you at least still read the data, but are made aware of the limitation of geopandas).",
    "head_branch": "geoparquet-warn-sperical",
    "is_a_fork": true,
    "comments": [
      "Thanks!"
    ],
    "commit_messages": [
      "Add warning for ignoring spherical edges in read_parquet/feather (#2866)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d535ac254a19ac29df8d",
    "number": 2865,
    "body": "Bumps [peter-evans/create-pull-request](https://github.com/peter-evans/create-pull-request) from 4 to 5.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/peter-evans/create-pull-request/releases\">peter-evans/create-pull-request's releases</a>.</em></p>\n<blockquote>\n<h2>Create Pull Request v5.0.0</h2>\n<h2>Behaviour changes</h2>\n<ul>\n<li>The action will no longer leave the local repository checked out on the pull request <code>branch</code>. Instead, it will leave the repository checked out on the branch or commit that it was when the action started.</li>\n<li>When using <code>add-paths</code>, uncommitted changes will no longer be destroyed. They will be stashed and restored at the end of the action run.</li>\n</ul>\n<h2>What's new</h2>\n<ul>\n<li>Adds input <code>body-path</code>, the path to a file containing the pull request body.</li>\n<li>At the end of the action run the local repository is now checked out on the branch or commit that it was when the action started.</li>\n<li>Any uncommitted tracked or untracked changes are now stashed and restored at the end of the action run. Currently, this can only occur when using the <code>add-paths</code> input, which allows for changes to not be committed. Previously, any uncommitted changes would be destroyed.</li>\n<li>The proxy implementation has been revised but is not expected to have any change in behaviour. It continues to support the standard environment variables <code>http_proxy</code>, <code>https_proxy</code> and <code>no_proxy</code>.</li>\n<li>Now sets the git <code>safe.directory</code> configuration for the local repository path. The configuration is removed when the action completes. Fixes issue <a href=\"https://redirect.github.com/peter-evans/create-pull-request/issues/1170\">peter-evans/create-pull-request#1170</a>.</li>\n<li>Now determines the git directory path using the <code>git rev-parse --git-dir</code> command. This allows users with custom repository configurations to use the action.</li>\n<li>Improved handling of the <code>team-reviewers</code> input and associated errors.</li>\n</ul>\n<h2>News</h2>\n<p>:trophy:  create-pull-request won <a href=\"https://twitter.com/peterevans0/status/1638463617686470657?s=20\">an award</a> for &quot;awesome action&quot; at the Open Source Awards at GitHub Universe. Thank you for your support and for making create-pull-request one of the top used actions. Please give it a :star:, or even <a href=\"https://github.com/sponsors/peter-evans\">buy me a coffee</a>.</p>\n<h2>What's Changed</h2>\n<ul>\n<li>v5 by <a href=\"https://github.com/peter-evans\"><code>@​peter-evans</code></a> in <a href=\"https://redirect.github.com/peter-evans/create-pull-request/pull/1792\">peter-evans/create-pull-request#1792</a></li>\n<li>15 dependency updates by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/peter-evans/create-pull-request/compare/v4.2.4...v5.0.0\">https://github.com/peter-evans/create-pull-request/compare/v4.2.4...v5.0.0</a></p>\n<h2>Create Pull Request v4.2.4</h2>\n<p>⚙️ Patches some recent security vulnerabilities.</p>\n<h2>What's Changed</h2>\n<ul>\n<li>Update concepts-guidelines.md by <a href=\"https://github.com/chrisbruford\"><code>@​chrisbruford</code></a> in <a href=\"https://redirect.github.com/peter-evans/create-pull-request/pull/1610\">peter-evans/create-pull-request#1610</a></li>\n<li>58 dependency updates by <a href=\"https://github.com/dependabot\"><code>@​dependabot</code></a></li>\n</ul>\n<h2>New Contributors</h2>\n<ul>\n<li><a href=\"https://github.com/chrisbruford\"><code>@​chrisbruford</code></a> made their first contribution in <a href=\"https://redirect.github.com/peter-evans/create-pull-request/pull/1610\">peter-evans/create-pull-request#1610</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/peter-evans/create-pull-request/compare/v4.2.3...v4.2.4\">https://github.com/peter-evans/create-pull-request/compare/v4.2.3...v4.2.4</a></p>\n<h2>Create Pull Request v4.2.3</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>fix: add check for missing token input by <a href=\"https://github.com/peter-evans\"><code>@​peter-evans</code></a> in <a href=\"https://redirect.github.com/peter-evans/create-pull-request/pull/1324\">peter-evans/create-pull-request#1324</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/peter-evans/create-pull-request/compare/v4.2.2...v4.2.3\">https://github.com/peter-evans/create-pull-request/compare/v4.2.2...v4.2.3</a></p>\n<h2>Create Pull Request v4.2.2</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>fix: support github server url for pushing to fork by <a href=\"https://github.com/peter-evans\"><code>@​peter-evans</code></a> in <a href=\"https://redirect.github.com/peter-evans/create-pull-request/pull/1318\">peter-evans/create-pull-request#1318</a></li>\n</ul>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/peter-evans/create-pull-request/commit/5b4a9f6a9e2af26e5f02351490b90d01eb8ec1e5\"><code>5b4a9f6</code></a> v5 (<a href=\"https://redirect.github.com/peter-evans/create-pull-request/issues/1792\">#1792</a>)</li>\n<li><a href=\"https://github.com/peter-evans/create-pull-request/commit/1847e5d1d66115e99988ff4ccbe629ae5b14820b\"><code>1847e5d</code></a> build(deps-dev): bump eslint from 8.36.0 to 8.37.0 (<a href=\"https://redirect.github.com/peter-evans/create-pull-request/issues/1803\">#1803</a>)</li>\n<li><a href=\"https://github.com/peter-evans/create-pull-request/commit/c246f7e9126aba0f1cc780a7133429d9771e9b66\"><code>c246f7e</code></a> build(deps-dev): bump <code>@​typescript-eslint/parser</code> from 5.57.0 to 5.57.1 (<a href=\"https://redirect.github.com/peter-evans/create-pull-request/issues/1801\">#1801</a>)</li>\n<li><a href=\"https://github.com/peter-evans/create-pull-request/commit/2dd2b11b09f0b3bf86c25cf615e4bbe624f80314\"><code>2dd2b11</code></a> build(deps-dev): bump eslint-import-resolver-typescript (<a href=\"https://redirect.github.com/peter-evans/create-pull-request/issues/1802\">#1802</a>)</li>\n<li><a href=\"https://github.com/peter-evans/create-pull-request/commit/05d5a3c3f9506f8628125834beec3993d3eada67\"><code>05d5a3c</code></a> build(deps-dev): bump <code>@​types/node</code> from 18.15.10 to 18.15.11 (<a href=\"https://redirect.github.com/peter-evans/create-pull-request/issues/1800\">#1800</a>)</li>\n<li><a href=\"https://github.com/peter-evans/create-pull-request/commit/21479f22fcc890fd56c1b5a47d47162fa907dddc\"><code>21479f2</code></a> build(deps-dev): bump ts-jest from 29.0.5 to 29.1.0 (<a href=\"https://redirect.github.com/peter-evans/create-pull-request/issues/1799\">#1799</a>)</li>\n<li><a href=\"https://github.com/peter-evans/create-pull-request/commit/36a56dac0739df8d3d8ebb9e6e41026ba248ec27\"><code>36a56da</code></a> build(deps-dev): bump <code>@​typescript-eslint/parser</code> from 5.56.0 to 5.57.0 (<a href=\"https://redirect.github.com/peter-evans/create-pull-request/issues/1768\">#1768</a>)</li>\n<li><a href=\"https://github.com/peter-evans/create-pull-request/commit/b7f0c9773b3f9bd0eb8d00cc963aceb9da2345e5\"><code>b7f0c97</code></a> build(deps-dev): bump prettier from 2.8.6 to 2.8.7 (<a href=\"https://redirect.github.com/peter-evans/create-pull-request/issues/1767\">#1767</a>)</li>\n<li><a href=\"https://github.com/peter-evans/create-pull-request/commit/6a62596740af10ccfc9800db9f74c255f65c9055\"><code>6a62596</code></a> build(deps): bump peter-evans/enable-pull-request-automerge from 2 to 3 (<a href=\"https://redirect.github.com/peter-evans/create-pull-request/issues/1766\">#1766</a>)</li>\n<li><a href=\"https://github.com/peter-evans/create-pull-request/commit/d1ed29fe1ea9695e51f6bdda3db7211f3294d9d5\"><code>d1ed29f</code></a> build(deps-dev): bump <code>@​types/node</code> from 18.15.5 to 18.15.10 (<a href=\"https://redirect.github.com/peter-evans/create-pull-request/issues/1765\">#1765</a>)</li>\n<li>Additional commits viewable in <a href=\"https://github.com/peter-evans/create-pull-request/compare/v4...v5\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=peter-evans/create-pull-request&package-manager=github_actions&previous-version=4&new-version=5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
    "head_branch": "dependabot/github_actions/peter-evans/create-pull-request-5",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Bump peter-evans/create-pull-request from 4 to 5 (#2865)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d536ac254a19ac29df8e",
    "number": 2864,
    "body": "Adding a documentation page outlying the migration period from pygeos being the default to only shapely 2.0 being supported and the recommended way of adapting the code.\r\n\r\nXref #2691",
    "head_branch": "pygeos_guide",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add a pygeos -> shapely migration guide (#2864)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>\r\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d537ac254a19ac29df8f",
    "number": 2863,
    "body": "[Pandas 2.0.0](https://pandas.pydata.org/docs/dev/whatsnew/v2.0.0.html) added support for a `dtype_backend` argument to many IO functions. This PR adds support for this argument to `read_feather`, `read_parquet` and `read_postgis`.\r\nThis is my first contribution to this project, so there are still some things I'm not sure about that needs to be solved for this PR to be ready:\r\n\r\n- How to handle previous previsions of pandas where functions wouldn't accept this argument more safely ?\r\n- Ideally, how to add this option to `read_file` ?\r\n- Add more tests ?",
    "head_branch": "dtype_backend",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d538ac254a19ac29df90",
    "number": 2862,
    "body": "This should resolve those failing tests on Windows with Python 3.8. Pandas now support dtypes in Index but int defaults to int32 in that environment causing the failure. Given the issue is only in this one env and Py3.8 will be phased out soon, skipping felt like an appropriate response.",
    "head_branch": "multiindex_dtype",
    "is_a_fork": true,
    "comments": [
      "I feel there might some \"bug\" in there (either in our own implementation (eg using some numpy functionality without specifying a dtype where the default is platform dependent), or in something we use from pandas/shapely). But again, if that's only on windows py3.8, that's still not necessarily worth investigating. So fine with skipping!"
    ],
    "commit_messages": [
      "TST: skip tests with multiindex on win and Py38 (#2862)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d538ac254a19ac29df91",
    "number": 2861,
    "body": "Final bit of #2751. \r\n\r\nThis adds a deprecation warning when you try to get the path and points you to a better place to look for the data.",
    "head_branch": "depr_datasets",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DEP: add FutureWarning to geopandas.datasets (#2861)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d539ac254a19ac29df92",
    "number": 2860,
    "body": "Ad discussed in person and during the dev call, to help the review process of #2363, it was decided to split the PR into multiple smaller ones dealing with one task per PR. \r\n\r\nThis PR implements the sampling based on samples either from a uniform distribution or using pointpats. Mostly based off #2363, with some minor changes and exposure of seed and random generator for better control.",
    "head_branch": "simple_sampling",
    "is_a_fork": true,
    "comments": [
      "The CI failure is unrelated and is also on main.",
      "> Can you just add a changelog note?\r\n\r\nDone.",
      "Failures are unrelated: the py38 is one is related to pyogrio (if that keeps failing, might be something with the 0.6.0 release), and the dev build is failing because of https://github.com/scikit-learn/scikit-learn/issues/26290",
      "Thanks @ljwolf and @martinfleis!"
    ],
    "commit_messages": [
      "ENH: Method to sample points randomly from within geometries (#2860)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d53aac254a19ac29df93",
    "number": 2859,
    "body": "Addresses https://github.com/geopandas/geopandas/issues/2517\r\n\r\nBased on discussion in #2857, remove the special None handling of geometry column name as the associated error message is less helpful than the equivalent for loc/iloc.\r\n\r\nThis includes #2857, so will have a much smaller diff after that is merged.\r\n\r\nThe end goal is to simplify the logic in #2577 by removing `_geometry_column=None` as a possible case.\r\n\r\n",
    "head_branch": "remove_getitem_special_behaviour",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CLN: Remove getitem special error behaviour (#2859)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d53bac254a19ac29df94",
    "number": 2858,
    "body": "Closes #2492\r\n",
    "head_branch": "issue2492",
    "is_a_fork": false,
    "comments": [
      "Looks like this introducing quite a few test failures. From a quick look, some of the failures look like slightly surprising expectations of functionality given the inputs. I'll dig in more soon. ",
      "> Looks like this introducing quite a few test failures. \r\n\r\nTook a look at those failures, and so the reason is that we were now always copying the data when passed a Series, and not only when a `crs` was specified (and this then interfered with things like just getting a column of the dataframe (`_geodataframe_constructor_sliced`).\r\n\r\nWe already had a code block about copying in case crs was passed just above, that worked for the case of GeometryArray or GeoSeries input. So I integrated your fix into that code block so we handle both the same."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d53cac254a19ac29df95",
    "number": 2857,
    "body": "This was to give me (and reviewers) more confidence around what was actually changing in parts of #2577.\r\n\r\nBut in documenting this explicitly, I've realised that our `__getitem__` behaviour is inconsistent with _constructor (i.e. loc, iloc, ...).  I think i've stumbled across this in the past, being confused at when different of errors in #2329 are triggered.\r\n\r\n```python\r\ngdf =gpd.GeoDataFrame(gpd.read_file(gpd.datasets.get_path(\"nybb\")))\r\ngdf['geom2'] = gdf.geometry.centroid\r\ngdf[['geom2']].geometry.name\r\nAttributeError: You are calling a geospatial method on the GeoDataFrame, but the active geometry column to use has not been set. \r\nThere are columns with geometry data type (['geom2']), and you can either set one as the active geometry with df.set_geometry(\"name\") or access the column as a GeoSeries (df[\"name\"]) and call the method directly on it.\r\ngdf.loc[:, [\"geom2\"]].geometry.name\r\nAttributeError: You are calling a geospatial method on the GeoDataFrame, but the active geometry column ('geometry') is not present. \r\nThere are columns with geometry data type (['geom2']), and you can either set one as the active geometry with df.set_geometry(\"name\") or access the column as a GeoSeries (df[\"name\"]) and call the method directly on it.\r\n```\r\n\r\nLooking at 0.11 release notes, we weren't explicit on which of these two is actually more desirable.\r\nI think this all stems from https://github.com/geopandas/geopandas/issues/2133#issuecomment-1024111760 which was implemented as #2329. In the same discussion, I suggested that setting the geometry column name to None explicitly improved clarity (https://github.com/geopandas/geopandas/issues/2133#issuecomment-1024832460), but now I don't think that's the case - given where the new error messages ended up, I think it's probably more useful to know that the old column is missing, rather than nothing is set.\r\n\r\nTo me, it seems like we should updated getitem to no longer set the active geometry column to None. This has the added benefit of making #2577 much simpler I think, as then there should be no need for the tri-state handling of `_geometry_column_name` is unset and None, unset and DEFAULT_GEO_COL_NAME and set and a string.\r\n\r\n\r\n\r\n",
    "head_branch": "improve_output_types_test",
    "is_a_fork": true,
    "comments": [
      "> ... I think it's probably more useful to know that the old column is missing, rather than nothing is set.\r\n> \r\n> To me, it seems like we should updated getitem to no longer set the active geometry column to None. ...\r\n\r\nYes, seeing that example, I agree the second error message is actually nicer\r\n\r\n",
      "Windows failures are because of the new pandas 2.0 release, some int32 vs int64 issues to look into",
      "Thanks!"
    ],
    "commit_messages": [
      "TST: Improve output types test assertions (#2857)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d53dac254a19ac29df96",
    "number": 2856,
    "body": "For https://github.com/geopandas/geopandas/issues/2818 to add support for topological colouring via `scheme=\"greedy\"`. Looking for some feedback on this approach before doing the equivalent changes for `explore` as well.",
    "head_branch": "2818-expose-greedy",
    "is_a_fork": true,
    "comments": [
      "Just added a commit to make sure the legend labels are correctly added. The following example -- based on the one [here](html) -- produces what I think is expected:\r\n\r\n```python\r\nimport geopandas\r\nfrom geopandas.plotting import plot_dataframe\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\nworld = geopandas.read_file(geopandas.datasets.get_path(\"naturalearth_lowres\"))\r\nafrica = world.loc[world.continent == \"Africa\"].copy()\r\nafrica = africa.to_crs(\"ESRI:102022\").reset_index(drop=True)\r\nax = plot_dataframe(africa, column=\"gdp_md_est\", scheme=\"greedy\", legend=True)\r\nplt.show()\r\n```\r\n<img width=\"390\" alt=\"Screenshot 2023-04-01 at 17 05 01\" src=\"https://user-images.githubusercontent.com/6566948/229301761-4f5614bd-668d-474f-a2cc-f24391500606.png\">\r\n\r\nOne thing I'm not sure about is that the `column` kwarg needs to be specified even though it isn't used by the classfier for `scheme=\"greedy\"`.\r\n\r\n",
      "Thanks @martinfleis, I've just added a commit which uses your suggestion with some minor changes to make it work."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d53dac254a19ac29df97",
    "number": 2855,
    "body": "Starting with pandas 2.0, it preserves the non-ns resolution of datetime64 input. And pyogrio creates datetime64[ms] data (that's the accuracy that GDAL supports)",
    "head_branch": "fix-pyogrio-datetime",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: read_file with pyogrio and pandas>=2 gives datetime64 with ms unit (#2855)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d53eac254a19ac29df98",
    "number": 2854,
    "body": "Automatic update of Versioneer by the `versioneer.yml` workflow.",
    "head_branch": "update-versioneer",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Update Versioneer (#2854)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d53fac254a19ac29df99",
    "number": 2853,
    "body": "A quick pull-request to fix distributing list-like style kwargs when plotting multi-part geometries.\r\n\r\n\r\nAt the moment, `_expand_kwargs(kwargs, multiindex)` is called twice:\r\n- once **before** the actual plotting functions (e.g. `_plot_polygon_collection` etc.)\r\n- once **inside** the plotting functions (which is obsolete if no multi-geometries exist and causes an error otherwise)\r\n\r\nIf multi-part geometries exist, the second call to `_expand_kwargs` will result in an  `IndexError` since the `geoms` list passed to the plotting functions is already exploded and so the newly evaluated `multiindex` will be based on the exploded geoms, e.g.:  \r\n `np.arange( <length of exploded geometries> )` .\r\n\r\n\r\n---- \r\n\r\nNow this works as expected:\r\n\r\n```python\r\nfrom shapely.geometry import Polygon, GeometryCollection\r\nimport geopandas as gpd\r\n\r\npoly = Polygon([(0, 0), (1, 0), (1, 1), (0, 1)])\r\npoly2 = Polygon([(1, 1), (2, 1), (2, 2), (1, 2)])\r\npoly3 = Polygon([(2, 2), (3, 2), (3, 3), (2, 3)])\r\ngc = GeometryCollection([poly2, poly3])\r\n\r\ndf = gpd.GeoDataFrame({\"geometry\": [poly, gc]})\r\ndf.plot(facecolor=[\"r\", \"g\"])\r\n```\r\n\r\n<img src=https://user-images.githubusercontent.com/22773387/229220291-49c5db74-7997-4f12-8aed-a0d053a0e9c6.png width=20%>\r\n\r\n\r\n## fixes\r\nThis also fixes #2208\r\n\r\n\r\n",
    "head_branch": "mpl_multigeom_kwargs",
    "is_a_fork": true,
    "comments": [
      "Hey, it seems that this doesn't work as expected. Can you check the results of CI and try to figure out what is happening there?"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d540ac254a19ac29df9a",
    "number": 2852,
    "body": "Since I'm always puzzled when i run into problems using matplotlib's abbreviation syntax... \r\n\r\nHere's a quick pull-request to add support for the following matplotlib abbreviations:\r\n\r\n- `fc` (for `facecolor`)\r\n- `ec` (for `edgecolor`)\r\n- `ls` (for `linestyle`)\r\n- `lw` (for `linewidth`)\r\n\r\n\r\nNow you can do:\r\n```python\r\ngdf.plot(fc=(1, 0, 0, .5), ec=\"b\", ls=\"--\", lw=4)\r\n```\r\ninstead of\r\n```python\r\ngdf.plot(facecolor=(1, 0, 0, .5), edgecolor=\"b\", linestyle=\"--\", lw=4)\r\n```\r\n",
    "head_branch": "mpl_abbreviations",
    "is_a_fork": true,
    "comments": [
      "Are those all abbreviations? I suppose not? If we want to support them we should do that for all that are normally available in matplotlib. \r\n\r\nCould you also add tests and a line to the docstring about this behaviour? And then a changelog note.\r\n\r\nThanks!",
      "Hey, I'm currently a bit busy, but I'll keep it on the radar and try to implement it as soon as I find some time!"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d541ac254a19ac29df9b",
    "number": 2850,
    "body": "# What this PR does \r\nAddresses #2777 : Adds the option `metadata` to `DataFrame.to_file` that supports writing metadata in `dict[str, str]` format into GeoPackage files (fiona only).\r\n\r\n### Details\r\nThe requirement for `str` values is a limitation. I thought about something like\r\n```python\r\n{'metadata': json.dumps(user_metadata)}  # or the XML equivalent of this\r\n```\r\nto allow for other types.\r\n\r\nHowever, since GeoPandas does not currently read the metadata anyway and thus does not require a specific format, we can leave this up to the user. \r\n\r\n\r\n# Closes\r\ncloses #2777 ",
    "head_branch": "feature/write-metadata",
    "is_a_fork": true,
    "comments": [
      "Some tests fail when the test environment [has fiona 1.8.20](https://github.com/geopandas/geopandas/actions/runs/4552930065/jobs/8028906520?pr=2850#step:4:46) which doesn't yet support metadata/tags ([added in 1.9](https://github.com/Toblerity/Fiona/issues/713))\r\n\r\nEdit: Tried simply bumping fiona version, but that has other conflicts. If I loosen the pin on `proj` the environment gets solved with `proj=7.1.0`, but that also makes many other tests fail. \r\n\r\nI'm happy to help further, but I will wait for any directions from maintainers here.",
      "Hey @DahnJ rather than updating the the environments, you could instead use use the `FIONA_GE_19` defined in `geopandas/io/file.py`. You probably want to do this check as part of your implementation, but also use it as part of the tests - we should skip the round trip tests you added for old versions of fiona, but also add a test that an appropriate exception is thrown for old versions of fiona too.",
      "Any update on this?\r\n",
      "Sorry for the delay on this.\r\n\r\n@m-richards thanks for the suggestion. I've tried to follow it in https://github.com/geopandas/geopandas/pull/2850/commits/8899ddec419162a7bfc99bab152528a98d83ae0a and the tests are now looking good.\r\n\r\nIn the meantime, Pyogrio started [supporting metadata as well](https://github.com/geopandas/pyogrio/pull/237). I would probably define a new variable `PYOGRIO_GE_06` analogously to `FIONA_GE_19` and allow to write metadata using Pyogrio, too. What do you think, @m-richards ? \r\n\r\ncc: @jorisvandenbossche ",
      ">  I would probably define a new variable PYOGRIO_GE_06 analogously to FIONA_GE_19 and allow to write metadata using Pyogrio, too.\r\n\r\nYes please.",
      "This is almost ready for review, but there's a single [failing test](https://github.com/geopandas/geopandas/actions/runs/5563505077/jobs/10162505006?pr=2850#step:5:2984) ` geopandas/tests/test_pandas_methods.py::test_astype `. Not sure if that's got anything to do with the changes I've introduced here. Any tips on it appreciated 🙏 ",
      "Not related. ",
      "> Not related.\r\n\r\nIn that case this is ready to review from my side 👍 ",
      "@m-richards sorry for dropping the ball on this and thanks for picking it up! Very happy for you to finalize this 🙏 ",
      "In the PR setting pyogrio as default we seemed to have consensus on using 0.7 as the minimum so I took those tests out, but they can go back if we don't see that as a hard minimum ",
      "Thanks @DahnJ and @m-richards !",
      "The writing metadata works nicely. Currently, I can read the metadata tags using `fiona.collection.Collection.get_tag_item()` is there a way to read metadata using just `geopandas` without the need of explicitly importing and using `fiona` just for this?",
      "Currently this isn't exposed toplevel in geopandas and you need to use fiona as you've done, or pyogrio. \r\n\r\nBut this would be a welcome addition, similarly to the way we have exposed list layers:\r\nhttps://github.com/geopandas/geopandas/pull/3224/files"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d542ac254a19ac29df9c",
    "number": 2849,
    "body": "Closes #2407\r\n\r\nI was looking back and realized I said I would make a PR for #2407 but never did. I thought I ought to just tie up that loose end once and for all, because it annoyed me again the other day.",
    "head_branch": "raise-valueerror-when-duplicate-geom-col-from-sql",
    "is_a_fork": true,
    "comments": [
      "@iboates for some reason, the CI step testing postgis didn't fully run on this PR .. and now it is failing on main.\r\n\r\nSo we have two builds that run those tests:\r\n\r\n- ubuntu-latest, ci/envs/39-pd13-conda-forge.yaml: using sqlalchemy 1.4.46, pandas 1.3.5 -> working (example: https://github.com/geopandas/geopandas/actions/runs/4886340573/jobs/8751195340)\r\n- ubuntu-latest, ci/envs/311-latest-conda-forge.yaml: using sqlalchemy 2.0.12, pandas 2.0.1 -> failing (example: https://github.com/geopandas/geopandas/actions/runs/4886340573/jobs/8751195434)\r\n\r\n(and for some reason only the first ran on this PR ..)\r\n\r\nMaybe sqlachemy changed something to deduplicate on their side? If you would have time to look into the failure, that would be welcome; will also try to take a look.",
      "OK, it's probably related to pandas. Testing with this snippet (just using sqlite):\r\n\r\n```\r\nimport pandas as pd\r\ndf = pd.DataFrame({'a': [1, 2, 3], 'b': [0.1, 0.2, 0.3]})\r\n\r\nfrom sqlalchemy import create_engine\r\neng = create_engine(\"sqlite://\")\r\ndf.to_sql(\"test_table\", eng, index=False)\r\n\r\npd.read_sql(\"SELECT a, b, a FROM test_table;\", eng)\r\n```\r\n\r\nWith either slqalchemy 1.4 or 2.0 and pandas 2.0, this gives only a single \"a\" column, while if downgrading pandas to 1.5, it gives the duplicated columns.\r\n\r\n-> https://github.com/pandas-dev/pandas/issues/53117",
      "Yeah, it is likely pandas. If you try to execute that query we have in tests with the recent SQLAlchemy, you still get both. Pandas must deduplicate it. ",
      "OK, this is worked around in our tests, all good!"
    ],
    "commit_messages": [
      "Made read_postgis raise ValueError if the geom_col is specified twice (current error is cryptic) (#2849)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d543ac254a19ac29df9d",
    "number": 2846,
    "body": "This builds on the work already done by rietesh  in #2807. \r\n\r\nTo do this migration maintaining compatibility i've worked through the sqlalchemy 2 migration guide (https://docs.sqlalchemy.org/en/20/changelog/migration_20.html)\r\n using a local environment with sqlalchemy 1.4.46 and pandas main.\r\n\r\nI then enabled the `SQLALCHEMY_WARN_20=1` warnings and ran the sql tests with the `-W error` flag in pytest and worked through all the deprecations.\r\n\r\nGiven that we want to be backwards compatible with older sqlalchemy I did not turn on the `Engine` future flag an stopped at step 4 of the migration guide.\r\n\r\nTo test against sqlalchemy 1.4.46 and sqlalchemy >2, I've enabled the postgis tests in ci/envs/311-latest-conda-forge.yaml (and temporarily set that environment to install the pandas 2.0 release candidate)\r\n",
    "head_branch": "slqalchemy_2_prep",
    "is_a_fork": true,
    "comments": [
      "This is a great PR we can use this to go forward",
      "I think this is ready to be reviewed. The test failure is unrelated, and is tied to the pandas 2.0 datetime changes (pretty sure that's a features and not a regression). It doesn't show up in the dev build, because pyogrio is not installed in the dev environment.",
      "Thanks!",
      "Thanks also to @rietesh to your intial work on this!"
    ],
    "commit_messages": [
      "Slqalchemy 2 compatibility (#2846)\n\nCo-authored-by: Rietesh <rietesh4535@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d543ac254a19ac29df9e",
    "number": 2845,
    "body": null,
    "head_branch": "try_constructor_as_class",
    "is_a_fork": true,
    "comments": [
      "Thanks for taking a look at this.\r\n\r\nI'm curious: why not just always return a Geopandas object and then have the relevant methods disabled if there is no geo-dtype column?",
      "> why not just always return a Geopandas object and then have the relevant methods disabled if there is no geo-dtype column?\r\n\r\nWe also override a bunch of methods from pandas to have different behaviour. Of course also in those we could first check if there is a geometry column, and otherwise fall back to the parent implementation. But while it is technically possible, I personally think this is confusing for our users (seeing an object being a geo one without actually having geo data, a bunch of additional methods in tab completion that never work, wrong docstrings for some methods, ...). We intentionally moved away from always preserving the class in the past for those reasons.\r\n\r\nAnd even if we would do this for GeoDataFrame (and just use the class for its `_constructor`), I think from a user perspective, it certainly doesn't make any sense to use GeoSeries for non-geo columns. So even if we don't use the \"_constructor can be generic callable\" feature for `GeoDataFrame._constructor`, we would still need it for `GeoDataFrame._constructor_sliced` and `GeoSeries._constructor`."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d544ac254a19ac29df9f",
    "number": 2841,
    "body": "testing workflow",
    "head_branch": "test_workflow",
    "is_a_fork": true,
    "comments": [
      "Superceded by #2846."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d545ac254a19ac29dfa0",
    "number": 2839,
    "body": "Fixes #2838 \r\n\r\nThis adds an explicit CRS value to an example data frame to make it explicit what format the data is in and make the code more compatible with other libraries, eg. contextily. ",
    "head_branch": "2838-example-update",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Update to example gallery (#2839)\n\nSigned-off-by: Eric Kerfoot <eric.kerfoot@kcl.ac.uk>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d546ac254a19ac29dfa1",
    "number": 2836,
    "body": "Especially on Windows and Mac, but also on Linux, creating and cleaning up the conda env takes a big part of the testing time using setup-miniconda@v2 (with mamba). \r\n\r\nIt seems that the action doing the same thing developed by mamba-org is a lot faster...",
    "head_branch": "CI-speedup-tests-by-using-mamba-org-action",
    "is_a_fork": true,
    "comments": [
      "The defaults channel doesn't seem to be supported, or at least the combination of defaults and conda-forge isn't ([link](https://mamba.readthedocs.io/en/latest/user_guide/troubleshooting.html#mixing-the-defaults-and-conda-forge-channels)), which seems to be necessary for some yml files...",
      "> which seems to be necessary for some yml files...\r\n\r\nWe could also try to remove that (I suppose this stems from a _long_ time ago, it might not be necessary right now). \r\n\r\nLooking at the different files, I think is is only 38-minimal.yaml that has the mixture. You could try to remove the defaults channel in that file to see what that gives / what might be missing from conda-forge.",
      "Yeah, we probably don't need to have the mixture anymore but we still shall test against defaults, not only conda-forge.",
      "For 3.8_minimal.yml, when the defaults channel is removed (so only conda-forge channel is retained), that env works properly.\r\n\r\nHowever, for the 2 \"defaults\" yml files, about 25% of packages installed is coming from conda-forge even though the conda-forge channel is not mentioned in de yml file? So I suppose conda-forge is somewhere in the default settings for the miniconda based action?\r\n\r\nSo, because in practice the \"defaults\" yml's do need both channels and this isn't supported, they fail when using micromamba...",
      "Looking at the `38-latest-defaults.yaml` environment locally and trying to create this with micromamba, it seems that the requirement of `pyproj>=3` is what causes the conflict (and causes mamba to get some packages from conda-forge in the current CI). \r\nEssentially, defaults cannot currently install geopandas with a requirement of pyproj>=3 (just doing `micromamba create -n test geopandas --channel defaults` gives you pyproj 2.6, and so a simple `micromamba create -n test geopandas \"pyproj>=3\" --chanel defaults` gives conflicts with gdal)\r\n\r\nFor that file, if we want to keep this defaults install, the only possible short term solution I see is to install pyproj with pip. So with the following patch (updating python while we are at it) it works for me locally:\r\n\r\n```diff\r\ndiff --git a/ci/envs/38-latest-defaults.yaml b/ci/envs/38-latest-defaults.yaml\r\nindex d995d22a..d6beb4d8 100644\r\n--- a/ci/envs/38-latest-defaults.yaml\r\n+++ b/ci/envs/38-latest-defaults.yaml\r\n@@ -2,14 +2,13 @@ name: test\r\n channels:\r\n   - defaults\r\n dependencies:\r\n-  - python=3.8\r\n+  - python=3.10\r\n   # required\r\n   - numpy\r\n   - pandas\r\n   - shapely\r\n   - fiona\r\n-  - pyproj>=3\r\n-  - geos\r\n+  # - pyproj>=3\r\n   - packaging\r\n   # testing\r\n   - pytest\r\n@@ -24,6 +23,7 @@ dependencies:\r\n   - libspatialite\r\n   - pip\r\n   - pip:\r\n+      - pyproj>=3\r\n       - geopy\r\n       - mapclassify\r\n       - pyarrow\r\n\r\n```",
      "Hmm, and now that illustrates why you shouldn't mix conda and pip packages .. ;) Because this is giving test failures related to fiona and PROJ",
      "> Hmm, and now that illustrates why you shouldn't mix conda and pip packages .. ;) Because this is giving test failures related to fiona and PROJ\r\n\r\nYes, any type of mixing is a risk to get runtime errors if binaries are involved: I used to have to mix defaults and conda-forge channels for a project and that also often gave issues.... ",
      "OK, looked a bit at the state of the packages in the defaults channel, and so everything there is still built with proj 6.2.1, while pyproj 3.0.0 requires a minimum of proj 7 (opened https://github.com/AnacondaRecipes/gdal-feedstock/issues/18). \r\n\r\nSo basically you currently can't get both a recent pyproj and a gdal/fiona install using the defaults channel. So either we give up on defaults, or either we wait a bit longer with requiring pyproj 3 (looking at https://github.com/geopandas/geopandas/pull/2655, I think it would mostly be some versions checks in the tests that would need to be added back)",
      "If the defaults is not able to keep up with the release cycle of packages they aim to ship I don't think it is our role to ensure that it all works. PROJ 6.2.1 is more than 3 years old. If we're not able to solve environment with dependencies following [NEP29](https://numpy.org/neps/nep-0029-deprecation_policy.html) or upcoming [SPEC0](https://scientific-python.org/specs/spec-0000/) then I would simply remove tests against defaults until they fix the issue on their side. This is the packaging issue a packaging provider needs to resolve.",
      "Because there is no reaction on https://github.com/AnacondaRecipes/gdal-feedstock/issues/18 and there wasn't any remark on https://github.com/geopandas/geopandas/pull/2836#issuecomment-1474858336, I removed the environments to test the defaults channel from test.yaml.\r\n\r\nI didn't remove the env files yet from https://github.com/geopandas/geopandas/tree/main/ci/envs ... not sure if the maintainers which to keep them there to reactivate them once the problem is solved in defaults or not.",
      "> I didn't remove the env files yet from https://github.com/geopandas/geopandas/tree/main/ci/envs ... not sure if the maintainers which to keep them there to reactivate them once the problem is solved in defaults or not.\r\n\r\nWe can actually maybe even keep them in the yaml and only comment out those two lines. That way we will more likely come back to it later, hopefully once the defaults channel resolves better.",
      "Thanks!"
    ],
    "commit_messages": [
      "CI: speedup tests by using mamba-org micromamba action (#2836)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d547ac254a19ac29dfa2",
    "number": 2835,
    "body": "Attempts to fix `.to_parquet` not respecting \"Z\" geometries.\r\n\r\nCloses #2824",
    "head_branch": "to_parquet_fix_2824",
    "is_a_fork": true,
    "comments": [
      "@martinfleis `Tests / ubuntu-latest, ci/envs/310-latest-conda-forge.yaml (pull_request)` seems to be stuck. Can we rerun it?",
      "@jorisvandenbossche it doesn't seem that the last test fail is related to my changes",
      "> @jorisvandenbossche it doesn't seem that the last test fail is related to my changes\r\n\r\nThat looks right, nothing to be worried about in this PR (the failing environment is built against the nightly dev release of pandas, so the failures are due to upstream changes we'll need to incorporate)",
      "@jorisvandenbossche any news on that?",
      "@JohnMoutafis apologies for the very slow follow-up. I rebased this again to fix the conflicts with latest main, cleaned up a few comments and unnecessary test code, but for the rest it is looking good! Thanks again for the contribution"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d547ac254a19ac29dfa3",
    "number": 2834,
    "body": "Trying to make it a bit more explicit about when and what will change.\r\n\r\nxref https://github.com/geopandas/geopandas/issues/2691",
    "head_branch": "update-import-warning-pygeos",
    "is_a_fork": true,
    "comments": [
      "Failures are because of a recent pyogrio change."
    ],
    "commit_messages": [
      "Update warning on import when both Shapely 2 and PyGEOS are installed (#2834)\n\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d548ac254a19ac29dfa4",
    "number": 2833,
    "body": "Next step for the PyGEOS->Shapely migration of https://github.com/geopandas/geopandas/issues/2691\r\n\r\nNext step after adding `_data` in https://github.com/geopandas/geopandas/pull/2785 to actually raise a warning when accessing `data` (I now am doing this always, not only when there are pygeos geometries)",
    "head_branch": "geometry-array-data-depr",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DEPR: deprecate the usage of GeometryArray.data to access PyGEOS geometries (#2833)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d549ac254a19ac29dfa5",
    "number": 2832,
    "body": "Sphinx warns about this nowadays.",
    "head_branch": "doc-cleanup",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: fix some sphinx warnings (underlines) (#2832)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d54aac254a19ac29dfa6",
    "number": 2831,
    "body": "Closes https://github.com/geopandas/geopandas/issues/2823\r\n\r\n",
    "head_branch": "sindex-query",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "API: deprecate sindex.query_bulk and move functionality to sindex.query (matching shapely) (#2831)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d54bac254a19ac29dfa7",
    "number": 2830,
    "body": "A quick pull-request to pass the `autolim` kwarg to matplotlib collections.\r\n\r\n### ❗ NOTE\r\n\r\n- This does **NOT work when plotting points** since `plt.scatter()` is used directly which does not (yet?) support disabling autolim\r\n\r\n\r\nPossible options to address this: (let me know what you'd prefer):\r\n1. Get `autolim` into `plt.scatter()`   \r\n   (might take a while and not sure I'll find the time soon to do this)\r\n2. Print a warning if points are plotted and add `autolim` support for polygons and lines until `plt.scatter` issues are addressed\r\n3. Plot a custom `PathCollection` instead of using `plt.scatter()`  \r\n  (might be a bit of an overkill and requires quite some work)\r\n4. Use a contextmanager to temporarily disable autoscaling if points are plotted  \r\n  (should be easy to implement but somewhat hacky)\r\n\r\nThe only doable options (for me) that I'd be willing to add here are 2 and 4.\r\n\r\n\r\n",
    "head_branch": "autolim",
    "is_a_fork": true,
    "comments": [
      "@juseg turned his branch discussed in #2602 into a PR in the meantime - #2817. So I guess this is a duplication of the same? There's also some discussion on points there and a link to the matplotlib issue and PR.",
      "@martinfleis yep just noticed this... I'll happily step back from this if @juseg is still on it!"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d54cac254a19ac29dfa8",
    "number": 2829,
    "body": "Because writing to spatialite is now added as an example in to_file, it was mentioned in #2821 that it would be better to add a test on it as well...",
    "head_branch": "Add-test-for-to_file-and-read_file-for-spatialite",
    "is_a_fork": true,
    "comments": [
      "While writing the test I stumbled upon a specific case that seems to be giving trouble. When writing a PointZ geometry to a spatialite file using pyogrio this gives an error. Apparently SpatiaLite is pickyer than GeoPackage,... and doesn't want to save 3D points in a \"Point\"column. So it was necessary to explicitly specify geometry_type = \"Point Z\" to get this case working.\r\n\r\nNot sure how to deal with it, because in pyogrio this is detemined using gdf.geometry.type, which returns \"Point\" for a 3D point... Not sure if this is by design.",
      "The geom type of 3D points is probably also related to  #2824.",
      "> The geom type of 3D points is probably also related to #2824.\r\n\r\nProbably. I just found the has_z property... so that can be used to fix it in pyogrio... I'll create an issue there.",
      "Apparently the SQLite driver was only added to fiona in version 1.8.20 (2021-05-31) and the \"minimal\" version is now set to 1.8.18 (2020-11-17). Not sure how to deal with that. Add a skip to the test or ?",
      "Yeah, I would skip the test. We'll be bumping the minimal to the supported one in two months anyway. ",
      "I added the skip..."
    ],
    "commit_messages": [
      "TST: Add tests for to_file/read_file for spatialite format (#2829)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d54dac254a19ac29dfa9",
    "number": 2828,
    "body": "Final bits of removing `geopandas.datasets` from the user-facing documentation. I have also replaced Chicago health in many cases with a smaller version of the same (less columns) and standardized strings we use to fetch the data.\r\n\r\nxref #2751 ",
    "head_branch": "docstrings",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: remove datasets from docstrings + cleanup (#2828)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d54dac254a19ac29dfaa",
    "number": 2827,
    "body": null,
    "head_branch": "shapelyexpose",
    "is_a_fork": true,
    "comments": [
      "Thanks!"
    ],
    "commit_messages": [
      "ENH: add minimum_bounding_radius as GeoSeries method (#2827)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d54eac254a19ac29dfab",
    "number": 2826,
    "body": "Continuation of #2751",
    "head_branch": "examples",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: remove usage of datasets from examples (#2826)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d54fac254a19ac29dfac",
    "number": 2821,
    "body": "Some extra clarification in doc based on the comment here: #2799 :\r\n- an example of GeoDataFrame.to_file using some engine-specific keyword arguments. Based on the issue above the example is related to the creation of a spatialite file.\r\n  - **QST**: if the example is OK, should it also be added to GeoSeries.to_file ? In geoseries.to_file is now already an example less, not sure if this is on purpose.\r\n- clarify in to_postgis that file databases are easier to write using to_file.",
    "head_branch": "DOC-clarify-that-file-databases-are-easier-to-write-using-to_file",
    "is_a_fork": true,
    "comments": [
      "Hmm... I just realised that `to_file` probably doesn't only work for file databases because normally any gdal datasource can be used, including [postgis](https://gdal.org/drivers/vector/pg.html), [oracle spatial](https://gdal.org/drivers/vector/oci.html),... \r\n\r\nNot sure though if to_file is the recommended way to go for those (\"real\") databases... ",
      "\r\n> Not sure though if to_file is the recommended way to go for those (\"real\") databases...\r\n\r\nI'm not sure what the best guidance is either.\r\n\r\nWould you mind also adding a sentence to `_read_postgis` to also indicate that read_file can be used for spatialite databases? And also updating the example\r\n```\r\n>>> sql = \"SELECT ST_AsBinary(geom) AS geom, highway FROM roads\"\r\n>>> df = geopandas.read_postgis(sql, con)  # doctest: +SKIP\r\n```\r\nwhich has a typo in the spatialite function name (ST_AsBinary - https://www.gaia-gis.it/gaia-sins/spatialite-sql-5.0.1.html)\r\n\r\nIt also perhaps makes sense to explicitly test writing spatialite with to_file if we're advocating that in the docs, but I don't think that necessarily needs to be part of this PR.\r\n\r\n",
      "> > Not sure though if to_file is the recommended way to go for those (\"real\") databases...\r\n> \r\n> I'm not sure what the best guidance is either.\r\n\r\nI tried to reword it a little bit to make it more general while keeping the focus of the \"advice\" on file databases.\r\n\r\n> Would you mind also adding a sentence to `_read_postgis` to also indicate that read_file can be used for spatialite databases? \r\n\r\nGood idea. Done.\r\n\r\n> And also updating the example\r\n> \r\n> ```\r\n> >>> sql = \"SELECT ST_AsBinary(geom) AS geom, highway FROM roads\"\r\n> >>> df = geopandas.read_postgis(sql, con)  # doctest: +SKIP\r\n> ```\r\n> \r\n> which has a typo in the spatialite function name (ST_AsBinary - https://www.gaia-gis.it/gaia-sins/spatialite-sql-5.0.1.html)\r\n\r\nDone\r\n\r\n> It also perhaps makes sense to explicitly test writing spatialite with to_file if we're advocating that in the docs, but I don't think that necessarily needs to be part of this PR.\r\n\r\nI'll put it in a seperate PR.\r\n"
    ],
    "commit_messages": [
      "DOC: Clarify that file databases can also be written using to_file (#2821)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d550ac254a19ac29dfad",
    "number": 2820,
    "body": null,
    "head_branch": "add-tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d551ac254a19ac29dfae",
    "number": 2817,
    "body": "Close #2602.\r\n\r\n- [x] Add `autolim` keyword to `GeoDataFrame.plot()`.\r\n- [x] Add `autolim` keyword to `GeoSeries.plot()`.\r\n- [x] Preserve limits for linestring, polygons if `autolim=False`. \r\n- [ ] Support scatter plots with https://github.com/matplotlib/matplotlib/pull/15595?\r\n- [x] Add tests.",
    "head_branch": "autolim",
    "is_a_fork": true,
    "comments": [
      "This implements `autolim` for linestrings and polygons. Do we want to wait for the matplotlib PR or ignore scatter plots for now? And maybe add a note about it in the dostring?\r\n\r\nMy branch pointed to a very old commit, sorry...",
      "I'd give them a few days over at https://github.com/matplotlib/matplotlib/pull/15595 to respond to your comment. Right now we can only ignore point case for now or wait for that PR to be merged. Ideally we would prepare this PR knowing how it will be done in matplotlib but that doesn't seem to be clear yet.",
      "Sorry for again leaving this branch stale for much longer than \"a few days\" (see previous comment). As far as I understand matplotlib still does not support auto-scaling scatter plots. Would it be possible to merge this PR to support `autolim` on lines and polygons, ignoring points for now?",
      "Thanks! I opened a follow-up issue for the point geometry case at #3331."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d551ac254a19ac29dfaf",
    "number": 2816,
    "body": "SQL quesry string needs to be turned from python str to sqlalchmey text",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [
      "@AdnanAvdagic I will now close this as I believe it is superceded by #2846, thanks for your initial investigation into this."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d552ac254a19ac29dfb0",
    "number": 2815,
    "body": "Building the docs give an error on an \"icon_links\" key that doesn't exist.\r\n\r\nThis PR uses the \"icon_links\" syntax to create the links to github and twitter and this seems to work.\r\n\r\nNoticed the problem when building docs failed in #2814",
    "head_branch": "Fix-icon_links-error-in-docs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Fix icon_links error in docs (#2815)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d553ac254a19ac29dfb1",
    "number": 2814,
    "body": "Closes #2813",
    "head_branch": "Add-GeoSeries.make_valid-to-API-doc",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Add GeoSeries.make_valid to API doc (#2814)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d554ac254a19ac29dfb2",
    "number": 2811,
    "body": "Hi all, this PR fixes  #2684. \r\n\r\nAs recommended in the discussion, instead of applying pd.isnull() to individual elements in GeoDataFrame (which will return an array for non-scalar values, hence breaking the logic), we can apply a boolean array created by pd.isna() and include that in the iteration. This will work with nested values. \r\n\r\nTesting the original code in the bug report, with an added NaN column (naCol):\r\n\r\n```\r\nimport geopandas\r\n\r\ngdf = geopandas.GeoDataFrame(dict(geometry=geopandas.GeoSeries.from_wkt(['POINT EMPTY']), naCol=None, test=[[1, 2]]))\r\nprint(list(gdf.iterfeatures(na='drop')))\r\n```\r\n\r\nreturns:\r\n\r\n`\r\n[{'id': '0', 'type': 'Feature', 'properties': {'test': [1, 2]}, 'geometry': None}]\r\n`",
    "head_branch": "main",
    "is_a_fork": true,
    "comments": [
      "Ok, seems I haven't formatted correctly. Let me run the tests locally and submit a new PR. ",
      "You could have just updated this branch by committing other changes, no need to open a new PR with changes.",
      "Will do for next time - am very new to github!\r\nEDIT: I've reopened this with reformatted code",
      "Hello 😄, could someone please have a look at this? Thanks",
      "Hey @hydroEng try re-merging with master to get the docs build to re-trigger, not sure what's happening there - not related to your pull request. You should also see if you can add a test under tests/test_geodataframe.py to your changes are working as intended.",
      "@m-richards please let me know if this needs anything else",
      "Hello, could someone please review this? ",
      "Thanks @m-richards - I've made the suggested changes. Should be good to go if anyone's happy to do another review. Not sure what's up with the failing test but seems like the same test is failing everywhere. ",
      "Thanks @jorisvandenbossche. I've committed your changes and have also updated the changelog."
    ],
    "commit_messages": [
      "BUG: replace pd.isnull() with na mask to handle non-scalar values (#2811)\n\nCo-authored-by: hydroEng <tahasoomro888@gmail.com>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d555ac254a19ac29dfb3",
    "number": 2810,
    "body": "Numpy has since moved discussion of Numpy style docstrings into the `numpydoc` package documentation.\r\n\r\nhttps://github.com/numpy/numpy/blob/main/doc/HOWTO_DOCUMENT.rst.txt was [renamed](https://github.com/numpy/numpy/commit/5f9baec85cec9b4c024552ecc15756686d6ab6d7) to https://github.com/numpy/numpy/blob/main/doc/HOWTO_DOCUMENT.rst which now just links to [`numpydoc`](https://numpydoc.readthedocs.io/en/latest/format.html#docstring-standard) anyway.",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Fix broken link in contributing file (numpydoc) (#2810)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d555ac254a19ac29dfb4",
    "number": 2809,
    "body": "Not sure if a check on incompatible parameters to to_file() is wanted or not, so I didn't add it yet.\r\n\r\nIt would eg. be possible to raise a ValueError if a user passes mode=\"w\" + kwarg append=True, or if a user passes mode=\"a\" + append = False if this is deemed better...\r\n\r\n",
    "head_branch": "Add-support-for-appending-via-pyogrio-engine",
    "is_a_fork": true,
    "comments": [
      "I also have a PR open for this: https://github.com/geopandas/geopandas/pull/2788. And the question about what to do with `mode` came up there as well.",
      "Oops... ok, no prob... I'll close it again ;-)."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d556ac254a19ac29dfb5",
    "number": 2808,
    "body": "Hi - I'm interested in writing partitioned datasets to parquet and saw #2361 \r\n\r\nI've only done the easy thing here so far - threading a `partition_cols` argument through the `to_parquet` call so we end up with a call to `parquet.write_to_dataset`.\r\n\r\nThere's some other relevant discussion:\r\n- https://github.com/geopandas/geopandas/pull/1180/files#r409350933\r\n- #1382\r\n- various issues on `dask-geopandas`\r\n\r\nWhat do you think about this as it stands? Useful enough already? Would updating the bbox metadata for each partition be essential?",
    "head_branch": "main",
    "is_a_fork": true,
    "comments": [
      "Thanks! This has been on my personal wishlist for some time.\r\n\r\nBut if we want to write partitioned GeoParquet we should ensure that we have all metadata correctly set so when we read it with dask-geopandas for example, we get the partition bounds as expected.",
      "Cool - I'll keep this on the TODO list and will take a look at the metadata properly - any quick pointers into dask-geopandas would be welcome.",
      "Bits of parquet IO are in https://github.com/geopandas/dask-geopandas/blob/main/dask_geopandas/io/parquet.py and other in https://github.com/geopandas/dask-geopandas/blob/main/dask_geopandas/io/arrow.py",
      "Hi everyone, any news on this topic?",
      "Unfortunately nothing recently from me, still desirable but not high priority in the near future.",
      "I was wondering why the method of writing Parquet files was changed compared to Pandas, even though Parquet, as a standard, should support partitioning. That is one of its features. And pull requests keep being rejected as if it were merely an exercise of power.",
      "> And pull requests keep being rejected as if it were merely an exercise of power.\r\n\r\n@dalberti I am sorry? Would you mind pointing to at least a single example of this? We are all volunteers doing the geopandas maintenance and development in our free time. Yeah, some PRs are hanging for a while but we're typically not rejecting anything without a good reason. This one is WIP because the original author does not have time to finish it. Are you willing to finish the implementation so we can merge this? That would be more than welcome.\r\n\r\n> I was wondering why the method of writing Parquet files was changed compared to Pandas, even though Parquet, as a standard, should support partitioning\r\n\r\nBecause we need to support GeoParquet. Until recently, there was no native support of geospatial data in Parquet spec itself.",
      "@martinfleis sorry, I was wrong. I don't know how this project is being carried out and I had no right to speak in this way.\r\nInstead, I will try to explain myself better on the topic of this pull request: I don't understand why you can't implement a feature because of an optional GeoParquet metadata such as bbox. At first, for example, you could leave that field empty because it is optional, or fill it with a total bbox [not breaking, not optimized, conceptually out of specification]. It's just my opinion, but the benefits of partitioning outweigh the fact of not optimizing the filter with respect to the bbox.\r\nSorry again for the previous message"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d557ac254a19ac29dfb6",
    "number": 2807,
    "body": "Fixes #2681 \r\nThe GeoAlchemy 2 requires SQLAlchemy >= 1.4. \r\nSQLAlchemy introduced [TextClause](https://github.com/sqlalchemy/sqlalchemy/blob/main/lib/sqlalchemy/sql/elements.py#L2170) in version 1.0 which is used to compose a textual statement that is passed to the database. ",
    "head_branch": "main",
    "is_a_fork": true,
    "comments": [
      "Thanks! Not sure I understand why this makes a difference though but that is just my ignorance of the SQL world probably. Also not sure why our tests here https://github.com/geopandas/geopandas/blob/a24aad542014814764438d13026f07ca50a4a580/geopandas/io/tests/test_sql.py#L413 don't fail...\r\n\r\nAny chance you could come up with a way to reproduce and test this case in our tests? This is our setup https://github.com/geopandas/geopandas/blob/a24aad542014814764438d13026f07ca50a4a580/ci/scripts/setup_postgres.sh\r\n\r\n",
      "This is a great fix; please merge it soon. We are also blocked by this bug.",
      "> https://github.com/geopandas/geopandas/blob/a24aad542014814764438d13026f07ca50a4a580/ci/scripts/setup_postgres.sh\r\n\r\nIn order to reproduce it, you need SqlAlchemy > 2.0.\r\nThis is not an issue with Postgres itself but with SQLAlchemy which is the underlying engine of geopandas.\r\n\r\nThe breaking change was: https://docs.sqlalchemy.org/en/20/changelog/migration_20.html\r\n```\r\n# direct string SQL not supported; use text() or exec_driver_sql() method\r\nresult = connection.execute(\"select * from table\")\r\n```\r\n\r\nSo SQLAlchemy 2.0 needs to have text() in the execute queries, otherwise it will fail and that's why it is throwing:\r\n`Not an executable object: \"SELECT Find_SRID'`\r\ntext() is also compatible with SQLAlchemy 1.x, so this should not be a breaking change:\r\n\r\n```\r\nThe new [Connection.execute()](https://docs.sqlalchemy.org/en/20/core/connections.html#sqlalchemy.engine.Connection.execute) method now accepts a subset of the argument styles that are accepted by the 1.x [Connection.execute()](https://docs.sqlalchemy.org/en/20/core/connections.html#sqlalchemy.engine.Connection.execute) method, so the following code is cross-compatible between 1.x and 2.0:\r\n\r\nconnection = engine.connect()\r\n\r\nfrom sqlalchemy import text\r\n\r\nresult = connection.execute(text(\"select * from table\"))\r\n```\r\n\r\nI assume this will affect all the statements which execute raw queries.\r\n\r\nYou can try updating SQLAlchemy in the requirements.txt to test it:\r\n```\r\nSQLAlchemy = \"^2.0.4\"\r\n```\r\n",
      "xref #2778",
      "@martinfleis The test cases indeed fail when we have SQLAlchemy > 2.   \r\nThis is my setup:  \r\n``` \r\ngit clone https://github.com/geopandas/geopandas.git   \r\ncd geopandas  \r\npip install . \r\nexport PGUSER='pguser'\r\nexport PGPASSWORD='xxxxxxx'\r\nexport PGHOST='127.0.0.1'\r\nexport PGPORT=5432\r\npip install GeoAlchemy2 #installs SQLAlchemy==2.0.7 \r\npytest geopandas/geopandas/io/tests/test_sql.py \r\n```\r\nThe reason why all the test cases in all environments of the GitHub Actions are passing is because the env files specifically requests SQLAlchemy<2\r\n\r\nThe Failed test cases for SQLAlchemy>2  \r\n[testcases.txt](https://github.com/geopandas/geopandas/files/11033805/testcases.txt)\r\n\r\nALL the test cases pass if I install SQLAlchemy<2\r\n",
      "Hi @rietesh the pinning of SQLalchemy is deliberate as pandas <2 does not support sqlalchemy 2 (see #2776). In terms of this pull request, I would first suggest removing the pin on sqlalchemy in `ci/envs/310-dev.yaml` -as this is actually installing pandas main. \r\nOnce this is successful we may look at keeping a mix of sqlalchemy <2 and >=2 across the set of test environments.",
      "@m-richards @martinfleis from what i can see in the [`tests.yaml`](https://github.com/rietesh/geopandas/blob/main/.github/workflows/tests.yaml) file in the github workflow only the env `ci/envs/39-pd13-conda-forge.yaml` tests with POSTGIS for all the other envs the tests are skipped including for `ci/envs/310-dev.yaml` So is it fine if I test with that env? i.e, change the SQLAlchemy>2 and rewrite the test cases to be compatible with pandas.to_sql() and SQLAlchemy>2 ? ",
      "Hi @rietesh, I had a look at the test failures and a bit more deeply at what is required for sqlalchemy 2 support. To deal with some of the test migrations, I opened up a separate pull request at #2846 - keeping the commits for the work you have done already of course, I hope you don't mind!\r\n\r\nIf you have a chance would you mind quickly having a review of the changes there and seeing what you think?\r\n\r\n",
      "Now incorporated into #2046 which is merged into main."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d558ac254a19ac29dfb7",
    "number": 2803,
    "body": "Normally, selecting multiple columns in pandas returns a copy, but that was not done for extension dtype columns. This is fixed in 2.0 (https://github.com/pandas-dev/pandas/pull/51197), so we have to update one of our tests accordingly (this should fix one of the failing tests in the dev build).\r\n\r\nThis is somewhat a regression from the point of view of geopandas (adding an extra copy), but with the experimental Copy-on-Write feature of pandas, this will go back to not copying (unless you would afterwards mutate the column).",
    "head_branch": "tst-sindex-columns-subset-copy",
    "is_a_fork": true,
    "comments": [
      "Thanks @jorisvandenbossche!"
    ],
    "commit_messages": [
      "TST: selecting multiple columns copies GeometryArray with pandas >= 2.0, losing sindex (#2803)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d559ac254a19ac29dfb8",
    "number": 2802,
    "body": "The matplotlib failures in the dev build are known and the change might be reverted on the matplotlib side: https://github.com/matplotlib/matplotlib/issues/25162 (and if not, it's also easy to solve with adding some `squeeze()` calls to remove the extra dimension of length 1 in the color array). \r\n\r\nFor now, assuming this will be changed back in matplotlib, skipping the tests just for mpl 3.8.0.dev, to get a green CI build.",
    "head_branch": "ci-tmp-skip-mpl-38",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: temporary skip test_legend for matplotlib 3.8.0.dev (#2802)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d559ac254a19ac29dfb9",
    "number": 2796,
    "body": "Addresses issues related to pyogrio engine noted in [#2795 comment](https://github.com/geopandas/geopandas/issues/2795#issuecomment-1435264056)\r\n\r\nThis skips preprocessing of the file path or bytes passed to `read_file` and instead delegates that to `pyogrio` to parse.\r\n\r\nSince this was the simpler case, I moved it to the first condition.\r\n\r\nTested manually with the remote file referenced in #2795 and it yields the same performance as using `pyogrio` directly.",
    "head_branch": "skip_bytes_download_pyogrio",
    "is_a_fork": true,
    "comments": [
      "Is this worth a small changelog note?",
      "Thanks @brendan-ward!",
      "I'm not 100% sure this is related, but this used to work:\r\n```python\r\nurl = \"https://api.weather.gc.ca/collections/climate-stations/items?ENG_PROV_NAME=NOVA-SCOTIA\"\r\ngpd.read_file(url)\r\n```",
      "@huard it might be related to the same change (this PR), but I assume it is another issue. You don't have a zip file I think, but a GeoJSON file. But for some reason GDAL doesn't recognizes it. \r\n\r\nUsing GDAL directly, using the plain url works, while prepending it with `\\vsicurl\\` (as we do under the hood) doesn't work:\r\n\r\n```\r\n$ ogrinfo https://api.weather.gc.ca/collections/climate-stations/items?ENG_PROV_NAME=NOVA-SCOTIA\r\nINFO: Open of `https://api.weather.gc.ca/collections/climate-stations/items?ENG_PROV_NAME=NOVA-SCOTIA'\r\n      using driver `GeoJSON' successful.\r\n1: OGRGeoJSON (Point)\r\n\r\n$ ogrinfo /vsicurl/https://api.weather.gc.ca/collections/climate-stations/items?ENG_PROV_NAME=NOVA-SCOTIA\r\nWarning 1: HTTP response code on https://api.weather.gc.ca/collections/climate-stations/items?ENG_PROV_NAME=NOVA-SCOTIA: 500\r\nFAILURE:\r\nUnable to open datasource `/vsicurl/https://api.weather.gc.ca/collections/climate-stations/items?ENG_PROV_NAME=NOVA-SCOTIA' with the following drivers.\r\n  -> FITS\r\n  ...\r\n```",
      "Should I open an issue here or elsewhere for this ? ",
      "@huard could you move your example to a comment in https://github.com/geopandas/geopandas/issues/2908?",
      "Done",
      "Thanks @huard !"
    ],
    "commit_messages": [
      "FIX: remove download from URL in read_file before calling Fiona / pyogrio (#2796)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d55aac254a19ac29dfba",
    "number": 2790,
    "body": "- Installation commands are provided\r\n- More in-depth explanation of plotting with geopandas is given with example code\r\n- Brief clarification on file formatting",
    "head_branch": "main",
    "is_a_fork": true,
    "comments": [
      "Hey, thanks for the PR! I am fine with adding the installation instructions but am less keen on adding more documentation to the Readme. It is harder to maintain stuff at two different places and we it will likely get soon out of date. The current state of readme confirms that, with plots coming from something like geopandas 0.2... If you run the code now, you will not get the figures shown there. So my proposal for this PR would be to reduce it to installation commands.",
      "Hi, I'm not sure if the latest commit was intentional or not but given it is an unknown action to me and clearly unrelated to the PR, I have closed and locked the PR as a security measure. "
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d55bac254a19ac29dfbb",
    "number": 2789,
    "body": "This PR will eventually replace all occurrences of `geopandas.datasets` with alternative data using `geodatasets`. At the moment WIP, want to see RTD builds.\r\n\r\nIt will allow us to deprecate `geopandas.datasets`.",
    "head_branch": "rm_datasets_docs",
    "is_a_fork": true,
    "comments": [
      "I think this is ready. It covers the introduction, user guide and the advanced guide. I guess it will be easier to leave docstrings and examples as follow-up PRs, this one it beefy enough to review already...\r\n\r\nPart of the reason I started this was to figure out if there is something to add to `geodatasets` but it seems we're well covered for our purposes, so I may cut the first non-beta release and ensure it is on conda-forge.\r\n\r\nIn a few cases I have cleaned the docs along the way as some bits were no longer true. Other parts would deserve some care but that can be left for future.\r\n\r\nI think it works nicely now and we have a bit wider variety of data to show, from some US data to Chile, Colombia or Nepal.",
      "@martinfleis sorry I'm not going to get a chance to look at this for a bit, I'm overseas without a laptop for the next week and a bit. I was hoping to get to it today, but I hit this trying to import geodatasets (same for both pypi and pip installing from github, it doesn't seem to be on conda forge yet?\r\n```python\r\nPython 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 05:59:45) [MSC v.1929 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import geodatasets\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\tools\\miniconda3\\envs\\py38_pd13_gpd_dev\\lib\\site-packages\\geodatasets\\__init__.py\", line 1, in <module>\r\n    from .api import get_path, get_url, fetch  # noqa\r\n  File \"C:\\tools\\miniconda3\\envs\\py38_pd13_gpd_dev\\lib\\site-packages\\geodatasets\\api.py\", line 3, in <module>\r\n    from .data import data\r\n  File \"C:\\tools\\miniconda3\\envs\\py38_pd13_gpd_dev\\lib\\site-packages\\geodatasets\\data.py\", line 6, in <module>\r\n    json = importlib.resources.read_text(json, \"database.json\")\r\n  File \"C:\\tools\\miniconda3\\envs\\py38_pd13_gpd_dev\\lib\\importlib\\resources.py\", line 169, in read_text\r\n    with open_text(package, resource, encoding, errors) as fp:\r\n  File \"C:\\tools\\miniconda3\\envs\\py38_pd13_gpd_dev\\lib\\importlib\\resources.py\", line 126, in open_text\r\n    _check_location(package)\r\n  File \"C:\\tools\\miniconda3\\envs\\py38_pd13_gpd_dev\\lib\\importlib\\resources.py\", line 82, in _check_location\r\n    raise FileNotFoundError(f'Package has no location {package!r}')\r\nFileNotFoundError: Package has no location <module 'geodatasets.json' (namespace)>\r\n```\r\n\"database.json\" does appear to exist in my site packages though. It's not a clean environment and I'm using pip from conda, so could definitely be something wrong on my end, just don't have to troubleshoot unfortunately.",
      "There may as well be a bug in geodatasets. It is not on conda-forge yet.",
      "I think we need to revise how we do this in geodatasets and probably also xyzservices according to https://stackoverflow.com/a/58941536",
      "@m-richards you have actually found a bug we had with Py38. Shall be fixed in the latest beta on PyPI.",
      "RTD is now failing because the nybb dataset got updated and the hash got out of sync on the geodatasets side. Need to figure out how to deal with that with a long-term perspective.",
      "> RTD is now failing because the nybb dataset got updated and the hash got out of sync on the geodatasets side. Need to figure out how to deal with that with a long-term perspective.\r\n\r\nhttps://github.com/geopandas/geodatasets/pull/9"
    ],
    "commit_messages": [
      "DOC: replace geopandas.datasets with geodatasets in user-facing documentation (#2789)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d55cac254a19ac29dfbc",
    "number": 2788,
    "body": "cc @brendan-ward this translates the current `mode` keyword and enables the tests\r\n\r\nI think it would still be good to document (and test) you can also pass `append=True` (that should already work since we pass through the keywords). And we could actually also do that for the fiona engine (translate append=True to mode=\"a\")",
    "head_branch": "pyogrio-append",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: enable and test append mode for pyogrio engine (#2788)\n\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d55dac254a19ac29dfbd",
    "number": 2786,
    "body": "Follow-up on https://github.com/geopandas/geopandas/pull/2297 to make use of the Hilbert distance when sorting GeoSeries/GeoDataFrame.\r\n\r\nCloses #2070",
    "head_branch": "sort-values-hilbert",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: support sorting geometry columns based on Hilbert distance (#2786)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d55eac254a19ac29dfbe",
    "number": 2785,
    "body": "As a first step, this makes the `.data` attribute of GeometryArray into a read-only property, and switches to use `_data` internally. In a next step we can then add a deprecation warning to the public property.",
    "head_branch": "geometry-array-data-depr",
    "is_a_fork": true,
    "comments": [
      "FWIW, the matplotlib failures in the dev build are known and the change might be reverted on the matplotlib side: https://github.com/matplotlib/matplotlib/issues/25162 (and if not, it's also easy to solve with adding some `squeeze()` calls to remove the extra dimension of length 1 in the color array. ",
      "Two more cases to change (unless we suppress deprecation warnings there, once we have them):\r\n\r\nHere\r\nhttps://github.com/geopandas/geopandas/blob/ed20d113d58f23dd5f564c7347a3883aa248e84a/geopandas/tests/test_sindex.py#L439\r\n\r\nAnd two cases here\r\n\r\nhttps://github.com/geopandas/geopandas/blob/ed20d113d58f23dd5f564c7347a3883aa248e84a/geopandas/tests/test_sindex.py#L644-L648\r\n\r\nThose are the only places that pop up when I add `raise`  to `data`.\r\n\r\nAlso - shall we add a specific test for this?",
      "> FWIW, the matplotlib failures in the dev build are known and the change might be reverted on the matplotlib side: [matplotlib/matplotlib#25162](https://github.com/matplotlib/matplotlib/issues/25162) (and if not, it's also easy to solve with adding some `squeeze()` calls to remove the extra dimension of length 1 in the color array.\r\n\r\nThanks for working this out, I had a look earlier but couldn't tell if this was deliberate or a bug, nice to now know.",
      "Sorry for not providing much context. This is rather related to https://github.com/geopandas/geopandas/issues/2691 (PyGEOS -> Shapely migration). By making `.data` a property (instead of just a simple attribute), we can add warnings in a next step (specifically warning that those pygeos geometries will become shapely geometries in the future, when we switch to prefer shapely above pygeos; and maybe generally deprecating accessing `.data` directly in favor of `np.asarray(..)` or `.to_numpy()`, to avoid exposing \"internal\" implementation details)"
    ],
    "commit_messages": [
      "REF: rename GeometryArray.data to _data (#2785)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d55eac254a19ac29dfbf",
    "number": 2781,
    "body": null,
    "head_branch": "fix_value_counts",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: update test for value counts and pandas 2.0 (#2781)\n\nupdate test"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d55fac254a19ac29dfc0",
    "number": 2780,
    "body": "As more projects I've used have adopted `black` for styling, one minor\nannoyance has been the impact that `black` commits that impact many\nlines of code have on the usability of `git blame`. A co-worker\nintroduced me to the changes proposed here, which make the blame more\nusable. As of spring last year, github now looks at\n.git-blame-ignore-devs by default\n(https://docs.github.com/en/repositories/working-with-files/using-files/viewing-a-file#ignore-commits-in-the-blame-view),\nso the blame view in github will use these commits. devs who want their\nlocal `git blame` will need the step added to the CONTRIBUTING.md file.\n",
    "head_branch": "cleaner-blame",
    "is_a_fork": false,
    "comments": [
      "Thanks also for sharing, I knew this was a problem, didn't know there was a nice solution"
    ],
    "commit_messages": [
      "Exclude major black only commits from git blame (#2780)\n\n* Exclude major black only commits from git blame\r\n\r\nAs more projects I've used have adopted `black` for styling, one minor\r\nannoyance has been the impact that `black` commits that impact many\r\nlines of code have on the usability of `git blame`. A co-worker\r\nintroduced me to the changes proposed here, which make the blame more\r\nusable. As of spring last year, github now looks at\r\n.git-blame-ignore-devs by default\r\n(https://docs.github.com/en/repositories/working-with-files/using-files/viewing-a-file#ignore-commits-in-the-blame-view),\r\nso the blame view in github will use these commits. devs who want their\r\nlocal `git blame` will need the step added to the CONTRIBUTING.md file.\r\n\r\n* Update .git-blame-ignore-revs\r\n\r\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>\r\n\r\n---------\r\n\r\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d560ac254a19ac29dfc1",
    "number": 2779,
    "body": null,
    "head_branch": "black23",
    "is_a_fork": true,
    "comments": [
      "Happy to merge this to keep up to date with black. "
    ],
    "commit_messages": [
      "LINT: Update to Black 23.1 (#2779)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d561ac254a19ac29dfc2",
    "number": 2776,
    "body": "Probably also need to pin deps until pandas is compatible?",
    "head_branch": "pin_sqlalchemy",
    "is_a_fork": true,
    "comments": [
      "I'd leave pandas to deal with the support and just point users temporarily to older versions of sqlalchemy. We can revise that ahead of a release but I'd rather not pin in geopandas if the fix is not on us.\r\n\r\nThat said, I'd certainly merge this now, we just need a reminder to unpin it at some point.",
      "I've created an issue to track future compatibility separately. The failures in the 310-dev environment are unrelated, (value counts and test legend)"
    ],
    "commit_messages": [
      "CI: pin sqlalchemy <2 for now (#2776)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d562ac254a19ac29dfc3",
    "number": 2775,
    "body": "closes #2765 and #2130. I know we don't have 100% consensus on the latter - I originally was just going to add a custom copy method along the lines of \r\n```python\r\ndef copy(self, deep=True):\r\n    copied = super().copy(deep=deep)\r\n    if type(copied) is pd.DataFrame:\r\n        copied = GeoDataFrame(copied)\r\n    return copied\r\n```  \r\nThis does work, but the constructor wrapper doesn't preserve everything that an ordindary copy would (like .attrs for example) - albeit they would only affect `GeoDataFrame()`. Given this, it seemed better to just do a \"proper\" fix in `_constructor` by special casing the empty constructor.\r\n",
    "head_branch": "fix_copy_class_preservation",
    "is_a_fork": true,
    "comments": [
      "One additional corner case to consider: no columns, but with non-zero number of rows. Also such a case currently looses the class type:\r\n\r\n```\r\nIn [3]: df = geopandas.GeoDataFrame(np.empty((10,0)))\r\n\r\nIn [4]: df\r\nOut[4]: \r\nEmpty GeoDataFrame\r\nColumns: []\r\nIndex: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\r\n\r\nIn [5]: df.shape\r\nOut[5]: (10, 0)\r\n\r\nIn [6]: df.copy()\r\nOut[6]: \r\nEmpty DataFrame\r\nColumns: []\r\nIndex: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\r\n```",
      "Generally, I think I am fine with this special case for empty in `_constructor`, but we should maybe still consider overriding `copy()` anyway? \r\nBecause it is still _allowed_ to explicitly create a GeoDataFrame without geometry column (even though we won't return it anymore ourselves as return value for operations), and also for that kind of dataframes the `copy()` will change class. If we want to keep to the rule that \"copy\" should never change the type, we might still need a custom override for that:\r\n\r\n```\r\nIn [1]: df = geopandas.GeoDataFrame(pd.DataFrame({'a': [1, 2, 3]}))\r\n\r\nIn [2]: type(df)\r\nOut[2]: geopandas.geodataframe.GeoDataFrame\r\n\r\nIn [3]: df._geometry_column_name\r\nOut[3]: 'geometry'\r\n\r\nIn [4]: type(df.copy())\r\nOut[4]: pandas.core.frame.DataFrame\r\n```",
      "> Generally, I think I am fine with this special case for empty in `_constructor`, but we should maybe still consider overriding `copy()` anyway? Because it is still _allowed_ to explicitly create a GeoDataFrame without geometry column (even though we won't return it anymore ourselves as return value for operations), and also for that kind of dataframes the `copy()` will change class. If we want to keep to the rule that \"copy\" should never change the type, we might still need a custom override for that:\r\n\r\n\r\nThat does make sense, just not sure how to do it. In my first post is what I originally tried to override copy, this didn't pass through df.attrs (and I think something else but can't remember what now). \r\n\r\nI guess we could also alter `gdf.__class__` dynamically (and make sure geometry name and crs are preserved, but this feels like a hack. I will have a look and see.\r\n\r\n",
      "> this didn't pass through df.attrs \r\n\r\nSidenote: that seems something we should try to fix anyway for the `GeoDataFrame(..)` constructor? \r\n(and then this might also be OK to use it here)\r\n\r\n> I guess we could also alter `gdf.__class__` dynamically (and make sure geometry name and crs are preserved, but this feels like a hack. I will have a look and see.\r\n\r\nIt's not necessarily a hack (or it can be the \"right\" hack). Because actually using `GeoDataFrame(..)` inside `copy()` might not be the proper solution, as that will copy the dataframe again now (although, if we only do this for empty geodataframes, that probably doesn't matter much). \r\nIt might be useful to have some internal helper method that converts a DataFrame to a GeoDataFrame with minimal overhead (without copying)",
      "Having another look, I can't replicate my own finding re `attrs`, running on ci to see if it shows up for another pandas version.\r\n\r\nEdit:\r\n\r\nThere's no test failure but this snippet fails\r\n\r\n```python\r\ngdf = gpd.GeoDataFrame({'a':[1,2,3]})\r\ngdf.attrs['foo'] = 'bar'\r\ngdf.reset_index().attrs\r\nOut[7]: {}\r\ngdf.copy().attrs\r\nOut[8]: {}\r\n```\r\n",
      "> There's no test failure but this snippet fails\r\n\r\nAnd that snippet works on the main branch, so this PR is breaking that snippet?",
      "And that's because the `GeoDataFrame(gdf)` constructor doesn't preserve `attrs`, and you now use this constructor in `copy()` (and assigning the `__class__` instead would solve this?).\r\n\r\nNow, I was assuming this is a bug in our constructor, but it seems also the pandas.DataFrame constructor doesn't preserve attrs:\r\n\r\n```\r\nIn [8]: df = pd.DataFrame({'a':[1,2,3]})\r\n   ...: df.attrs['foo'] = 'bar'\r\n   ...: \r\n\r\nIn [9]: pd.DataFrame(df).attrs\r\nOut[9]: {}\r\n\r\n```",
      "\r\n\r\n\r\n\r\n> And that's because the `GeoDataFrame(gdf)` constructor doesn't preserve `attrs`, and you now use this constructor in `copy()` (and assigning the `__class__` instead would solve this?).\r\n\r\nYep, just had a look and you are right, using `__class__` instead makes a difference\r\n\r\n\r\n> Now, I was assuming this is a bug in our constructor, but it seems also the pandas.DataFrame constructor doesn't preserve attrs:\r\n> \r\n> ```\r\n> In [8]: df = pd.DataFrame({'a':[1,2,3]})\r\n>    ...: df.attrs['foo'] = 'bar'\r\n>    ...: \r\n> \r\n> In [9]: pd.DataFrame(df).attrs\r\n> Out[9]: {}\r\n> ```\r\n\r\nThis is interesting, I was wondering how our attr preservation works at all then - given `_geodataframe_constructor_with_fallback` always passes through the GeoDataFrame constructor. Looking at our tests, attrs are dropped (seem to also be dropped with blockmanager inputs) but they are restored by `__finalize__`. So I suppose if pandas calls finalize everywhere it needs to, this won't materialize?\r\n\r\nIn the context of `copy` then, should the overload call finalize? - it calls finalize as part of the call to `super()` so I've just preserved `_geometry_column_name` explicitly. Technically this may also not be required as changing `__class__` sets `_geometry_column_name` to the class variable value (currently \"geometry\"), which should always be what the geometry column is set to in the case where the downcasting happens.\r\n\r\n",
      "> In the context of `copy` then, should the overload call finalize?\r\n\r\nAh, yes, that might also work",
      "Thanks!"
    ],
    "commit_messages": [
      "BUG: fix copy class preservation with empty geodataframe with no columns (#2775)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d562ac254a19ac29dfc4",
    "number": 2762,
    "body": "There are multiple reports[^1][^2][^3] that coordinate transformations between pyproj 1 and 2/3 can be significantly slower. This PR implements the recommendation[^4] for optimising transformations with pyproj 2 and 3 by caching the Transformer:\r\n\r\n> Without the cache, it takes around 2 seconds to do 100 iterations. With the cache, it takes 0.1 seconds to do 1 million iterations.[^4]\r\n\r\nTests are passing locally. I ran the transform benchmarks with `asv` and the notable differences are as follows:\r\n\r\n* -3.4% for `transform.CRS.time_transform_many_points` (1.052 ms faster)\r\n* -16.7% for `transform.CRS.time_transform_wgs84` (56.680 ms faster)\r\n\r\nI did also consider whether to implement caching for the `CRS` object, which is also recommended, but this is a little more challenging as the `lru_cache` requires that inputs are hashable which causes incompatibility; for example `CRS.from_user_input` is allowed to have a `dict` as input which is not hashable.\r\n\r\n\r\n[^1]: https://github.com/pyproj4/pyproj/issues/484\r\n[^2]: https://github.com/pyproj4/pyproj/issues/187#issuecomment-472089089\r\n[^3]: https://github.com/pyproj4/pyproj/issues/661\r\n[^4]: https://pyproj4.github.io/pyproj/stable/advanced_examples.html#caching-pyproj-objects",
    "head_branch": "optimise-pyproj-3",
    "is_a_fork": true,
    "comments": [
      "@mblackgeo thanks for taking a look at this\r\n\r\n> There are multiple reports[1, 2, 3] that coordinate transformations between pyproj 1 and 2/3 can be significantly slower\r\n\r\nAFAIK those reports are all about repeatedly calling `pyproj.transform` (i.e. creating the transformation object each time and only call it once), and the answer to those issue is: with pyproj > 2, you can create a Transformer object once, and call its transform method multiple times (or call it once with an array). \r\n\r\nGeoPandas already does this, and so I think that most of the performance issues should be solved with that. Did you yourself run into a performance issue regarding usage of `to_crs`?\r\n\r\nIn practice, you should only notice the overhead of creating the Transformer object for tiny datasets. As an example, using the small countries dataset:\r\n\r\n```\r\nIn [26]: df = geopandas.read_file(geopandas.datasets.get_path(\"naturalearth_lowres\"))\r\n\r\nIn [27]: import pyproj\r\n\r\nIn [29]: %timeit pyproj.Transformer.from_crs(df.crs, \"EPSG:3857\")\r\n1.91 ms ± 90.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\r\n\r\nIn [31]: %timeit df.geometry.to_crs(\"EPSG:3857\")\r\n4.46 ms ± 590 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\r\n```\r\n\r\nSo here the part of creating the transformer is almost half of the total runtime of `to_crs`, but, this part is constant, and the actual conversion of coordinates grows with the dataset. So for larger datasets, this millisecond will be hardly noticeable.\r\n\r\nAnd as a user you can also cut down on this time by providing a CRS object yourself instead of a string that still needs to be interpreted:\r\n\r\n```\r\nIn [32]: target_crs = pyproj.CRS(\"EPSG:3857\")\r\n\r\nIn [33]: %timeit pyproj.Transformer.from_crs(df.crs, target_crs)\r\n1.1 ms ± 84.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\r\n```\r\n\r\nSo while this can be significant if you would call `to_crs()` on _many_ tiny dataframes, I just want to be clear about the scope and impact of this change.",
      "@jorisvandenbossche thanks for taking a look at this so quickly.\r\n\r\nAgree as you summarise in your response than in general most users would probably not benefit, as you say the transformer is only initialised once in effectively constant time.\r\n\r\n> So while this can be significant if you would call to_crs() on many tiny dataframes, I just want to be clear about the scope and impact of this change.\r\n\r\nThis was the exact scenario in which I was hitting the problem. The issue is perhaps quite niche, and I probably can't share a concrete example for privacy reasons, but the process did exactly involve many small geodataframes. It required the conversion into an azimuthal equidistant projection, do some calculations, and then reproject back into a geographic CRS. We had noticed a significant degradation in performance with the changes in pyproj 2/3, hence the rationale behind this PR. ",
      "> This was the exact scenario in which I was hitting the problem.\r\n\r\nOK, sounds good. I was a bit hesitant to add this complexity for a corner case, but I think we can actually simplify the PR a bit, and then that shouldn't be a concern I think.",
      "> > This was the exact scenario in which I was hitting the problem.\r\n> \r\n> OK, sounds good. I was a bit hesitant to add this complexity for a corner case, but I think we can actually simplify the PR a bit, and then that shouldn't be a concern I think.\r\n\r\nThanks, all done"
    ],
    "commit_messages": [
      "PERF: Implement cached transformer.from_crs for to_crs (#2762)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d563ac254a19ac29dfc5",
    "number": 2761,
    "body": "Closes #2653",
    "head_branch": "geoparquet-empty-bbox",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: avoid invalid bbox for empty GeoDataFrame in to_parquet (#2761)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d564ac254a19ac29dfc6",
    "number": 2760,
    "body": "Closes #2654",
    "head_branch": "geoparquet-wkb-flavor",
    "is_a_fork": true,
    "comments": [
      "Do we want to raise a warning if you are not using Shapely 2.0 and have 3D geometries about that it will write a non-conformant file? \r\n(in practice, most other libraries will happily read such files, so not sure if that is needed)"
    ],
    "commit_messages": [
      "BUG: fix to_parquet/to_feather to write ISO WKB flavor for 3D geometries (if shapely >= 2 is available) (#2760)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d565ac254a19ac29dfc7",
    "number": 2756,
    "body": "Small change to the notebook showing interactive mapping.\r\n\r\n- The `control` parameter is already True by default, no need to specify it.\r\n- [We've recently merged a PR in folium](https://github.com/python-visualization/folium/pull/1690) that changes the default behavior when adding multiple base layers. Keep the current behavior by specifying we don't want to see the extra tilelayer when opening the map.",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: update usage of `folium.TileLayer` (#2756)\n\nUpdate usage of `folium.TileLayer`\r\n\r\n- The `control` parameter is already True by default, no need to specify it.\r\n- We've recently merged a PR in folium that changes the default behavior of multiple base layers. Prepare for this by specifying we want to show the first base layer by default, which is the same as the current behavior."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d566ac254a19ac29dfc8",
    "number": 2755,
    "body": "Renamed the base branch from this PR -- didn't realise it would close the original: https://github.com/geopandas/geopandas/pull/2184\r\n\r\nThis is an execution test harness that is extremely useful for finding edge cases in the overlay code. ",
    "head_branch": "random_poly-execution-test",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d566ac254a19ac29dfc9",
    "number": 2701,
    "body": "I have enabled discussion, now editing the issue templates and adding links.\r\n\r\nI have also removed the installation issue type as that is usually not actionable on our side so it shall go to discussions.",
    "head_branch": "discussions",
    "is_a_fork": true,
    "comments": [
      "Once this gets merged :)",
      "Hmm, the templates are gone but the link to the discussions didn't show up... Another attempt will come soon.",
      "I think I'll try to fix this by pushing directly to main, sorry! I am not able to get a feedback from GitHub otherwise.",
      "Works now."
    ],
    "commit_messages": [
      "Adapt issue templates to discussions (#2701)\n\n* Adapt issue templates to discussions\r\n\r\n* link\r\n\r\n* add links to docs"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d567ac254a19ac29dfca",
    "number": 2698,
    "body": "Closes #2697\r\n\r\nFolium made a small change in ordering of values in the output JS, so we need to adapt to that. The result is exactly the same.",
    "head_branch": "explore_vmin_vmax",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: adapt test for folium main (#2698)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d568ac254a19ac29dfcb",
    "number": 2696,
    "body": "Fiona 1.9 is adding deprecation warnings in advance of some changes coming to Fiona 2.0 (cfr https://github.com/Toblerity/Fiona/issues/758, https://github.com/Toblerity/fiona-rfc/blob/master/rfc/0001-fiona-2-0-changes.md)\r\n\r\nIn the dev build (where fiona 1.9b1 is installed), we can see those:\r\n\r\n```\r\ngeopandas/io/tests/test_file.py: 2108 warnings\r\ngeopandas/io/tests/test_file_geom_types_drivers.py: 99 warnings\r\ngeopandas/tests/test_geoseries.py: 2 warnings\r\n  /usr/share/miniconda3/envs/test/lib/python3.10/site-packages/fiona/collection.py:551: \r\n        FionaDeprecationWarning: Support for feature and geometry dicts is deprecated. \r\n        Instances of Feature and Geometry will be required in 2.0.\r\n    self.session.writerecs(records, self)\r\n```\r\n\r\nThis PR already starts using the new API if fiona >= 1.9\r\n\r\n\r\n",
    "head_branch": "compat-fiona-19",
    "is_a_fork": true,
    "comments": [
      "With the latest changes in Fiona to support `__geo_interface__` objects/dicts directly (without needing to manually convert to a fiona Feature or Geometry object, cfr https://github.com/Toblerity/Fiona/discussions/1183), our test suite now runs again without warnings already on the main branch (the last commit includes fiona 1.9b2, and has no warnings, in contrast to the commit before that which includes fiona 1.9b1)\r\n\r\nSo we can close this PR."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d569ac254a19ac29dfcc",
    "number": 2695,
    "body": "Fixes #2690.\r\n\r\nManually remove `__init__.py` changes from the commit to avoid the duplication of those two lines like we have now in #2694.\r\n\r\nI tested it on my fork but it will probably needs to be merged to test it properly.",
    "head_branch": "versioneer_gha",
    "is_a_fork": true,
    "comments": [
      "Confirmed https://github.com/geopandas/geopandas/actions/runs/4153385156/jobs/7184987613"
    ],
    "commit_messages": [
      "CI: fix versioneer update action (#2695)\n\n* specify paths to commit\r\n\r\n* test add-paths\r\n\r\n* list\r\n\r\n* try with custom run\r\n\r\n* add names\r\n\r\n* revert branch name\r\n\r\n* remove only init"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d56aac254a19ac29dfcd",
    "number": 2694,
    "body": "Automatic update of Versioneer by the `versioneer.yml` workflow.\n\nPlease review changes manually, especially if a duplicate `from . import _version` is added.",
    "head_branch": "update-versioneer",
    "is_a_fork": false,
    "comments": [
      "Not to be merged. see #2690"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d56aac254a19ac29dfce",
    "number": 2689,
    "body": "Closes #2688 \r\n",
    "head_branch": "doctests_are_broken",
    "is_a_fork": true,
    "comments": [
      "@m-richards thanks for looking into this!\r\n\r\n- For the LineString -> LinearRing change, see comment inline (caused by https://github.com/geopandas/geopandas/pull/2275, it could potentially be fixed on our side)\r\n- For the \"LINESTRING (Z) EMPTY\" one, see my explanation on the shapely issue. Probably nothing to do about on the short term on our side (except for changing the example data .. but probably we explicitly included an example that resulted in empty line)\r\n- The \"GEOMETRYCOLLECTION EMPTY\" to \"POINT EMPTY\"/\"POLYGON EMPTY\" changes are expected (and actual improvements)"
    ],
    "commit_messages": [
      "DOC: doctest fixes for shapely 2.0 (#2689)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d56bac254a19ac29dfcf",
    "number": 2687,
    "body": "This is trying to address the crashes in the pandas 1.2 and pandas 3.9 latest environments seen here: https://github.com/geopandas/geopandas/actions/runs/3771037533/jobs/6411224335\r\n\r\n----------------------\r\nSubsequently repurposed to pin numpy versions after this was fixed upstream.",
    "head_branch": "matt/fix_plotting_mpl_numpy",
    "is_a_fork": true,
    "comments": [
      "On the main branch, this no longer seems necessary? (I just merged a PR, so a recent run https://github.com/geopandas/geopandas/actions/runs/3795324743/jobs/6454340166 shows the docstring failures)\r\n\r\nMaybe numpy 1.24.1 fixed it in the meantime? (released 2 days ago, https://github.com/numpy/numpy/releases/tag/v1.24.1). https://github.com/numpy/numpy/pull/22849 seems matplotlib related.",
      "> On the main branch, this no longer seems necessary? (I just merged a PR, so a recent run https://github.com/geopandas/geopandas/actions/runs/3795324743/jobs/6454340166 shows the docstring failures)\r\n> \r\n> Maybe numpy 1.24.1 fixed it in the meantime? (released 2 days ago, https://github.com/numpy/numpy/releases/tag/v1.24.1). [numpy/numpy#22849](https://github.com/numpy/numpy/pull/22849) seems matplotlib related.\r\n\r\nYep, pretty sure https://github.com/numpy/numpy/issues/22842 is the specific issue we see here and is now fixed (I thought this must have been a behaviour change, didn't check upstream to see if it was a bug).\r\n\r\n\r\nI'll update this with a pinned numpy from pandas 1.2 era"
    ],
    "commit_messages": [
      "CI: numpy version for pandas 1.2 (#2687)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d56cac254a19ac29dfd0",
    "number": 2686,
    "body": "This fixes one of the CI failures at the moment, the default representation of timezones has changed on the pandas main branch (https://github.com/pandas-dev/pandas/pull/49677)",
    "head_branch": "fix_pandas_tz_defaults",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "COMPAT: Fix pandas tz defaults (#2686)\n\nupdated tests to handle https://github.com/pandas-dev/pandas/pull/49677"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d56dac254a19ac29dfd1",
    "number": 2685,
    "body": "To keep these merge requests well defined, will have to incrementally get ci to pass. This solves the dissolve related issues.\r\nThere are also separately pandas 2.0 representation of utc timezones which has changed (#2686), an interaction issue between matplotlib 3.3.2 and the new numpy 1.2.4 and some doctests seem to have changed as well.\r\n\r\nedit: checking the tests on CI now, I think all these failures are expected, these are unrelated to the dissolve stuff.",
    "head_branch": "matt/dissolve_warnings_v2",
    "is_a_fork": true,
    "comments": [
      "The last test failure is codecov - for the line which is passing through non captured warnings. This doesn't seem particularly straightforward to try and test.",
      "> This doesn't seem particularly straightforward to try and test.\r\n\r\nNot tested, but maybe you can create a small custom aggregation function that raises a warning:\r\n\r\n```\r\ndef my_func(group):\r\n    warnings.warn(...)\r\n    return group.mean()\r\n\r\ngdf.dissolve(.., aggfunc=my_func)\r\n```",
      "> Not tested, but maybe you can create a small custom aggregation function that raises a warning:\r\n\r\nthanks, looks like you're right, we'll see if this is all green now.",
      "I fixed the one remaining failure yesterday and forgot to push. Now there's a new unrelated failure to do with gdf.explore"
    ],
    "commit_messages": [
      "COMPAT: Pandas 1.5.2 / Pandas 2.0 dissolve numeric only (#2685)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d56eac254a19ac29dfd2",
    "number": 2682,
    "body": "This fixes two things:\r\n\r\n1. There is a GitHub bug where the project name is assumed to be in `setup.py` to show dependents in the dependency graph; currently [it is empty](https://github.com/geopandas/geopandas/network/dependents)\r\n2. Re-format the \"text\" TOML entry to it's own section, as the current form has problems with some packages, e.g. try \"tox\", and see \"toml.decoder.TomlDecodeError: Stuff after closed string. WTF? (line 32 column 1 char 977)\". The content of the readme is unchanged.",
    "head_branch": "setup-py-name",
    "is_a_fork": true,
    "comments": [
      "https://github.com/orgs/community/discussions/6456 seems to be the best public report",
      "[fix confirmed](https://github.com/geopandas/geopandas/network/dependents)"
    ],
    "commit_messages": [
      "BUG: Add name to setup.py for GitHub, re-format text TOML entry (#2682)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d56fac254a19ac29dfd3",
    "number": 2680,
    "body": "Closes #2679",
    "head_branch": "fix_concat_unaligned_cols_warn",
    "is_a_fork": true,
    "comments": [
      "Thanks @m-richards!"
    ],
    "commit_messages": [
      "Fix concat unaligned cols warn (#2680)\n\n* TST: test to document issue\r\n\r\n* BUG: solve issue\r\n\r\n* cleanup\r\n\r\n* CLN: cleanup\r\n\r\n* BUG: fix error in implementation\r\n\r\nCo-Authored-By: Joris Van den Bossche <1020496+jorisvandenbossche@users.noreply.github.com>\r\n\r\nCo-authored-by: Joris Van den Bossche <1020496+jorisvandenbossche@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d56fac254a19ac29dfd4",
    "number": 2675,
    "body": "see geopandas/ci/local/README.md\r\n\r\nThis enables running whole GitHub Action test framework locally in an ubuntu VM\r\n\r\nfor discussion\r\n- have made `tests.yaml` more dynamic,  building the test matrix in **python**\r\n- have needed to patch conda action to use local installation of **mamba**",
    "head_branch": "ci_update",
    "is_a_fork": true,
    "comments": [
      "@rraymondgh why do we need this? It is super complex (I wouldn't be able or willing to maintain that) and I am not aware of any other project having something like this. \r\n\r\nimho it is fine to check tests locally in one env and fix potential issues in other if they appear on GHA CI.",
      "Hi @rraymondgh, I don't think we'll want to merge this as it covers very specific use case. We almost never run the CI matrix locally, that is what GHA is for and we would not be able to maintain that. Sorry about that!"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d570ac254a19ac29dfd5",
    "number": 2674,
    "body": "Testing the latest main in an additional build, and then will later today update this to use the actually released 2.0.0",
    "head_branch": "ci-update-shapely",
    "is_a_fork": true,
    "comments": [
      "The non-dev-build failure are the docstring failures -> https://github.com/geopandas/geopandas/pull/2689"
    ],
    "commit_messages": [
      "CI: update shapely versions in test build matrix (#2674)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d571ac254a19ac29dfd6",
    "number": 2672,
    "body": null,
    "head_branch": "changelog0122",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "RLS: 0.12.2 changelog (#2672)\n\n* 0.12.2 changelog\r\n\r\n* remove duplicated header"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d572ac254a19ac29dfd7",
    "number": 2670,
    "body": "Fixes #2382\r\n\r\nThis is an immediate patch of the `naturalearth_lowres` dataset included in GeoPandas. The current version shipped by the provider unfortunately include Crimea as a part of Russia due to their [de facto](https://www.naturalearthdata.com/about/disputed-boundaries-policy/) policy.\r\n\r\nThis PR overrides that and assigns the peninsula back to Ukraine.\r\n\r\nThis PR is considered a bug fix and is targeted for the next patch release 0.12.2 that is due most likely by the end of today.\r\n\r\nHowever, this is a temporary solution until the complex approach towards _disputed regions_ and their treatment in GeoPandas is properly discussed and solved. While the exact solution is unsure as of now, due to some concerns regarding the latest proposal raised by the community on Github, twitter and mastodon, we can assure that as long as this projects ships a world map with political boundaries, Crimea will be part of Ukraine.\r\n\r\nI want to, once again, deeply apologise to the GeoPandas community and everyone affected within and outside of Ukraine for our slow response and initial reluctancy.",
    "head_branch": "crimea",
    "is_a_fork": true,
    "comments": [
      "Thanks for the prompt fix. The people of Ukraine do appreciate it.",
      "The map can be verified here (very bottom) https://geopandas--2670.org.readthedocs.build/en/2670/docs/user_guide/interactive_mapping.html",
      "> The cities dataset should in principle not have changed?\r\n\r\nI ran the whole creation script so it probably just picked a new patch release. ~Can remove that if you prefer that.~ edit: I have\r\n\r\n",
      "@martinfleis thank you and the other geopandas maintainers for the quick response on this. i am grateful for the huge effort that you put into maintaining geopandas!"
    ],
    "commit_messages": [
      "BUG: assign Crimea to Ukraine in naturalearth_lowres (#2670)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d573ac254a19ac29dfd8",
    "number": 2667,
    "body": "I accidentally deleted my geopandas fork so this is just https://github.com/geopandas/geopandas/pull/2306 born again.\r\n\r\n**_Original PR description:_** \r\n\r\nThis PR is very similar to https://github.com/geopandas/geopandas/pull/1324 and fixes https://github.com/geopandas/geopandas/issues/2301 (as well as duplicates https://github.com/geopandas/geopandas/issues/1804, https://github.com/geopandas/geopandas/issues/2017, https://github.com/geopandas/geopandas/issues/2186, and https://github.com/geopandas/geopandas/issues/2301).\r\n\r\nIn the spirit of [this logic](https://github.com/pandas-dev/pandas/blob/ab42f85f192ab054a18f94825ced1bb4c1ab7d3f/pandas/core/frame.py#L616-L629), if a DataFrame is passed to the GeoDataFrame constructor, and the copy kwarg is not explicitly set by the user, then copy=True is set so that the input is not modified.",
    "head_branch": "feat/copy-if-dataframe",
    "is_a_fork": true,
    "comments": [
      "This looks okay to me. Can you also add a changelog note?",
      "> Can you also add a changelog note?\r\n\r\n@martinfleis done in https://github.com/geopandas/geopandas/pull/2667/commits/30e1ef63abe9f3ccd4e0f7229f4f0d99cf9698d1",
      "> as there was no dev version section yet\n\nah yes, sorry I missed that, thanks!!\n\n",
      "Thank you @spolloni!"
    ],
    "commit_messages": [
      "BUG: GeoDataFrame constructor set `copy=true` if copy is not set and `data` is a `DataFrame` (#2667)\n\n* feat: set copy to true if copy is not set and data is a DataFrame\r\n\r\n* style: double quotes for black\r\n\r\n* fix: GeoDataFrame is  Dataframe... check if not gdf instead\r\n\r\n* fix: copying everything except GeoDataFrame breaks the tests, simply copy if type is DataFrame instead\r\n\r\n* fix: discriminate via isinstance()\r\n\r\n* Add test for geodataframe copy\r\n\r\n* feat: set copy to true if data is a DataFrame but not a GeoDataFrame\r\n\r\n* fix: missing import\r\n\r\n* chore: update CHANGELOG.md\r\n\r\n* fixes: assert type, use already imported asserter\r\n\r\n* feat: added test assertions\r\n\r\n* fix: lint appease precommit\r\n\r\n* edit changelog\r\n\r\nCo-authored-by: Zachary Blackwood <zachary@streamlit.io>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d573ac254a19ac29dfd9",
    "number": 2663,
    "body": "Update for the latest geoparquet version (https://geoparquet.org/releases/v1.0.0-beta.1/)\r\n\r\nAlso closes #2693",
    "head_branch": "geoparquet-v1",
    "is_a_fork": true,
    "comments": [
      "Thanks for the feedback! Added an explicit test and updated the docs."
    ],
    "commit_messages": [
      "ENH: support GeoParquet 1.0.0-beta.1 spec (#2663)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d574ac254a19ac29dfda",
    "number": 2662,
    "body": "I noticed that currently our changelog doesn't get formatted properly on readthedocs: https://geopandas.org/en/latest/docs/changelog.html\r\n\r\nThis is because it's being read as RST and in the past we wrote the changelogs such that they were valid markdown and RST. \r\n\r\nGiven that sphinx supports markdown directly via myst, I've just updated this to parse it directly as markdown, which should be less confusing for contributors writing changelog messages.\r\n\r\nI've built locally and it seems to work by probably good to do a read the docs test as well at some point.",
    "head_branch": "changelog_formatting",
    "is_a_fork": true,
    "comments": [
      "Let me allow RTD pull request builds. One min. You may need to push something (even empty) again once enabled.\r\n\r\nedit: enabled",
      "Looks okay to me https://geopandas--2662.org.readthedocs.build/en/2662/docs/changelog.html",
      "> Looks okay to me https://geopandas--2662.org.readthedocs.build/en/2662/docs/changelog.html\r\n\r\nYep, seems to be working. There's still a lot of warnings emitted from the build though (https://readthedocs.org/projects/geopandas/builds/18821387/), all except for the pyproj I can see locally as well.\r\n`UserWarning: potentially wrong underline length... ` this one is confusing to me, it shows up a lot and as far as I can tell there's nothing wrong with those snippets - they're not meant to be headings.\r\n\r\nhttps://geopandas.org/en/stable/gallery/choropleths.html has a broken image and link to pysal.\r\n\r\nThere are two file not found errors, but these are correct, they're relative paths from a notebook to the html pages which are generated: WARNING: File not found: 'docs\\\\reference\\\\api\\\\geopandas.GeoDataFrame.plot.html'\r\n",
      "I just noticed that the url in the second paragraph at https://geopandas.org/en/latest/docs/changelog.html#version-0-12-october-24-2022 (*\"See https://geopandas.org/en/latest/getting_started/install.html#using-the-optional-pygeos-dependency for more details\"*) is no longer working, I assume since this PR. \r\n\r\nWhich is a bit strange, as I would assume that plain urls (without specific syntax) would certainly work in markdown .. ",
      "It is working okay on my side. ",
      "Hmm, that's bizarre, I see:\r\n\r\n![image](https://user-images.githubusercontent.com/1020496/206870292-017f9f35-e1e1-439c-aaea-5b2910cd4388.png)\r\n\r\nso the link is plain text (on the latest docs)",
      "<img width=\"674\" alt=\"Screenshot 2022-12-10 at 19 39 03\" src=\"https://user-images.githubusercontent.com/36797143/206870410-4e4a4530-148a-46e4-b1f4-d912153a935c.png\">\r\nThis is what I see on my side.",
      "It worked fine in chrome, but so after clearing the cache also in firefox .. So indeed false alarm!"
    ],
    "commit_messages": [
      "DOC: Changelog formatting (#2662)\n\n* DOC: Switch changelog to be rendered as markdown by sphinx\r\n\r\n* DOC: fix warnings in docs\r\n\r\n* make ci happen\r\n\r\n* DOC: fix bullet list format\r\n\r\n* DOC: fix whitespace whinging"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d575ac254a19ac29dfdb",
    "number": 2659,
    "body": "Automatic update of Versioneer by the `versioneer.yml` workflow.\n\nPlease review changes manually, especially if a duplicate `from . import _version` is added.",
    "head_branch": "update-versioneer",
    "is_a_fork": false,
    "comments": [
      "I suppose this shouldn't be creating a PR if nothing actually changed?\r\n\r\ncc @EwoutH ",
      "Yes, you're right, this isn't desired behaviour and beats the purpose of this CI. Let me think a bit about how to handle this.\r\n\r\nAt this point it might be good to file an issue upstream.",
      "just reverse any changes to  `__init__.py` and `setup.py` after `versioneer install` like following\r\n\r\n```console\r\ngit reset -- setup.py geopandas/__init__.py\r\ngit checkout -- setup.py geopandas/__init__.py\r\n```"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d576ac254a19ac29dfdc",
    "number": 2658,
    "body": "Hi, I added the process to escape the curly braces {{}} for jinja2 templates.\r\n\r\nCloses #2657",
    "head_branch": "main",
    "is_a_fork": true,
    "comments": [
      "Hi, I just find out one check is failed,\r\n```bash\r\nFAILED geopandas/tests/test_dissolve.py::test_mean_dissolve - TypeError: Could not convert Staten IslandQueensBrooklyn to numeric\r\nFAILED geopandas/tests/test_dissolve.py::test_dissolve_none_mean - TypeError: Could not convert Staten IslandQueensBrooklynManhattanBronx to numeric\r\nFAILED geopandas/tests/test_extension_array.py::TestGroupby::test_in_numeric_groupby - AssertionError: Regex pattern did not match.\r\n Regex: 'does not support'\r\n Input: 'cannot perform sum with type geometry'\r\nFAILED geopandas/tests/test_op_output_types.py::test_constructor_sliced_in_pandas_methods - TypeError: '<' not supported between instances of 'Point' and 'Point'\r\nFAILED geopandas/tests/test_pandas_methods.py::test_numerical_operations - TypeError: cannot perform sum with type geometry\r\nFAILED geopandas/tests/test_pandas_methods.py::test_groupby - TypeError: cannot perform sum with type geometry\r\n= 6 failed, 1793 passed, 264 skipped, 11 xfailed, 2 xpassed, 2294 warnings in 97.43s (0:01:37) =\r\nError: Process completed with exit code 1.\r\n```\r\nDose anyone know how it come?",
      "The errors are not related to this PR (the same are on main) and can be ignored here.",
      "Hey, thanks for the fix. Could you also add a test for this to `test_explore.py`?",
      "> Hey, thanks for the fix. Could you also add a test for this to `test_explore.py`?\r\n\r\nI just added [a test](https://github.com/wybert/geopandas/blob/3b5fb3f1486153b5d9021283d89c60d0da50e690/geopandas/tests/test_explore.py#L468) for it. \r\n",
      "Thanks! looks good. 2 more things \r\n- can you remove `oryx-build-commands.txt` that is added in this PR? \r\n- can you add a changelog note to the Changelog.md?",
      "> \r\n\r\nI just deleted that file and added a changelog note to the Changelog.md",
      "(FYI the failures you will see on the dev branch are unrelated: https://github.com/scipy/scipy/issues/17811)"
    ],
    "commit_messages": [
      "BUG: Escape special characters in explore (#2657) (#2658)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d577ac254a19ac29dfdd",
    "number": 2655,
    "body": "I was coming back to look at #2542 to review and noted the CI failure there is only for pandas 1.0.5. In in another issue it was noted that this actually falls outside the supported depency range we follow based on #1457.\r\n\r\nSo this bumps the minmum pandas version to 1.1 and it also seemed sensible to look at the minimum version of our other dependencies.\r\n\r\n(Perhaps it would make more sense to do this just after a release date is approximately locked in, or after a release - so I'm happy to revert changes to the other packages and keep it just to pandas for now if that makes more sense?)\r\n\r\nThus far I've bumped the following minimum versions:\r\n- Shapely 1.7.1 (released 2020-08-20) - 1.7 was released January 2020 (technically based on supporting dependencies released in the last two years as suggested in NEP29 this should be shapely 1.8.0, but since this was released nearly a year later in Oct 2021, I've opted to keep 1.7.1 for now)\r\n- Numpy 1.20 - NEP 29 says support for 1.19 dropped on Jun 21, 2022\r\n- Fiona 1.8.19 (released Apr 2, 2021 and 1.8.18 before released on Nov 18 2020 and so is outside the 2 year support window)\r\n- PyProj 3.0.1 (released Mar 5, 2021 and 3.0.0.post1 before was released Nov 6, 2020 so is outside the window)\r\n- Matplotlib 3.3.4 (released Jan 28, 2021, 3.3.3 released Nov 12, 2020)\r\n\r\n\r\n(Note at this point I still haven't updated the pyproject.toml, docs, etc, I'll see if I've broken the CI before doing this.",
    "head_branch": "update_min_versions",
    "is_a_fork": true,
    "comments": [
      "I have actually been looking at this systematically.  Getting release dates from **github** and then comparing to compliance with https://numpy.org/neps/nep-0029-deprecation_policy.html\r\n\r\nI think min versions become:\r\n<details>\r\n\r\n| package     |     min |     mid |     max | min_date            | mid_date            | max_date            |\r\n|:------------|--------:|--------:|--------:|:--------------------|:--------------------|:--------------------|\r\n| fiona       |    1.8  |    1.8  |    1.8  | 2022-02-07 00:00:00 | 2022-02-07 00:00:00 | 2022-02-07 00:00:00 |\r\n| folium      |    0.12 |    0.13 |    0.13 | 2021-01-04 00:00:00 | 2022-10-07 00:00:00 | 2022-10-07 00:00:00 |\r\n| geoalchemy2 |    0.1  |    0.11 |    0.12 | 2021-12-24 00:00:00 | 2022-03-04 00:00:00 | 2022-06-07 00:00:00 |\r\n| geopandas   |    0.8  |    0.1  |    0.12 | 2021-01-25 00:00:00 | 2021-10-03 00:00:00 | 2022-10-24 00:00:00 |\r\n| geopy       |    2.1  |    2.2  |    2.3  | 2020-12-27 00:00:00 | 2021-07-11 00:00:00 | 2022-11-13 00:00:00 |\r\n| mapclassify |    2.4  |    2.4  |    2.4  | 2020-12-14 00:00:00 | 2020-12-14 00:00:00 | 2020-12-14 00:00:00 |\r\n| matplotlib  |    3.3  |    3.5  |    3.6  | 2020-11-12 00:00:00 | 2021-11-16 00:00:00 | 2022-09-16 00:00:00 |\r\n| numpy       |    1.19 |    1.21 |    1.23 | 2020-10-29 00:00:00 | 2021-06-19 00:00:00 | 2022-06-22 00:00:00 |\r\n| packaging   |   20.5  |   20.9  |   21.3  | 2020-11-27 00:00:00 | 2021-01-29 00:00:00 | 2021-11-18 00:00:00 |\r\n| pandas      |    1.1  |    1.3  |    1.5  | 2020-10-30 00:00:00 | 2021-07-02 00:00:00 | 2022-09-19 00:00:00 |\r\n| pygeos      |    0.9  |    0.11 |    0.13 | 2021-01-23 00:00:00 | 2021-10-30 00:00:00 | 2022-08-25 00:00:00 |\r\n| pyogrio     |    0.2  |    0.3  |    0.4  | 2021-04-01 00:00:00 | 2021-12-22 00:00:00 | 2022-06-20 00:00:00 |\r\n| pyproj      |    3    |    3.2  |    3.4  | 2020-11-05 00:00:00 | 2021-09-04 00:00:00 | 2022-09-10 00:00:00 |\r\n| python      |    3.7  |    3.9  |    3.11 | 2018-06-27 00:00:00 | 2020-10-05 00:00:00 | 2022-10-24 00:00:00 |\r\n| rtree       |    0.9  |    1    |    1    | 2020-12-16 00:00:00 | 2022-04-04 00:00:00 | 2022-04-04 00:00:00 |\r\n| scipy       |    1.5  |    1.7  |    1.9  | 2020-11-04 00:00:00 | 2021-06-19 00:00:00 | 2022-07-29 00:00:00 |\r\n| shapely     |    1.8  |    1.8  |    1.8  | 2021-10-21 00:00:00 | 2021-10-21 00:00:00 | 2021-10-21 00:00:00 |\r\n| sqlalchemy  |    1.3  |    1.4  |    1.4  | 2020-12-17 00:00:00 | 2021-03-15 00:00:00 | 2021-03-15 00:00:00 |\r\n| xyzservices | 2021.7  | 2022.1  | 2022.9  | 2021-07-30 00:00:00 | 2022-01-17 00:00:00 | 2022-09-19 00:00:00 |\r\n</details>\r\n\r\nI have a jupyter notebook that extracts and generates this (that I can't attach!).  I'm looking to refresh all the environment files in a re-produceable way which can be re-run periodically (maybe on a release basis).  Also getting the whole framework to run locally using https://github.com/nektos/act\r\n\r\nProbably a separate issue / PR.  I think **ci** should be `pytest -q` instead of `pytest -v`.  The verbose output just hides the warnings and errors.  It's far easier to get to wanted content without the verbose logging.\r\n",
      "> I have actually been looking at this systematically. Getting release dates from **github** and then comparing to compliance with https://numpy.org/neps/nep-0029-deprecation_policy.html\r\n\r\nI think this could be quite useful - as this is something that we periodically should review. I haven't looked to see if there is already a tool for this (the above I just did manually as I was looking at the package versionings which are pinned in the CI environments. I don't think this is fully automatable though - for instance take fiona - it's missing releases on github, but they are there on pypi. Additionally we'd want to make sure only to change the dependencies which actually matter, we don't do any version checks for e.g. folium, geopy, packaging, scipy in the geopandas code, so there's no benefit to pinning them.\r\n\r\n> I'm looking to refresh all the environment files in a re-produceable way which can be re-run periodically (maybe on a release basis). Also getting the whole framework to run locally using https://github.com/nektos/act\r\n\r\nThis could also be useful (for instance I updated a numpy pin in one of the CI files and it wasn't clear what version it would make the most sense to update to). But on the other hand sometimes we need to test versions in specific situations rather than based on a schedule - for instance if there are known regressions.\r\n \r\n> Probably a separate issue / PR. I think **ci** should be `pytest -q` instead of `pytest -v`. The verbose output just hides the warnings and errors. It's far easier to get to wanted content without the verbose logging.\r\n\r\nA separate issue to discuss would make sense.\r\n\r\n",
      "The pins look okay to me. It seems that some work on optional pins needs to be done to make CI green.",
      "alright, other ci envs are now green. For reasons I don't quite understand I had to lower fiona to 1.8.18 (see this failure referencing orc and protobuf). Without forcing pyarrow=8, I was able to get an environment with fiona 1.8.19 to resolve, but that ended up installing pyarrow 3, which fails our tests. For now I have only lowered it in the ci, and not in docs/ other places.",
      "Ci is now finally passing on this (I finally realised that I missed updating the postgis section of the tests yaml) so is hopefully ready to merge.",
      "Thanks a lot for this!"
    ],
    "commit_messages": [
      "DEP: Update pandas min version to 1.1 (#2655)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d577ac254a19ac29dfde",
    "number": 2651,
    "body": "In my env pre-commit started hanging.  Have not found further references other than this:\r\n\r\nhttps://www.reddit.com/r/Python/comments/yvfww8/flake8_took_down_the_gitlab_repository_in_favor/",
    "head_branch": "ci_precommit",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: flake8 moved to github (#2651)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d578ac254a19ac29dfdf",
    "number": 2650,
    "body": "This contributes to #1896. Rephrased some of the documentation to use second person perspective per the style guide.",
    "head_branch": "use-second-person",
    "is_a_fork": true,
    "comments": [
      "@Leviob I have updated this one from main. Is it ready for a review?",
      "Yes! Thank you. ",
      "This is an aside for when others review this, I'm genuinely interested in whether second person seems like an improvement or not? \r\n\r\nI actually prefer the first person plural tense as written before this pull request, although I know that's not what is recommended in the style guide (which to be fair, I have not refered to at all contributing to geopandas up to this point). (@Leviob this is not at all critiquing what you've done, just an observation as I went to review this, so please don't take this comment the wrong way). I suspect it's related to how I've been taught in the past, but  \"we\" feels to me inclusive and like a walk-through or tutorial which I like.\r\n\r\nI haven't taken note of how other similar projects voice their documentation (I'm also ignorant of if there are clear best practices around this and this is already a \"solved\" discussion). I wasn't able to find a rationale for the use of second person in the google style guide but I did think this was interesting, it's also a recommendation in the microsoft style guide (https://learn.microsoft.com/en-us/style-guide/grammar/person#avoid-plural-first-person-we-us) which says,\r\n>First-person plural, which often uses the pronoun we, can feel like a daunting corporate presence—the opposite of Microsoft's modern voice. It's OK to use phrasing like we recommend if it helps you avoid awkward phrasing like it's recommended, but write around it if you can. Try to keep the focus on the customer, not Microsoft.\r\nI'd hope geopandas doesn't feel like a \"daunting corporate presence\".\r\n\r\nEdit: reversed clauses in the second sentence to be clearer in meaning.\r\n",
      "[This page](https://developers.google.com/style/person) from Google guide seems to be quite clear regarding second person.\r\n\r\n> In general, use second person in your documents rather than first person—you instead of we.\r\n\r\nSo this PR is perfectly aligned with our goals stated in #1896."
    ],
    "commit_messages": [
      "DOC: Use second person (#2650)\n\n* DOC: Fix perspective\r\n\r\n* Update doc/source/docs/user_guide/aggregation_with_dissolve.rst\r\n\r\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>\r\n\r\n* Remove old section on metadata specification stability\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* DOC: break long line into two lines\r\n\r\n---------\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d579ac254a19ac29dfe0",
    "number": 2649,
    "body": "Fix typo `no notion or projecting` -> `no notion of projecting`",
    "head_branch": "kyle/typo",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix docstring typo in to_crs (#2649)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d57aac254a19ac29dfe1",
    "number": 2648,
    "body": "Reverts #2643 and skips the test for pandas 2 instead.",
    "head_branch": "append",
    "is_a_fork": true,
    "comments": [
      "@martinfleis \r\ncan the `filterwarnings()` be restored as well after the skip?"
    ],
    "commit_messages": [
      "TST: bring back append test for pandas<2.0.0 (#2648)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d57bac254a19ac29dfe2",
    "number": 2647,
    "body": "new branca release https://github.com/python-visualization/branca/releases/tag/v0.6.0\r\n\r\nused in `explore()`.   There's a subtle change where embedded html/javascript that is generated by **branca** has changed from single quoted to double quoted strings.  Change test cases to pass on either case,  making it forward and backward compatible test case.\r\n\r\nWhere CI virtual machines have been rebuilt and using **branca** 0.6.0 CI is failing.",
    "head_branch": "compat_branca_6_0",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "COMPAT: branca 0.6.0 (#2647)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d57cac254a19ac29dfe3",
    "number": 2646,
    "body": "Bumps [actions/setup-python](https://github.com/actions/setup-python) from 3 to 4.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/actions/setup-python/releases\">actions/setup-python's releases</a>.</em></p>\n<blockquote>\n<h2>v4.0.0</h2>\n<h3>What's Changed</h3>\n<ul>\n<li>Support for <code>python-version-file</code> input: <a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/336\">#336</a></li>\n</ul>\n<p>Example of usage:</p>\n<pre lang=\"yaml\"><code>- uses: actions/setup-python@v4\n  with:\n    python-version-file: '.python-version' # Read python version from a file\n- run: python my_script.py\n</code></pre>\n<p>There is no default python version for this <code>setup-python</code> major version, the action requires to specify either <code>python-version</code> input or <code>python-version-file</code> input. If the <code>python-version</code> input is not specified the action will try to read required version from file from <code>python-version-file</code> input.</p>\n<ul>\n<li>Use pypyX.Y for PyPy <code>python-version</code> input: <a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/349\">#349</a></li>\n</ul>\n<p>Example of usage:</p>\n<pre lang=\"yaml\"><code>- uses: actions/setup-python@v4\n  with:\n    python-version: 'pypy3.9' # pypy-X.Y kept for backward compatibility\n- run: python my_script.py\n</code></pre>\n<ul>\n<li>\n<p><code>RUNNER_TOOL_CACHE</code> environment variable is equal <code>AGENT_TOOLSDIRECTORY</code>: <a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/338\">#338</a></p>\n</li>\n<li>\n<p>Bugfix: create missing <code>pypyX.Y</code> symlinks: <a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/347\">#347</a></p>\n</li>\n<li>\n<p><code>PKG_CONFIG_PATH</code> environment variable: <a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/400\">#400</a></p>\n</li>\n<li>\n<p>Added <code>python-path</code> output: <a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/405\">#405</a>\n<code>python-path</code> output contains Python executable path.</p>\n</li>\n<li>\n<p>Updated <code>zeit/ncc</code> to <code>vercel/ncc</code> package: <a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/393\">#393</a></p>\n</li>\n<li>\n<p>Bugfix: fixed output for prerelease version of poetry: <a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/409\">#409</a></p>\n</li>\n<li>\n<p>Made <code>pythonLocation</code> environment variable consistent for Python and PyPy: <a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/418\">#418</a></p>\n</li>\n<li>\n<p>Bugfix for <code>3.x-dev</code> syntax: <a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/417\">#417</a></p>\n</li>\n<li>\n<p>Other improvements: <a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/318\">#318</a> <a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/396\">#396</a> <a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/384\">#384</a> <a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/387\">#387</a> <a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/388\">#388</a></p>\n</li>\n</ul>\n<h2>Update actions/cache version to 2.0.2</h2>\n<p>In scope of this release we updated <code>actions/cache</code> package as the new version contains fixes related to GHES 3.5 (<a href=\"https://github-redirect.dependabot.com/actions/setup-python/pull/382\">actions/setup-python#382</a>)</p>\n<h2>Add &quot;cache-hit&quot; output and fix &quot;python-version&quot; output for PyPy</h2>\n<p>This release introduces new output cache-hit (<a href=\"https://github-redirect.dependabot.com/actions/setup-python/pull/373\">actions/setup-python#373</a>) and fix python-version output for PyPy (<a href=\"https://github-redirect.dependabot.com/actions/setup-python/pull/365\">actions/setup-python#365</a>)</p>\n<p>The cache-hit output contains boolean value indicating that an exact match was found for the key. It shows that the action uses already existing cache or not. The output is available only if cache is enabled.</p>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/actions/setup-python/commit/13ae5bb136fac2878aff31522b9efb785519f984\"><code>13ae5bb</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/517\">#517</a> from rentziass/rentziass/update-actions-core</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/0c4d7b878c451046f4c9003d4b7c6a28d18e16d7\"><code>0c4d7b8</code></a> Update <code>@​actions/core</code> to 1.10.0</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/13a464fa1180c0025831475fa35bb1878b1a4728\"><code>13a464f</code></a> Fix typo (<a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/503\">#503</a>)</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/b4fe97ecda6b7a5fcd2448cdbf6a8fc76b3bedb0\"><code>b4fe97e</code></a> upgrade <code>@​actions/cache</code> so it respects SEGMENT_DOWNLOAD_TIMEOUT_MINS (<a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/499\">#499</a>)</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/434aeabbb4286782ee8393c55a08efe7edd89027\"><code>434aeab</code></a> Bump <code>@​actions/core</code> from 1.7.0 to 1.9.1 (<a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/495\">#495</a>)</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/98c991d13f3149457a7c1ac4083885d0d9db98e1\"><code>98c991d</code></a> Only use github.token on github.com (<a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/443\">#443</a>)</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/397a35f9886aa9c6f22fb1dc41eefccf99deb2fb\"><code>397a35f</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/492\">#492</a> from al-cheb/al-cheb/update-runner-link</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/48a0f006ffb715bfd0eb1ae1a2d62f61a7fa231f\"><code>48a0f00</code></a> Update runner links</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/978fd06d1f249d7f080233457c2ae6324d08eac2\"><code>978fd06</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/actions/setup-python/issues/491\">#491</a> from lkfortuna/patch-2</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/050e616f665562657a663dd1cc4b9ac6fb194d28\"><code>050e616</code></a> Update README.md</li>\n<li>Additional commits viewable in <a href=\"https://github.com/actions/setup-python/compare/v3...v4\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/setup-python&package-manager=github_actions&previous-version=3&new-version=4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
    "head_branch": "dependabot/github_actions/actions/setup-python-4",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Bump actions/setup-python from 3 to 4 (#2646)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d57cac254a19ac29dfe4",
    "number": 2645,
    "body": "**pandas 1.5** generates FutureWarning on specific use cases of `loc[]`\r\n- https://pandas.pydata.org/docs/whatsnew/v1.5.0.html#inplace-operation-when-setting-values-with-loc-and-iloc\r\n\r\n`clip()` and `overlay()` were generating inplace FutureWarning. This is a subtle issue, where if mask was all rows, warning is generated. Code below shows solution as standalone:\r\n\r\n```\r\nimport geopandas as gpd\r\nimport pandas as pd\r\nimport numpy as np\r\nfrom shapely.geometry import Point\r\n\r\nN = 3\r\ndf = gpd.GeoDataFrame(\r\n    geometry=[Point([i, i]) for i in range(N)],\r\n    data=pd.DataFrame({\"col\": np.repeat([\"GeometryCollection\"], N)}),\r\n)\r\n# df.loc[2, \"col\"] = \"diff\"\r\nmask = df[\"col\"] == \"GeometryCollection\"\r\nif mask.sum() == len(df):\r\n    df[\"geometry\"] = gpd.GeoSeries([Point([10, 10]) for _ in range(mask.sum())]).values\r\nelse:\r\n    df.loc[mask, \"geometry\"] = gpd.GeoSeries(\r\n        [Point([10, 10]) for _ in range(mask.sum())]\r\n    ).values\r\n\r\ndf\r\n```",
    "head_branch": "pandas15_clip_overlay",
    "is_a_fork": true,
    "comments": [
      "xref https://github.com/pysal/momepy/issues/423",
      "closing conclusion is better to have warnings in CI.  this does appear to be an incorrect warning in **pandas** but I can't reproduce with just **pandas** condition where mask is all rows and warning pops up with `loc`. It does appear this is a bogus incorrect warning in **pandas**.  unfortunately this means these warnings are acceptable which IMHO leads to all warnings being acceptable ...",
      "> closing conclusion is better to have warnings in CI.  this does appear to be an incorrect warning in **pandas** but I can't reproduce with just **pandas** condition where mask is all rows and warning pops up with `loc`. It does appear this is a bogus incorrect warning in **pandas**.  unfortunately this means these warnings are acceptable which IMHO leads to all warnings being acceptable ...\n\nThat's not quite what I was suggesting - if we are okay with the warnings - i.e. the situation will not break geopandas I see no reason why we shouldn't filter the warnings inside clip - in the same way we do for shapely 2 compatibility warnings in a couple of places. \n\nBut you say about it being non-reproducible in a simpler setting - I think it's unlikely to be bogus and is probably just subtle, I'll try and take another look for a minimal reproducer. ",
      "> But you say about it being non-reproducible in a simpler setting - I think it's unlikely to be bogus and is probably just subtle, I'll try and take another look for a minimal reproducer.\r\n\r\nThis is how I've been trying to re-produce.\r\n```\r\nimport geopandas as gpd\r\nimport pandas as pd\r\nimport numpy as np\r\nfrom shapely.geometry import Point\r\n\r\nN = 3\r\ndf = gpd.GeoDataFrame(\r\n    geometry=[Point([i, i]) for i in range(N)],\r\n    data=pd.DataFrame([i for i in range(N)]), # no data frame no warning\r\n)\r\n\r\n# construct as a straight pandas DF no warning\r\n# df = pd.DataFrame({\"geometry\":[Point(1,1) for _ in range(N)], \"col\":[1 for _ in range(N)]})\r\n\r\nmask = df.index == df.index\r\n# a list no problem, a numpy array warning\r\ndf.loc[mask, \"geometry\"] = np.array([Point([10, 10]) for _ in range(mask.sum())])\r\n\r\n```",
      "So this is subtle in pandas, here's a minimal reproducer in a geopandas context:\r\n```python\r\nimport geopandas as gpd\r\n\r\ngdf = gpd.GeoDataFrame({\"foo\": [\"a\"]}, geometry=gpd.GeoSeries.from_xy([1], [3]))\r\ns2 = gpd.GeoSeries.from_xy([2], [4])\r\n\r\ngdf.loc[[True], \"geometry\"] = s2\r\n```\r\n\r\n(Note the \"foo\" columns needs to be here because there's a special path for if there's only one type of blockmanager associated with the dataframe.)\r\n\r\nI think however it might not be worth wasting further brainpower on how best to deal with this - it seems like the warning will be removed (and we are not the only ones a bit confused by it): https://github.com/pandas-dev/pandas/issues/48673.\r\n\r\nGiven that, I think it would be acceptable to filter the warning out of our ci completely, for now at least.\r\n",
      "> Given that, I think it would be acceptable to filter the warning out of our ci completely, for now at least.\r\n\r\nAgreed - I'll refactor the code changes for this in next few days.   Working on getting a PR that will need more brain power.  Ability to run whole CI GitHub Action suite locally...  \r\n",
      "> Given that, I think it would be acceptable to filter the warning out of our ci completely, for now at least.\r\n\r\nAnd given that the pandas issue about potentially removing the warning is not yet resolved, I think we should maybe also actually filter out the warning the in overlay/clip code. \r\n\r\nAFAIU the situation around this warning, for the cases in the diff of this PR, we actually don't care about the warning, we just don't want that the user sees it (as they cannot do anything about it, and so it is just confusing for them). \r\nSo I think \"just\" doing a filterwarnings context around those lines seems the easiest solution (like we do in other places for shapely warnings):\r\n\r\n```\r\nwith warnings.catch_warnings():\r\n    warnings.filterwarnings(\"ignore\", \"..text match..\", FutureWarning)\r\n    ...\r\n```",
      "In the meantime, the warning has actually been removed on the pandas side (and released in pandas 1.5.3). So, are we OK with closing this then, or do we still want to silence the warning for pandas 1.5.0-1.5.2?",
      "I'd ignore it and point users towards an update of pandas if needed. ",
      "> I'd ignore it and point users towards an update of pandas if needed.\r\n\r\nAgree, especially since the warning was both introduced and removed all within the 1.5.x series. \r\n\r\n(Although with that said, if the solution in https://github.com/geopandas/geopandas/pull/2645#issuecomment-1368075434 was contributed, I don't see a problem with including that)",
      "OK, closing then. @rraymondgh thank you all the same for the PR!"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d57dac254a19ac29dfe5",
    "number": 2644,
    "body": "There are too many warnings in **pytest** log files in CI.  Structured cleanup to enable more structured review of change in logs.\r\n\r\nSplit out from PR #2642 \r\n\r\nSummary post change:\r\n```\r\nlogs_post_change/310-dev.log:1799 passed, 266 skipped, 11 xfailed, 2 xpassed, 2306 warnings in 250.91s (0:04:10)\r\nlogs_post_change/310-latest-conda-forge.log:1924 passed, 139 skipped, 13 xfailed, 2 xpassed, 117 warnings in 230.60s (0:03:50)\r\nlogs_post_change/311-latest-conda-forge.log:1924 passed, 139 skipped, 13 xfailed, 2 xpassed, 118 warnings in 244.20s (0:04:04)\r\nlogs_post_change/38-latest-conda-forge.log:1774 passed, 291 skipped, 11 xfailed, 2 xpassed, 120 warnings in 203.19s (0:03:23)\r\nlogs_post_change/38-latest-defaults.log:1713 passed, 352 skipped, 11 xfailed, 2 xpassed, 22 warnings in 229.03s (0:03:49)\r\nlogs_post_change/38-minimal.log:1605 passed, 347 skipped, 26 xfailed, 1 xpassed, 24 warnings in 177.52s (0:02:57)\r\nlogs_post_change/38-pd11-defaults.log:1658 passed, 343 skipped, 21 xfailed, 1 xpassed, 32 warnings in 199.19s (0:03:19)\r\nlogs_post_change/39-latest-conda-forge.log:1715 passed, 344 skipped, 7 xfailed, 2 xpassed, 18 warnings in 203.71s (0:03:23)\r\nlogs_post_change/39-no-optional-deps.log:1064 passed, 790 skipped, 8 xfailed, 2 xpassed, 19 warnings in 85.90s (0:01:25)\r\nlogs_post_change/39-pd12-conda-forge.log:1769 passed, 268 skipped, 21 xfailed, 1 xpassed, 79 warnings in 222.56s (0:03:42)\r\n```\r\n\r\nsummary before change:\r\n```\r\nlogs/310-dev.log:1799 passed, 266 skipped, 11 xfailed, 2 xpassed, 2311 warnings in 243.74s (0:04:03)\r\nlogs/310-latest-conda-forge.log:1924 passed, 139 skipped, 13 xfailed, 2 xpassed, 125 warnings in 232.15s (0:03:52)\r\nlogs/311-latest-conda-forge.log:1924 passed, 139 skipped, 13 xfailed, 2 xpassed, 125 warnings in 250.22s (0:04:10)\r\nlogs/38-latest-conda-forge.log:1774 passed, 291 skipped, 11 xfailed, 2 xpassed, 127 warnings in 208.21s (0:03:28)\r\nlogs/38-latest-defaults.log:1713 passed, 352 skipped, 11 xfailed, 2 xpassed, 25 warnings in 227.88s (0:03:47)\r\nlogs/38-minimal.log:1605 passed, 347 skipped, 25 xfailed, 2 xpassed, 24 warnings in 179.41s (0:02:59)\r\nlogs/38-pd11-defaults.log:1658 passed, 343 skipped, 21 xfailed, 1 xpassed, 48 warnings in 190.56s (0:03:10)\r\nlogs/39-latest-conda-forge.log:1715 passed, 344 skipped, 7 xfailed, 2 xpassed, 43 warnings in 205.64s (0:03:25)\r\nlogs/39-no-optional-deps.log:1064 passed, 790 skipped, 8 xfailed, 2 xpassed, 26 warnings in 80.90s (0:01:20)\r\nlogs/39-pd12-conda-forge.log:1769 passed, 268 skipped, 21 xfailed, 1 xpassed, 109 warnings in 226.67s (0:03:46)\r\n\r\n```",
    "head_branch": "tests_warning_cleanup",
    "is_a_fork": true,
    "comments": [
      "> I would focus on the warning that appear in the \"latest\" + \"dev\" builds.\r\n\r\n+1 on this."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d57eac254a19ac29dfe6",
    "number": 2643,
    "body": "**pandas** 2.0 is removing `Series.append()`.  There is a test that incorrectly suppresses deprecation warning.  Changed to use `pandas.concat()`",
    "head_branch": "ci_310_dev_append",
    "is_a_fork": true,
    "comments": [
      "I'm not convinced this actually make sense to update this test to not use append. We actually still support pandas 1.1 onwards and append is only being removed in pandas 2.0 - and we no longer have test coverage that append still works with geometry data.\r\n\r\nNow, in practice this probably doesn't matter, we already know append works for existing verisons, and its rather unlikely that a patch release of pandas 1.4 or 1.5 would break this, but still thought it was worth mentioning.\r\n\r\n",
      "Yes, should probably have kept using append, and just skip the test for pandas >= 2 (and we also already have coverage for concat, so changing to concat is not really needed. If at some point only support pandas >= 2, we can just remove the test I think)\r\n\r\n> its rather unlikely that a patch release of pandas 1.4 or 1.5 would break this\r\n\r\nThe more likely (but still unlikely ;)) case is that a change in geopandas would break the function, I think\r\n",
      "Sorry! Didn't realise this when merging. My bad. "
    ],
    "commit_messages": [
      "CI: 310-dev tests failing (#2643)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d57fac254a19ac29dfe7",
    "number": 2642,
    "body": "**pandas** 1.5 \r\n- https://pandas.pydata.org/docs/whatsnew/v1.5.0.html#numeric-only-default-value\r\n\r\nExtend `dissolve()` with `agg_kwargs` parameter so that `numeric_only` parameter can be passed to https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html\r\n\r\n",
    "head_branch": "compat_dissolve",
    "is_a_fork": true,
    "comments": [
      ">  Should review minimum pandas version and number of supported versions. There is an argument to move support to three point releases. i.e. 1.3, 1.4 & 1.5 and remove support for < 1.3\r\n\r\nWe tend to follow [NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html) which suggest supporting all the versions released in the last 24 months. That would be pandas 1.1. if we release before the end of the year and 1.2 if we release after. Not a huge change from 1.0.5. Supporting N point releases may result in an uneven time.\r\n\r\n> A number of latest CI env yaml files are pinning to pandas 1.3 and matplotlib is unpinned\r\n\r\nYeah, don't remember why we did that but it is worth keeping to have that check using intermediate version. Though the env should probably be called differently.\r\n\r\n---\r\n\r\nI see that you are trying to resolve #2637 here. However, there was no response on that issue yet and no agreement on how it should be handled. The reason we ask to open issues before opening a PR is not that we want them for the sake of having something to close. It is always much better to discuss the topic before getting to code something as it may result in a lot of unnecessary reworking. It is fine now, we can deal with this in this PR now but I would suggest waiting for some form of a response next time unless the fix is a no brainer (does not apply to enhancements, only fixes though). I realise that I may sound a bit harsh and I apologise if I do, but having a proper _community_ discussion before coding eventually saves your time of a contributor as well as ours as maintainers needing to review it and often speeds up review and merge significantly. It is just a good practice and helps avoiding situations like we have in #2590.\r\n\r\n---\r\n\r\nOn the actual changes, we'll need to think about those. Mainly what our default should be and how to handle the warning coming from pandas as it is not very clear how to fix it if you use dissolve and not groupby yourself.\r\n\r\n> clip() and overlay() were generating inplace FutureWarning. This is a subtle issue, where if mask was all rows, warning is generated.\r\n\r\nThis is an unrelated change to the dissolve warning - can you make it another PR? It helps to have PRs containing a single change only as it is much easier to find and fix a potential issue like a regression or a new bug later.\r\n\r\n> Filtered unwanted warnings in CI from pandas. \r\n\r\nSame case. Unrelated change and should be a PR of its own.\r\n\r\n_Note: sorry, I realise my comments may not sound the most welcoming but following some best practices will help us all. And thanks a lot for your work!_",
      "> We tend to follow [NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html) which suggest supporting all the versions released in the last 24 months. That would be pandas 1.1. if we release before the end of the year and 1.2 if we release after. Not a huge change from 1.0.5. Supporting N point releases may result in an uneven time.\r\n> \r\nOK - got it.  I can look into making more structured approach to maintaining test cases and CI to better comply with this policy.\r\n\r\n> I see that you are trying to resolve #2637 here. However, there was no response on that issue yet and no agreement on how it should be handled. \r\n\r\nI agree - it's more about time management.  I had a spare day so moved from posing an idea to prototyping a potential solution.\r\n\r\n> On the actual changes, we'll need to think about those. Mainly what our default should be and how to handle the warning coming from pandas as it is not very clear how to fix it if you use dissolve and not groupby yourself.\r\n\r\n> This is an unrelated change to the dissolve warning - can you make it another PR? It helps to have PRs containing a single change only as it is much easier to find and fix a potential issue like a regression or a new bug later.\r\n> \r\n> Same case. Unrelated change and should be a PR of its own.\r\n\r\nI looked at it a different way.  I think it's important that a unit of work is complete.  A bit of a dinosaur from my experience  where too often units of change were synthetically split and then difficult to combine!  These are the components that I have looked at as atomic\r\n1. compatibility with **pandas 1.5** deprecations\r\n   - warning on silent removal of none numeric columns.  `dissolve()` changes are foundational to this\r\n   - warning on `loc[]` inplace.  changes to `overlay()` and `clip()`\r\n2. update testing to ensure warnings related to **pandas** and **matplotlib** versions are not too noisy.  (it would be great if **pytest** could be run with `-W error` ! )\r\n3. fix CI. **310-dev** build has started failing due to removal of `Series.append()`. Every PR has to pass CI\r\n\r\nI appreciate I'm a new contributor so happy to take further direction and split into sub-atomic particles.",
      "Closing as a duplicate of https://github.com/geopandas/geopandas/pull/2685. Thank you for the effort @rraymondgh!",
      "Thanks @rraymondgh for the initial PR on this and prompting discussion to work towards a solution!"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d580ac254a19ac29dfe8",
    "number": 2641,
    "body": "Closes #1345",
    "head_branch": "to_crs-z",
    "is_a_fork": true,
    "comments": [
      "I think that we should try to mimic the behaviour of shapely 1.8, meaning we would include Z for geometries that have Z and don't include it when the geometry don't have it. Like this:\r\n\r\n```py\r\n        has_z = shapely.has_z(data)\r\n\r\n        result = np.empty(data.shape, dtype=data.dtype)\r\n\r\n        coords = shapely.get_coordinates(data[~has_z], include_z=False)\r\n        new_coords_z = func(coords[:, 0], coords[:, 1])\r\n        result[~has_z] = shapely.set_coordinates(\r\n            data[~has_z].copy(), np.array(new_coords_z).T\r\n        )\r\n\r\n        coords_z = shapely.get_coordinates(data[has_z], include_z=True)\r\n        new_coords_z = func(coords_z[:, 0], coords_z[:, 1], coords_z[:, 2])\r\n        result[has_z] = shapely.set_coordinates(\r\n            data[has_z].copy(), np.array(new_coords_z).T\r\n        )\r\n```",
      "Thank you, @jorisvandenbossche . This response was incredibly fast and exactly what I was hoping for. Question: if we want to allow overriding the include_z inference, don't geodataframe.py and geoseries.py to_crs method definitions need the include_z argument exposed and subsequently drilled down as well?",
      "> I think that we should try to mimic the behaviour of shapely 1.8, meaning we would include Z for geometries that have Z and don't include it when the geometry don't have it. \r\n\r\nOK, I was assuming to make this a on/off choice for the _whole_ geometry column, basically not allowing mixed dimensions in the output (knowing this is still a breaking change in behaviour compared to before). \r\nBut it's true we can do the effort to keep the mixed geometries. You example code is not that complex.\r\n\r\nNow, I have to check more, but it might also be this already works somewhat out of the box (the following is with the current PR):\r\n\r\n```\r\nIn [8]: arr = geopandas.array.from_shapely([shapely.Point(1, 2, 3), shapely.Point(2, 3), shapely.Point(3, 4, 5)], crs=\"EPSG:432\r\n   ...: 6\")\r\n\r\nIn [9]: arr\r\nOut[9]: \r\n<GeometryArray>\r\n[<POINT Z (1 2 3)>, <POINT (2 3)>, <POINT Z (3 4 5)>]\r\nLength: 3, dtype: geometry\r\n\r\nIn [10]: arr.to_crs(\"EPSG:3857\", include_z=True)\r\nOut[10]: \r\n<GeometryArray>\r\n[<POINT Z (111319.491 222684.209 3)>,     <POINT (222638.982 334111.171)>,\r\n  <POINT Z (333958.472 445640.11 5)>]\r\nLength: 3, dtype: geometry\r\n```\r\n\r\nI _think_ this is because `get_coordinates` fills with NaNs for the geometries without z:\r\n\r\n```\r\nIn [12]: shapely.get_coordinates(arr.data, include_z=True)\r\nOut[12]: \r\narray([[ 1.,  2.,  3.],\r\n       [ 2.,  3., nan],\r\n       [ 3.,  4.,  5.]])\r\n```\r\n\r\nAnd then the transform function keeps the NaN, and when recreating the original geometries those NaNs are just ignored (since the original geometry was 2D).\r\n",
      "Although, my test above uses a CRS transformation that is not defined for Z values, and so leaves those values alone. If you have a transformation that includes the z values, NaN elevation values might actually give problems. \r\nIs that what you mean with getting empty Points? (if the NaN z values gets used and propagates to x/y?)",
      "Consider this snippet:\r\n\r\n```py\r\ns = geopandas.GeoSeries(\r\n    [\r\n        Point(1, 2),\r\n        LineString([(1, 2, 3), (4, 5, 6)]),\r\n    ],\r\n    crs=2056\r\n)\r\ndata = s.values.data\r\n\r\ntransformer = Transformer.from_crs(s.crs, 4326, always_xy=True)\r\nfunc = transformer.transform\r\n\r\ncoords_z = pygeos.get_coordinates(data, include_z=True)\r\nnew_coords_z = func(coords_z[:, 0], coords_z[:, 1], coords_z[:, 2])\r\nresult = pygeos.set_coordinates(data.copy(), np.array(new_coords_z).T)\r\n```\r\n```\r\narray([<pygeos.Geometry POINT EMPTY>,\r\n       <pygeos.Geometry LINESTRING Z (-19.918 32.125 3, -19.918 32.125 6)>],\r\n      dtype=object)\r\n```\r\n\r\nIf you include Z which is NaN, pyproj actually returns an array of NaNs resulting in an empty point. If you mask non-Z and use 2d transformation, all is fine.",
      "Trying to find an example of 3D CRS, the following still seems to work (it gives the same x/y values regardless of include_z=True/False, and the z value is actually transformed for the 3D Point):\r\n\r\n```\r\nIn [17]: arr = geopandas.array.from_shapely([shapely.Point(4, 50, 10), shapely.Point(4, 51)], crs=\"EPSG:4979\")\r\n\r\nIn [18]: arr.to_crs(\"EPSG:6190\", include_z=True)\r\nOut[18]: \r\n<GeometryArray>\r\n[<POINT Z (123563.583 76585.173 -33.228)>, <POINT (124114.915 187817.059)>]\r\nLength: 2, dtype: geometry\r\n\r\nIn [19]: arr.to_crs(\"EPSG:6190\", include_z=False)\r\nOut[19]: \r\n<GeometryArray>\r\n[<POINT (123563.583 76585.173)>, <POINT (124114.915 187817.059)>]\r\nLength: 2, dtype: geometry\r\n```",
      "Use the one above. That fails.\r\n\r\n```py\r\narr = geopandas.array.from_shapely([shapely.Point(4, 50, 10), shapely.Point(4, 51)], crs=\"EPSG:2056\")\r\narr.to_crs(\"EPSG:4326\", include_z=True)\r\n```\r\n```\r\n<GeometryArray>\r\n[<POINT Z (-19.918 32.125 10)>, <POINT EMPTY>]\r\nLength: 2, dtype: geometry\r\n```\r\n```py\r\narr.to_crs(\"EPSG:4326\", include_z=False)\r\n```\r\n```\r\n<GeometryArray>\r\n[<POINT (-19.918 32.125)>, <POINT (-19.918 32.125)>]\r\nLength: 2, dtype: geometry\r\n```",
      "OK, I see, it very much depends on the exact CRS you are using what PROJ exactly does with NaN z values: (I was just using the wrong example ;))\r\n\r\n```\r\nIn [40]: transformer = Transformer.from_crs(4326, 2056, always_xy=True)\r\n\r\nIn [41]: transformer.transform(1, 2, np.nan)\r\nOut[41]: (nan, nan, nan)\r\n\r\nIn [42]: transformer = Transformer.from_crs(4326, 3857, always_xy=True)\r\n\r\nIn [43]: transformer.transform(1, 2, np.nan)\r\nOut[43]: (111319.49079327357, 222684.20850554405, nan)\r\n```",
      "Yeah, I was a bit lucky to catch that selecting 2056->4326. But if some transformations result in this, which I'd assume comes from PROJ, we should make an effort to mask Z geometries as I suggested in https://github.com/geopandas/geopandas/pull/2641#issuecomment-1303127373. The overhead of that doesn't seem to be significant, timings of `has_z` check over the whole array are in ms.",
      "Updated to handle mixed dimensions as suggested!\r\n\r\nQuestion: if we handle mixed dimensions automatically (and so preserve the dimensionality of each individual input geometry), then I don't think there is any need to expose a `ìnclude_z` keyword in the public `to_crs` methods? (cc @derinwalters) \r\nThe only thing I could think of is that one could set `include_z=False` to also convert your XYZ geometries to XY while transforming. But then there are APIs to do that specifically (shapely has `force_2d()` / `force_3d()` functions, and so we should better expose those, xref https://github.com/geopandas/geopandas/issues/2010), which I think is the preferred way. ",
      "> Question: if we handle mixed dimensions automatically (and so preserve the dimensionality of each individual input geometry), then I don't think there is any need to expose a `ìnclude_z` keyword in the public `to_crs` methods? \r\n\r\nHandling mixed dimensions automatically as proposed, rather than having to specify explicitly via include_z, is my preferred mechanism as well. I agree Shapely provides sufficient API for controlling other things like dropping dimensions and that it would be convenient to expose many methods in Geopandas (ex. geometry 3d->2d for polyline generation).",
      "@martinfleis I think this was ready",
      "Thanks! And thanks for the ping to review it :)."
    ],
    "commit_messages": [
      "BUG: Handle z coordinates in to_crs for Shapely 2.0 / PyGEOS (#2641)\n\n* Handle z coordinates in to_crs for Shapely 2.0 / PyGEOS\r\n\r\n* handle mixed dimensions\r\n\r\n* add explicit test for empty array\r\n\r\n* also support pygeos\r\n\r\n* remove include_z\r\n\r\n* add whatsnew"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d580ac254a19ac29dfe9",
    "number": 2640,
    "body": "Automatic update of Versioneer by the `versioneer.yml` workflow.\n\nPlease review changes manually, especially if a duplicate `from . import _version` is added.",
    "head_branch": "update-versioneer",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Update Versioneer (#2640)\n\n* [Bot] Update Versioneer\r\n\r\n* remove duplicated import\r\n\r\nCo-authored-by: jorisvandenbossche <jorisvandenbossche@users.noreply.github.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d581ac254a19ac29dfea",
    "number": 2639,
    "body": "This contributes to #1896. [Formatting](https://developers.google.com/style/code-in-text) and capitalization was corrected on product names. \r\n\r\n",
    "head_branch": "format-product-names",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Fix code font and capitalization of product names (#2639)\n\n* DOC: Fix code font and capitalization of product names\r\n\r\n* Fix code font of directories and arguments\r\n\r\n* Fix code font of directories and arguments\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d582ac254a19ac29dfeb",
    "number": 2638,
    "body": "The default black options _for GitHub Actions_ are `--check --diff`, which is different from the regular CLI. This PR overwrites that which allows Black to fix things instead giving an error.\r\n```yml\r\n    - uses: psf/black@stable\r\n      with:\r\n        options: \"--verbose\"\r\n```\r\n\r\nSucceeds #2634.",
    "head_branch": "patch-8",
    "is_a_fork": true,
    "comments": [
      "Should **pyproject.toml** be updates so that CLI and CI config  **black** in the same way?",
      "Yes, I think that would be useful!",
      "> Should pyproject.toml be updates so that CLI and CI config black in the same way?\r\n\r\nAs far as I can tell, we do not deviate from `black` default in any way, so the reformatting should be exactly the same if both use the same version. Only black-related config is specifying behaviour go `flake8` to be compatible with black:(https://github.com/geopandas/geopandas/blob/5dc982edbfc2633cd2c7a22ebd314d1b9b810a9a/setup.cfg#L18-L25\r\n\r\nThe option @EwoutH overrides in the CI action are not affecting the code output, it just changes from _check and report_ to _check, format and report_.",
      "Thanks!"
    ],
    "commit_messages": [
      "Versioneer CI: Allow Black to fix formatting (#2638)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d583ac254a19ac29dfec",
    "number": 2636,
    "body": "This runs `black` using the `black[jupyter]` option formatting everything that has not been formatted so far. So benchmarks and notebooks in the docs. This is not covered by the pre-commit hook at the moment but will help with versioneer autoupdate (#2634).",
    "head_branch": "blacken",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "blacken the rest of the code (docs, benchmarks) (#2636)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d584ac254a19ac29dfed",
    "number": 2635,
    "body": "Currently the pre-commit.ci configuration, [`.pre-commit-config.yaml`](https://github.com/shapely/shapely/edit/main/.pre-commit-config.yaml), is a bit outdated. We could update it manually or write a custom workflow for it, but the easiest way to fix is is enable [pre-commit.ci](https://pre-commit.ci/). By default, it checks weekly if pre-commit versions can be updated and if so opens a PR to do so.\r\n\r\nIt also has an option to autofix PRs, which can be a great quality of life feature. It's `false` for now because it's a bit of a larger change.",
    "head_branch": "pre-commit-update",
    "is_a_fork": true,
    "comments": [
      "> It also has an option to autofix PRs, which can be a great quality of life feature\r\n\r\nDo you know how does it work in practice? It pushes a commit to the branch?\r\n\r\nedit: yes, it does as shown here https://pre-commit.ci",
      "I am not fully sure I like the idea of a bot pushing changes to a branch. It solves the formatting issue but can cause conflicts when the author does not pull before making changes. I'll let others weigh on that.",
      "Sorry for coming back so late.\r\n\r\nAs for the behaviour, the autofix feature that pushes commits directly to the PR branch is disabled:\r\n```yml\r\nci:\r\n    autofix_prs: false\r\n```\r\nWhat is functionally added is the\r\n```yml\r\n    autoupdate_schedule: weekly\r\n```\r\npart, which specifies how often the `.pre-commit-config.yaml` is checked for outdated actions. So when [pre-commit.ci](https://pre-commit.ci/) get's enabled, it will check weekly if the pre-commit actions are up to date if (and open a PR if so) but won't push anything by itself.",
      "Thanks for merging!\r\n\r\nNote that this PR only changes the configuration file, it has no effect if https://pre-commit.ci/ isn't enabled.",
      "That also does the lining check based on our pre-commit, right? That would now result in a duplication as we have the same step on GHA marked as required for other steps so we don't run the tests if we know another commit needs to come anyway. Is it possible to configure pre-commit.ci to do the update PRs only?",
      "Looking into the documentation, it seems that we cannot use this to update versions only. Not sure if we want to enable the hook given what I've noted above."
    ],
    "commit_messages": [
      "pre-commit config: Add auto update schedule (#2635)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d584ac254a19ac29dfee",
    "number": 2634,
    "body": "Run Black after updating Versioneer, and add a message to the PR body with some specific instructions (see https://github.com/geopandas/geopandas/pull/2633#pullrequestreview-1166413777)",
    "head_branch": "patch-6",
    "is_a_fork": true,
    "comments": [
      "@EwoutH seems that this will need a bit more work :) - https://github.com/geopandas/geopandas/actions/runs/3387828276/jobs/5629070410",
      "When running `black`, I would also try to target just those three touched files.",
      "I just saw the default black options _for GitHub Actions_ are `--check --diff`, which is different from the regular CLI. Overwriting those should fix that.\r\n```yml\r\n    - uses: psf/black@stable\r\n      with:\r\n        options: \"--verbose\"\r\n```\r\n\r\n> I would also try to target just those three touched files.\r\n\r\nIdeally yes, but in the configuration that will complicate things. Pre-commit checks that everything is Black formatted, so it should only alter those files.\r\n\r\nIt's a bit ironic that we're struggling with version control of package that should make version control easy.",
      "Okay I [updated](https://github.com/geopandas/geopandas/commit/ed96b76c13a9fa20e116f9bba714b0ee4d006ea9) to the code above, but apparently not everything actually is Black formatted, because Black finds a lot of other things to format: https://github.com/EwoutH/geopandas/pull/4",
      "I think the issue is the pre-commit Black version is outdated. I opened #2635 which could fix that.",
      "No, the issue was that the pre-commit hook checks only the `geopandas/` folder while `black .` checks it all. #2636 should solve this.",
      "@EwoutH can you check on your fork now? #2636 has been merged, so the diff may become more reasonable.",
      "It works and it now only modifies those three files. See https://github.com/EwoutH/geopandas/pull/4.\r\n\r\nI opened a PR with the CI changes at #2638."
    ],
    "commit_messages": [
      "Versioneer CI: Run black, add PR message (#2634)\n\nRun Black after updating Versioneer, and add a message to the PR body with some specific instructions (see https://github.com/geopandas/geopandas/pull/2633#pullrequestreview-1166413777)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d585ac254a19ac29dfef",
    "number": 2633,
    "body": "Automated changes by [create-pull-request](https://github.com/peter-evans/create-pull-request) GitHub action",
    "head_branch": "update-versioneer",
    "is_a_fork": false,
    "comments": [
      "I would probably try to adapt the Action generating this PR to either do some work on top of `versioneer install` like formatting and a removal of the duplication (tricky), or post a message that these steps need to be done manually by a human maintainer. Since the commit by the bot did not trigger CI (not sure why), we may not catch the formatting issue and a merge would immediately fail the CI on main.",
      "Good ideas, I opened a PR: #2634",
      "Will be superseded by #2634."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d586ac254a19ac29dff0",
    "number": 2632,
    "body": "CI logs are full of *distutils Version classes are deprecated* from older versions of **pandas** and **numpy**.  This then means that real warnings that should be cleaned up are missed.  Add to **pyproject.toml** to suppress `DeprecationWarning` from **pandas** and **numpy** that match this text.\r\n\r\nMoved other **pytest** settings from **setup.cfg** into **pyproject.toml**",
    "head_branch": "ci_pytest_ini",
    "is_a_fork": true,
    "comments": [
      "Thanks, this is a good idea!\r\n\r\nPractical comment: we already have some pytest configuration in setup.cfg, so let's keep it all together in that file (nowadays pytest also supports using pyproject.toml as a place to put configuration, so if putting it in another file, we should eventually move to use that one I think)",
      "> nowadays pytest also supports using pyproject.toml as a place to put configuration, so if putting it in another file, we should eventually move to use that one I think\r\n\r\n+1 to that now that #2512 is mergeable.",
      "@jorisvandenbossche @martinfleis \r\n> +1 to that now that #2512 is mergeable.\r\n\r\nI noted that #2512 has been merged.  Have now put config into **pyproject.toml** and moved other **pytest** config from **setup.cfg**"
    ],
    "commit_messages": [
      "CI: Filter distutils Version warnings from pytest output (#2632)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d587ac254a19ac29dff1",
    "number": 2630,
    "body": "Bumps [codecov/codecov-action](https://github.com/codecov/codecov-action) from 2 to 3.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/codecov/codecov-action/releases\">codecov/codecov-action's releases</a>.</em></p>\n<blockquote>\n<h2>v3.0.0</h2>\n<h3>Breaking Changes</h3>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/689\">#689</a> Bump to node16 and small fixes</li>\n</ul>\n<h3>Features</h3>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/688\">#688</a> Incorporate <code>gcov</code> arguments for the Codecov uploader</li>\n</ul>\n<h3>Dependencies</h3>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/548\">#548</a> build(deps-dev): bump jest-junit from 12.2.0 to 13.0.0</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/603\">#603</a> [Snyk] Upgrade <code>@​actions/core</code> from 1.5.0 to 1.6.0</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/628\">#628</a> build(deps): bump node-fetch from 2.6.1 to 3.1.1</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/634\">#634</a> build(deps): bump node-fetch from 3.1.1 to 3.2.0</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/636\">#636</a> build(deps): bump openpgp from 5.0.1 to 5.1.0</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/652\">#652</a> build(deps-dev): bump <code>@​vercel/ncc</code> from 0.30.0 to 0.33.3</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/653\">#653</a> build(deps-dev): bump <code>@​types/node</code> from 16.11.21 to 17.0.18</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/659\">#659</a> build(deps-dev): bump <code>@​types/jest</code> from 27.4.0 to 27.4.1</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/667\">#667</a> build(deps): bump actions/checkout from 2 to 3</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/673\">#673</a> build(deps): bump node-fetch from 3.2.0 to 3.2.3</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/683\">#683</a> build(deps): bump minimist from 1.2.5 to 1.2.6</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/685\">#685</a> build(deps): bump <code>@​actions/github</code> from 5.0.0 to 5.0.1</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/681\">#681</a> build(deps-dev): bump <code>@​types/node</code> from 17.0.18 to 17.0.23</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/682\">#682</a> build(deps-dev): bump typescript from 4.5.5 to 4.6.3</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/676\">#676</a> build(deps): bump <code>@​actions/exec</code> from 1.1.0 to 1.1.1</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/675\">#675</a> build(deps): bump openpgp from 5.1.0 to 5.2.1</li>\n</ul>\n<h2>v2.1.0</h2>\n<h2>2.1.0</h2>\n<h3>Features</h3>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/515\">#515</a> Allow specifying version of Codecov uploader</li>\n</ul>\n<h3>Dependencies</h3>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/499\">#499</a> build(deps-dev): bump <code>@​vercel/ncc</code> from 0.29.0 to 0.30.0</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/508\">#508</a> build(deps): bump openpgp from 5.0.0-5 to 5.0.0</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/514\">#514</a> build(deps-dev): bump <code>@​types/node</code> from 16.6.0 to 16.9.0</li>\n</ul>\n<h2>v2.0.3</h2>\n<h2>2.0.3</h2>\n<h3>Fixes</h3>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/464\">#464</a> Fix wrong link in the readme</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/485\">#485</a> fix: Add override OS and linux default to platform</li>\n</ul>\n<h3>Dependencies</h3>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/447\">#447</a> build(deps): bump openpgp from 5.0.0-4 to 5.0.0-5</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/458\">#458</a> build(deps-dev): bump eslint from 7.31.0 to 7.32.0</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/465\">#465</a> build(deps-dev): bump <code>@​typescript-eslint/eslint-plugin</code> from 4.28.4 to 4.29.1</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/466\">#466</a> build(deps-dev): bump <code>@​typescript-eslint/parser</code> from 4.28.4 to 4.29.1</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/468\">#468</a> build(deps-dev): bump <code>@​types/jest</code> from 26.0.24 to 27.0.0</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/470\">#470</a> build(deps-dev): bump <code>@​types/node</code> from 16.4.0 to 16.6.0</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/472\">#472</a> build(deps): bump path-parse from 1.0.6 to 1.0.7</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/473\">#473</a> build(deps-dev): bump <code>@​types/jest</code> from 27.0.0 to 27.0.1</li>\n</ul>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/codecov/codecov-action/blob/main/CHANGELOG.md\">codecov/codecov-action's changelog</a>.</em></p>\n<blockquote>\n<h2>3.1.1</h2>\n<h3>Fixes</h3>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/661\">#661</a> Update deprecation warning</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/593\">#593</a> Create codeql-analysis.yml</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/712\">#712</a> README: fix typo</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/725\">#725</a> fix: Remove a blank row</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/726\">#726</a> Update README.md with correct badge version</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/633\">#633</a> Create scorecards-analysis.yml</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/747\">#747</a> fix: add more verbosity to validation</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/750\">#750</a> Regenerate scorecards-analysis.yml</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/774\">#774</a> Switch to v3</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/783\">#783</a> Fix network entry in table</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/791\">#791</a> Trim arguments after splitting them</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/769\">#769</a> Plumb failCi into verification function.</li>\n</ul>\n<h3>Dependencies</h3>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/713\">#713</a> build(deps-dev): bump typescript from 4.6.3 to 4.6.4</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/714\">#714</a> build(deps): bump node-fetch from 3.2.3 to 3.2.4</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/724\">#724</a> build(deps): bump github/codeql-action from 1 to 2</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/717\">#717</a> build(deps-dev): bump <code>@​types/jest</code> from 27.4.1 to 27.5.0</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/729\">#729</a> build(deps-dev): bump <code>@​types/node</code> from 17.0.25 to 17.0.33</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/734\">#734</a> build(deps-dev): downgrade <code>@​types/node</code> to 16.11.35</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/723\">#723</a> build(deps): bump actions/checkout from 2 to 3</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/733\">#733</a> build(deps): bump <code>@​actions/github</code> from 5.0.1 to 5.0.3</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/732\">#732</a> build(deps): bump <code>@​actions/core</code> from 1.6.0 to 1.8.2</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/737\">#737</a> build(deps-dev): bump <code>@​types/node</code> from 16.11.35 to 16.11.36</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/749\">#749</a> build(deps): bump ossf/scorecard-action from 1.0.1 to 1.1.0</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/755\">#755</a> build(deps-dev): bump typescript from 4.6.4 to 4.7.3</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/759\">#759</a> build(deps-dev): bump <code>@​types/node</code> from 16.11.36 to 16.11.39</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/762\">#762</a> build(deps-dev): bump <code>@​types/node</code> from 16.11.39 to 16.11.40</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/746\">#746</a> build(deps-dev): bump <code>@​vercel/ncc</code> from 0.33.4 to 0.34.0</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/757\">#757</a> build(deps): bump ossf/scorecard-action from 1.1.0 to 1.1.1</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/760\">#760</a> build(deps): bump openpgp from 5.2.1 to 5.3.0</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/748\">#748</a> build(deps): bump actions/upload-artifact from 2.3.1 to 3.1.0</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/766\">#766</a> build(deps-dev): bump typescript from 4.7.3 to 4.7.4</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/799\">#799</a> build(deps): bump openpgp from 5.3.0 to 5.4.0</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/798\">#798</a> build(deps): bump <code>@​actions/core</code> from 1.8.2 to 1.9.1</li>\n</ul>\n<h2>3.1.0</h2>\n<h3>Features</h3>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/699\">#699</a> Incorporate <code>xcode</code> arguments for the Codecov uploader</li>\n</ul>\n<h3>Dependencies</h3>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/694\">#694</a> build(deps-dev): bump <code>@​vercel/ncc</code> from 0.33.3 to 0.33.4</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/696\">#696</a> build(deps-dev): bump <code>@​types/node</code> from 17.0.23 to 17.0.25</li>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/698\">#698</a> build(deps-dev): bump jest-junit from 13.0.0 to 13.2.0</li>\n</ul>\n<h2>3.0.0</h2>\n<h3>Breaking Changes</h3>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/689\">#689</a> Bump to node16 and small fixes</li>\n</ul>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/codecov/codecov-action/commit/d9f34f8cd5cb3b3eb79b3e4b5dae3a16df499a70\"><code>d9f34f8</code></a> release: update changelog and version to 3.1.1 (<a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/828\">#828</a>)</li>\n<li><a href=\"https://github.com/codecov/codecov-action/commit/0e9e7b4e8a4cbde89b1d36ffe91a812536089d02\"><code>0e9e7b4</code></a> Plumb failCi into verification function. (<a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/769\">#769</a>)</li>\n<li><a href=\"https://github.com/codecov/codecov-action/commit/7f20bd4c4151750a1d013be0901b7e35a46c2aad\"><code>7f20bd4</code></a> build(deps): bump <code>@​actions/core</code> from 1.8.2 to 1.9.1 (<a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/798\">#798</a>)</li>\n<li><a href=\"https://github.com/codecov/codecov-action/commit/13bc2536ab285b021e72dfb3cd53e56f5c1f4e26\"><code>13bc253</code></a> build(deps): bump openpgp from 5.3.0 to 5.4.0 (<a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/799\">#799</a>)</li>\n<li><a href=\"https://github.com/codecov/codecov-action/commit/5c0da1b28f1c589bf17db0088d610ae638f4ccb7\"><code>5c0da1b</code></a> Trim arguments after splitting them (<a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/791\">#791</a>)</li>\n<li><a href=\"https://github.com/codecov/codecov-action/commit/68d5f6d0be32fb7f92b47e97218cf01690e6e3b5\"><code>68d5f6d</code></a> Fix <code>network</code> entry in table (<a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/783\">#783</a>)</li>\n<li><a href=\"https://github.com/codecov/codecov-action/commit/2a829b95deaeea2d11d127cc0358005714ff35ea\"><code>2a829b9</code></a> Switch to v3 (<a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/774\">#774</a>)</li>\n<li><a href=\"https://github.com/codecov/codecov-action/commit/8e09eaf1b47fbb5da0e32a27bf08cd11929a1b4a\"><code>8e09eaf</code></a> build(deps-dev): bump typescript from 4.7.3 to 4.7.4 (<a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/766\">#766</a>)</li>\n<li><a href=\"https://github.com/codecov/codecov-action/commit/39e222921fd6f8ff1aae5c56948ff1599a2b57d1\"><code>39e2229</code></a> build(deps): bump actions/upload-artifact from 2.3.1 to 3.1.0 (<a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/748\">#748</a>)</li>\n<li><a href=\"https://github.com/codecov/codecov-action/commit/b2b77034732e1f073c09521d4f31f4db18b099e2\"><code>b2b7703</code></a> build(deps): bump openpgp from 5.2.1 to 5.3.0 (<a href=\"https://github-redirect.dependabot.com/codecov/codecov-action/issues/760\">#760</a>)</li>\n<li>Additional commits viewable in <a href=\"https://github.com/codecov/codecov-action/compare/v2...v3\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=codecov/codecov-action&package-manager=github_actions&previous-version=2&new-version=3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
    "head_branch": "dependabot/github_actions/codecov/codecov-action-3",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Bump codecov/codecov-action from 2 to 3 (#2630)\n\nBumps [codecov/codecov-action](https://github.com/codecov/codecov-action) from 2 to 3.\r\n- [Release notes](https://github.com/codecov/codecov-action/releases)\r\n- [Changelog](https://github.com/codecov/codecov-action/blob/main/CHANGELOG.md)\r\n- [Commits](https://github.com/codecov/codecov-action/compare/v2...v3)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: codecov/codecov-action\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-major\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d588ac254a19ac29dff2",
    "number": 2629,
    "body": "Bumps [pre-commit/action](https://github.com/pre-commit/action) from 2.0.3 to 3.0.0.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/pre-commit/action/releases\">pre-commit/action's releases</a>.</em></p>\n<blockquote>\n<h2>pre-commit/action@v3.0.0</h2>\n<h3>Breaking</h3>\n<ul>\n<li>remove pushing behaviour.\n<ul>\n<li>PR <a href=\"https://github-redirect.dependabot.com/pre-commit/action/issues/164\">#164</a> by <a href=\"https://github.com/asottile\"><code>@​asottile</code></a>.</li>\n</ul>\n</li>\n</ul>\n<p>see <a href=\"https://github.com/pre-commit/action#using-this-action-in-private-repositories\">README</a> for alternatives</p>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/pre-commit/action/commit/646c83fcd040023954eafda54b4db0192ce70507\"><code>646c83f</code></a> v3.0.0</li>\n<li><a href=\"https://github.com/pre-commit/action/commit/7a7fccb381efc61696dc74784c65cbd8ba08dba7\"><code>7a7fccb</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/pre-commit/action/issues/164\">#164</a> from pre-commit/remove-pushing</li>\n<li><a href=\"https://github.com/pre-commit/action/commit/f5c2d257b41b727742d1bb25e1d1457e1baafeec\"><code>f5c2d25</code></a> remove pushing behaviour</li>\n<li><a href=\"https://github.com/pre-commit/action/commit/c67424282e7cc932164c9966cf263f5840b7cc41\"><code>c674242</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/pre-commit/action/issues/162\">#162</a> from pre-commit/pre-commit-ci-update-config</li>\n<li><a href=\"https://github.com/pre-commit/action/commit/8a43c8467f9df969f50d3f78337d9aaa8e0cec05\"><code>8a43c84</code></a> [pre-commit.ci] pre-commit autoupdate</li>\n<li><a href=\"https://github.com/pre-commit/action/commit/09322329f46a8f0a580444ee47753af5905dd205\"><code>0932232</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/pre-commit/action/issues/161\">#161</a> from pre-commit/pre-commit-ci-update-config</li>\n<li><a href=\"https://github.com/pre-commit/action/commit/3945558147b73399e040b2dfdb799b7c3f071153\"><code>3945558</code></a> [pre-commit.ci] pre-commit autoupdate</li>\n<li><a href=\"https://github.com/pre-commit/action/commit/d1945e3ce270ffc4042cf33a625df1176e45cbbe\"><code>d1945e3</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/pre-commit/action/issues/158\">#158</a> from pre-commit/pre-commit-ci-update-config</li>\n<li><a href=\"https://github.com/pre-commit/action/commit/705d6c10ed76ed06a6e5a1c2186b73f7bb580542\"><code>705d6c1</code></a> [pre-commit.ci] pre-commit autoupdate</li>\n<li><a href=\"https://github.com/pre-commit/action/commit/c81293cb5edf7ebc16684cf3543fa70be2051607\"><code>c81293c</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/pre-commit/action/issues/156\">#156</a> from pre-commit/pre-commit-ci-update-config</li>\n<li>Additional commits viewable in <a href=\"https://github.com/pre-commit/action/compare/v2.0.3...v3.0.0\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pre-commit/action&package-manager=github_actions&previous-version=2.0.3&new-version=3.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
    "head_branch": "dependabot/github_actions/pre-commit/action-3.0.0",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Bump pre-commit/action from 2.0.3 to 3.0.0 (#2629)\n\nBumps [pre-commit/action](https://github.com/pre-commit/action) from 2.0.3 to 3.0.0.\r\n- [Release notes](https://github.com/pre-commit/action/releases)\r\n- [Commits](https://github.com/pre-commit/action/compare/v2.0.3...v3.0.0)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: pre-commit/action\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-major\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d588ac254a19ac29dff3",
    "number": 2628,
    "body": "Add a Dependabot configuration that checks once a week if the GitHub Actions are still using the latest version. If not, it opens a PR to update them.\r\n\r\nIt will actually open very few PRs, since we only have major versions specified (like v3), so only on a major v4 release it will update and open a PR.\r\n\r\nSee [Keeping your actions up to date with Dependabot](https://docs.github.com/en/code-security/dependabot/working-with-dependabot/keeping-your-actions-up-to-date-with-dependabot).",
    "head_branch": "patch-5",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add Dependabot configuration for GitHub Actions updates (#2628)\n\nAdd a Dependabot configuration that checks once a week if the GitHub Actions are still using the latest version. If not, it opens a PR to update them.\r\n\r\nIt will actually open very few PRs, since we only have major versions specified (like v3), so only on a major v4 release it will update and open a PR.\r\n\r\nSee https://docs.github.com/en/code-security/dependabot/working-with-dependabot/keeping-your-actions-up-to-date-with-dependabot"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d589ac254a19ac29dff4",
    "number": 2627,
    "body": "With pyogrio being rebuilt for 3.11 (~Fiona not yet~), we should have all we need to test geopandas with Python 3.11.\r\n\r\n~This env also excludes pygeos and uses shapely 2.~ (does not resolve)\r\n\r\nCloses #2592",
    "head_branch": "311",
    "is_a_fork": true,
    "comments": [
      "Awesome!"
    ],
    "commit_messages": [
      "CI: add Python 3.11 to the test matrix (#2627)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d58aac254a19ac29dff5",
    "number": 2625,
    "body": "Pytest's short summary at the end of the run now shows only skipped tests. This ensures that every result other than pass is listed.",
    "head_branch": "pytest_better",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: include errors, failures, xfails and xpasses in the pytest short summary (#2625)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d58bac254a19ac29dff6",
    "number": 2624,
    "body": "This exposes `get_coordinates` from shapely2/pygeos as a GeoSeries/GeoDataFrame method, returning a pandas.DataFrame. The index handling mirrors the implementation we have in `explode` as both are very similar operations in nature. One is returing parts of original geometries, the other goes one step further and returns coordinates.\r\n\r\nI am aware that this is a borderline function we weren't sure we want to expose as a method but given there is a relatively close precedent with `explode` and we can reuse its indexing machinery, it is in the end a nice addition I think. \r\n\r\nI will add tests and documentation once there's an agreement that we want to do this and we have the API set.\r\n\r\nCurrent behaviour:\r\n```py\r\n>>> from shapely.geometry import Point, LineString, Polygon\r\n>>> s = geopandas.GeoSeries(\r\n...     [\r\n...         Point(1, 1),\r\n...         LineString([(1, -1), (1, 0)]),\r\n...         Polygon([(3, -1), (4, 0), (3, 1)]),\r\n...     ]\r\n... )\r\n>>> s\r\n0                              POINT (1.00000 1.00000)\r\n1       LINESTRING (1.00000 -1.00000, 1.00000 0.00000)\r\n2    POLYGON ((3.00000 -1.00000, 4.00000 0.00000, 3...\r\ndtype: geometry\r\n```\r\n```py\r\n>>> s.get_coordinates()\r\n     x    y\r\n0  1.0  1.0\r\n1  1.0 -1.0\r\n1  1.0  0.0\r\n2  3.0 -1.0\r\n2  4.0  0.0\r\n2  3.0  1.0\r\n2  3.0 -1.0\r\n```\r\n```py\r\n>>> s.get_coordinates(ignore_index=True)\r\n     x    y\r\n0  1.0  1.0\r\n1  1.0 -1.0\r\n2  1.0  0.0\r\n3  3.0 -1.0\r\n4  4.0  0.0\r\n5  3.0  1.0\r\n6  3.0 -1.0\r\n```\r\n```py\r\n>>> s.get_coordinates(index_parts=True)\r\n       x    y\r\n0 0  1.0  1.0\r\n1 0  1.0 -1.0\r\n  1  1.0  0.0\r\n2 0  3.0 -1.0\r\n  1  4.0  0.0\r\n  2  3.0  1.0\r\n  3  3.0 -1.0\r\n```",
    "head_branch": "get_coordinates",
    "is_a_fork": true,
    "comments": [
      "This should be ready now.\r\n\r\n@m-richards I've moved the exploded index handling into a helper function that is now shared by both explode and get_coordinates. Nice tip! \r\n\r\n> one might expect the gdf case to return a geodataframe reindexed to correspond to all the coordinates\r\n\r\nnot sure I agree. I would expect it to behave as `.bounds` does. Can limit it to the GeoSeries but not sure about that. Or you'd rather have it behave the same as explode on gdf?",
      "> not sure I agree. I would expect it to behave as `.bounds` does. Can limit it to the GeoSeries but not sure about that. Or you'd rather have it behave the same as explode on gdf?\r\n\r\nI actually agree with you - I think the current behaviour makes the most sense in terms of how I might use this method, and the parallel with bounds is a good justification - just thought I'd mention it though so we're happy this is the expected behaviour.\r\n\r\n",
      "@jorisvandenbossche can we try to get this in?",
      "Thanks!"
    ],
    "commit_messages": [
      "ENH: expose get_coordinates as a method (#2624)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d58cac254a19ac29dff7",
    "number": 2623,
    "body": "This should fix the failures on CI in an env with shapely 2.0b2. https://github.com/shapely/shapely/pull/1590 uncovered that we were passing a list of tuples to a Point constructor. While old shapely uses only the first tuple and ignores the rest, shapely 2.0b2 correctly raises an error.",
    "head_branch": "point_sh2",
    "is_a_fork": true,
    "comments": [
      "(From Martin's comment in the linked shapely issue)\r\n>GeoPandas CI fails on this\r\nPoint([(2, 3), (11, 4), (7, 2), (8, 9), (1, 13)])\r\nWhich I'd say is a correct behaviour. I don't really understand what is the intention of this line. \r\n\r\nJust doing some archeology on this,\r\nseems to have been introduced here:\r\nhttps://github.com/lwasser/geopandas/commit/67c58c0cff174e6724ea370c9cda17b39c311d8b#diff-999030931f6802617e56e4c04679840188538ca61816e9ee97d9fac0763563dc\r\nand then copied through into the analogous test for geometrycollections. Seems fairly likely that the intent was to actually add a point. "
    ],
    "commit_messages": [
      "TST: fix point creation in clip test suite (#2623)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d58cac254a19ac29dff8",
    "number": 2622,
    "body": "See https://github.com/geopandas/geopandas/issues/2603#issuecomment-1295080298",
    "head_branch": "remove-shapely-pin",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Remove shapely <2 pin in install requirements (#2622)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d58dac254a19ac29dff9",
    "number": 2621,
    "body": "Expose `minimum_bounding_circle` as a GeoSeries method.\r\n\r\nxref #2010",
    "head_branch": "mbc",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: add minimum_bounding_circle as GeoSeries method (#2621)\n\n* ENH: add minimum_bounding_circle as GeoSeries method\r\n\r\n* skipif\r\n\r\n* changelog\r\n\r\n* fix docs build"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d58eac254a19ac29dffa",
    "number": 2620,
    "body": "There's probably a more direct way of accomplishing this, and likely this has performance implications, but it does ensure that a DataFrame that is used to create a GeoDataFrame is unchanged, which seems like the behavior that is reasonably assumed and desired.\r\n\r\nResolves #1179 ",
    "head_branch": "copy-dataframe",
    "is_a_fork": true,
    "comments": [
      "Am i right the only addition here is in class GeoDataFrame:\r\n\r\n```\r\n    def __init__(self, data=None, *args, geometry=None, crs=None, **kwargs):\r\n        if type(data) == pd.DataFrame:\r\n            data = data.copy()\r\n```\r\n\r\nand the `test_dataframe_not_manipulated` test.\r\n\r\nThe rest is isort fixes?",
      "@raybellwaves Correct. I can undo the isort changes if that would be better.",
      "This seems to duplicate work being done in #2306.",
      "@martinfleis Sorry about that -- that looks like a better solution. Is 2306 still open because there isn't an associated test? @spolloni would you like to add my test to your PR?",
      "Missing test is one reason, lower priority another.",
      "> @spolloni would you like to add my test to your PR?\r\n\r\nsure thing @blackary, how about you PR the tests diff into [my branch](https://github.com/spolloni/geopandas/tree/feat/copy-if-dataframe)?",
      "Added https://github.com/spolloni/geopandas/pull/1"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d58fac254a19ac29dffb",
    "number": 2619,
    "body": "Fixes #2566 ",
    "head_branch": "improve-error-message",
    "is_a_fork": true,
    "comments": [
      "I have revived this.\r\n\r\nNot sure if it needs a changelog note?"
    ],
    "commit_messages": [
      "ENH: Improve error message for attempting to write multiple geometry columns using to_file (#2619)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d590ac254a19ac29dffc",
    "number": 2618,
    "body": "As discussed in #2580, we want to make the outcome of an empty `unary_union` consistent with shapely 2.0 which returns `'GEOMETRYCOLLECTION EMPTY'`. Adding a FutureWatning here assuming the behaviour will change in 1.0.",
    "head_branch": "depr_union",
    "is_a_fork": true,
    "comments": [
      "Should have checked before merging, but this seems to cause some of such warnings in our own test suite:\r\n\r\n```\r\n geopandas/tests/test_overlay.py::test_keep_geom_type_geomcoll_different_types\r\n  /home/runner/work/geopandas/geopandas/geopandas/geodataframe.py:1687: FutureWarning: `unary_union` returned None due to all-None GeoSeries. In future, `unary_union` will return 'GEOMETRYCOLLECTION EMPTY' instead.\r\n    merged_geom = block.unary_union\r\n```\r\n\r\nSo this seems to be from calling `unary_union` inside `dissolve`. We should avoid this warning bubbles up to the user in that case, since there is nothing to do about? (although it still signals that something in the result changed)",
      "> We should avoid this warning bubbles up to the user in that case, since there is nothing to do about?\r\n\r\nI don't think so. User cannot do anything about the warning coming from `unary_union` itself. It is as useful in case of dissolve as it is in case of calling directly `unary_union`. The output will change in both cases. I would even say it would not be okay to hide it as the change would then happen without a notice."
    ],
    "commit_messages": [
      "DEPR: deprecate None as a result of empty unary_union (#2618)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d590ac254a19ac29dffd",
    "number": 2617,
    "body": "See https://github.com/geopandas/geopandas/issues/2615#issuecomment-1292408029\r\n\r\nAgreed to update the way to create a develop environment using `pip install -e .`",
    "head_branch": "patch-4",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add pip install -e . to contributing.rst (#2617)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d591ac254a19ac29dffe",
    "number": 2616,
    "body": "Closes #2615 ",
    "head_branch": "simplify-contributing-guide",
    "is_a_fork": true,
    "comments": [
      "See https://github.com/geopandas/geopandas/issues/2615#issuecomment-1292408029",
      "superseded by https://github.com/geopandas/geopandas/pull/2617 closing"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d592ac254a19ac29dfff",
    "number": 2611,
    "body": "Pinning the correct min version required for new handling of cmaps in explore as pointed out by @rraymondgh in https://github.com/geopandas/geopandas/pull/2596#issuecomment-1287905024.\r\n\r\n@jorisvandenbossche this should make it to the 0.12.",
    "head_branch": "mplfix",
    "is_a_fork": true,
    "comments": [
      "@martinfleis just because I've already merged and don't want to have another hand crafted merge,  can we target merging #2590 instead of this fix?  I'm currently building ubuntu VMs to be able to run tests locally to pass CI.  Will be < 24hrs before everything is resolved",
      "Thanks Martin!\r\n\r\n@rraymondgh sorry for another merge conflict (although it's only a small change so I think the merge shouldn't be too bad). I am going to merge this one, though, because I want to release _right now_. See https://github.com/geopandas/geopandas/issues/2603 for context"
    ],
    "commit_messages": [
      "COMPAT: fix matplotlib version required for new cmaps (#2611)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d593ac254a19ac29e000",
    "number": 2610,
    "body": null,
    "head_branch": "ci-shapely-dev",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: install shapely 2.0b1 using pip to avoid conda timeout issues (#2610)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d594ac254a19ac29e001",
    "number": 2609,
    "body": "xref https://github.com/conda-forge/tiledb-feedstock/issues/170, https://github.com/conda-forge/gdal-feedstock/issues/654",
    "head_branch": "fix-ci",
    "is_a_fork": true,
    "comments": [
      "The remaining failure is the timeout error that has been happening from time to time for the envs that include shapely_dev label. Will already merge since it seems to fix the other issues."
    ],
    "commit_messages": [
      "CI: temporary fix for GDAL/tiledb conda-forge issues (#2609)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d594ac254a19ac29e002",
    "number": 2608,
    "body": null,
    "head_branch": "changelog-shapely-2",
    "is_a_fork": true,
    "comments": [
      "Thanks for the proofreading!"
    ],
    "commit_messages": [
      "DOC: add note about Shapely 2.0 support to the changelog (#2608)\n\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>\r\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d595ac254a19ac29e003",
    "number": 2605,
    "body": "This gives:\r\n\r\n```\r\n>>> import geopandas\r\n<stdin>:1: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still\r\nuse PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment\r\nvariable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before\r\nimporting geopandas:\r\n\r\nimport os\r\nos.environ['USE_PYGEOS'] = '0'\r\nimport geopandas\r\n",
    "head_branch": "warn-shapely2",
    "is_a_fork": true,
    "comments": [
      "This looks okay but there is a question what comes next. Deprecation of pygeos in 0.13? And automatic use of shapely 2.0 only when geopandas 1.0 will come? Or earlier?",
      "Good questions. At some point we should switch to Shapely as default, and at some point deprecate and remove pygeos support. But when each of those steps happens in something we should still decide.\r\n\r\nI would say that for GeoPandas 1.0, we want to just support shapely >= 2.0, so we can clean-up our code. \r\n\r\nI could add something generic to the warning message that in the future we will switch to shapely as default, and that if you are using pygeos directly (not just through geopandas), you are encouraged to migrate to shapely 2.0. Would that help? (without already being super concrete)\r\n\r\nThe main reason I want something like the current warning in this PR is that _if_ you have shapely 2.0, this is at the moment intentionally to test it (since it is still a pre-release, users won't have it accidentally), and so to properly test it with geopandas you have to set this env variable. \r\nI think it is only when shapely 2.0 is actually released, that it gets more important to warn about switching away from pygeos / making it the default.",
      "> I could add something generic to the warning message that in the future we will switch to shapely as default, and that if you are using pygeos directly (not just through geopandas), you are encouraged to migrate to shapely 2.0. Would that help? (without already being super concrete)\n\nI think that this would be a good solution. ",
      "(failures are a conda rebuild issue -> https://github.com/conda-forge/tiledb-feedstock/issues/170)"
    ],
    "commit_messages": [
      "Add warning when having both PyGEOS and Shapely 2.0 installed (#2605)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d596ac254a19ac29e004",
    "number": 2604,
    "body": "Fixes #2538\r\n\r\nNeed confirmation, apart from the deletion I did do we need to remove 'geom_almost_equals' and its usages as well? \r\nThis is first **code** contribution in OS. ",
    "head_branch": "main",
    "is_a_fork": true,
    "comments": [
      "hi @m-richards , could you please check on this.",
      "Hi @darshanip, this is unused code so is good to delete. With geom_almost_equals, we won't remove that yet, but should rather add a FutureWarning to indicate to users it will be removed in a future version.\r\n\r\nThe warnings removed in #2267 are an example of the kind of message you should add here if you'd like some guidance.",
      "@m-richards Could you please review the changes.",
      "@jorisvandenbossche @martinfleis, Could you please review changes.",
      "@m-richards can you please review code.",
      "I've revived this, should be close to ready now. I'm not sure if we should also deprecate geopandas.testing.geom_almost_equals. I don't really see a huge issue with keeping it. If we were to deprecate, it would definitely be worth keeping a private internal helper for this.",
      "> We should have it one one level only, probably on array. We could also keep it on both level but use `geom_equals_exact` array-level method in base-level `geom_almost_equals`.\r\n\r\nI've done the latter, it seems better to keep the warning in base.py so the stacklevel is correct for an end user.\r\n\r\n",
      "@martinfleis I've had to continue this at #3017 as I seem to no longer have push permissions on the fork.",
      "Superseded by https://github.com/geopandas/geopandas/pull/3017"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d597ac254a19ac29e005",
    "number": 2600,
    "body": "Corrects the old reference to the `op` kwarg.",
    "head_branch": "main",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: update spatial_joins predicate param ref (#2600)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d598ac254a19ac29e006",
    "number": 2599,
    "body": "This closes #2325 to prevent zoom levels in map_kwds from being overridden.",
    "head_branch": "zoom-change",
    "is_a_fork": true,
    "comments": [
      "Conda build failures seem sporadic and unrelated...",
      "> Conda build failures seem sporadic and unrelated...\r\n\r\nThey are - there are issues with **39-latest-conda-forge.yaml** at moment with a bit on chat on gitter\r\n\r\nChange looks ok - but I would expect a test case in **test_explore.py** as this is a behaviour change (from incorrect to correct).  I would expect this is quite simple using `_fetch_map_string()` helper function.  need to check for expected zoom levels",
      "Hey @rraymondgh, thanks for the tip. I went ahead and added three tests instead of just the one (only min, only max, and both). Hope this works.",
      "@martinfleis, mind giving this one a look?",
      "@m-richards or @jorisvandenbossche, any of you available to give this a look please?",
      "@kapoor1992 sorry, this completely slipped of my radar. Can you update this branch from main and ensure that all tests are green?",
      "Hey @martinfleis, I updated the branch and everything's been re-ran. The only failure is unrelated to the change here (and I see it in other PRs). Does this look fine to you?",
      "@martinfleis or @m-richards, mind giving this a look? It was updated.",
      "Hey @m-richards, is the changelog entry something you'll be taking on or shall I? The current version in main has no newest version number for the next release and there's no date, and I'm not familiar with the process on this repository for adding a placeholder release (or even if we do) to the changelog.",
      "> Hey @m-richards, is the changelog entry something you'll be taking on or shall I? The current version in main has no newest version number for the next release and there's no date, and I'm not familiar with the process on this repository for adding a placeholder release (or even if we do) to the changelog.\n\nAh sorry, didn't realise we have no template at rhe moment. I can add an entry if that's easier. ",
      "@m-richards good to know that we can have a placeholder. I went ahead and added a new section to the changelog in this PR with a TBD date, hope it looks alright!",
      "@martinfleis and @m-richards, is there anything else I need to do here or will someone take care of the merge when the time is right? Just hoping I don't need to refresh from main again :)",
      "Hey @kapoor1992, thanks for checking in, nothing needed from you. In principle there's nothing stopping this from being merged, the ci failure is unrelated, but ideally #2637 would be resolved and we'd fix the CI checks before merging this. I'm happy to re-merge this back up to date with origin/main myself if we need to when it this does actually get merged.",
      "Thanks @kapoor1992!"
    ],
    "commit_messages": [
      "Don't override map_kwds zoom levels (#2599)\n\n* dont override map_kwds\r\n\r\n* remove nl\r\n\r\n* tests\r\n\r\n* formatting\r\n\r\n* ending parenthesis on new line\r\n\r\n* comma\r\n\r\n* changelog\r\n\r\n* typo\r\n\r\n* DOC: reformat develop changelog section\r\n\r\n* DOC: reformat develop changelog section\r\n\r\n* changelog tweak\r\n\r\n* fix changelog\r\n\r\nCo-authored-by: kapoor_sitezeus <dkapoor@sitezeus.com>\r\nCo-authored-by: Matt Richards <mrichards7@outlook.com.au>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d599ac254a19ac29e007",
    "number": 2598,
    "body": "This contributes to #1896. I tried to primarily focus on [link text](https://developers.google.com/style/link-text) and [capitalization](https://developers.google.com/style/capitalization) discrepancies. There is still plenty of work necessary to fix the tone and second-person perspective, among others. ",
    "head_branch": "fix-docs-style",
    "is_a_fork": true,
    "comments": [
      "Great feedback, thanks! "
    ],
    "commit_messages": [
      "DOC: use consistent style for capitalization and link text (#2598)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d599ac254a19ac29e008",
    "number": 2596,
    "body": "This PR resolves the [`PendingDeprecationWarning`](https://github.com/geopandas/geopandas/actions/runs/3243624358/jobs/5318620857#step:6:4291) that is being thrown by `matplotlib` due to the upcoming deprecation of [`matplotlib.cm`](https://matplotlib.org/stable/api/cm_api.html#module-matplotlib.cm).\r\n\r\n```\r\nPendingDeprecationWarning: The get_cmap function will be deprecated in a future version. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\r\n```",
    "head_branch": "matplotlib_cm_warning",
    "is_a_fork": true,
    "comments": [
      "Looks like [`matplotlib==3.5.2`](https://github.com/geopandas/geopandas/actions/runs/3246874730/jobs/5326152154#step:4:48) is causing the failure in `38-latest-defaults`. Perhaps a `matplotlib` version flag would be appropriate in [`_explore()`](https://github.com/geopandas/geopandas/blob/main/geopandas/explore.py#L30)?",
      "Yes, I think we still want to support matplotlib 3.5 and below (we are currently saying >= 3.2.0 in the docs), so that means you will have to do it in the new way conditionally on the matplotlib version. \r\n\r\nIn plotting.py, you can also see a few places where we do something based on `Version(matplotlib.__version__)`",
      "I coded pretty much and identical solution, actually switched to new version as of Matplotlib 3.5.  that I believe is needed so that we don't have deprecation warning generated by **test_explore.py**",
      "> actually switched to new version as of Matplotlib 3.5\r\n\r\nI must have overlooked that. I'll update this PR accordingly.",
      "I see that the [Colormap Registry](https://matplotlib.org/3.5.3/users/prev_whats_new/whats_new_3.5.0.html#colormap-registry-experimental) was added in `matplotlib==3.5.0`. However, CI [fails](https://github.com/geopandas/geopandas/actions/runs/3246874730/jobs/5326152154#step:5:11383) when [`matplotlib==3.5.2`](https://github.com/geopandas/geopandas/actions/runs/3246874730/jobs/5326152154#step:4:48), as shown [above](https://github.com/geopandas/geopandas/pull/2596#issuecomment-1278376396). It's highly likely I'm missing something obvious though.",
      "> I see that the [Colormap Registry](https://matplotlib.org/3.5.3/users/prev_whats_new/whats_new_3.5.0.html#colormap-registry-experimental) was added in `matplotlib==3.5.0`. However, CI [fails](https://github.com/geopandas/geopandas/actions/runs/3246874730/jobs/5326152154#step:5:11383) when [`matplotlib==3.5.2`](https://github.com/geopandas/geopandas/actions/runs/3246874730/jobs/5326152154#step:4:48), as shown [above](https://github.com/geopandas/geopandas/pull/2596#issuecomment-1278376396). It's highly likely I'm missing something obvious though.\r\n\r\ncolor registry came in 3.5.  I just realised I advised slightly incorrectly.  `resampled()` is introduced in 3.6 to enable the migration which is needed for this change.  Hence min version is 3.6 to use color registry",
      "Do we still need a different solution for matplotlib 3.5 as well?",
      "> Hence min version is 3.6 to use color registry\r\n\r\n@jorisvandenbossche my interpretation from @rraymondgh's comment was that we do not need a different solution for 3.5. Maybe I missed something?",
      "@jGaboardi can you check if 3.5 warns or not with this PR?",
      "> can you check if 3.5 warns or not with this PR?\r\n\r\nnot with [`matplotlib==3.5.1`](https://github.com/geopandas/geopandas/actions/runs/3250710015/jobs/5334760825#step:4:196) or [`matplotlib==3.5.2`](https://github.com/geopandas/geopandas/actions/runs/3250710015/jobs/5334760998#step:4:186)",
      "Looks like neither `fiona` nor `pyogrio` are making into [the CI environment(s)](https://github.com/geopandas/geopandas/actions/runs/3300485036/jobs/5445038826#step:4:45), though [`pyogrio` should be there](https://github.com/geopandas/geopandas/blob/174b38c5e379deb7b771102019af42b9b0de7330/ci/envs/38-latest-conda-forge.yaml#L9).",
      "xref https://github.com/Toblerity/Fiona/issues/944",
      "@jGaboardi @jorisvandenbossche when merging this with #2590 I realised min MPL version is 3.6.1 not 3.6 for this change.  Have changed this when I merged",
      "@rraymondgh Ah! Good catch!"
    ],
    "commit_messages": [
      "COMPAT: resolve matplotlib.cm warning in explore() (#2596)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d59aac254a19ac29e009",
    "number": 2595,
    "body": "Closes #2589 ",
    "head_branch": "gh-2589",
    "is_a_fork": true,
    "comments": [
      "I went ahead and added tests to check that empty geometries, series, and dataframes all produce an empty result.",
      "Well now I'm confused. It looks like the tests are failing because of NaN inputs to shapely geometries but as far as i can tell shapely itself is happy to accept them. Does anyone know what the critical difference is between the test environments?",
      "Thanks a lot for the PR!\r\n\r\n> Well now I'm confused. It looks like the tests are failing because of NaN inputs to shapely geometries but as far as i can tell shapely itself is happy to accept them. Does anyone know what the critical difference is between the test environments?\r\n\r\nThat seems to be an issue with older GEOS versions (older GEOS is failing to buffer a point if there are NaN coordinates). \r\n\r\nBut I think we can avoid that by creating the empty geometry in a different way. For example, `Polygon()` should also create an empty geometry.\r\n",
      "Thanks for the help! I think it's good to go now. The failed test seems to be mamba related.",
      "Thanks for the update!\r\n\r\n> The failed test seems to be mamba related.\r\n\r\nYes, there was some flaky CI, I merged main, that should help now"
    ],
    "commit_messages": [
      "BUG: Fix handling of empty shapely geometries in clip() (#2595)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d59bac254a19ac29e00a",
    "number": 2594,
    "body": "Closes #2561\r\n\r\nRemoving the pin as the issue has been fixed.",
    "head_branch": "rm_theme_pin",
    "is_a_fork": true,
    "comments": [
      "I have built it locally, looks okay to me. "
    ],
    "commit_messages": [
      "DOC: remove pydata-sphinx-theme pin (#2594)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d59cac254a19ac29e00b",
    "number": 2591,
    "body": "Updates the used checkout, setup-python and gh-action-pypi-publish actions.\r\n\r\nOn another note, the [upload-release-asset](https://github.com/actions/upload-release-asset) and [create-release](https://github.com/actions/create-release) actions are archived and unmaintained, so should probably be replaced at some point.",
    "head_branch": "patch-4",
    "is_a_fork": true,
    "comments": [
      "> On another note, the [upload-release-asset](https://github.com/actions/upload-release-asset) and [create-release](https://github.com/actions/create-release) actions are archived and unmaintained, so should probably be replaced at some point.\r\n\r\nThanks for the heads up! It seems that both can be replaced with https://github.com/softprops/action-gh-release\r\n\r\n"
    ],
    "commit_messages": [
      "release CI: Update used actions (#2591)\n\nUpdates the used checkout, setup-python and gh-action-pypi-publish actions"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d59dac254a19ac29e00c",
    "number": 2590,
    "body": "Have built framework to run through combinations of `column`, `cmap`, `color`, `legend`, `categorical`, `scheme`, `k`, `vmin`  and `vmax`.  This framework identified a number of combinations that should have worked but failed.\r\n\r\nHave created utility class **RobustHelper** as part of **test_explore.py** This generates permutations, evaluates errors and warnings and provides mechanism to generate output of all generated **folium** maps.\r\n\r\nFixed code: `{'__column_type': 88, '__error': 13, '__warning': 37}` (88 combinations}\r\nv0.11: `{'__column_type': 88, '__error': 71, '__warning': 0}`\r\n\r\nIn addition this takes **explore.py** to 100% **codecov**\r\n\r\n<details>\r\n<summary>errors post fix summary</summary>\r\n\r\n| __error                        |   0 |\r\n|:-------------------------------|----:|\r\n| Invalid RGBA argument: 'bluee' |   1 |\r\n| Invalid scheme. Scheme must be |   2 |\r\n| The GeoDataFrame and given col |   3 |\r\n| `cmap` is invalid. For categor |   2 |\r\n| `cmap` is not known matplotlib |   5 |\r\n</details>\r\n\r\n<details>\r\n<summary>errors pre fix summary</summary>\r\n\r\n| __error                        |   0 |\r\n|:-------------------------------|----:|\r\n| '<=' not supported between ins |   1 |\r\n| '__plottable_column'           |  16 |\r\n| 'bad' is not a valid value for |   2 |\r\n| 'cmap' is invalid. For categor |   7 |\r\n| ('red', 'blue', 'pink', 'yello |   1 |\r\n| ((1.0, 0.7529411764705882, 0.7 |   1 |\r\n| Invalid scheme. Scheme must be |   3 |\r\n| Must have equal len keys and v |  12 |\r\n| The GeoDataFrame and given col |   3 |\r\n| The truth value of a DataFrame |   5 |\r\n| The truth value of a Series is |   3 |\r\n| Thresholds are not sorted.     |   6 |\r\n| ['pink', 'white', 'pink', 'yel |   1 |\r\n| ['red', 'blue', 'pink', 'yello |   1 |\r\n| ufunc 'multiply' did not conta |   8 |\r\n| unsupported operand type(s) fo |   1 |\r\n</details>\r\n\r\nCode can be used in a Jupyter notebook\r\n```\r\nimport geopandas as gpd\r\nfrom geopandas.tests.test_explore import RobustHelper\r\nfrom IPython.display import display, HTML\r\n\r\ngdf = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\")) \r\ngdf = gdf.head(25)\r\nrobust = RobustHelper(gdf)\r\ndf = robust.generate(max_tests=100, exclude=[])\r\ndf, maps = robust.run(df)\r\nprint({c: (~df[c].isna()).sum() for c in [\"__column_type\", \"__error\", \"__warning\"]})\r\ndisplay(HTML(robust.html(df, maps)))\r\n```\r\n\r\nAlso fixes this question on [SO](https://stackoverflow.com/questions/73979846/error-with-cmap-from-a-matplotlib-defined-list-of-colors-in-folium-choropleth/74033263#74033263l)\r\n\r\ncloses GH2408 and GH2583",
    "head_branch": "explore_cmap_scheme",
    "is_a_fork": true,
    "comments": [
      "closes  #2583 and #2408 and #2587",
      "Have found other parameter combinations that land up in inconsistent behaviour and errors.  No need to consider for review until sorted.\r\n\r\nThis is resolved in commits on 21-oct\r\n```\r\nimport geopandas as gpd\r\ngdf = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\r\n\r\ngdf.explore(column=\"iso_a3\")\r\ngdf.explore(column=gdf[\"iso_a3\"])\r\n```",
      "> Have found other parameter combinations that land up in inconsistent behaviour and errors. No need to consider for review until sorted.\r\n> \r\n> Second `explore()` call fails with ugly exception. I would expect these should behave the same...\r\n> \r\n> ```\r\n> import geopandas as gpd\r\n> gdf = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\r\n> \r\n> gdf.explore(column=\"iso_a3\")\r\n> gdf.explore(column=gdf[\"iso_a3\"])\r\n> ```\r\n\r\nAs discussed in #2587 this can be fixed by changing\r\n\r\n`elif pd.api.types.is_categorical_dtype(gdf[column]):` to `if pd.api.types.is_categorical_dtype(gdf[column]):`\r\n\r\nin [line 374 in explore.py](https://github.com/geopandas/geopandas/blob/main/geopandas/explore.py#L374)\r\n\r\nAs is done in my fork, here: https://github.com/geopandas/geopandas/compare/main...olsgaard:geopandas:main",
      "Another thing to look at is when calling `.explore()` on an empty dataframe. This can easily happen if you have a pipeline with a number of filters, and inadvertently end up filtering out all the rows.\r\n\r\nOften Pandas can give hard to understand errors in those cases, so I don't know if it is something we want to check for here, but I think it would be nice.\r\n\r\nsetup\r\n```python\r\nimport geopandas as gpd\r\nimport folium\r\n\r\ngdf = gpd.GeoDataFrame({'a': [], 'geometry': []})```\r\n```\r\n\r\n## situation 1\r\n```python\r\ngdf.explore()\r\n```\r\n```\r\nFile ~/miniconda3/envs/gds/lib/python3.9/site-packages/folium/utilities.py:66, in validate_location(location)\r\n     62         raise ValueError('Location should consist of two numerical values, '\r\n     63                          'but {!r} of type {} is not convertible to float.'\r\n     64                          .format(coord, type(coord)))\r\n     65     if math.isnan(float(coord)):\r\n---> 66         raise ValueError('Location values cannot contain NaNs.')\r\n     67 return [float(x) for x in coords]\r\n\r\nValueError: Location values cannot contain NaNs.\r\n```\r\nFairly reasonable.\r\n\r\n## situation 2\r\n```python\r\ngdf.explore(m=folium.Map())\r\n```\r\n```\r\nFile ~/miniconda3/envs/gds/lib/python3.9/site-packages/folium/features.py:568, in GeoJson._validate_function(self, func, name)\r\n    563 def _validate_function(self, func, name):\r\n    564     \"\"\"\r\n    565     Tests `self.style_function` and `self.highlight_function` to ensure\r\n    566     they are functions returning dictionaries.\r\n    567     \"\"\"\r\n--> 568     test_feature = self.data['features'][0]\r\n    569     if not callable(func) or not isinstance(func(test_feature), dict):\r\n    570         raise ValueError('{} should be a function that accepts items from '\r\n    571                          'data[\\'features\\'] and returns a dictionary.'\r\n    572                          .format(name))\r\n\r\nIndexError: list index out of range\r\n```\r\nSeems unnecessarily hard to understand.\r\n\r\n## situation 3\r\n```python\r\ngdf.explore(m=folium.Map(), column=gdf.a)\r\n```\r\n```\r\nFile ~/miniconda3/envs/gds/lib/python3.9/site-packages/mapclassify/classifiers.py:2271, in UserDefined.__init__(self, y, bins, lowest)\r\n   2270 def __init__(self, y, bins, lowest=None):\r\n-> 2271     if bins[-1] < max(y):\r\n   2272         bins = np.append(bins, max(y))\r\n   2273     self.lowest = lowest\r\n\r\nValueError: max() arg is an empty sequence\r\n```\r\nShould be easier to understand\r\n\r\n## situation 4\r\n\r\n```\r\n# Now there is 1 row with `NaN` in the geometry. \r\ngdf.assign(a=[1]).explore(m=folium.Map())\r\n```\r\n```\r\nFile ~/miniconda3/envs/gds/lib/python3.9/site-packages/folium/features.py:903, in <listcomp>(.0)\r\n    898 def warn_for_geometry_collections(self):\r\n    899     \"\"\"Checks for GeoJson GeometryCollection features to warn user about incompatibility.\"\"\"\r\n    900     geom_collections = [\r\n    901         feature.get('properties') if feature.get('properties') is not None else key\r\n    902         for key, feature in enumerate(self._parent.data['features'])\r\n--> 903         if feature['geometry']['type'] == 'GeometryCollection'\r\n    904     ]\r\n    905     if any(geom_collections):\r\n    906         warnings.warn(\r\n    907             \"{} is not configured to render for GeoJson GeometryCollection geometries. \"\r\n    908             \"Please consider reworking these features: {} to MultiPolygon for full functionality.\\n\"\r\n    909             \"https://tools.ietf.org/html/rfc7946#page-9\".format(self._name, geom_collections), UserWarning)\r\n\r\nTypeError: 'NoneType' object is not subscriptable\r\nOut[64]: <folium.folium.Map at 0x7f62a9a25160>\r\n```\r\nThis should definitely produce the same error as `gdf.explore()`. If we don't add a map to `.explore()`, it will fail with `NaN` not allowed in geometry, just like situation 1.\r\n\r\n",
      "@olsgaard \r\n> Another thing to look at is when calling `.explore()` on an empty dataframe. This can easily happen if you have a pipeline with a number of filters, and inadvertently end up filtering out all the rows.\r\n> \r\nThe scope of this PR is already quite extensive so I'm not going to add creating an additional `ValueError` if there is no geometry at this point.  Really going to keep this to argument permutations on valid parameters rather than dealing with error situations in a different way (they are errors,  no valid geometry)",
      "@martinfleis \r\n\r\n> It brings quite a bit of additional complexity to a method that should ideally be lightweight. We had a discussion on the maintenance burden before we introduced `explore` and wanted to avoid a situation when the method is growing into a full-scale visualisation tool rather than a quick way of checking how the data look like.\r\n\r\nInterestingly the *fixes* in this change don't change the complexity, but handle existing documented interface more consistently.  To simplify I actually think the permutations of allowable `cmap` parameters should be reduced to a named **matplotlib** color map or a **matplotlib** colormap instance.  i.e. cut **branca**, `callable` and list-like\r\n\r\nI do concur with your concerns.  I feel that now many more permutations of arguments are handled consistently there is an opportunity to refactor all the conditional logic to a simpler form.  That would probably mean very different looking code base for `explore()`... \r\n\r\n> I haven't reviewed new tests at all because the complexity of that is even higher and I don't currently have a capacity to properly review that and understand what is going on there.\r\n\r\nI've been quite torn by this - there is a real permutation explosion.  Raw (dumb) it was >100k permutations of arguments which would take hours to run.  Hence `generate()` landed up getting quite sophisticated to reduce the permutation explosion.  One thing I could do is to further look at reducing number of test cases (currently 88) that translate them into just code, rather than a generator and framework.   By far most of my time on this PR has been generating appropriate tests rather than fixing issues shown up by them.  It's one of the reasons I went for 100% code coverage using **coverage.py** with a single run of **pytest**  because less than that risks leaving issues in place\r\n\r\n\r\n\r\n",
      "another change that I have done is optimise **test_explore.py** have reduced amount of geometry in `self.world`.  This means **folium** will generate a map more efficiently given less *geojson*.  Reduced to ~50 rows with all continents represented",
      "> Thanks for looking into all of this. Though, I have to admit I am nos excited about these changes. It brings quite a bit of additional complexity to a method that should ideally be lightweight. We had a discussion on the maintenance burden before we introduced `explore` and wanted to avoid a situation when the method is growing into a full-scale visualisation tool rather than a quick way of checking how the data look like.\r\n> \r\n> I haven't reviewed new tests at all because the complexity of that is even higher and I don't currently have a capacity to properly review that and understand what is going on there.\r\n> \r\n> I think that I already mentioned that somewhere, but we need to make sure we know where to stop adding more enhancements to keep the code base sustainable and I am a bit on a verge with this one. Let's see what others say (@m-richards any thoughts here?).\r\n\r\nSorry for the delayed reply here, just haven't had the time.\r\n\r\n@martinfleis I'm inclined to agree with your concerns about complexity - even before any changes from this PR, `explore` stands at more that 400 lines of code with a number of nested conditionals.\r\n\r\nI think we are already probably at the point where we should think carefully about adding further functionality to `explore` without very clear input that it's worthwhile (i.e. lots of people asking for the ability to do something). But in this case however, the issues have been tagged as bugs and I think we should do something to resolve them (perhaps 2583 is more of a limitation than a bug).\r\n\r\nThe options I see are either, we fix them and cope with the complexity, or we catch and re-throw the exceptions to state that xyz case is not supported using `gdf.explore` use folium directly.\r\n\r\nI'm left with a couple of other thoughts to consider, given that one of the goals of the project is to improve the plotting situation. \r\n\r\nGiven that there are a small number of issues related to extending `explore`, and now that we already have a core feature set implemented in geopandas, I wonder if there is space to spin out another third party library to cover these additional cases and if it is successful and maintainable - readopt it (either vendoring or as a dependency) as an `explore` V2 sometime in the future (but we'd want there to be a clear mandate for doing this, over recommending any of the existing geospatial plotting libraries).\r\n\r\nSecondly, in a different direction, I wonder if the issue of coverage and logical and testing complexity raised might be better dealth with in another way, keeping in mind the fact that explore is already quite complicated. Can we simplify things by refactoring the existing implementation into component pieces before building further extensions on top? Now the coverage tests  developed by @rraymondgh could be quite helpful to check we haven't broken stuff during this process, but ideally we could get to a point, where we can test the pieces of explore (or the composition of pieces) and make sure they work, without having to resort to generating tests based on permutations of parameters. \r\n",
      "> \r\n> @martinfleis I'm inclined to agree with your concerns about complexity - even before any changes from this PR, `explore` stands at more that 400 lines of code with a number of nested conditionals.\r\n> \r\nFrom going through the process of finding cases where parameters aren't handled as documented.  The number one thing that really came out is nested and disjointed conditional logic generate a number of issues.  i.e. is ripe for refactoring...\r\n\r\nHence I really see this as a step to working as documented,  with an important follow on step.  Refactor.\r\n> \r\n> The options I see are either, we fix them and cope with the complexity, or we catch and re-throw the exceptions to state that xyz case is not supported using `gdf.explore` use folium directly.\r\n\r\nI can look into this as a refactor project.  Make interactive plotting pluggable with pluggable components in separate repo.\r\n\r\n> \r\n> Secondly, in a different direction, I wonder if the issue of coverage and logical and testing complexity raised might be better dealth with in another way, keeping in mind the fact that explore is already quite complicated. Can we simplify things by refactoring the existing implementation into component pieces before building further extensions on top? Now the coverage tests developed by @rraymondgh could be quite helpful to check we haven't broken stuff during this process, but ideally we could get to a point, where we can test the pieces of explore (or the composition of pieces) and make sure they work, without having to resort to generating tests based on permutations of parameters.\r\n\r\nI sort of have all the test cases necessary now embedded in all the permutations.  I can look to extract these as static.  I think effort would be better spent as refactor but as a second phase.  I did find by working sequentially I kept on missing conditions that didn't work.   Interestingly a number of the embedded issues found were pointing me more towards needing to apply a validation framework on the arguments before then simplifying the core conditional logic as it could *trust* the arguments.  `_binning_cmap()` was a piece of reusable logic that I did identify\r\n",
      "What is the status of this PR?\r\n\r\nIt contains fixes I'd like to see in geopandas.",
      "> What is the status of this PR?\r\n> \r\n> It contains fixes I'd like to see in geopandas.\r\n\r\nMy guess is it's a long way off - probably 6 months+.  Have been working on other things to improve CI so that any dev work I do on **geopandas** is far more around TDD and continuous integration.  i.e. foundational work for complete refactoring of function so that it is no longer highly embedded conditional logic which is subject to lots of bugs and requires an extensive permutation based test approach"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d59dac254a19ac29e00d",
    "number": 2586,
    "body": "I worked on the following issue and fixed typos (geometries’s to geometry's) in docs.\r\n\r\nhttps://github.com/geopandas/geopandas/issues/2563",
    "head_branch": "fix_docs",
    "is_a_fork": true,
    "comments": [
      "@m-richards \r\nThanks for approving my pull request! I wasn't sure how I can solve test failures so it was great to know that they are unrelated 🙇 "
    ],
    "commit_messages": [
      "DOC: change geometries’s to geometry's (#2586)\n\nCo-authored-by: shogohida <shogohida@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d59eac254a19ac29e00e",
    "number": 2580,
    "body": "xref #2579 \r\n\r\nThis should ensure we have the same behaviour or unary_union not matter the geometry backend and turn our CI green again.\r\n\r\nThere is still an open discussion on whether we want to keep `None` or transition towards GeometryCollection Empty to have a consistency with shapely.",
    "head_branch": "union",
    "is_a_fork": true,
    "comments": [
      "I think it would be good to change to an empty collection as well, eventually (and for that add a deprecation warning and change in 1.0, or just change then without prior warning?)",
      "> Can you maybe add a test case that covers this?\r\n\r\nThere is a test for this, that is the one failing on main currently.\r\n\r\nhttps://github.com/geopandas/geopandas/blob/3993bd178abed309a75d1f79a80c325fd111ed7d/geopandas/tests/test_geom_methods.py#L379-L380",
      "> and for that add a deprecation warning and change in 1.0, or just change then without prior warning?\r\n\r\nI would add a deprecation in 0.12 and change the behaviour in 1.0. Shall I add it here (or can do a follow-up)?",
      "> There is a test for this, that is the one failing on main currently.\r\n\r\nAh, yes ;) Missed that we had failures on main back then.\r\n\r\n> I would add a deprecation in 0.12 and change the behaviour in 1.0. Shall I add it here (or can do a follow-up)?\r\n\r\nYes, let's indeed deprecate this to become consistent with shapely. I am already going to merge this to get green CI, so you can do in a follow-up\r\n"
    ],
    "commit_messages": [
      "COMPAT: return None instead of empty collection in unary_union using shapely 2.0 (#2580)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d59fac254a19ac29e00f",
    "number": 2578,
    "body": "This is almost entirely based on the TODOs in https://github.com/geopandas/geopandas/pull/2373.\r\n\r\nThe only deviation I've made is in the getter for `crs`, I re-raise an AttributeError for trying to access `gdf.crs` when the active geometry column is not set. I think this is clearer for a user - rather than getting an error about `gdf.geometry` not being defined propagating from inside `gdf.crs` - and there is also the current case of where `gdf.geometry` isn't defined but `\"geometry\"` is in `gdf.columns` which gives pd.Series has no attribute crs right now - but that would change after #2575.\r\n ",
    "head_branch": "remove_crs",
    "is_a_fork": true,
    "comments": [
      "Thanks!"
    ],
    "commit_messages": [
      "DEPR: remove `_crs` attribute (#2578)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5a0ac254a19ac29e010",
    "number": 2577,
    "body": "This is a proof of concept based upon discussion in https://github.com/geopandas/geopandas/issues/2517#issuecomment-1212852039 to change the default geometry column name to None, rather than assuming it is \"geometry\".\r\n\r\nThis will be failing some tests related to the current ability to set the crs of a GeoDataFrame without an active geometry column. This is meant to be deprecated in 0.12 though. Edit: opened #2578 to draft this",
    "head_branch": "change_default_geometry_column_name",
    "is_a_fork": true,
    "comments": [
      "I like this change. Thanks for looking into that!",
      "There are still a bunch of actual failures related to this change (eg https://github.com/geopandas/geopandas/actions/runs/3302728571/jobs/5449873350)\r\n\r\nOne of them is caused by this snippet:\r\n\r\n```\r\ndf = GeoDataFrame()\r\ndf[\"geometry\"] = scalar\r\ndf.crs = 4326\r\n```\r\n\r\nwhere the last line now fails to set the CRS because there is no active geometry column. And that's no longer the case because when creating the empty `df`, the default geometry column name is not \"geometry\", and so the second line does not set this active column.\r\n\r\nDo we want to keep that snippet working? Or are we fine with this breaking?",
      "Ah sorry, I think I was aware of this but forgot when I wrote that comment.\r\n\r\n>Do we want to keep that snippet working? Or are we fine with this breaking?\r\n\r\nI personally think this isn't ideal to keep permitting, but I could also understand it's a breaking change and probably should have associated deprecation warnings. Seems tricky to deprecate though would have to intercept getitem specifically for \"geometry\" when the active geometry column is none (and perhaps that has some confusing edge cases associated with it?).",
      "> Seems tricky to deprecate though would have to intercept getitem specifically for \"geometry\" when the active geometry column is none\r\n\r\nThat's maybe actually possible? We already override `__setitem__` on GeoDataFrame, so then inside we could do something like (untested pseudocode):\r\n\r\n```\r\nif self._geometry_column_name is None and isinstance(key, str) and key == \"geometry\" and \"geometry\" not in self.columns:\r\n    warnings.warn(\r\n        \"you are adding a \"geometry\" column to a GeoDataFrame without active geometry column. \"\r\n        \"Currently, this makes this the active geometry column, but in the future that will no longer \"\r\n        \"happen automatically. Do ... instead\"\r\n    )\r\n    self._geometry_column_name = \"geometry\"\r\n...",
      "I've just had another go of reworking this, to try and deal with issuing a UserWarning in the right cases. To achieve this, the default geometry column name unfortunately is no longer None, but rather a sentinel object, so this is a bit uglier. I was a bit worried about issuing warnings in the wrong situations, rather than only on init - so locally I've been testing with `pytest -W error::FutureWarning` and making sure the new warning isn't issued in any unexpected places.\r\n\r\nThere's still an issue with multiindexes, which I'm hoping will be resolved by the other PR, and I've also just noticed that there's a handful of extra failures in some of the older CI envs. But I'll worrry about that after I get some input of this is still the right way forward.",
      "> To achieve this, the default geometry column name unfortunately is no longer None, but rather a sentinel object, so this is a bit uglier.\r\n\r\nNo problem with using a custom sentinel (that's an approach we use in pandas as well if we want to have a default optional value where None cannot be used because it's a valid option). But just wondering: where there cases where `None` was a valid value for `_geometry_column_name` where we don't want to warn? Do you have an example of that?",
      "> But just wondering: where there cases where `None` was a valid value for `_geometry_column_name` where we don't want to warn? Do you have an example of that?\r\n\r\nAh, if you drop the active geometry column (but there is still another geometry dtype column), this gets set to None. Is that a case that should be handled differently than when explicitly constructing a geodataframe without geometry column?",
      "Hopefully this should be the last of fixups if CI is still green.",
      "Let's give this a go, thanks @m-richards!"
    ],
    "commit_messages": [
      "ENH: set the default geometry column name to none (#2577)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5a1ac254a19ac29e011",
    "number": 2576,
    "body": "This is a proof of concept based upon discussion in https://github.com/geopandas/geopandas/issues/2517#issuecomment-1212852039 to change the default geometry column name to None, rather than assuming it is \"geometry\".\r\n\r\nThis will be failing some tests related to the current ability to set the crs of a GeoDataFrame without an active geometry column. This is meant to be deprecated in 0.12 though",
    "head_branch": "main",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5a1ac254a19ac29e012",
    "number": 2575,
    "body": "Closes #2574",
    "head_branch": "geometry_attr_behaviour",
    "is_a_fork": true,
    "comments": [
      "This looks good to me. ",
      "Thanks!"
    ],
    "commit_messages": [
      "BUG: Fix inconsistency with \"geometry\" in frame but not active geometry column (#2575)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5a2ac254a19ac29e013",
    "number": 2572,
    "body": "Extend capability to pass list-like parameters to be used in styling **folium** map when parameters of `style_kwds` and `marker_kwds` are list like\r\n\r\n<details>\r\n<summary>Example</summary>\r\n\r\n```\r\nimport geopandas as gpd\r\nimport pandas as pd\r\n\r\ngdf = gpd.read_file(gpd.datasets.get_path(\"naturalearth_cities\"))\r\ngdf[\"cool\"] = (gdf[\"name\"].str[0].apply(ord) - ord(\"A\")) // 8\r\ngdf[\"size\"] = gdf[\"cool\"] * 4\r\ngdf[\"fill\"] = gdf[\"cool\"] >= 2\r\ngdf.explore(\r\n    marker_kwds={\"radius\": \"size\", \"fill\": pd.Series(gdf[\"fill\"])},\r\n    style_kwds={\r\n        \"fillColor\": gdf[\"cool\"].map({0: \"red\", 1: \"blue\", 2: \"green\", 3: \"yellow\"})\r\n    },\r\n    height=300, width=600\r\n)\r\n\r\n```\r\n\r\n<img width=\"619\" alt=\"image\" src=\"https://user-images.githubusercontent.com/42769112/192518798-67891342-7da4-4088-9014-1b6d9cbaffd9.png\">\r\n\r\n</details>\r\n\r\n\r\n",
    "head_branch": "explore_list_like",
    "is_a_fork": true,
    "comments": [
      "closes #2564"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5a3ac254a19ac29e014",
    "number": 2571,
    "body": "Update `geopandas.show_versions()` to work with Shapely 2, and also to use pyogrio (if fiona is not installed) to detect the GDAL version.",
    "head_branch": "update-show-versions",
    "is_a_fork": true,
    "comments": [
      "I am going to include this, so we already have the GEOS version for shapely 2.0. We can still include the GEOS library path in a follow-up PR."
    ],
    "commit_messages": [
      "Update geopandas.show_versions() for GEOS and GDAL (#2571)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5a4ac254a19ac29e015",
    "number": 2570,
    "body": "This fixes some new warnings that you get when running with Shapely 2:\r\n\r\n- `BaseGeometry()` -> `GeometryCollection()` (the result is the same in practice, both on shapely 1.8 as 2.0)\r\n- `type` -> `geom_type` (shapely deprecated `.type` to only have `.geom_type`, so I updated that in our code base. I also updated equivalent usage for GeoSeries, but so we can also deprecate GeoSeries.type for GeoSeries.geom_type if we want)",
    "head_branch": "shapely-2-warnings",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "COMPAT: resolve new Shapely 2 deprecation warnings (#2570)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5a5ac254a19ac29e016",
    "number": 2568,
    "body": "This is a proposal of a roadmap for the GeoPandas project (not covering sub-projects) resulting from the [discussions](https://hackmd.io/pq8MqmtxTFqqaiayFuuEYQ) during the GeoPandas community calls. \r\n\r\nFeel free to open a discussion on a removal of individual goals or moving them between the milestones. If you have another suggestion on what would you like to see on a roadmap, feel free to suggest it here or open a separate issue for a discussion (not everything needs to be included in the first version but we need one for NumFocus in about 2 weeks).\r\n\r\nI would like to merge the first version in relatively soon, ideally during the first week of October or sooner.\r\n\r\ncc @geopandas/collaborators ",
    "head_branch": "roadmap",
    "is_a_fork": true,
    "comments": [
      "@brendan-ward thanks for the thorough proofreading! I've added the suggested I/O bit.",
      "I haven't included anything on plotting that needs a bit of love, do we want to list it here? Legend enhancements etc.",
      "@m-richards that topic is certainly missing here, but we have been struggling a bit with \"roadmap for `geopandas` the package\" vs \"roadmap for GeoPandas the project\", and were thinking that we should also have, somewhere, this broader roadmap mentioning those aspects you bring up. \r\n\r\n@martinfleis this is ready to be merged as a first iteration?",
      "> this is ready to be merged as a first iteration?\r\n\r\nYep!\r\n\r\n",
      "On the [r/gis](https://www.reddit.com/r/gis) subreddit, the roadmap is very well [received](https://www.reddit.com/r/gis/comments/y0eckd/geopandas_released_a_roadmap_to_version_10_and/)!"
    ],
    "commit_messages": [
      "DOC/MAINT: GeoPandas roadmap draft (#2568)\n\n* geopandas roadmap draft\r\n\r\n* Apply suggestions from code review\r\n\r\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>\r\n\r\n* Lighter-weight geospatial I/O\r\n\r\n* Update doc/source/about/roadmap.md\r\n\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>\r\n\r\n* move prepared geoms\r\n\r\n* add plotting and limit line length\r\n\r\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5a6ac254a19ac29e017",
    "number": 2560,
    "body": "The readthedocs build is also failing since a few weeks (since pydata-sphinx-theme 0.10 was out): https://readthedocs.org/projects/geopandas/builds/17963754/)\r\n\r\nTemporary pinning this to 0.9.0, but we should also look into fixing the errors -> https://github.com/geopandas/geopandas/issues/2561",
    "head_branch": "doc-pin-theme",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: pin pydata-sphinx-theme to 0.9 for now (#2560)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5a6ac254a19ac29e018",
    "number": 2559,
    "body": "I don't think there is a reason to still install it with pip (originally this was done to install the latest main version)",
    "head_branch": "ci-pyogrio",
    "is_a_fork": true,
    "comments": [
      "CI for WIndows and MacOS is failing -> https://github.com/conda-forge/gdal-feedstock/pull/629#issuecomment-1255564052",
      "Hmm, it's taking a very long time in the conda step ..",
      "I did finish eventually. Thanks!"
    ],
    "commit_messages": [
      "CI: install pyogrio from conda-forge instead of pip (#2559)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5a7ac254a19ac29e019",
    "number": 2555,
    "body": "closes #2554\r\n\r\n<details>\r\n<summary>Changed data</summary>\r\n\r\n### ne_110m_populated_places.zip row count changed ###\r\n|     | name                      | geometry_old                                    | geometry_new                                    |\r\n|----:|:--------------------------|:------------------------------------------------|:------------------------------------------------|\r\n|  36 | Lome                      | POINT (1.22081126074562 6.133882930268385)      |                                                 |\r\n|  52 | Asuncion                  | POINT (-57.643451027901335 -25.294457117057675) |                                                 |\r\n|  63 | Chisinau                  | POINT (28.85771113965143 47.005023619670624)    |                                                 |\r\n|  80 | San Jose                  | POINT (-84.08599721127536 9.936958288356607)    |                                                 |\r\n|  83 | Ndjamena                  | POINT (15.047202455462298 12.115042394810644)   |                                                 |\r\n|  89 | Guatemala                 | POINT (-90.52891143656154 14.623080521448173)   |                                                 |\r\n|  96 | Astana                    | POINT (71.427774209483 51.18112530425759)       |                                                 |\r\n| 107 | Yaounde                   | POINT (11.514704896854425 3.868646520754112)    |                                                 |\r\n| 122 | Nukualofa                 | POINT (-175.22056447761656 -21.13851235669864)  |                                                 |\r\n| 123 | Hargeysa                  | POINT (44.06531001666542 9.56002239881775)      |                                                 |\r\n| 125 | Sao Tome                  | POINT (6.733325153234773 0.3334021188329075)    |                                                 |\r\n| 128 | Male                      | POINT (73.499947467955 4.1667081898118)         |                                                 |\r\n| 150 | Kuwait                    | POINT (47.97635528762527 29.371663488629565)    |                                                 |\r\n| 157 | Brasilia                  | POINT (-47.91799814700306 -15.781394372878992)  |                                                 |\r\n| 162 | Rangoon                   | POINT (96.16473175266185 16.785299963188777)    |                                                 |\r\n| 164 | Kiev                      | POINT (30.514682110472165 50.43531318760722)    |                                                 |\r\n| 186 | Washington, D.C.          | POINT (-77.01136443943716 38.901495235087054)   |                                                 |\r\n| 202 | Lobamba                   |                                                 | POINT (31.1999971 -26.4666675)                  |\r\n| 203 | Bir Lehlou                |                                                 | POINT (-9.6525222 26.1191667)                   |\r\n| 204 | The Hague                 |                                                 | POINT (4.2699613 52.0800368)                    |\r\n| 205 | Sri Jayawardenepura Kotte |                                                 | POINT (79.949993 6.9000039)                     |\r\n| 206 | Baguio                    |                                                 | POINT (120.5699426 16.4299907)                  |\r\n| 207 | Dodoma                    |                                                 | POINT (35.7500036 -6.1833061)                   |\r\n| 208 | Laayoune                  |                                                 | POINT (-13.2000059 27.1499823)                  |\r\n| 209 | Putrajaya                 |                                                 | POINT (101.6950374044619 2.9325152122667406)    |\r\n| 210 | Kyoto                     |                                                 | POINT (135.7480521 35.0319381)                  |\r\n| 211 | Porto-Novo                |                                                 | POINT (2.6166255 6.483311)                      |\r\n| 212 | Lomé                      |                                                 | POINT (1.2208113 6.1338829)                     |\r\n| 213 | Asunción                  |                                                 | POINT (-57.62583375528301 -25.29067083610963)   |\r\n| 214 | Chișinău                  |                                                 | POINT (28.8577111 47.0050236)                   |\r\n| 215 | San José                  |                                                 | POINT (-84.07881396964633 9.930370727948475)    |\r\n| 216 | N'Djamena                 |                                                 | POINT (15.0472025 12.1150424)                   |\r\n| 217 | Guatemala City            |                                                 | POINT (-90.5289114 14.6230805)                  |\r\n| 218 | Valparaíso                |                                                 | POINT (-71.61702619154609 -33.04773936269631)   |\r\n| 219 | Nur-Sultan                |                                                 | POINT (71.4277742 51.1811253)                   |\r\n| 220 | Yaoundé                   |                                                 | POINT (11.5147049 3.8686465)                    |\r\n| 221 | Nuku'alofa                |                                                 | POINT (-175.2205645 -21.1385124)                |\r\n| 222 | Hargeisa                  |                                                 | POINT (44.06531 9.5600224)                      |\r\n| 223 | São Tomé                  |                                                 | POINT (6.729649806269851 0.3374664069826239)    |\r\n| 224 | Malé                      |                                                 | POINT (73.5089005260037 4.17203699470936)       |\r\n| 225 | Kuwait City               |                                                 | POINT (47.9763553 29.3716635)                   |\r\n| 226 | Tel Aviv                  |                                                 | POINT (34.7680659 32.0819373)                   |\r\n| 227 | Brasília                  |                                                 | POINT (-47.9179981 -15.7813944)                 |\r\n| 228 | Yangon                    |                                                 | POINT (96.1647318 16.7853)                      |\r\n| 229 | San Francisco             |                                                 | POINT (-122.39959956304557 37.784262651527904)  |\r\n| 230 | Denver                    |                                                 | POINT (-104.9859618 39.7411339)                 |\r\n| 231 | Houston                   |                                                 | POINT (-95.34843625672217 29.741272831862542)   |\r\n| 232 | Miami                     |                                                 | POINT (-80.2260519 25.7895566)                  |\r\n| 233 | Atlanta                   |                                                 | POINT (-84.36764186571386 33.73945728378348)    |\r\n| 234 | Chicago                   |                                                 | POINT (-87.63523655322338 41.847961283364114)   |\r\n| 235 | Kyiv                      |                                                 | POINT (30.5146821 50.4353132)                   |\r\n| 236 | Dubai                     |                                                 | POINT (55.28694561354246 25.21491189371225)     |\r\n| 237 | Geneva                    |                                                 | POINT (6.140028 46.2100075)                     |\r\n| 238 | Casablanca                |                                                 | POINT (-7.6183133 33.6019221)                   |\r\n| 239 | Monterrey                 |                                                 | POINT (-100.3319306 25.671941)                  |\r\n| 240 | Ürümqi                    |                                                 | POINT (87.5730598 43.8069581)                   |\r\n| 241 | Chengdu                   |                                                 | POINT (104.0680736 30.6719459)                  |\r\n| 242 | Ōsaka                     |                                                 | POINT (135.50375419006232 34.691095244477914)   |\r\n| 243 | Bengaluru                 |                                                 | POINT (77.5580639 12.971941)                    |\r\n| 244 | Vancouver                 |                                                 | POINT (-123.1235901 49.2753624)                 |\r\n| 245 | Toronto                   |                                                 | POINT (-79.38945855491194 43.66464454743429)    |\r\n| 246 | Melbourne                 |                                                 | POINT (144.9730704 -37.8180855)                 |\r\n| 247 | Auckland                  |                                                 | POINT (174.763027 -36.8480549)                  |\r\n| 248 | Los Angeles               |                                                 | POINT (-118.23198647223317 34.049219260337075)  |\r\n| 249 | Washington,  D.C.         |                                                 | POINT (-77.0113644 38.9014952)                  |\r\n| 250 | New York                  |                                                 | POINT (-73.99571754361698 40.72156174972766)    |\r\n| 251 | Istanbul                  |                                                 | POINT (28.97427681675554 41.01760173507249)     |\r\n| 252 | Lagos                     |                                                 | POINT (3.3895852 6.4452075)                     |\r\n| 253 | Shanghai                  |                                                 | POINT (121.4345588 31.2183983)                  |\r\n| 254 | Mumbai                    |                                                 | POINT (72.8758393972653 19.06840847529168)      |\r\n| 255 | Kolkata                   |                                                 | POINT (88.36912550443886 22.569578883795778)    |\r\n| 256 | Rio de Janeiro            |                                                 | POINT (-43.212117466834385 -22.907308056882364) |\r\n| 257 | São Paulo                 |                                                 | POINT (-46.6269658 -23.5567337)                 |\r\n| 258 | Sydney                    |                                                 | POINT (151.2125477744749 -33.87137339218338)    |\r\n| 259 | Hong Kong                 |                                                 | POINT (114.1830635 22.3069268)                  |\r\n\r\n### ne_110m_admin_0_countries.zip data changed ###\r\n|     | ('iso_a3', 'self')   | ('iso_a3', 'other')   |\r\n|----:|:---------------------|:----------------------|\r\n| 167 | SOL                  | -99                   |\r\n| 174 | -99                  | KOS                   |\r\n\r\n</details>",
    "head_branch": "natural_earth_5dot1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: naturalearth v5.1.1 consistent country and city datasets (#2555)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5a8ac254a19ac29e01a",
    "number": 2553,
    "body": "use warnings context manager to suppress map classify warning when column is invariant",
    "head_branch": "explore_warning_cmap",
    "is_a_fork": true,
    "comments": [
      "I guess that this should be suppressed in `mapclassify` rather than here, to make a proper fix. Would you mind trying to push a fix there? Or opening an issue at least?",
      "@martinfleis I'll take a look at cloning **mapclassify** and fixing there.  for now I'll leave this PR open",
      "This was just fixed in the upstream PR https://github.com/pysal/mapclassify/pull/131",
      "@martinfleis you beat me to it!"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5a9ac254a19ac29e01b",
    "number": 2552,
    "body": "Related:\r\n- https://github.com/Toblerity/Fiona/pull/1097\r\n- #2458\r\n",
    "head_branch": "fiona_where",
    "is_a_fork": true,
    "comments": [
      "Thanks for the suggestions. It is ready for another round of reviews.",
      "Thanks all for the review 👍"
    ],
    "commit_messages": [
      "ENH: Add where filter to read_file (#2552)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5aaac254a19ac29e01c",
    "number": 2543,
    "body": null,
    "head_branch": "team",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add Matt to the Team page (#2543)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5aaac254a19ac29e01d",
    "number": 2542,
    "body": "Closes #2535\r\n\r\n```python\r\n        >>> from shapely.geometry import Polygon\r\n        >>> s = geopandas.GeoSeries(\r\n        ...     [\r\n        ...         Polygon([(0, 0), (1, 1), (0, 1)]),\r\n        ...         None,\r\n        ...         Polygon([(0, 0), (-1, 1), (0, -1)]),\r\n        ...     ]\r\n        ... )\r\n        >>> from shapely.geometry import Point\r\n        >>> s_fill = geopandas.GeoSeries(\r\n        ...     [\r\n        ...         Point(0, 0),\r\n        ...         Point(1, 1),\r\n        ...         Point(2, 2),\r\n        ...     ]\r\n        ... )\r\n        >>> s.fillna(s_fill)\r\n        0    POLYGON ((0.00000 0.00000, 1.00000 1.00000, 0....\r\n        1                              POINT (1.00000 1.00000)\r\n        2    POLYGON ((0.00000 0.00000, -1.00000 1.00000, 0...\r\n        dtype: geometry\r\n```",
    "head_branch": "fillna/value-support-array-like",
    "is_a_fork": true,
    "comments": [
      "I found there having three places to test `fillna`. Where should I test this new feature?\r\n\r\n- geopandas/tests/test_geoseries.py::TestSeries::test_fillna\r\n- geopandas/tests/test_geoseries.py::test_missing_values\r\n- geopandas/tests/test_pandas_methods.py::test_fillna",
      "`geos.fillna(another_geos)` [testcase](https://github.com/geopandas/geopandas/runs/8284283423?check_suite_focus=true#step:5:4046) failed on [38-minimal.yaml](https://github.com/geopandas/geopandas/blob/af50debbbbeab62f3601518f814c9cb271b1859c/ci/envs/38-minimal.yaml#L9), but other py38 CIs were passed.\r\n\r\nNote that [py38 and pandas1.0.5](https://github.com/geopandas/geopandas/runs/8284283423?check_suite_focus=true#step:5:4046) failed, [py38 and pandas1.1](https://github.com/geopandas/geopandas/runs/8284283549?check_suite_focus=true) passed.\r\nI thought pandas 1.0.x can't convert GeoSeries type `value` to GeometryArray type.\r\n\r\nThere seems that need to update the minimal pandas version.\r\nOr use `elif isinstance(value, (GeometryArray, GeoSeries))` instead temporarily.",
      "This PR is almost done.\r\n`test_pandas_methods.py::test_fillna` was splitted into two, and `test_extension_array.py::TestMissing::test_fillna_series` was updated.\r\nBut it still has a little problem. ci/envs/38-minimal.yaml failed.",
      "I forgot, one final thing @Zeroto521, would you be able to add a changelog entry for this?",
      "@Zeroto521 can you check and resolve the CI failure in the 38-minimal environment?"
    ],
    "commit_messages": [
      "ENH: Let `(GeometryArray|GeoSeries).fillna` support to fill with another `GeoSeries` (#2542)\n\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Matt Richards <mrichards7@outlook.com.au>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5abac254a19ac29e01e",
    "number": 2541,
    "body": "part of #2010",
    "head_branch": "minimum_rotated_rectangle",
    "is_a_fork": true,
    "comments": [
      "Hi, for the sake of having a clean PR, is it ok to you if I create a new PR from scratch?",
      "> Hi, for the sake of having a clean PR, is it ok to you if I create a new PR from scratch?\r\n\r\n@SimoParmeg no need for that. The diff itself is clean, and when merging the PR on github, we do so by squashing all commits into one anyway. ",
      "@SimoParmeg there were a few files added (images), I suppose by accident. Can you remove those again from the branch?",
      "I have updated this PR and included review comments. \r\n\r\n@jorisvandenbossche One question here - which API name do we want to follow? `minimum_rotated_rectangle` coming from older shapely or `oriented_envelope`? I know that they are equal in shapely 2 but I would pick only one in geopandas and am not sure which one to follow here. I am personally fine with the rectangle version but would be equally fine with envelope... Just for a context, QGIS call it \"Oriented minimum bounding box\" to add a bit of additional confusion to the mix :D.\r\n\r\nWe can say that we want to follow what was in the shapely ecosystem available until now and call it `minimum_rotated_rectangle` but if there are plans in shapely to keep only one of the two eventually, it would be good to pick the that one.",
      "Ah, one more thing to consider - shapely has `minimum_rotated_rectangle` as a property. Until now, we've been following their distinction between property and method, though it can be weird sometimes (like this time). Do we want this to be a property for consistency? I have to admit that a method feel more _right_ here.",
      "> which API name do we want to follow? `minimum_rotated_rectangle` coming from older shapely or `oriented_envelope`?\r\n\r\nGood question: in shapely we have the general guideline of following PostGIS naming where appropriate/possible (well, that was the rule we started to use in pygeos), and so that is the reason that the `oriented_envelope` name was added (and `minimum_rotated_rectangle` kept in shapely for backwards compatibility). \r\n\r\nSince in geopandas it is added as new functionality, we should then maybe rather go with `oriented_envelope`? \r\n(although personally I actually find `minimum_rotated_rectangle` more descriptive ...)\r\n\r\n> shapely has `minimum_rotated_rectangle` as a property. Until now, we've been following their distinction between property and method, though it can be weird sometimes (like this time). Do we want this to be a property for consistency? I have to admit that a method feel more _right_ here.\r\n\r\nYes, I fully agree that the distinction in shapely isn't always great. Things like this which is clearly calculating a new geometry (and not a simple \"characteristic\") should be a method. But that's also very hard (impossible?) to change in shapely (except for new methods). \r\nIf we are going to add a bunch of new properies/methods from shapely to geopandas, we _could_ make a better decision here. But that of course also creates inconsistencies .. which is not great either. Maybe that ship has (unfortunately) sailed?",
      ">If we are going to add a bunch of new properies/methods from shapely to geopandas, we _could_ make a better decision here. But that of course also creates inconsistencies .. which is not great either. Maybe that ship has (unfortunately) sailed?\r\n\r\nJust thought I'd chime in quickly, with a perhaps narrow focused perspective. I had a quick scan through our docs, we say that shapely is used to perform geometry operations, but not necessarily that we implement an api equivalent to shapely. Certainly there will be people that work with shapely first, or work with both geopandas and shapely simultaneously and consistency might benefit them (but also think that autocomplete in most editors would take care of that anyway), but there will also be people using GeoPandas first and if we have the chance to change something that feels weird in the api to improve internal consistency then that seems beneficial.\r\n\r\nWhatever we decide though, it would be good to have an explicit rationale on what makes something a method and what makes something a property that is clearly documented somewhere, I guess that is trivial if we just do exactly what shapely does.\r\n\r\n",
      "I personally wouldn't replicate suboptimal design choices just for the sake of consistency. Properties should be things that are either retrieving a value stored internally or that are nearly zero-cost to compute. MBR is neither, so I would prefer to have it as a method. Especially if shapely decides to default to the _old_ Python implementation as default, it would be a costly call.\r\n\r\nNot sure about names. If shapely is not planning to sunset `minimum_rotated_rectangle` in favour of `oriented_envelope`, it is not that we are inconsistent, we're just choosing to implement only one of the options. I don't really mind which of them we'll use, some users will expect one other another. If you're coming from QGIS you are used to \"oriented minimum bounding box\", if from PostGIS \"oriented envelope\" if from R (sf) \"minimum rotated rectangle\", so whichever we use someone will not expect it. If shapely strongly prefers `oriented_envelope`, let's do that.",
      "The decision on the API made during the last dev call is to expose this as a method called `minimum_rotated_rectangle`. We can potentially add alias to `oriented_envelope` if users will ask for it in future. It should not be a property in any case.",
      "@SimoParmeg there's a test [failure](https://github.com/geopandas/geopandas/actions/runs/5562613811/jobs/10161038651?pr=2541#step:5:4474) in an env shapely dev that is built against GEOS 3.12, that fixed the underlying algorithm. Can you adapt our tests to accommodate that?"
    ],
    "commit_messages": [
      "ENH: Added minimum_rotated_rectangle from shapely (#2541)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Matt Richards <mrichards7@outlook.com.au>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5acac254a19ac29e01f",
    "number": 2539,
    "body": "Part of #2010",
    "head_branch": "make_valid",
    "is_a_fork": true,
    "comments": [
      "@SimoParmeg you have some conflicts here (now I merged the other PR). I think the easiest way to resolve those conflicts will be to fetch the latest upstream and merge that in your branch here, typically something like:\r\n\r\n```\r\ngit fetch upstream\r\ngit merge upstream/main\r\n... # fix conflicts, \"git add\" files that were updated\r\ngit commit\r\n``` "
    ],
    "commit_messages": [
      "ENH: Added make_valid method from shapely (#2539)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5adac254a19ac29e020",
    "number": 2537,
    "body": "Part of #2010",
    "head_branch": "main",
    "is_a_fork": true,
    "comments": [
      "> But since we still support shapely 1.7, that code cannot be removed entirely as it is used.\r\n\r\nIndeed, for that reason we need to keep the existing one. It should work for 1.8 as well, so it's not strictly needed to update it to use the built-in shapely one for 1.8. Although it's maybe a bit safer to do so.",
      "Thank you for the edit"
    ],
    "commit_messages": [
      "ENH: added normalize function from shapely (#2537)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5aeac254a19ac29e021",
    "number": 2533,
    "body": "Resolves #2528 by adding the missing binary predicates to the docstrings for query / query_bulk.\r\n\r\nNote: `dwithin` is intentionally omitted because it requires a distance parameter, which isn't part of the API here yet.\r\n\r\nAlso note: only a few of the predicates are actually tested using real geometries in `test_sjoin.py`, but updating that was beyond the scope of this PR.",
    "head_branch": "doc_strtree_predicates",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add all valid binary predicates to STRtree query / query_bulk (#2533)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5afac254a19ac29e022",
    "number": 2532,
    "body": "This updates the copyright year to current year.\r\n\r\nThis also corrects the 3rd clause to be the name of the copyright holder as per [BSD license](https://opensource.org/licenses/BSD-3-Clause) ",
    "head_branch": "update_license",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Update copyright year, fix 3rd clause ref to GeoPandas (#2532)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5b0ac254a19ac29e023",
    "number": 2530,
    "body": "Just noticed this while running tests in an environment where I did have matplotlib, but not scipy. We are testing here that the plot call raises an ImportError, but then still continued the rest of the test (triggering that import error again, failing the test)",
    "head_branch": "tst-plot-no-scipy",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: fix accessor plotting tests skip for no scipy (#2530)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5b0ac254a19ac29e024",
    "number": 2526,
    "body": "Closes #2525 \r\n\r\nIt is a pandas implementation with two additional try/except parts covering properties. It may actually be worth porting that back to pandas as they also don't link to source code for properties at the moment.",
    "head_branch": "doc_source",
    "is_a_fork": true,
    "comments": [
      "I will enable PR builds on RTD temporarily so we can check this.",
      "Ah, RTD builds have actually been failing for some time... wrong pins. Will push an update.",
      "There's practically no difference in the build time with pinned and unpinned env on RTD right now, so I suggest we leave it unpinned.\r\n\r\nI will also push an update for the recent pydata theme in a second.",
      "> There's practically no difference in the build time with pinned and unpinned env on RTD right now, so I suggest we leave it unpinned.\r\n\r\nYep, I suppose with mamba there is not much difference since solving the environment is quite fast now anyway. \r\n\r\n_Some_ pins (but broader ones, not on the micro version) might still be useful just to avoid breaking the docs when some new version is out. On the other hand that's also a good way to get notified of issues ;) ",
      "Now we should be dark-mode ready.\r\n\r\nI think we can leave the env unpinned. We point to stable by default and latest can be used to catch the issues. ",
      "thanks for working on this. LGTM\r\nclicking the source button in https://geopandas--2526.org.readthedocs.build/en/2526/docs/reference/api/geopandas.GeoSeries.bounds.html#geopandas.GeoSeries.bounds takes you to https://github.com/geopandas/geopandas/blob/main/geopandas/base.py#L2612-L2634\r\n\r\n<img width=\"1482\" alt=\"Screen Shot 2022-08-12 at 9 13 54 PM\" src=\"https://user-images.githubusercontent.com/17162724/184462987-069b2d54-6635-44da-83cc-5a92775c7b54.png\">\r\n\r\nThanks for your fix upstream as well\r\n"
    ],
    "commit_messages": [
      "DOC: update env, add links to source code (#2526)\n\n* DOC: add links to source code\r\n\r\n* cleanup\r\n\r\n* catch proper error\r\n\r\n* move the comment where it belongs\r\n\r\n* unpin the env to see how it resolves on RTD\r\n\r\n* typo\r\n\r\n* theme update\r\n\r\n* make illustratoins dark-mode compatible"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5b1ac254a19ac29e025",
    "number": 2524,
    "body": "I have added one line to the example of `bounds` which shows how to assign the values back to the `GeoDataFrame`.\r\n\r\nI know this goes beyond a simple example of the function and more into a cookbook but I think users would benefit from this. Adding it here makes it easy to discover for users. I imagine it'll have quite a bit of usage for people wanting to filter rows of the `GeoDataFrame` from the output of `bounds`. The method should be stable that it continues to work in the future.",
    "head_branch": "patch-3",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: assign bounds to geodataframe example (#2524)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5b2ac254a19ac29e026",
    "number": 2519,
    "body": "Closes #1852.\r\n\r\nNote this issue was already resolved (pretty sure as part of 0.11 and defining _constructor_sliced but I haven't checked explicitly), this is just a test to document correct behaviour.",
    "head_branch": "document_column_apply",
    "is_a_fork": true,
    "comments": [
      "> pretty sure as part of 0.11 and defining _constructor_sliced but I haven't checked explicitly\r\n\r\nYes, based on my old comment in the issue about it needing `_constructor_sliced` being defined, that's my assumption as well"
    ],
    "commit_messages": [
      "TST: add test to close GH1852 (#2519)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5b3ac254a19ac29e027",
    "number": 2516,
    "body": "Using the stress test harness here: https://github.com/bretttully/shapely-v2 I found several collections of geometries that led to a failure of overlay “union” and “difference” when run using shapely v2 and `set_precision(…, 1)`. Shapely 1.8.2 (with naive integer rounding) fails on almost all tests in that repo and v2 passes in all but a small handful of rare cases that are fixed by this PR.\r\n\r\nIf I am right, this change is only useful for shapely >=2 so not sure how to add tests that fail on main and pass on this PR.\r\n\r\ncc @jorisvandenbossche as I believe you wrote the original code here.",
    "head_branch": "_overlay_difference",
    "is_a_fork": true,
    "comments": [
      "Hi, thanks! We have now support for shapely 2.0 in geopandas so this can be even testable and you can use `_compat.SHAPELY_GE_20` flag to write shapely 2.0-specific code, instead of try/except clause. Can you update this branch and include some tests covering this situation?",
      "Thanks! Any chance we can get a test for it?",
      "I started working on it before Christmas but ran out of time. Ok if I get it done in a few weeks?",
      "Sure, thanks!",
      "Test case added\r\n![image](https://user-images.githubusercontent.com/5830269/210722891-b2d89cfe-478a-4901-80f4-166b539c9ac9.png)\r\n",
      "@martinfleis I could definitely use some help understanding these test failures. I suspect it is a shapely2 vs pygeos conflict; but don't quite understand well enough how to use the global variables in `_compat` whilst testing",
      "> @martinfleis I could definitely use some help understanding these test failures. I suspect it is a shapely2 vs pygeos conflict; but don't quite understand well enough how to use the global variables in `_compat` whilst testing\r\n\r\nI have disabled the test if `USE_PYGEOS == True`. Not sure if this is the correct approach, but I found that dynamically setting `_compat.set_use_pygeos(False)` in the test isn't enough to remove the decorators from things like `sindex` so they continue to use pygeos vectorized version of `multithreading_enabled` instead of shapely. And then the test fails with a `TypeError` from within pygeos because we have passed in an array of shapely Geometry."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5b4ac254a19ac29e028",
    "number": 2515,
    "body": "Closes #2514",
    "head_branch": "ci-shapely-17",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: pin to older numpy for compat with older shapely in defaults channel (#2515)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5b4ac254a19ac29e029",
    "number": 2512,
    "body": "This PR is a follow-up from #2419, and moves the project metatdata from `setup.py` to `pyproject.toml` as described by [PEP 621](https://peps.python.org/pep-0621/) and supported by [setuptools >= 61](https://setuptools.pypa.io/en/latest/userguide/pyproject_config.html). This supersedes #2424 as there are more community commitments behind maintaining project metadata in `pyproject.toml` than `setup.cfg`.\r\n\r\nDetails:\r\n\r\n- Add new metadata: keywords and classifiers.\r\n- Change author to \"Kelsey Jordahl\" (with existing email match), move \"GeoPandas contributors\" as maintainers.\r\n- Change licence from slightly ambiguous \"BSD\" to SPDX compliant \"BSD 3-Clause\".\r\n- Change how packages are found, using patterns `geopandas` and `geopandas.*`. This now finds `geopandas.io.tests`, which seems to be unintentionally excluded.\r\n- Change how package data is found, using an explicit list of datasets.\r\n- Option `install_requires` is moved to `pyproject.toml` as `dependencies`. If a workaround is indeed required for ReadTheDocs, a modern approach should be found.\r\n- Most of `setup.py` is used to support versioneer or anyone that expects to see this file. For POSIX systems, it is now an executable, and runs python3.\r\n\r\nSome of these are new or changed, so feedback or suggestions are welcome.",
    "head_branch": "move-static-metadata-to-pyproj-toml",
    "is_a_fork": true,
    "comments": [
      "Given the experimental status for this feature in setuptools (and the problems we have seen in pyproj/shapely for debian packagers), let's maybe wait a few more months with this? (I think it's OK to just leave open the PR)",
      "I've checked this with a few debian docker images, and not surprisingly, it does not build with testing (bookworm), which uses a slightly older [setuptools](https://packages.debian.org/bookworm/python3-setuptools). But it does work with debian unstable (sid), which is encouraging.\r\n\r\nAgree to hold off a merge until I can see a clean check with debian testing.",
      "> Given the experimental status for this feature in setuptools\r\n\r\nJust a heads up: setuptools [declared](https://github.com/pypa/setuptools/pull/3347) defining metadata in `pyproject.toml` to be stable in June.",
      "That's only for the general project metadata, though, the `[tool.setuptools]` table is still \"beta\".\r\n\r\n(and anyway, whatever setuptools says about it doesn't change potential downstream packaging problems if they don't yet support such recent setuptools)",
      "Good news, [setuptools in debian testing was recently upgraded](https://tracker.debian.org/news/1374817/setuptools-6530-11-migrated-to-testing/) and I've checked this with a docker image of bookworm (debian testing) with success. I can resolve the conflicts if there is appetite to merge this.",
      "@mwtoews great! Let's resolve the conflicts and merge then!",
      "Thanks @mwtoews!",
      "Hi, since [0.26](https://github.com/python-versioneer/python-versioneer/blob/master/NEWS.md#release-026-6-sep-2022), versioneer has started to support `pyproject.toml` file.\r\nI thought we could move `[versioneer]` section from `setup.cfg` into `pyproject.toml`.",
      "We could do the same with pytest but flake8 does not currently support pyproject.toml (https://github.com/PyCQA/flake8/issues/234), so we won't be able to get rid of setup.cfg anyway."
    ],
    "commit_messages": [
      "MAINT: move static metadata to pyproject.toml (#2512)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5b5ac254a19ac29e02a",
    "number": 2508,
    "body": "xref https://github.com/geopandas/geopandas/issues/2444#issuecomment-1190632831\r\n\r\nOne question is whether we still want to include https://github.com/geopandas/geopandas/pull/2505 as well",
    "head_branch": "changelog-0111",
    "is_a_fork": true,
    "comments": [
      "> One question is whether we still want to include https://github.com/geopandas/geopandas/pull/2505 as well\r\n\r\nGiven that it is strictly speaking also caused by 0.11.0 (before we were reading it as strings, so those errors didn't pop up), let's try to include it as well",
      "Going to merge this, and handle the conflict in https://github.com/geopandas/geopandas/pull/2505"
    ],
    "commit_messages": [
      "DOC: update changelog for 0.11.1 (#2508)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5b6ac254a19ac29e02b",
    "number": 2507,
    "body": "Looking into reducing the number of warnings in the pytest output. This resolves the PytestRemovedIn8Warning issued from using [pytest.warns(None)](https://docs.pytest.org/en/7.0.x/reference/reference.html#pytest.warns). \r\n- My understanding is that geopandas was using this correctly - as we capture the warnings and check that there are no corresponding records, but it has been deprecated because the behaviour is confusing. \r\n- The docs suggest\r\n```python\r\nwith warnings.catch_warnings():\r\n    warnings.simplefilter(\"error\")\r\n```\r\nshould be used to ensure no warnings are omitted, however after reading the discussion [here](https://github.com/pytest-dev/pytest/issues/9002) I've opted not to use this idiom.\r\n\r\nAs we were currently using `pytest.warns(None)` correctly, I've just replaced this with the equivalent in terms of `warnings.catch_warnings` - which is also what scipy did [here](https://github.com/scipy/scipy/pull/15192)\r\n(but I've also just seen that [scikit learn is instead doing] (https://github.com/scikit-learn/scikit-learn/issues/22572)\r\n```python\r\nwith warnings.catch_warnings():\r\n    warnings.simplefilter(\"error\", EXPECTED_WARNING)\r\n```\r\n.\r\n\r\nThe benefit of keeping it like this is the test failure can filter based upon the warning message (so if for example pandas internals started emitting warnings, the would not break existing tests) - which to be honest is both a good and bad thing but I think that's a separate issue.\r\n\r\n",
    "head_branch": "test_warnings",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: fix pytest 8 deprecation warnings (#2507)\n\n* TST: fix pytest 8 deprecation warnings\r\n\r\n* TST: catch pandas append deprecationwarnings\r\n\r\n* missing one pytest in 8\r\n\r\n* filter futurewarning\r\n\r\n* get rid of concat warning\r\n\r\n* CLN: simplify warning filtering"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5b7ac254a19ac29e02c",
    "number": 2505,
    "body": "Fixes #2502 dealing with out of bounds datetimes.\r\nNote that this includes #2479 so that should be merged before this (I originally was going to solve both things in the one PR but the tests were a little more complicated than I first thought - with GPKG and GeoJSON behaving differently.",
    "head_branch": "fix_out_of_bounds_datetime",
    "is_a_fork": true,
    "comments": [
      "@m-richards I updated this now the other PR is merged.",
      "> @m-richards I updated this now the other PR is merged.\r\n\r\nThanks, was going to try have a look tonight but you beat me to it. Hopefully this is good to go now - there's an awkward pyogrio edge case that I'm skipping in one of the tests (pyogrio is calling pandas internally and converting dates there) but otherwise should be sensible.\r\n\r\n"
    ],
    "commit_messages": [
      "BUG: Fix out of bounds datetime (#2505)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5b8ac254a19ac29e02d",
    "number": 2503,
    "body": "Fixes #2501\r\n\r\nChanges in #2292 resulted in a geometry column name being lost and only partially recovered in `__finalize__`. This should ensure that it gets always fully retained.",
    "head_branch": "explode_regr",
    "is_a_fork": true,
    "comments": [
      "The CI is failing on a reported codecov issue (https://github.com/codecov/codecov-action/issues/788), not the tests."
    ],
    "commit_messages": [
      "REGR: regression in ``GeoDataFrame.explode()`` with non-default geometry column name (#2503)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5b8ac254a19ac29e02e",
    "number": 2498,
    "body": "xref https://github.com/geopandas/geopandas/pull/2497#issuecomment-1186442292\r\n\r\nThe test I added is still failing as it will be fixed by https://github.com/geopandas/geopandas/pull/2497\r\n\r\nCloses #2333",
    "head_branch": "assert-geodataframe-fixes",
    "is_a_fork": true,
    "comments": [
      "I haven't had a properly look at this PR yet, but it seems to also fix #2333.",
      "> I think this is actually right - there's no use in keeping \"geometry\" as the active geometry column \r\n\r\nYes, agreed that the result of pivot is looking ok now. And the way we create `expected` nowadays also sets the geometry column name to None (since there is no single \"geometry\" column). So I think both result and expected are fine now, and I updated `assert_geodataframe_equal` to handle the case that both left and right can have no active geometry column",
      "Thanks @jorisvandenbossche!"
    ],
    "commit_messages": [
      "TST/BUG: fix assert_geodataframe_equal to handle no-active-geometry corner cases (#2498)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5b9ac254a19ac29e02f",
    "number": 2497,
    "body": "Closes https://github.com/geopandas/geopandas/issues/2486",
    "head_branch": "fix-recursion",
    "is_a_fork": true,
    "comments": [
      ">  I suppose the only thing to add is the changelog entry, now we are doing that on individual PRs?\r\n\r\nRight, added!\r\n\r\n> Aside, this also appears to fix https://github.com/geopandas/geopandas/issues/2057\r\n\r\nThanks, I added your test for that",
      "> but `assert_geodataframe_equal` doesn't handle the multiindexes properly and crashes. So perhaps also something for another PR.\r\n\r\nYeah, that's something I generally struggled with here, that `assert_geodataframe_equal` breaks down in several corner cases (MultiIndex, no proper geometry column, ..)",
      "Thanks @jorisvandenbossche!"
    ],
    "commit_messages": [
      "REGR: fix recursion error in GeoDataFrame constructor with MultiIndex (#2497)\n\n* REGR: fix recursion error in GeoDataFrame constructor with MultiIndex\r\n\r\n* Add test for pivot (GH-2057)\r\n\r\n* add changelog\r\n\r\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5baac254a19ac29e030",
    "number": 2496,
    "body": "Fixes #2495 \r\n\r\nThis deprecates the `version` parameter used for `to_feather` / `to_parquet` because it collides with the underlying feather / parquet writer parameter of the same name.  It is replaced with `schema_version`.\r\n\r\nTemporarily, this captures the `version` parameter only if it is 0.1.0 or 0.4.0 (since neither collide with versions of feather or parquet); otherwise it is passed directly to the underlying writer.",
    "head_branch": "fix_parquet_version_collision",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix: Deprecate version for to_feather / to_parquet (#2496)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5bbac254a19ac29e031",
    "number": 2494,
    "body": "The formatting of [Plotting with Folium](https://geopandas.org/en/latest/gallery/plotting_with_folium.html) is a bit inconsistent.\r\nThus, I reformatted the file with [jblack](https://github.com/jupyter-black/jblack).\r\n\r\nI can also reformat other Jupyter Notebooks with `jblack` if it makes sense in your opinion.",
    "head_branch": "jblack",
    "is_a_fork": true,
    "comments": [
      "> That would be superb! It would be optimal if all the code we show in our docs follows black.\r\n\r\nPerfect, I will work on that in September."
    ],
    "commit_messages": [
      "DOC: Reformat plotting_with_folium.ipynb (#2494)\n\nreformat plotting_with_folium.ipynb"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5bcac254a19ac29e032",
    "number": 2491,
    "body": "Closes #2490",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [
      "@iamtekson Can you please provide more information about the fix in your PR description?  Can you please paste in a short snippet of the GeoDataFrame that is producing the issue, so can better understand that this fix is appropriate?\r\n\r\nI'm thinking that the issue is perhaps that there are numeric column names as might result from a groupby() / reset_index() or something, but want to be sure.",
      "Hi @brendan-ward, yes you are right. The issue is due to numeric column names in the data frame from the pivot table operation. The #2490 issue is solved with this commit but still, Fiona is sending me the following error,\r\n\r\n```python\r\nTraceback (most recent call last):\r\n  File \"/opt/sdss/django/sdss/exposure/views.py\", line 361, in downloadExposureResult\r\n    df.to_file(filename=shp_path, driver='ESRI Shapefile')\r\n  File \"/home/sdss/.virtualenvs/sdss/lib/python3.8/site-packages/geopandas/geodataframe.py\", line 1114, in to_file\r\n    _to_file(self, filename, driver, schema, index, **kwargs)\r\n  File \"/home/sdss/.virtualenvs/sdss/lib/python3.8/site-packages/geopandas/io/file.py\", line 393, in _to_file\r\n    with fiona.open(\r\n  File \"/home/sdss/.virtualenvs/sdss/lib/python3.8/site-packages/fiona/env.py\", line 398, in wrapper\r\n    return f(*args, **kwargs)\r\n  File \"/home/sdss/.virtualenvs/sdss/lib/python3.8/site-packages/fiona/__init__.py\", line 262, in open\r\n    c = Collection(path, mode, crs=crs, driver=driver, schema=this_schema,\r\n  File \"/home/sdss/.virtualenvs/sdss/lib/python3.8/site-packages/fiona/collection.py\", line 157, in __init__\r\n    self.session.start(self, **kwargs)\r\n  File \"fiona/ogrext.pyx\", line 1124, in fiona.ogrext.WritingSession.start\r\nAttributeError: 'float' object has no attribute 'encode'\r\n```\r\n\r\nThat means, I think I need to type cast the column names to a string before exporting my data. Do you have any alternatives or suggestions on this issue?",
      "I am able to solve this issue by type cast before calling the `df.to_file` function as below,\r\n\r\n```python\r\ndf.columns = df.columns.astype(str)\r\n```\r\n\r\nI think this PR can be closed. ",
      "@iamtekson sorry for the delayed response; your fix of casting column names to strings seems reasonable.\r\n\r\nWe have the same issue when writing numeric column names to `pyogrio` engine as well, so I think for now we can leave this PR open as a reminder that we need to consider casting column names to strings before serializing (perhaps with a warning), or raising a more clear error message.",
      "I think that the fix in this PR is the right solution, not forcing users to cast column names to string. This is a check we have introduced in geopandas, therefore we should make sure it works for any column names we support. \r\n\r\n@iamtekson would you be willing to add a small test for this? Just create a small GeoDataFrame with integer column index and save it as a shapefile, ensuring the error is not raised.",
      "While trying to write a test for this, it turned out that ESRI Shapefile or its GDAL writer do not support integer column names anyways. So I will close this PR. Discussion on how to close the original issue will be there.\r\n\r\nThank you for the invention anyway!"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5bcac254a19ac29e033",
    "number": 2488,
    "body": "Also sorts groups of deps alphabetically to make it easier to maintain and review output in submitted bug reports.\r\n(only substantive change is adding `pyogrio`).\r\n\r\nEven though Fiona isn't yet truly optional, I included it in the optional deps since it is heading that way.",
    "head_branch": "show_versions_pyogrio",
    "is_a_fork": true,
    "comments": [
      "Test failure is unrelated to changes in this PR"
    ],
    "commit_messages": [
      "ENH: add pyogrio to show_versions (#2488)\n\nadd pyogrio to show_versions, sort deps alphabetically"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5bdac254a19ac29e034",
    "number": 2484,
    "body": "close #2483\r\n\r\nUse `RateLimiter` to wrap the `geocoder.(geocode|reverse_geocode)` method of geocoder to avoid getting empty geometry or address.\r\n\r\nWe could see the benefit of `RateLimiter` with the below test cases.\r\nThe limit time of service is 0.2.\r\n- when throttle_time >= 0.2, cost time via `RateLimiter` < `throttle_time` * data size < cost time via `sleep`\r\n- when throttle_time < 0.2\r\n    - cost time via `RateLimiter` > cost time via `sleep`\r\n    - 0 = empty geometry number of result via `RateLimiter` < empty geometry number of result via `sleep`\r\n\r\n```python\r\ngpd.tools.geocode(\r\n    [\"上海\"] * 200,\r\n    provider=\"BaiduV3\",\r\n    throttle_time=throttle_time,\r\n    api_key=\"...\",\r\n)\r\n```\r\n\r\n| data size | `throttle_time` | cost time via `RateLimiter` | empty geometry number of result via `RateLimiter` | cost time via `sleep` | empty geometry number of result via `sleep` |\r\n| :-------: | :-------------: | :-------------------------: | :-----------------------------------------------: | :-------------------: | :-----------------------------------------: |\r\n|    200    |        1        |           3m 23s            |                         0                         |        3m 35s         |                      0                      |\r\n|    200    |       0.5       |           1m 43s            |                         0                         |        1m 55s         |                      0                      |\r\n|    200    |       0.3       |            1m 3s            |                         0                         |        1m 16s         |                      0                      |\r\n|    200    |       0.2       |             42s             |                         0                         |          58s          |                      0                      |\r\n|    200    |       0.1       |           2m 25s            |                         0                         |          35s          |                     30                      |\r\n",
    "head_branch": "geocoding/rate-limiting",
    "is_a_fork": true,
    "comments": [
      "@Zeroto521 is this ready for a final review and a merge or not yet? If so, can you mark it Ready for review?"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5beac254a19ac29e035",
    "number": 2482,
    "body": "This resolves #2480, which was introduced by #2286.\r\n\r\nWithin there I added the check that `df.apply` producing geometry should return a geoseries\r\n```python\r\nresult = df.apply(lambda row: row.geometry, axis=1)\r\nassert_geoseries_equal(result, df.geometry, check_crs=False)\r\n```\r\nThis conflicts in the case of columns which are all  NaN as null is a legal value in a geometry array and cast by preserve geometry.\r\n\r\nTo resolve, this casting to a GeoSeries is more strict - it only happens for object dtypes now, rather than being attempted for any dtype.\r\n\r\nThis leaves the additional (slightly pathological) case of how a list of how an object dtype of all None's is handled. I've opted that this should stays as all Nones rather than becoming a geometry array - it seems hoping for these to be geometrydtype and finding they're not is preferable to expecting them to stay object dtype and having them promoted to geometry - especially since apply may not even interact with geometry data at all.\r\n\r\n",
    "head_branch": "fix_allnan_float_regression",
    "is_a_fork": true,
    "comments": [
      "Thanks!"
    ],
    "commit_messages": [
      "REGR: Fix df.apply NaN to None regression (#2482)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5bfac254a19ac29e036",
    "number": 2479,
    "body": "Fixes #2478",
    "head_branch": "fix_mixed_offset_datetime",
    "is_a_fork": true,
    "comments": [
      "Thanks! Can you also add a test and a note to the change log?\n\nSince this is a regression I would suggest to cut 0.11.1 at some point soon. Maybe just wait a few days in case something else will show up  ",
      "> Thanks! Can you also add a test and a note to the change log?\r\n\r\nYep, hence draft 😄. Was hoping to do it all at once but just a bit short on time at the moment.\r\n",
      "Alternatively, we could also convert to UTC (`pd.to_datetime(.., utc=True)`) in case of mixed timezones (actually this are not mixed timezones, but rather different _offsets_ that can come from a single timezone, for example when having data from a full year with/without DST). \r\n\r\nOf course, leaving it as object dtype gives the user the choice whether they prefer to keep it as object or rather convert it to datetime64. But returning it as datetime64 (and thus UTC, as that is the only option without knowing the original timezone) makes the resulting columns typically much more useful.",
      "> Alternatively, we could also convert to UTC (`pd.to_datetime(.., utc=True)`) in case of mixed timezones \n\nThis seems sensible, just wondering if it should be a separate PR though since this is a specific regression fix. Maybe it's fine since it all relates to a case I missed in the original PR adding datetime read support. \n\n",
      "Good point, we can indeed already merge this for the regression (the fact that it raises an error). On the other hand, being able to read datetime column as datetime dtype instead of string is also a new feature in 0.11. So if we want to change the behaviour here, probably also good to do this sooner rather than later.",
      "> > Alternatively, we could also convert to UTC (pd.to_datetime(.., utc=True)) in case of mixed timezones\r\n> \r\n> Coming back to this, if we do this automatically there is then no way to inspect the original timezones offsets - which is perhaps not an issue, but if you want to re-localise (say into a non-daylight saving time) you have to already know what the offset since you can't inspect it when we read it.\r\n\r\nYes, that is certainly a drawback. That's in general an issue with how GDAL supports timezones (i.e. it basically doesn't support \"time zones\", it only supports numeric offsets without information of the timezone), which basically means we can never know the original timezone. So I think the only options are to leave as string / datetime.datetime in object dtype, or to return UTC values. \r\nI still think a default of UTC makes sense, but maybe we should add a way for the user to override this default to get object dtype? \r\n\r\n> It also means that with the edge case in #2502 we would have 3 possible output \"type\" cases (utc datetime, original datetime and object dtype) rather than two.\r\n\r\nI think we can see the first two as the same: it's a datetime64 dtype, only with or without a timezone (because the data have or don't have a timezone). So it would only be the object dtype that is an exception.\r\n"
    ],
    "commit_messages": [
      "BUG: fix mixed datetime regression (#2479)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5c0ac254a19ac29e037",
    "number": 2477,
    "body": "Enhance `explore()` to be able to accept **matplotlib** color abbreviations\r\n- b: blue\r\n- g: green\r\n- r: red\r\n- c: cyan\r\n- m: magenta\r\n- y: yellow\r\n- k: black\r\n- w: white\r\n\r\n```\r\nimport geopandas as gpd\r\nimport numpy as np\r\n\r\ndf = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\r\ndf.explore(color=\"b\", style_kwds={\"color\":\"r\"}, height=300, width=300)\r\n```\r\n\r\n<img width=\"308\" alt=\"image\" src=\"https://user-images.githubusercontent.com/42769112/175830312-034c64b6-8158-4835-a1f2-afc65e57f8b1.png\">\r\n\r\n```\r\ndf.loc[df.sample(50).index, \"gdp_md_est\"] = np.nan\r\ndf.explore(column=\"gdp_md_est\", missing_kwds={\"color\":\"g\"}, height=300, width=300, legend=False)\r\n```\r\n<img width=\"318\" alt=\"image\" src=\"https://user-images.githubusercontent.com/42769112/175830366-a1280a3c-139e-4ade-bbe9-09ac97af96b3.png\">\r\n\r\n```\r\ndf.boundary.explore(color=np.random.choice([\"r\",\"g\",\"b\"], len(df)), height=300,width=300)\r\n```\r\n<img width=\"312\" alt=\"image\" src=\"https://user-images.githubusercontent.com/42769112/175830431-03c7ea25-71fd-4429-8326-b6804719b492.png\">\r\n",
    "head_branch": "matplotlib_color",
    "is_a_fork": true,
    "comments": [
      "close #2471 ",
      "There is an issue I am not sure how to approach. With this patch, we support the abbreviations in `color` but not all the other keywords that control color that can be passed to `style_kwds` (`fillColor` etc.). And I would rather avoid building something like that is it may unnecessary complicate the code here. Not sure what is best.",
      "> There is an issue I am not sure how to approach. With this patch, we support the abbreviations in `color` but not all the other keywords that control color that can be passed to `style_kwds` (`fillColor` etc.). And I would rather avoid building something like that is it may unnecessary complicate the code here. Not sure what is best.\r\n\r\nhave added an additional commit that WIP.  Have changed scope of `plt_color()` to that of `_explore()` method.  With this then test if `style_kwds` has color attributes and update them with return of `plt_color()`.  (Also needed to fix a test case with this change).  This is sort of simple,  still thinking about how to ensure that all *color* parameters would be covered.  Appreciate your thoughts on this commit addressing consistency challenge you have noted",
      "partial SSD failure so lost all supplementary work I had done on this PR so would be unable to get it to completion anymore.  also having worked on this really think it's a bad idea, folium is not matp[lotlib, trying to make it matplotlib should not be a function of geopandas"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5c1ac254a19ac29e038",
    "number": 2475,
    "body": "Related to #2458\r\n\r\nCherry-picked in #2456 to be sure it works as expected. Can remove later.",
    "head_branch": "fiona_crs",
    "is_a_fork": true,
    "comments": [
      "> Cherry-picked in https://github.com/geopandas/geopandas/pull/2456 to be sure it works as expected. Can remove later.\r\n\r\nI merged that one and updated this one from main, so that should be resolved.",
      "Thanks!"
    ],
    "commit_messages": [
      "BUG: Handle Fiona 1.9 CRS deprecation (#2475)\n\n* BUG: Handle Fiona 1.9 CRS deprecation\r\n\r\n* CI: add fiona latest to test runs\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5c1ac254a19ac29e039",
    "number": 2474,
    "body": "Minor typo fix:\r\n\r\ncontries --> countries",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: typo in aggregation_with_dissolve.rst\n\nMinor typo fix:"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5c2ac254a19ac29e03a",
    "number": 2473,
    "body": "We recently agreed that we should change the way we collect changelog notes. Instead of doing one massive work skimming through all commits ahead of a release, the idea is that each PR will include a change log note, unless it covers only CI, tests or some other internal work.\r\n\r\n(I also noticed that contributing guide in docs and the one in root are a bit out of sync, will have a look at it later).",
    "head_branch": "changleog",
    "is_a_fork": true,
    "comments": [
      "I merged this to start using it. We can amend later if needed."
    ],
    "commit_messages": [
      "DOC: add changelog for main (#2473)\n\n* DOC: add changelog for main\r\n\r\n* note in docs"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5c3ac254a19ac29e03b",
    "number": 2470,
    "body": "Addresses the issue of #2416  \r\nThis is my first contributing oss activity.  \r\nSo if you find something wrong, please point it out.\r\n\r\nThe main changes are as follows\r\n- Using pandas API instead of numpy API\r\n- Adding conditions in plotting as well as explore  \r\n\r\nThe reason for the above changes is that using pandas.api.types can be better way to catch more conditions, as stated in #2416.",
    "head_branch": "enh_better_detection",
    "is_a_fork": true,
    "comments": [
      "I would expect that there are test cases to go with this change.  i.e. there will be cases where in v0.11.0 it does not detect categorical and with this branch it does.  I can help you on how to integrate these tests if you have them",
      "Thanks for the comments!  \r\nI've submit some test cases and additionally the way to deal with string case.  \r\n\r\nIn the following case, category detection wouldn't work.  \r\n\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nimport geopandas as gpd\r\n\r\ngdf = gpd.read_file(gpd.datasets.get_path(\"nybb\"))\r\ngdf[\"bool\"] = [True, False, True, True, False]\r\ngdf[\"bool_extention\"] = pd.array([True, False, True, True, False])\r\ngdf[\"string\"] = pd.array(([True, False, True, True, False]), dtype=\"string\")\r\n\r\ngdf.plot(\"bool\") # category detection work well (#2416)\r\ngdf.explore(\"bool\") # category detection work well (#2416)\r\n\r\ngdf.explore(\"bool_extention\") # category detection wouldn't work\r\ngdf.plot(\"string\") # category detection wouldn't work\r\ngdf.explore(\"string\") # category detection wouldn't work\r\n```\r\n\r\nSo, I fixed by using pandas API insetad of numpy api in explore.py and plotting.py like the following.  \r\n```python\r\n    elif values.dtype is np.dtype(\"O\") or categories:\r\n    elif (\r\n        pd.api.types.is_object_dtype(values.dtype)\r\n        or pd.api.types.is_bool_dtype(values.dtype)\r\n        or pd.api.types.is_string_dtype(values.dtype)\r\n        or categories\r\n    ):\r\n```\r\nAlso, I've written the test cases to check them out.  \r\n\r\nAbout `pd.api.types.is_obeject_dtype`, maybe, I thougt that `pd.api.types.is_obeject_dtype` was better than `np.dtype('O')`. \r\n(I'm unconfident with this and I can't come up with the test cases.)"
    ],
    "commit_messages": [
      "ENH: better detection of categorical columns in plot and explore (#2470)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5c4ac254a19ac29e03c",
    "number": 2468,
    "body": "See https://github.com/geopandas/geopandas/issues/2465. Unfortunately the wheel hosting will be discontinued (but many thanks to Christoph Gohlke for the many years of providing this service!), so we should update our installation documentation to no longer point to this.\r\n\r\nI already mentioned that pyogrio is currently an alternative to get windows wheels, which of course depends on https://github.com/geopandas/geopandas/pull/2225",
    "head_branch": "update-install-docs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: remove mention of wheels from Christoph Gohlke (#2468)\n\nDOC: remove mention of wheels from Christopher Gohlke"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5c5ac254a19ac29e03d",
    "number": 2464,
    "body": "Here's an attempt at a solve for this, though it has it's flaws, I added the `'MapInfo File'` to `driver_ext_pairs ` in the `io/test_file.py` and have added a few questioning comments along with skipping a few of the tests with this driver. Seems like the read-in after write-out w/ no CRS automatically assigns\r\n\r\n> `ENGCRS[\"Nonearth\",EDATUM[\"\"],CS[Cartesian,2],AXIS[\"easting\",east,ORDER[1],LENGTHUNIT[\"Meter\",1]],AXIS[\"northing\",north,ORDER[2],LENGTHUNIT[\"Meter\",1]]]`\r\n\r\nThere is also a discrepancy in the geometry values in `assert_geodataframe_equal` which doesn't fall within the tolerance when `check_less_precise` is `True`.\r\n\r\nI [made a comment](https://github.com/geopandas/geopandas/pull/2265#issuecomment-1156923522) in the existing PR for this issue which references the link below as to why we may not be able to use `int64`.\r\n\r\n[Unable to create MapInfo table from file error message when opening Excel file in MapInfo Pro 64-bit](https://customer.precisely.com/s/article/Unable-to-create-MapInfo-table-from-file-error-message-when-opening-Excel-file-in-MapInfo-Pro-64-bit?language=en_US)\r\n\r\nOn question, the `types` dict has a `'Int64'` key but I think pandas always returns the lower-case version `'int64'`? Isn't that what should be used there?",
    "head_branch": "967_mapinfo_write",
    "is_a_fork": true,
    "comments": [
      "@m-richards , looks like if we have values to large we'll get an `OverflowError` from fiona. I have a failing test you can take a look at, not sure of the best way to handle this problem. I've also parametrized the `test_to_file_types` test to rattle through all of the `int` types across all file types and added a failing test that you can take a look at to see the `OverflowError` \r\n\r\nNOTE: it looks like the `str` representation of the dtype can differ from having `I` vs. `i` dependent on how the df is instantiated. I've added `.lower()` to the `convert_type` func to compensate. Looks like the dtype in the schema has been converted to `'int'` whenever it was unsigned, so I have left that to be the case in the `types` dict when converting. Not really sure how to handle things in that lookup dict when converting for the schema???\r\n\r\n`df[\"data\"] = pd.array([1, np.nan] * 5, dtype=pd.Int64Dtype())`\r\n```\r\n(Pdb) str(df.dtypes[1])\r\n'Int64'\r\n\r\n(Pdb) str(df_nybb.dtypes[0])\r\n'int64'\r\n```",
      "> NOTE: it looks like the `str` representation of the dtype can differ from having `I` vs. `i` dependent on how the df is instantiated. \r\n\r\nThis is actually to do with pandas nullable integer dtypes (this is current behaviour on main):\r\n```python\r\nIn [1]: df = gpd.read_file(gpd.datasets.get_path(\"nybb\"))\r\nIn [2]: df['BoroCode2'] = df['BoroCode'].astype('Int64')\r\nIn [3]: gpd.io.file.infer_schema(df)\r\nOut[3]:\r\n{'geometry': 'MultiPolygon',\r\n 'properties': OrderedDict([('BoroCode', 'int'),\r\n              ('BoroName', 'str'),\r\n              ('Shape_Leng', 'float'),\r\n              ('Shape_Area', 'float'),\r\n              ('BoroCode2', 'int')])}\r\n```\r\nThe existing dictionary handled the case for nullable int64s (#1220). And so if I were to include a nullable int32:\r\n```python\r\nIn [4]: df['BoroCode3'] = df['BoroCode'].astype('Int32')\r\ngpd.io.file.infer_schema(df)\r\n```\r\nwe end up with a typeerror in the `convert_type` function as this doesn't translate to a numpy type (and isn't in the `types` map). \r\n\r\nSo what you've done by converting to lowercase types now catches this.\r\n\r\nI think regardless of how those bits are solved, it would be good to extend `test_to_file_types` to actually check that the types we think are being written by the schema are actually being written (although perhaps that would be another PR). I think that would have to be done with fiona directly as I believe reading the files with geopandas will always end up with 64 bit ints due to pandas underlying (not 100% on that).\r\n\r\nOn the other bits I'll add some comments inline.\r\n\r\n\r\n\r\n",
      "In an attempt to add a test that checks which dtypes get read back in through fiona, I've found a bug that we might want to catch. It doesn't seem like the Map Info driver likes to write out GDF's which have an INT attribute label.\r\n![image](https://user-images.githubusercontent.com/7052993/176258214-4c03a151-9f3b-411d-829b-51eeaeb26047.png)\r\n\r\nHere's the parametrized test:\r\n```\r\n@pytest.mark.parametrize(\"driver,ext\", driver_ext_pairs)\r\ndef test_to_file_types(tmpdir, df_points, driver, ext):\r\n    \"\"\"Test various integer type columns (GH#93)\"\"\"\r\n    tempfilename = os.path.join(str(tmpdir), \"int.{0}\".format(ext))\r\n    int_types = [ np.int8, np.int16, np.int32, np.int64, np.intp,\r\n        np.uint8, np.uint16, np.uint32, np.uint64, ]\r\n    geometry = df_points.geometry\r\n    data = dict(\r\n        (str(i), np.arange(len(geometry), dtype=dtype))\r\n        for i, dtype in enumerate(int_types)\r\n    )\r\n    df = GeoDataFrame(data, geometry=geometry)\r\n    df.to_file(tempfilename, driver=driver)\r\n    with fiona.open(tempfilename) as fh:\r\n        sch = fh.schema\r\n```\r\n\r\n#### and the schema that is shown when reading from the tempfile:\r\n`{'geometry': 'Point', 'properties': OrderedDict([('_', 'int')])}`\r\n\r\n#### whereas, from the `.shp` extension:\r\n```\r\n{'geometry': 'Point',\r\n 'properties': OrderedDict([('0', 'int:9'),\r\n                            ('1', 'int:9'),\r\n                            ('2', 'int:9'),\r\n                            ('3', 'int:18'),\r\n                            ('4', 'int:18'),\r\n                            ('5', 'int:18'),\r\n                            ('6', 'int:18'),\r\n                            ('7', 'int:18'),\r\n                            ('8', 'int:18')])}\r\n```\r\n\r\nthe screenshot above of the attribute table is from QGIS from the `.tab` file that was written out.\r\n\r\nThere is also no width parameter when fiona reads-in any other extension GPKG, geojson, Map Info....\r\n\r\n```\r\n(Pdb) pprint(fh.schema)\r\n{'geometry': 'Point',\r\n 'properties': OrderedDict([('0', 'int'),\r\n                            ('1', 'int'),\r\n                            ('2', 'int'),\r\n                            ('3', 'int'),\r\n                            ('4', 'int'),\r\n                            ('5', 'int'),\r\n                            ('6', 'int'),\r\n                            ('7', 'int'),\r\n                            ('8', 'int')])}\r\n(Pdb) ext\r\n'.geojson'\r\n```\r\n\r\nThis is probably another issue, but we should probably throw an exception when writing out w/ the Map Info driver wen there are integer values for column labels?\r\n",
      ">There is also no width parameter when fiona reads-in any other extension GPKG, geojson, Map Info....\r\n\r\nMy understanding is that this a quirk of shapefiles rather than omissions of other formats (see https://gdal.org/drivers/vector/shapefile.html)\r\n\r\n>This is probably another issue, but we should probably throw an exception when writing out w/ the Map Info driver wen there are integer values for column labels?\r\n\r\nThis seems like something that should be solved in fiona rather than geopandas, unless I'm missing something.\r\n\r\nAlso just as an fyi, as part of geopandas 0.11 pyogrio io support was included  - which might further complicate some of this PR when you resolve the conflicts with main. I imagine the same issue is also present there as it seems to be related to the gdal mapinfo driver but it would be good to explicitly check that.\r\n"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5c6ac254a19ac29e03e",
    "number": 2462,
    "body": "Happy for this to be reviewed, or just commited to directly to fix, whatever is easier\r\n\r\nTo be easier to do another pass over, each section is in reverse chronological order. Probably makes sense to reorganise this. Some thoughts on sections:\r\n\r\n- Calling out improved handling of active geometry column as a section, since there are a quite a few related pieces (and also the deprecations) (need to rewrite the outcome of 2060 and  2329 collectively as they are related).\r\n- Group deprecations by the patch deprecation warnings were first issued in, so that's not repeated (or just drop those bits out)\r\n- Grouping the two clip_by_rect PRs\r\n- Grouping the improvements to `explore` and bug fixes\r\n\r\nThere are some todos in the body as well where I'm not sure if stuff is in the right spot. Hope this is at least somewhat useful to reshape into cleaner patch notes.",
    "head_branch": "release_notes",
    "is_a_fork": true,
    "comments": [
      "suggested change to first section - link to v0.4.0 of GeoParquet.  Tried to commit this to this PR,  but don't have access\r\n```\r\nHighlights of this release:\r\n\r\n- GeoParquet support updated to implement [v0.4.0](https://github.com/opengeospatial/geoparquet/releases/tag/v0.4.0) of the OpenGeospatial/GeoParquet spec  (#2441). # TODO emphasise \r\n  significance a bit more? \r\n- interop with GDAL / sf, first class support for columnar data. \r\n  Backwards compatibility with v0.1.0 of the metadata spec (implemented in the previous releases of GeoPandas) is guaranteed, \r\n  reading and writing parquet/ feather files will no longer produce a `UserWarning` (#2327). \r\n```\r\n\r\nMissed bug fix:\r\n```\r\n- Fix `GeoDataFrame.plot` incorrect colors with mixed geometry types and list of colors (#2420)\r\n```",
      "Thanks @rraymondgh, good catch, I've accidentally added 2420 to the 0.10 section's changelog instead of 0.11.\r\n\r\n> Tried to commit this to this PR, but don't have access\r\n\r\nSorry, that would be right, I was only expecting Joris to look at this (maintainers have push access to fork branches).\r\n\r\nI hope I've described all your patches for explore/plot accurately otherwise, sometimes a little tricky to work out how to describe issues suscintly.\r\n",
      "I suggest this markdown to group `explore()` changes in improvements section.  Last point is moved from bug fixes\r\n\r\n```\r\n- `GeoDataFrame.explore()` **folium** integrartion improvements\r\n  - Add new parameter `style_function` to enable plot styling based on GeoJSON properties \r\n  (#2377). \r\n  - `folium.Map` keyword arguments can now be specified as  `map_kwds`  (#2315)\r\n  - Fix error when `column` is of boolean dtype (#2403).\r\n```",
      "> Last point is moved from bug fixes\r\n\r\nIf possible I would keep bug fixes separately from enhancements. It makes it easier to skim for changes in the changelog.",
      "I have pushed some minor changes, fixing typos and formatting, removed your TO-DOs and fixed the formatting throughout the whole document. This should now be ready.",
      "Thanks @m-richards!"
    ],
    "commit_messages": [
      "RLS: 0.11 release notes (#2462)\n\n* DOC: draft 0.11 release notes\r\n\r\n* finish all commit\r\n\r\n* code review suggestions\r\n\r\nCo-Authored-By: rraymondgh <42769112+rraymondgh@users.noreply.github.com>\r\n\r\n* reword geodataframe downcasting changes\r\n\r\n* cln\r\n\r\n* review, formatting, cleanup\r\n\r\n* Apply suggestions from code review\r\n\r\nCo-authored-by: rraymondgh <42769112+rraymondgh@users.noreply.github.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5c6ac254a19ac29e03f",
    "number": 2460,
    "body": "This adds links to the fiona documentation with intersphinx.",
    "head_branch": "fiona_intersphinx",
    "is_a_fork": true,
    "comments": [
      "Failure is unrelated to this PR."
    ],
    "commit_messages": [
      "DOC: Add direct references to fiona docs in read_file (#2460)\n\n* DOC: Add direct references to fiona docs in read_file\r\n\r\n* do the same for pyogrio\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5c7ac254a19ac29e040",
    "number": 2459,
    "body": "Related to:\r\n- #2458\r\n- https://github.com/Toblerity/Fiona/pull/889\r\n- #1383",
    "head_branch": "include_fields",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Add include_fields example (#2459)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5c8ac254a19ac29e041",
    "number": 2456,
    "body": "https://github.com/Toblerity/Fiona/issues/1053\r\n\r\nI am checking to see if the CRS changes break anything.",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [
      "There's some installation issue causing these failures\r\n\r\n```\r\nModuleNotFoundError: No module named 'fiona'\r\n```",
      "Looking good!",
      "Logs say `fiona==1.9a1` and the CRS updates are in `1.9a2`. Must not have released them to pypi yet.",
      "Looks like no changes needed on the geopandas side.",
      "Do you think this would be a good addition for geopandas? If so, would you prefer installing from pip or git?",
      "I would prefer installing from wheels so we don't have to compile here.",
      "> I would prefer installing from wheels so we don't have to compile here.\r\n\r\nThat makes sense for the CI build. One downside is that it won't work on Windows for local development. Is that okay?",
      "Actually, I just realized that conda-forge has some patches it applies for Windows, so the experience will be the same either way."
    ],
    "commit_messages": [
      "CI: add fiona latest to test runs (#2456)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5c9ac254a19ac29e042",
    "number": 2454,
    "body": "xref https://github.com/dask/dask/issues/9152#issuecomment-1148553047",
    "head_branch": "pandas-dev-ci",
    "is_a_fork": true,
    "comments": [
      "> Once nightlies are fixed we should be able to switch back and won't need to build wheels from source?\r\n\r\nIndeed. Checking the output of github actions, setting up the env now takes around 15 min instead of 6 min, so it is certainly useful to go back to nightly wheels if they work",
      "> so it is certainly useful to go back to nightly wheels if they work\r\n\r\njust merged https://github.com/MacPython/pandas-wheels/pull/184 which is responsible for the py3.10 issue. opened https://github.com/pandas-dev/pandas/issues/47332 for the windows issue."
    ],
    "commit_messages": [
      "CI: ensure we use the latest pandas dev version in the dev build (#2454)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5caac254a19ac29e043",
    "number": 2453,
    "body": "See https://github.com/opengeospatial/geoparquet/discussions/110 for context",
    "head_branch": "parquet-proj-datum-ensemble",
    "is_a_fork": true,
    "comments": [
      "I verified locally that when creating a file with latest geopandas (+this PR) with PROJ 8, I can now read this file correctly in an env with PROJ 7",
      "Unfortunately, this now fails roundtrip tests since the serialized JSON is no longer the same.  The easiest way forward is likely to strip these from the PROJJSON in our tests as well before the comparison, e.g., geopandas/io/tests/test_arrow.py:690 would become:\r\n\r\n```Python\r\nassert metadata[\"columns\"][\"geometry\"][\"crs\"] == _remove_id_from_member_of_ensembles(gdf.crs.to_json_dict())\r\n```",
      "OK, updated the tests, and also added a specific test to ensure the id removal is actually working",
      "Thanks for the help!"
    ],
    "commit_messages": [
      "PROJ compatibility with PROJJSON datum ensemble member IDs (#2453)\n\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5caac254a19ac29e044",
    "number": 2449,
    "body": "We don't yet support writing partitioned datasets (xref https://github.com/geopandas/geopandas/issues/1382), but for parquet we actually do support reading them by using `pyarrow.parquet.read_table` (for feather this is not supported, see https://github.com/geopandas/geopandas/issues/2348). \r\nBut, I don't think we actually explicitly test this capability (`read_table` will do it automatically for us, but some of the surrounding handling of eg metadata could in theory break it). So this PR is adding a basic test.\r\n",
    "head_branch": "parquet-test-read-partitioned",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: read_parquet supports partitioned datasets (#2449)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5cbac254a19ac29e045",
    "number": 2448,
    "body": "See comment at https://github.com/geopandas/geopandas/pull/2332#discussion_r889136091\r\n\r\nI _think_ passing the `crs` is never needed here. In practice, this `_constructor_sliced` typically gets called from places within pandas, so where no `crs` keyword will get passed. And even if it is present, since we only get here if the actual underlying data is a GeometryArray, that should already have the crs in that case as well.",
    "head_branch": "clean-up-constructor-sliced",
    "is_a_fork": true,
    "comments": [
      "Restarted, now it is green"
    ],
    "commit_messages": [
      "CLN: no need to specify crs in _constructor_sliced (#2448)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5ccac254a19ac29e046",
    "number": 2447,
    "body": "Left this a little too late I suspect (was on my list a while ago but slipped off), but thought I'd put up anyway since getting this into a release will speed up when the final deprecations can actually happen.\r\n\r\nxref #2263 ",
    "head_branch": "switch_deprecationwarnings",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "MAINT: switch old deprecationwarnings to futurewarnings (#2447)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5cdac254a19ac29e047",
    "number": 2443,
    "body": "This is a small fix to get the metadata directly from the Parquet file, if possible, to workaround a bug in pyarrow (https://issues.apache.org/jira/browse/ARROW-16339, the \"geo\" metadata that GDAL stores in the Parquet file don't get mapped to metadata in the resulting pyarrow table schema's metadata).\r\n\r\nCurrently you get:\r\n\r\n```\r\nIn [2]: geopandas.read_parquet(\"naturalearth_lowres_top2_gdal350.parquet\")\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\nInput In [2], in <cell line: 1>()\r\n----> 1 geopandas.read_parquet(\"naturalearth_lowres_top2_gdal350.parquet\")\r\n\r\nFile ~/scipy/geopandas/geopandas/io/arrow.py:437, in _read_parquet(path, columns, storage_options, **kwargs)\r\n    434 kwargs[\"use_pandas_metadata\"] = True\r\n    435 table = parquet.read_table(path, columns=columns, filesystem=filesystem, **kwargs)\r\n--> 437 return _arrow_to_geopandas(table)\r\n\r\nFile ~/scipy/geopandas/geopandas/io/arrow.py:283, in _arrow_to_geopandas(table)\r\n    281 metadata = table.schema.metadata\r\n    282 if metadata is None or b\"geo\" not in metadata:\r\n--> 283     raise ValueError(\r\n    284         \"\"\"Missing geo metadata in Parquet/Feather file.\r\n    285         Use pandas.read_parquet/read_feather() instead.\"\"\"\r\n    286     )\r\n    288 try:\r\n    289     metadata = _decode_metadata(metadata.get(b\"geo\", b\"\"))\r\n\r\nValueError: Missing geo metadata in Parquet/Feather file.\r\n            Use pandas.read_parquet/read_feather() instead.\r\n\r\n```",
    "head_branch": "parquet-gdal-metadata",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix read_parquet/feather to read files written by GDAL (#2443)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5ceac254a19ac29e048",
    "number": 2441,
    "body": "Inherits from and supersedes #2413\r\n\r\nIntentionally skips GeoParquet versions 0.2, 0.3, so we jump from the original 0.1.0 to [0.4](https://github.com/opengeospatial/geoparquet/blob/v0.4.0/format-specs/geoparquet.md).\r\n\r\nThe major change here is that `crs` is now encoded as [PROJJSON](https://proj.org/specifications/projjson.html) instead of WKT2.\r\n\r\nPer the spec, we can assume that a missing `crs` key in the column metadata indicates that the data are in `OGC:CRS84`.  Not sure if we actually want to do that here; we are not required to do so.\r\n\r\nThis also adds small test files for each supported GeoParquet metadata spec to verify that we continue to be able to read them.  As `version` is a required element of the spec, we specifically check for either `version` or fallback to `schema_version` (which we always wrote under 0.1.0).  We don't currently _need_ this field to be set, as reading CRS from either WKT or PROJJSON is handled automatically, but this ensures that we are validating presence of version from here on out, since we may need that in the future.\r\n\r\n",
    "head_branch": "geoparquet_0.4.0",
    "is_a_fork": true,
    "comments": [
      "Thanks!\r\n\r\nSomething I have been wondering: would we want to keep the ability to write 0.1.0 files (for now)? For example, if you want to write a file that is compatible with GDAL 3.5.0 (don't know if the geoparquet 0.4.0 support would be included in future GDAL 3.5.x releases) or with the R sfarrow package (which didn't yet update for the new geoparquet spec). \r\nSo it probably has its use cases, but will complicate our code a bit (there could be a `version` keyword that defaults to the latest version, but could be used to ask for a specific version, for now only 0.1.0 or 0.4.0)",
      "> Per the spec, we can assume that a missing `crs` key in the column metadata indicates that the data are in `OGC:CRS84`. Not sure if we actually want to do that here; we are not required to do so.\r\n\r\nSince we won't ever write such file ourselves (we always include a `crs` or set it to null explicitly), I am fine with using OGC:CRS84 (otherwise I would more strongly argue for using EPSG:4326, since that is what people typically expect)",
      "> Since we won't ever write such file ourselves (we always include a `crs` or set it to null explicitly), I am fine with using OGC:CRS84 (otherwise I would more strongly argue for using EPSG:4326, since that is what people typically expect)\r\n\r\nActually, since it seems that GDAL is going to exclude a \"crs\" field for those cases even if the dataset started with EPSG:4326 (https://github.com/OSGeo/gdal/pull/5787), I am not fully sure about this ..\r\n\r\n(that PR also confirms that 0.4.0 support will be backported to GDAL 3.5.x)",
      "> here could be a version keyword that defaults to the latest version\r\n\r\nThis seems fine; I wondered that too.  Will also make testing version support easier as we won't have to archive files from each version.\r\n\r\n> GDAL is going to exclude a \"crs\" field for those cases even if the dataset started with EPSG:4326\r\n\r\nI think for us here this means that we can't expect to roundtrip EPSG:4326 through GDAL, but that following the spec to infer OGC:CRS84 isn't necessarily wrong.  We just have no way of knowing if it originated from EPSG:4326 vs OGC:4326, but if a provider chose to leave it out, then we should follow the spec.\r\n\r\nWe should probably add a note to the docstring to indicate that we're making that inference though.",
      "> This seems fine; I wondered that too. Will also make testing version support easier as we won't have to archive files from each version.\r\n\r\nSince you already wrote this, I would keep the current tests with archived files that you added (assuming you created them with geopandas before this PR). It's still good to ensure we can read those files, in case we change something slightly in the read+write code path for 0.1.0.",
      "@brendan-ward Thanks for finishing this up!"
    ],
    "commit_messages": [
      "ENH: Support GeoParquet 0.4.0 (#2441)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5cfac254a19ac29e049",
    "number": 2440,
    "body": "picked up by codecov warning in #2280",
    "head_branch": "cln_set_geometry",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CLN: remove pandas <1.0 check (#2440)\n\n* CLN: remove pandas <1.0 check\r\n\r\n* CLN: more old pandas"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5cfac254a19ac29e04a",
    "number": 2438,
    "body": "Since geopandas imports parts of Pandas’s actual test suite (`pandas.tests`), not only `pandas.testing`, its tests ought to depend on the `test` extra of Pandas.\r\n\r\nThis is mostly a formality, but it could possibly avoid any practical issues with new Pandas test dependencies in the future.\r\n\r\n[Currently](https://github.com/pandas-dev/pandas/blob/1be9d3868f4b9cfd083839cf39eecfd881f387ad/setup.cfg#L48), this change brings in:\r\n\r\n```ini\r\n[options.extras_require]\r\ntest =\r\n    hypothesis>=5.5.3\r\n    pytest>=6.0\r\n    pytest-xdist>=1.31\r\n```\r\n\r\nwhich adds a stricter minimum versions to the `pytest` dependency Geopandas’s tests already have, and (technically unnecessary in this case) test dependencies on `pytest-xdist` and `hypothesis`.\r\n\r\nAdditionally—and this is my personal motivation for this PR—the `python-pandas` package in Fedora Linux is splitting off `pandas.tests` from the main `python3-pandas` package and installing them with `python3-pandas+test` package. So those few dependent packages that need `pandas.tests` for their own tests (currently, `python-dask` and `python-geopandas`) will have to require `pandas[test]` at build/test time, not just `pandas`. We can do this downstream in the Fedora package if this PR is not accepted.",
    "head_branch": "pandas-test-extra",
    "is_a_fork": true,
    "comments": [
      "Personally I am fine with adding it to `requirements-dev.txt` (I don't use that file myself)\r\n\r\nI am bit curious though, do we actually need those test requirements of pandas? For example, in my development environment, I don't have `hypothesis` installed, and never ran into problems with that (didn't check if it would work without `pytest-xdist`).\r\n\r\nAlternatively, should we add a `pip install geopandas[test]` test extras in geopandas itself, instead of relying on `pandas[test]` ?",
      "> Personally I am fine with adding it to `requirements-dev.txt` (I don't use that file myself)\r\n> \r\n> I am bit curious though, do we actually need those test requirements of pandas? For example, in my development environment, I don't have `hypothesis` installed, and never ran into problems with that (didn't check if it would work without `pytest-xdist`).\r\n\r\nSummarizing and expanding on my comments in the PR text:\r\n\r\n- It’s true that these extra dependencies aren’t needed for `pandas.tests.extension.base`, which is the only part of `pandas.tests` that `geopandas.tests` uses (in `geopandas/tests/test_extension_array.py`).\r\n- The `pandas[test]` dependency might be useful if `pandas.tests.extension.base` gained new dependencies in the future, but then again you could just rely on CI and cross that bridge if you get there.\r\n- The `pandas[test]` dependency *is* needed in Fedora Linux, since we separate `pandas.tests` from the main Pandas RPM package, and instead distribute it in the same RPM package that provides the `test` extra. However, since this is a downstream decision, we can easily keep dealing with the consequences downstream, too.\r\n\r\n> Alternatively, should we add a `pip install geopandas[test]` test extras in geopandas itself, instead of relying on `pandas[test]` ?\r\n\r\nSpeaking as a distribution packager, a `test` extra is always nice because it separates testing dependencies from miscellaneous developer cruft like linters and formatters. I think it’s mostly orthogonal to this PR, though: adding a `test` extra moves the dependencies out of `requirements-dev.txt`, but doesn’t change what they need to be.",
      "I also don't mind this change but it should be noted that we have `environment-dev.yml` for dev purposes. It seems that `requirements-dev.txt` is not even up to date. Considering we recommend using `conda` and are clearly unable to keep the two in sync and up to date, wouldn't be best to actually remove `requirements-dev.txt` altogether?"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5d0ac254a19ac29e04b",
    "number": 2437,
    "body": "Closes https://github.com/geopandas/geopandas/issues/2435",
    "head_branch": "tst-shapely-closed",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: update is_closed test for shapely 1.8.2 (#2437)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5d1ac254a19ac29e04c",
    "number": 2436,
    "body": "Spun out of #2332\r\nFixes a TODO from one of my PRs, but there was no issue created for it.\r\n\r\nPerhaps a little overhead from this but should be more correct. (Potentially should only be done for axis=1? haven't given that much thought)",
    "head_branch": "fix_apply_edge_case",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5d2ac254a19ac29e04d",
    "number": 2433,
    "body": "Hi everyone, this PR addresses #2432 , currently fixing `from_dict` and `from_features`.\r\n\r\nWe should expect the same behavior from `from_file` and `from_postgis`, although they both wrap external functions which instantiate the objects explicitly. \r\n\r\nMy suggestion here is to either have both function from the `io` module return the data to be passed to the `cls()` constructor or set the `__class__` attribute manually.  Alternatively, we could pass their output to the `cls()` constructor leaving the code as is, but it would be less efficient.\r\nI could use your help in figuring out the most clean solution or in spotting any mistakes in my reasoning, thanks!",
    "head_branch": "main",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: GeoDataFrame.from* methods should use class constructor (#2433)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5d3ac254a19ac29e04e",
    "number": 2427,
    "body": "Follow-up on https://github.com/geopandas/geopandas/pull/1775 to make the fiona import really lazy (not only hiding the error message on geopandas import (and only showing it on first usage), but actually only trying to import on first usage)\r\n\r\n",
    "head_branch": "fiona-really-lazy",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DEP: make fiona import truly lazy (on first usage) (#2427)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5d3ac254a19ac29e04f",
    "number": 2424,
    "body": "This PR is a follow-up from #2419, and moves the project metatdata from `setup.py` to a [declarative configuration](https://setuptools.pypa.io/en/latest/userguide/declarative_config.html) `setup.cfg` file.\r\n\r\n- New metadata are `license_files` and `classifiers`\r\n- Option `packages` is changed from explicit to `find:`, which adds `geopandas.io.tests`. Was this intentionally excluded, or was it missed?\r\n- Option `package_data` is changed from custom-generated to an equivalent list of datasets\r\n- Option `install_requires` is moved to `setup.cfg`. It was not clear why this would be empty for ReadTheDocs, which has these dependencies met with `doc/environment.yml`. However, if there is a good reason, this dynamic option can be moved back to `setup.py`.\r\n- Most of `setup.py` is there to support versioneer or anyone that expects to see this file.",
    "head_branch": "move-static-metadata-to-setup-cfg",
    "is_a_fork": true,
    "comments": [
      "> * Option `packages` is changed from explicit to `find:`, which adds `geopandas.io.tests`. Was this intentionally excluded, or was it missed?\r\n\r\nMissed by mistake I suppose\r\n\r\n> * Option `install_requires` is moved to `setup.cfg`. It was not clear why this would be empty for ReadTheDocs, which has these dependencies met with `doc/environment.yml`. However, if there is a good reason, this dynamic option can be moved back to `setup.py`.\r\n\r\nI think the reason for this was to avoid pip upgrading some of the dependencies from the conda environment (Readthedocs installs the checkout using `pip install --upgrade .`). We would need to check on RTD if this still gives problems nowadays, but we don't have RTD builds enabled on PRs .. ",
      "> I think the reason for this was to avoid pip upgrading some of the dependencies from the conda environment\r\n\r\nAlthough this bit of code stems from a time before we used conda (https://github.com/geopandas/geopandas/pull/255), so it might not actually be needed anymore. I can check that on a branch in the main repo that gets temporarily enabled on RTD.",
      "See #2512"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5d4ac254a19ac29e050",
    "number": 2423,
    "body": "Added new example code for finding and displaying temperature data for African countries.",
    "head_branch": "main",
    "is_a_fork": true,
    "comments": [
      "- This notebook doesn't contain any markdown cells documenting what the example is doing.  \r\n- the output using `print()` rather than notebook cell output.   Take a look at any other notebook in **docs/source/gallery**\r\n- multiple warnings are generated from what it interacts with **pandas** slices `A value is trying to be set on a copy of a slice from a DataFrame.`",
      "Closing due to no response. Feel free to reopen @nat-salt if you'll come back to it later."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5d5ac254a19ac29e051",
    "number": 2420,
    "body": "Closes #1379 \r\n\r\nFixes this referenced example in issue\r\n```\r\nimport geopandas as gpd\r\nimport pandas as pd\r\nfrom shapely.geometry import Point, box\r\nimport matplotlib.pyplot as plt\r\nfrom matplotlib.colors import LinearSegmentedColormap\r\n\r\n# fmt: off\r\ngdf = gpd.GeoDataFrame({\r\n    \"geometry\": [box(0,0,1,1), box(1,1,2,2), box(2,2,3,3), Point(0, 0), Point(1,1), Point(2,2), Point(3,3)],\r\n    \"color_rgba\": [(0.0, 0.0, 0.0, 0.5), (0.0, 0.0, 0.0, 0.2), (0.0, 0.0, 0.0, 0.1), (1.0, 1.0, 1.0, 1.0), (1.0, 1.0, 1.0, 1.0), (1.0, 1.0, 1.0, 1.0), (1.0, 1.0, 1.0, 1.0)],\r\n})\r\n# fmt: on\r\n\r\ngdf.plot(markersize=1000, edgecolor=\"k\", color=gdf[\"color_rgba\"])\r\n```\r\n<img width=\"269\" alt=\"image\" src=\"https://user-images.githubusercontent.com/42769112/164934462-e17b432e-ad58-4bbd-ad14-2354e0b4803c.png\">\r\n\r\nAlso\r\n```\r\nfrom shapely.geometry import LineString, Point, Polygon\r\nimport geopandas as gpd\r\nimport numpy as np\r\n\r\ngdf = gpd.GeoDataFrame(geometry=[Polygon([(1, 1), (1, 2), (2, 2), (2, 1)]),\r\n                                LineString([(2, 0), (4, 2)]),\r\n                                Point(3, 2),\r\n                                Point(1, 0)])\r\n\r\ncolors = ['red', 'green', 'blue', 'blue']\r\n\r\ngdf.plot(color=colors)\r\n```\r\n<img width=\"388\" alt=\"image\" src=\"https://user-images.githubusercontent.com/42769112/164934503-e9ed2b16-ddb9-4196-8bed-84843e4c8d2a.png\">\r\n\r\nPlus geometry used in test cases:\r\n```\r\nimport numpy as np\r\nfrom shapely.geometry import box\r\nimport geopandas as gpd\r\n\r\ngeom = []\r\ncolor = []\r\nfor a, b in zip(np.linspace(0, 10, 4)[::2], np.linspace(0, 10, 4)[1::2]):\r\n    b = box(a,a,b,b)\r\n    geom += [b, b.buffer(.8).exterior, b.centroid]\r\n    color += [\"red\",\"green\",\"blue\"]\r\n    \r\ngdf = gpd.GeoDataFrame({\"geometry\":geom, \"color_rgba\":color})\r\n\r\ngdf.plot(color=gdf[\"color_rgba\"])\r\n```\r\n<img width=\"273\" alt=\"image\" src=\"https://user-images.githubusercontent.com/42769112/164934642-424eb99a-0436-44eb-af02-5a2c623eda61.png\">\r\n",
    "head_branch": "BUG-Incorrect-colours-#1379",
    "is_a_fork": true,
    "comments": [
      "Thanks!"
    ],
    "commit_messages": [
      "BUG: fix incorrect colors with mixed geometry types and list of colors (#2420)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5d6ac254a19ac29e052",
    "number": 2419,
    "body": "This PR does a few modern things:\r\n\r\n- Create a [pyproject.toml](https://pip.pypa.io/en/stable/reference/build-system/pyproject-toml/) file to specify how this package should be built\r\n- Build using PyPA's [build](https://github.com/pypa/build) tool; check source and wheel distributions\r\n- Add missing `long_description_content_type`, which would raise a warning with `twine check` (and fail with `--strict`)\r\n- In light of #2083, remove the distutils fallback in `setup.py`\r\n- Remove \"universal\" option for bdist_wheel, since this is now a Python 3 only project",
    "head_branch": "initial-pyproject-toml",
    "is_a_fork": true,
    "comments": [
      "Thanks, that are some long needed updates!"
    ],
    "commit_messages": [
      "MAINT: introduce pyproject.toml and build, remove distutils fallback (#2419)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5d7ac254a19ac29e053",
    "number": 2418,
    "body": "Refresh naturalearth_lowres from v5.0.1\r\n\r\n- A number of countries have **iso_a3** of *-99* implemented logic to use **ADM0_A3** as override.  \r\n- column **gdp_md_est** is sourced from **GDP_MD** (change in v5.0.0).  Column name kept constant in **geopandas** to ensure tests and documentation remain backwardly compatible\r\n\r\nCloses #1041 ",
    "head_branch": "wrong-country-code-ISO_3",
    "is_a_fork": true,
    "comments": [
      "Thanks!\r\n\r\nRegarding the coverage, I guess that `geopandas/datasets/naturalearth_creation.py` should be listed under `omit` in `.coveragerc`.",
      "Thanks for the PR!\r\n\r\nI confirmed locally with the latest version of this branch that it indeed includes the expected changes (using `compare` as you did in the issue):\r\n\r\n```\r\nIn [6]: df_new[[\"continent\", \"name\", \"iso_a3\"]].compare(df_old[[\"continent\", \"name\", \"iso_a3\"]])\r\nOut[6]: \r\n                name            iso_a3      \r\n                self      other   self other\r\n21               NaN        NaN    NOR   -99\r\n43               NaN        NaN    FRA   -99\r\n160              NaN        NaN    CYN   -99\r\n171  North Macedonia  Macedonia    NaN   NaN\r\n174              NaN        NaN    KOS   -99\r\n```\r\n\r\nThere is a failing test now because we recently added a test that relies on the exact values that were saved to a file. Will update that test.",
      "Hmm, I created the new 0.4.0 files with a more recent version of PROJ, which runs into problems reading this ensemble datum with older versions (we already skipped checking the crs for equality, but now it already errors on reading the file). I opened https://github.com/opengeospatial/geoparquet/discussions/110 about how to deal with this situation in general on the GeoParquet side. Short term here, I should probably recreate the files with an older PROJ.",
      "Thanks @rraymondgh !"
    ],
    "commit_messages": [
      "Update naturalearth_lowres dataset to v5.0.1 (#2418)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5d8ac254a19ac29e054",
    "number": 2415,
    "body": "RP to add in changes proposed in #2414 ,",
    "head_branch": "postgis_authority",
    "is_a_fork": true,
    "comments": [
      "Actually, we should probably add a test for this case. Can you have a look at the current tests and add one with ESRI projection to make sure it works as expected?",
      "`to_epsg` is the method that should be used for `to_postgis` at this time as it is the only `auth_name` that corresponds to one in the PROJ database:\r\n```\r\nselect distinct(auth_name) from spatial_ref_sys;\r\n       auth_name        \r\n------------------------\r\n spatialreferencing.org\r\n EPSG\r\n(2 rows)\r\n```\r\n```python\r\n>>> import pyproj.database\r\n>>> pyproj.database.get_authorities()\r\n['EPSG', 'ESRI', 'IAU_2015', 'IGNF', 'NKG', 'OGC', 'PROJ']\r\n```\r\nIt is also important to be aware that `to_authority` has the potential to return non-integer codes from authorities you probably don't want.\r\n\r\n",
      "@snowman2 , I get different results for that same query:\r\n```sql\r\nselect distinct(auth_name) from spatial_ref_sys;\r\n```\r\n\r\n```\r\nauth_name             |\r\n----------------------+\r\nspatialreferencing.org|\r\nEPSG                  |\r\nESRI                  |\r\n```\r\n\r\n```sql\r\nSELECT PostGIS_Version();\r\n```\r\n```\r\npostgis_version                      |\r\n-------------------------------------+\r\n3.0 USE_GEOS=1 USE_PROJ=1 USE_STATS=1|\r\n```",
      "That's interesting:\r\n```\r\nSELECT PostGIS_Version();\r\n            postgis_version            \r\n---------------------------------------\r\n 3.1 USE_GEOS=1 USE_PROJ=1 USE_STATS=1\r\n```",
      "Looks like it didn't update the `spatial_ref_sys` table when I upgraded a while back ([ref](https://trac.osgeo.org/postgis/ticket/5024)). I see `ESRI` now.",
      "Since ESRI has been added, I recommend this approach:\r\n```python\r\n           srid = gdf.crs.to_epsg(min_confidence=25)\r\n           if srid is None:\r\n               auth_srid = gdf.crs.to_authority(auth_name=\"ESRI\", min_confidence=25)\r\n               if auth_srid is not None:\r\n                  srid = int(auth_srid[1])\r\n```",
      "thanks @snowman2 , I will add in those changes. Also, @martinfleis , I'll add in a test for this as well.",
      "Actually, @snowman2 , that method doesn't quite work:\r\n```python\r\ncrs = CRS.from_string(\"ESRI:102003\")\r\nassert crs.to_epsg(min_confidence=25) == 3338\r\n```\r\nSo the first srid check, `to_epsg`, returns an `int` and doesn't hit the `to_authority` check",
      "What about this:\r\n```python\r\ndef get_srid(min_confidence):\r\n    srid = gdf.crs.to_epsg(min_confidence=min_confidence)\r\n    if srid is None:\r\n        auth_srid = gdf.crs.to_authority(auth_name=\"ESRI\", min_confidence=min_confidence)\r\n        if auth_srid is not None:\r\n            srid = int(auth_srid[1])\r\n    return srid\r\n\r\nfor confidence in (100, 70, 25):\r\n    srid = get_srid(min_confidence=confidence)\r\n    if srid is not None:\r\n        break\r\n```\r\nNote: with `pyproj 3.2+` [list_authority](https://pyproj4.github.io/pyproj/dev/api/crs/crs.html#pyproj.crs.CRS.list_authority) is available and could potentially simplify the logic to find the first match where the auth name is in `EPSG`|`ESRI`.",
      "Thanks for the feedback @snowman2  and @martinfleis ! I like the `list_authority` method better, but given the pyproj version requirements I went with @snowman2 's second suggestion and also included a test to cover the esri authority case in the latest commit."
    ],
    "commit_messages": [
      "BUG: support ESRI CRS in to_postgis #2414 (#2415)\n\n* replacing to_epsg call with to_authority call to resolve issue #2414\r\n\r\n* adding better check for None for to_authority call\r\n\r\n* Updating srid checks for ESRI authority with to_postgis calls, including tests\r\n\r\n* simplifying logic for srid check\r\n\r\n* cleaning up for-else statement\r\n\r\n* modifying srid check logic"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5d8ac254a19ac29e055",
    "number": 2413,
    "body": "Addresses part of https://github.com/geopandas/geopandas/issues/2376\r\n\r\nThis PR already does:\r\n\r\n- update the version from 0.1.0 to 0.2.0\r\n- renames \"schema_version\" to \"version\" to follow upstream geoparquet spec\r\n- makes the \"crs\" key optional, not using `null` if the crs is not defined\r\n- adds the \"geometry_type\" field\r\n\r\nWhat this PR does not yet do:\r\n\r\n- we should add some dummy v0.1.0 files to ensure we keep forward compatibility (to ensure we can still read files created by older geopandas correctly)\r\n- we should add explicit support for 3D geometries (and also update \"geometry_type\" for this)\r\n- this does not yet map an unspecified \"crs\" field to OGC:CRS84 (but keeping it as None)\r\n- this does not yet check/correct the winding order (this is still under discussion for 0.3.0, see https://github.com/opengeospatial/geoparquet/issues/46), so strictly speaking we are still generating incorrect files\r\n\r\nI also didn't include an \"epoch\" field because we basically don't support spherical coordinates at the moment (we could add a way to let users override this, if they know their data has spherical edges).",
    "head_branch": "geoparquet-v0.2",
    "is_a_fork": true,
    "comments": [
      "Thanks for those really insightful comments @brendan-ward. Sounds like it would be great to reopen some discussions on the main geoparquet spec repo.",
      "> Instead, maybe the focus here should shift to making sure that we write 0.1.0 compatible files, correcting the `schema_version` => `version` issue?\r\n\r\nIndeed, that is also an option. That would basically be exactly this PR but with keeping the version as 0.1.0 (the new \"geometry_type\" field is still something we can already keep, as the spec doesn't prohibit additional fields (we already have additional fields))\r\n\r\nPersonally I wouldn't worry too much about calling this 0.2.0 without the winding order guarantee. People implementing this in other projects know the spec is still in flux (and specifically this aspect, given the open issue), and we will probably quickly have another version that might change this. I don't think there will be projects that will strictly adhere to the differences between v0.1 / 0.2 / 0.3 / .. on the short term (we also don't do that ourselves)",
      "> > this does not yet map an unspecified \"crs\" field to OGC:CRS84 (but keeping it as None\r\n> \r\n> Seems reasonable, as that is optional - but perhaps an important thing to note in the docstring since that differs in behavior than the spec?\r\n\r\nThis is also something I would still like to discuss upstream, to allow setting the CRS to null (to circumvent the default of OGC:CRS84, which is not a default we can assume in geopandas if no crs is set on a GeoDataFrame)\r\n\r\n",
      "> I wouldn't worry too much about calling this 0.2.0 without the winding order guarantee\r\n\r\nI wouldn't do this.  I think implementers would look at the spec - which states rigid requirement - and then (for cases where it would be helpful, maybe not many) attempt to avoid checking / re-orienting polygons produced by GeoPandas, then run into issues, and blame us.  I think it is better to simply not state that we wrote it in 0.2.0 version of the spec when we did not.  We can easily just skip this version unless there is a really strong outside use case for writing 0.2.0 compliant files, in which case we need to deal with winding order as part of that.  Or an 0.2.1 version sooner that un-requires it.  😄 \r\n\r\nWith 0.1.0, it was very clear it was the very first version, and we included a now-very-annoying warning about such.  For subsequent versions, we should be more careful about partial support; it is intended as a compatibility promise.\r\n",
      "Fully agree with @brendan-ward here. We should either fully support the spec and state that or don't claim it if the support is only partial. And also agree that the order requirement is something that would be good to change. There's only a performance hit in my use cases with no benefit of that. ",
      "The \"orientation\" issue will be fixed in the upcoming 0.3.0 release of the GeoParquet spec (making that optional again, so we can write data without CCW guarantee). \r\n\r\nThere is one other issue mentioned above where we don't fully follow the spec, which is related to unspecified CRSs: \r\n\r\n* What if the GeoDataFrame has no `crs`?\r\n  * Currently we set the \"crs\" field to null in the GeoParquet metadata, but that is not explicitly allowed by the upstream spec\r\n  * We also cannot _not_ set the \"crs\" field, as that would now mean that other readers would interpret it as lon/lat (OGC:CRS84). But if there is no CRS information on the GeoDataFrame, we have no basis to assume that is correct.\r\n* What if the file has no \"crs\" field in the metadata? \r\n  * According to the spec this means \"OGC:CRS84\". I didn't do that yet, but that's easy to fix. And I suppose this is fine to actually follow, since we didn't write files without this field (following the above, we did set it to null in the case of no CRS information).\r\n",
      "Hmm seems the options are either:\r\n\r\n- Raise an error when a CRS is not set.\r\n- Document that an undefined CRS is treated as `OGC:CRS84`.\r\n- Update the spec to allow `null` in the CRS field.\r\n",
      "Implicitly casting None to CRS84 seems awkward to me (but I haven't yet looked over at the discussion on the spec to see why that was chosen). Within the GeoPandas context however, I think we should be warning about writing files without a CRS if we do this conversion - if I consume some data without a crs, do some analysis, write to parquet, read it again and then try to use that in conjunction with the original data they would now have inconsistent crs. \n\nWe also don't do this with any other formats, although there is the unresolved geojson crs issue that has been open for a long time. ",
      "This is superseded by https://github.com/geopandas/geopandas/pull/2441, so closing here."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5d9ac254a19ac29e056",
    "number": 2412,
    "body": "Added pypi badge in README and put geopandas header below badges",
    "head_branch": "patch-2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add pypi badge (#2412)\n\n* DOC: add pypi badge\r\n\r\n* DOC: move geopandas header below badges"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5daac254a19ac29e057",
    "number": 2404,
    "body": "Updating black to resolve the linting failures on CI caused by a conflict between old `black` and new `click`. The code changes are just a result of `black geopandas` with the recent release of `black`.",
    "head_branch": "black_update",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: update black (#2404)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5dbac254a19ac29e058",
    "number": 2403,
    "body": "Fixing a bug I just encountered in explore. Plotting a boolean column without specifying `categorical=True` rasied an error as our check for categoricals did not catch it.",
    "head_branch": "bool_explore",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: boolean column as categorical in explore (#2403)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5dcac254a19ac29e059",
    "number": 2398,
    "body": "Closes #2391 \r\n\r\nI tried to keep the same logic of the CI matrix, just on higher Python versions. Since I had to bump yaml names at the same time, the diff is a bit broken. The only thing I did was to change the Python versions.",
    "head_branch": "byebyepy37",
    "is_a_fork": true,
    "comments": [
      "And that also solves our own broken CI for python 3.7 :)"
    ],
    "commit_messages": [
      "DEP: bump minimal Python version to 3.8+ (#2398)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5dcac254a19ac29e05a",
    "number": 2397,
    "body": "Closes #2388\r\n\r\nFor more context on those tests (and the disabling of network), see https://github.com/geopandas/geopandas/issues/1360",
    "head_branch": "ci-proj-9",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: disabling of network usage with PROJ 9 (#2397)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5ddac254a19ac29e05b",
    "number": 2396,
    "body": "I have implemented the fix for the issue in https://github.com/geopandas/geopandas/issues/2394#issuecomment-1083426801\r\n\r\nUnfortunately I had to change the test as well, because the `from_features()` method, used in the test calls `iter_features()` itself, so that the expected order of columns had to be changed. \r\nHowever, after the fix, the order of columns is predictable and corresponds to `geometry`  and the ordered `keys` of the dict to greate the GeoDataFrame.\r\n\r\nIf there are issues with this PR let me know and I'll try to improve\r\n\r\nCloses https://github.com/geopandas/geopandas/issues/2394",
    "head_branch": "bug/iterfeatures_column_order",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: preserve column order inside iterfeatures (#2396)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5deac254a19ac29e05c",
    "number": 2393,
    "body": null,
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Fix `to_postgis()` docs (default index value) (#2393)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5dfac254a19ac29e05d",
    "number": 2384,
    "body": "Follow-up on https://github.com/geopandas/geopandas/pull/2329, updating the test (comments) to reflect the decision we made in https://github.com/geopandas/geopandas/issues/2133 ",
    "head_branch": "small_tests_cleanup",
    "is_a_fork": true,
    "comments": [
      "The compat comment should have been deleted in previous PR - This was from before Martin bumped the minimum pandas version and it wasn't deleted when the if (version) check was removed.",
      "Fairly sure these test failures are unrelated - I've only changed stuff in another test file, not really sure what is going on, it's like the crs projections / how check_less precise works is now different?",
      "> Fairly sure these test failures are unrelated - I've only changed stuff in another test file, not really sure what is going on, it's like the crs projections / how check_less precise works is now different?\r\n\r\nYes, there were some test issues related to a new PROJ release",
      "The remaining mac failure is a known issue with the conda env"
    ],
    "commit_messages": [
      "TST: update comments in tests after #2329 (#2384)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5e0ac254a19ac29e05e",
    "number": 2379,
    "body": "Preliminary draft that shows a possible way to proceed ( so far the only I found to work)",
    "head_branch": "iterate-by-chunks",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5e0ac254a19ac29e05f",
    "number": 2377,
    "body": "Closes #2350",
    "head_branch": "geopandas/issues/2350",
    "is_a_fork": true,
    "comments": [
      "replaces another pull request where commit history was messed up.  \r\n\r\nExample:\r\n```\r\nimport geopandas as gpd\r\nimport numpy as np\r\n\r\nworld = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\r\nworld[\"geometry\"] = world[\"geometry\"].centroid\r\nworld[\"bubble_size\"] = world[\"gdp_md_est\"].rank() / len(world) * 9\r\nworld[\"border_color\"] = np.random.choice([\"red\", \"green\", \"blue\"], len(world))\r\n\r\nworld.loc[\r\n    world[\"continent\"].eq(\"Europe\") & ~world[\"iso_a3\"].isin([\"RUS\", \"-99\"])\r\n].explore(\r\n    column=\"gdp_md_est\",\r\n    height=300,\r\n    width=600,\r\n    style_kwds={\r\n        \"style_function\": lambda x: {\r\n            \"radius\": x[\"properties\"][\"bubble_size\"],\r\n            \"color\": x[\"properties\"][\"border_color\"],\r\n        }\r\n    },\r\n)\r\n```\r\n\r\n<img width=\"616\" alt=\"image\" src=\"https://user-images.githubusercontent.com/42769112/158030604-a63f4781-18c9-487f-8d63-622fe07ce87c.png\">\r\n\r\n\r\nMartin Fleischmann <notifications@github.com>\r\n> Thanks!\r\n> \r\n> Can you clean up this PR to have diff showing only your commits? It now includes some that are already merged.\r\n> I am thinking about the best API here. Because when you pass a style function, you should probably override everything else, instead of trying to merge explicit args with the function and waiting for issues to happen. So I would maybe go for the API like this:\r\n> ```\r\n> world.explore(\r\n>     style_kwds=lambda x: {\r\n>             \"fillColor\": \"red\" if x[\"properties\"][\"gdp_md_est\"] < 10 ** 6 else \"green\",\r\n>             \"color\": \"black\" if x[\"properties\"][\"gdp_md_est\"] < 10 ** 6 else \"white\",\r\n>         }\r\n> )\r\n> ```\r\n> Instead of passing the function as one of the items in a style_kwds dictionary, you would pass it directly. And you would take it and send it to folium as it is, overriding every other kwarg. This needs to be properly documented but it should be much more error-resistant than current solution mixing it all together. One direct issue is that while we use internally lambda x, user may use something like lambda row and then it all breaks.\r\n> \r\n\r\nI actually think flexibility of `explore()` style functions extended with a style function is more useful.   The work to create colors in `explore()` is useful and best not removed by replacing instead of extending.  Additionally `lambda x:` or `;lambda row:` will not cause issues as this is just standard **python** scoping",
      "I closed this and associated PR as I don't know how interact with team that can review.  best not to clutter geopandas with my random ramblings",
      "Hi @rraymondgh, sorry for the silence. I have reopened it as we want to implement this. \r\n\r\nWe currently do not have a lot of capacity to review PRs an interact in discussions. That does not mean we are not interested, it simply means that there's no time on our side we could dedicate to geopandas and everything is really slow. This PR is on my radar and will be reviewed as soon as I'll find a day do go through my (large) geopandas backlog. Sorry about the suboptimal experience here.",
      "\r\n> but I don't think it needs changing, might just be that I don't see the dictionary merging with unpacking syntax all that often.\r\n\r\nAgreed, have refactored a little to improve readability\r\n"
    ],
    "commit_messages": [
      "ENH: explore() flexible style function (#2350) (#2377)\n\n* geopandas/issues/2350\r\n\r\n* resolve items raised in review #1\r\n\r\n* new version of black...\r\n\r\n* improve code readability\r\n\r\n* Apply suggestions from code review\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5e1ac254a19ac29e060",
    "number": 2373,
    "body": "As discussed, this attempts to remove `_crs` from the `GeoDataFrame` class and fetch CRS directly from an active geometry column.\r\n\r\nThere are three tests failing now. Two of them, testing `GeoSeries.to_frame` should be fixed by #2296. The changes I made just uncovered bugs we have there right now.\r\n\r\nThe last one checks the situation when you assign a crs to a GeoDataFrame with a column `'geometry'` that is not of a geometry dtype.\r\n\r\n```py\r\ndf = GeoDataFrame({\"geometry\": [0, 1]})\r\ndf.crs = 27700\r\n```\r\n\r\nOn main, this does not fail and doesn't even warn, even though `df = GeoDataFrame({\"geometry\": [0, 1]}, crs=27700)` now raises a `ValueError`. I have changed the behaviour, so the snippet above also raises a `ValueError`, but strictly speaking, that is a hard-breaking change (although consistent with everything else).\r\n\r\nI am keeping it as a draft for now as it requires #2296 to be merged first.\r\n\r\nedit: I also see that legacy pickles need to be covered (didn't test those locally).",
    "head_branch": "remove_crs",
    "is_a_fork": true,
    "comments": [
      "Would we first want to deprecate accessing the `crs` if there is no active geometry column? \r\n\r\nIn the `crs` property, we could do something like:\r\n\r\n```python\r\n    @property\r\n    def crs(self):\r\n        try:\r\n            return self.geometry.crs\r\n        except AttributeError:\r\n            # the active geometry column might not be set\r\n            warnings.warn(...)\r\n            return self._crs\r\n```\r\n\r\nYou currently can run into this if for some reason you loose your active geometry column, and then afterwards still check for the CRS. See my comment at https://github.com/geopandas/geopandas/issues/2133#issuecomment-1024364944 for an example",
      "> Would we first want to deprecate accessing the crs if there is no active geometry column?\r\n\r\nThat is sensible. I'll make a PR for that and mark this for 0.12 milestone instead.",
      "Change of plans. Adding only a `FutureWarning` to main would require more changes than that because it gets raised super often since we call it internally on many occasions. Since I have changed that behaviour in this PR, I have now reintroduced `_crs` in here and added deprecations when it is accesses. Plus I have left TODO comments in the code so it should be straightforward to fully remove it in the next release.",
      "Before I'll deal with the pickle issues - how far do we want to be backwards compatible there? It currently fails for pickles create by geopandas 0.6.3 and 0.7.0. I believe that 0.8+ works as at that point we have CRS on an array level. I am not very keen to keep the compatibility layer for such old pickles.",
      "@martinfleis I pushed a small commit that fixes the pickle compat for 0.6 and 0.7 (and slightly simplifying the logic, because `_crs` no longer needs to be restored as metadata). It still fails locally for 0.5.1, but the resulting geodataframe is actually also invalid (using object dtype instead of geometry dtype), so that's seems certainly to drop.",
      "@jorisvandenbossche Thanks! I removed 0.5.1 pickle. This should be ready now.",
      "@jorisvandenbossche I have updated this and resolved your comments. I'd appreciate if you can take another look because it is super long since I wrote it and I forgot most of what I did and why."
    ],
    "commit_messages": [
      "REF: deprecate GeoDataFrame._crs (#2373)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5e2ac254a19ac29e061",
    "number": 2370,
    "body": "Discovered two instances that could use augmented assignment to append values.",
    "head_branch": "aug-assign",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REF: use augmented assignments where feasible (#2370)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5e3ac254a19ac29e062",
    "number": 2369,
    "body": "Warehouse now uses the project_urls provided to display links in the sidebar on [this screen](https://pypi.org/project/requests/), as well as including them in API responses to help automation tool find the source code for Requests.\r\n\r\nDocs: [packaging.python.org/en/latest/guides/distributing-packages-using-setuptools/#project-urls](https://packaging.python.org/en/latest/guides/distributing-packages-using-setuptools/#project-urls)",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [
      "Thanks!"
    ],
    "commit_messages": [
      "add GitHub URL for PyPi (#2369)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5e4ac254a19ac29e063",
    "number": 2368,
    "body": "fix: https://github.com/geopandas/geopandas/issues/2346",
    "head_branch": "issue_2346",
    "is_a_fork": true,
    "comments": [
      "@m-richards @martinfleis Hi, Finally, I added a test to check every feature included, the test cover the behavior of the columns names, and the assignment of them, both in one test because they are checked with exactly the same sql queries and results.\r\n\r\nI try check why the PR is failing, and..., a lot of tests fails that are not related to any of the changes here, and even if I add test to try to cover the new funcs, is like codecov don't get it, or I don't know how to do it better, I would appreciate if someone can check the pr plis.",
      "Our CI is currently failing everywhere, it is not related to this PR. \r\n\r\nI'll try to review the code as soon as possible but I am not optimistic that it will happen soon. Sorry for a delay.",
      "@martinfleis Hi, remember this pr plis D:"
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5e5ac254a19ac29e064",
    "number": 2366,
    "body": "Adds fast rectangle clipping to `tools.clip` by allowing `mask` to be a 4 element tuple (minx, miny, maxx, maxy). \r\n\r\nThis leverages the `.clip_by_rect()` method, added to `GeoPandasBase` in https://github.com/geopandas/geopandas/pull/1928. Currently this PR bases off of #1928, so it might be nice to merge it first to get a nicer diff.",
    "head_branch": "add-rectangle-clipping-to-clip",
    "is_a_fork": true,
    "comments": [
      "Hi @martinfleis!\r\n\r\nThanks for merging #1928, I've rebased this PR on main and it should be ready for reviewing. \r\n\r\nA note on testing: As most tests use a `mask` as as an input, I've rearranged them and put them into `TestClipWithSingleRectangleGdf`. This way, I could parameterize the `mask` parameter to run all tests with a regular `GeoDataframe` (Polygon) mask as well as with a `Tuple` (rectangle) mask. \r\n\r\nI've moved all tests which were not parameterizable: \r\n- `test_clip_line_keep_slivers`\r\n- `test_clip_multipoly_keep_slivers`\r\n- `test_clip_with_polygon`\r\n- `test_clip_with_multipolygon`\r\n- `test_clip_single_multipoly_no_extra_geoms`\r\n\r\nbelow this class. \r\n\r\nSadly, Github does not produce a nice diff of this, but if you happen to have PyCharm, you should see that there there are actually not that many changes to this file. \r\n",
      "@martinfleis: Changed all the things from the comments",
      "It looks great, thanks for the changes!\r\n\r\nI have now realised that we also need to update docstrings of `GeoSeries.clip` and `GeoDataFrame.clip` methods, to keep them in sync. Apart from that, I think it is ready.",
      "@martinfleis: \r\nSorry for the late response and thanks for catching the missing docstrings! I have updated them accordingly"
    ],
    "commit_messages": [
      "ENH: Add fast rectangle clipping option to `tools.clip` (#2366)\n\n* Add rectangle clipping to `clip.py`\r\n\r\n* Add minor changes requested in PR\r\n\r\n* Allow for list-like masks\r\n\r\n* Update docstrings for GeoSeries.clip() and GeoDataFrame.clip()"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5e5ac254a19ac29e065",
    "number": 2363,
    "body": "Hey, this is what I'm thinking for the API & structure of the method. I can fill in the blanks if this looks good to @martinfleis @jorisvandenbossche. \r\n\r\nRemaining questions I have:\r\n1. The return type of the function could be a geoseries of multipoints with the same index as the original geoseries, *or* an exploded version of that geoseries with single points & duplicated indices. I think the latter is most useful, but the former is more consistent w/ how the rest of GeoSeries methods work. \r\n    - Should there be an option? \r\n    - Is it OK to make the exploded version the default? \r\n2. Sampling behavior will depend on the geometry type. I can write methods to deal with lines and polygons, but should we error if there is a point in the series, or should we return a null geometry? \r\n3. Projections: random samples on a projected coordinate system will be correct, but they will not be correct for lat/long. Should we intercept spherical projections & sample appropriately? ",
    "head_branch": "sample",
    "is_a_fork": true,
    "comments": [
      "1. I quite like the idea of multi points. Exploding it is cheap and you can control how to index the result. Having multi points allows `gdf[\"points\"] = gdf.sample_points(200)` which is consistent with other methods. \n2. You could have mixed geometry types in your geoseries. I would return something like None for point data.\n3. I would warn as we do with methods like buffer. Do not try to make it work on geodesic coords as it would be the only method that does that. ",
      "I'd also move `random.py` to tools and call it `_random.py`. The API looks fine to me. ",
      "Three questions:\r\n\r\n1. In order to provide the gridded sample methods, I've added a `geopandas.tools.grids` module. This should be where code about grid construction lives. I saw that this overlaps with #2197, though, so I only implemented the really simple closed-form centroid functions. This may be more performant than constructing the geometries & then constructing their centroids, but we should make everything about grids live together in a single module. How should we proceed? \r\n2. Should \"sample\" denote \"random\", and the `method=` argument specifies a kind of randomness? If so, I'll need to change the implementations of the grids to construct hexagonal/square grids off of a single random interior point. Right now, it just constructs the grid points that cover the shape. \r\n3. When `shape` is a tuple, I currently create `(n_samples, n_replications)` and store this in a `GeoDataFrame().` The first sample is always set as the active geometry. Is this reasonable, or should we only return a `DataFrame`? ",
      "> we should make everything about grids live together in a single module. How should we proceed?\r\n\r\nI have a feeling that this will go faster, so let's proceed in here as it is drafted and we can then adapt #2197 to use the same files.\r\n\r\n> Should \"sample\" denote \"random\", and the method= argument specifies a kind of randomness?\r\n\r\nWhat other options would `sample` have in this case than `'random'`? And what would the default be? `sample='random', method='uniform'`? I am not certain we need two arguments here but it is true that it can control the position of the grid.\r\n\r\n> When shape is a tuple, I currently create (n_samples, n_replications) and store this in a GeoDataFrame(). The first sample is always set as the active geometry. Is this reasonable, or should we only return a DataFrame?\r\n\r\nIt has GeoSeries, so it should be a GeoDataFrame. But I am not sure if I like this. What is the benefit of doing replications within the method and returning sometimes GeoSeries (one replication) and sometimes GeoDataFrame (n>1 replications) over a custom loop and generation of more GeoSeries if a user wants them?",
      "👍 on the `geopandas.tools.grids`! \r\n\r\n\r\n> > Should \"sample\" denote \"random\", and the method= argument specifies a kind of randomness?\r\n> \r\n> What other options would `sample` have in this case than `'random'`? And what would the default be? `sample='random', method='uniform'`? I am not certain we need two arguments here but it is true that it can control the position of the grid.\r\n\r\nMaybe this'll be clearer:\r\n \r\n![Figure_1](https://user-images.githubusercontent.com/2250995/155507293-03f3112b-4e58-4b97-baa8-5093a8a905c1.png)\r\n\r\nAll of those are \"sampled grids\" from the square shape in a [signal processing](https://en.wikipedia.org/wiki/Sampling_(signal_processing)) sense, but not sampling like statistical sampling. \r\n\r\nThat is, if you run the current implementation 100 times, it just yields 100 copies of the first grid. this is not true of the second or third grids, which are randomly offset or rotated each time. \r\n\r\nSo, should `data.sample_points(method='squaregrid')` be stochastic like this? If so, how? \r\n\r\nI'd be inclined to do the following:\r\n- `method='randomgrid'` gives you the random rotation+displacement. \r\n- `method='grid'` gives you the bounding box-aligned regular grid\r\n- a `shape` option is used instead to switch between hex/square grids. \r\n\r\n> > When shape is a tuple, I currently create (n_samples, n_replications) and store this in a GeoDataFrame(). The first sample is always set as the active geometry. Is this reasonable, or should we only return a DataFrame?\r\n> \r\n> It has GeoSeries, so it should be a GeoDataFrame. But I am not sure if I like this. What is the benefit of doing replications within the method and returning sometimes GeoSeries (one replication) and sometimes GeoDataFrame (n>1 replications) over a custom loop and generation of more GeoSeries if a user wants them?\r\n\r\nI don't think there's any performance benefit. I implemented it because\r\n- it's similar to how `numpy.random` `size=` arguments work,\r\n- it saves the user a bit of tricky code if they intend to sample by part.\r\n\r\nHappy to drop!",
      "I don't have a strong opinion on the API defining the sample, method and a shape of a grid so I'll leave this decision to you.",
      "This still needs\r\n- [x] finish actual `sample_points()` geoseries method & propagate to geodataframe\r\n- [x] finish grid sampling for linestrings\r\n- [x] docstring cleanup\r\n- [x] test migration and reformatting\r\n- [x] example notebook+docstring examples",
      "But, to indicate functionality, random sampling for uniform disrtributions, as well as uniform random & bounding box-aligned hexagonal and square grids are \"ready\" for polygons; uniform random sampling is also implemented for linestrings & points, but I still need to implemented grid sampling for linestrings. \r\n\r\n![sample_points](https://user-images.githubusercontent.com/2250995/155973823-d25f0b07-b525-4f02-974f-72090af5d923.png)\r\n\r\n",
      "> propagate to geodataframe\r\n\r\nMake it a `GeoPandasBase` method, not a `GeoSeries` method. That way both are covered.",
      "In finishing the last sample method (grids of points over `LineStrings`), I realized that [`GeoSeries.interpolate`](https://github.com/geopandas/geopandas/blob/855bdbb431f882def0ab71d81637b3c5cdcb274d/geopandas/base.py#L3054) (which delegates to [`pygeos.line_interpolate_point`](https://github.com/geopandas/geopandas/blob/855bdbb431f882def0ab71d81637b3c5cdcb274d/geopandas/_vectorized.py#L820)) doesn't mention that [`MultiLineStrings` only interpolate over their first geometry](https://github.com/pygeos/pygeos/blob/c53d77a37ab1335f196e39a632221202a3ef530c/pygeos/linear.py#L21). \r\n\r\nI'll add the same disclosure to the `interpolate` method in this PR, rather than filing a new bug+PR. ",
      "OK, I think this has all the functionality in all the relevant geometry types. It currently returns an empty multipoint for any point/multipoint/geometrycollections, and samples correctly from mixed-type GeoSeries/GeoDataFrames. Every `method=random` is stochastic, and every `grid` is deterministic.\r\n\r\n![test_sample](https://user-images.githubusercontent.com/2250995/156419438-5897a91c-867b-47e7-89a5-de7b42b28097.png)\r\n\r\nIt still needs docstring finishing, test reformatting, and a notebook explaining grids & `sample_points`. \r\n",
      "I'm a bit annoyed. Finishing the tests, I've just gone through to double check some constants in the grid construction and realized that the spacing wasn't always being respected when provided. So, if you gave `spacing=.1`, the output grid should always ensure that the minimum distance between points is .1. \r\n\r\nI have fixed this for the square grids in ac7e049, but I'm having trouble in the hexgrids. Will address & push with fixed tests hopefully next week. ",
      "@ljwolf ping me when this is ready for a review (or mark it ready). I wasn't looking at the code yet seeing you're still working on it.",
      "Will do!",
      "OK @martinfleis @brendan-ward, I have a question. \r\n\r\nI'd assume that the output of `pygeos.line_interpolate_point` will always lie on the target line. But, that's not the case; sometimes, an interpolated point will not intersect the target line. For example, one case that fails in this PR is a segment on the boundary of Staten Island (the first row of the `nybb` dataset in `geopandas`):\r\n\r\n```python\r\nimport numpy, pygeos\r\n\r\ntest_coords = numpy.array([[969013.331604  , 150484.31420898],\r\n                           [969014.98199463, 150571.0947876 ]])\r\ntest_line = pygeos.linestrings(test_coords)\r\nlength = 76.506\r\nassert length < pygeos.length(test_line) # so, the point should lie somewhere along the line\r\ntest_point = pygeos.line_interpolate_point(test_line, length, normalized=False)\r\nassert pygeos.intersects(test_line, test_point), \"the interpolated point is not on the line!\"\r\n```\r\n\r\nI'm betting this is a precision issue. If so, is there a way to adjust the precision dynamically to ensure that interpolated points will always intersect their reference line? Or, should I just test simpler cases here? ",
      "This seems like an issue on the GEOS side.  I agree with your assumption that an interpolated point should intersect the line (there is no warning in the GEOS dosctring to indicate it shouldn't).\r\n\r\nIt looks like a precision issue; the interpolated point is very very close to the line.  Attempts at setting a lower precision for the line before interpolating the point (`pg.intersects(pg.set_precision(test_line, 1), pg.set_precision(pygeos.line_interpolate_point(test_line, length), 1))`) did not produce intersections either.\r\n\r\nWe have not yet exposed the `GEOSDistanceWithin` functions from GEOS (>=3.10), which could be helpful here as an alternative predicate to intersects.",
      "@ljwolf looks like the conclusion from [GEOS #585](https://github.com/libgeos/geos/issues/585) is that this is an unfortunate outcome of floating point precision issues, and that there are not immediate solutions at hand to resolve this.  \r\n\r\nMy guess is that it may be necessary for sample points on lines / rings to use an approach that allows for a bit of tolerance in the result, either by using `GEOSDistanceWithin` (once implemented into Shapely and then GeoPandas), or the [`dwithin` predicate for pygeos STRtree](https://pygeos.readthedocs.io/en/latest/strtree.html#pygeos.strtree.STRtree.query_bulk) (I don't think this is exposed yet in GeoPandas as a dedicated sjoin type?), or by using very small buffers centered on the sample points.",
      "Wonderful, thank you @brendan-ward for checking in libgeos/geos#585! A disclosure on `line_interpolate_point()` would be totally sufficient imho. I'll revise the test to use a very small buffer on the line segment. ",
      "OK, this should be ready for review. ",
      "Rebased to re-run tests. ",
      "Can you try to fix CI and tests to make it green?",
      "Yes, aim to! needed to refresh it to start that process. ",
      "Hi @ljwolf,\r\nJust discovered your PR. I worked on #2062 which somehow never made it into review (not sure why).  \r\nHappy to contribute to your grid function. Let me know if I can help.",
      "This needs to:\r\n1. get rebased onto the current main branch\r\n2. re-written to use shapely2.0 rather than pygeos, if possible ",
      "@jGaboardi @janmanuelwinkler rebasing is a good first step, if you have time to contribute! ",
      "This should get updated to support shapely 2.0 alongside pygeos. It is fine to return NotImplementedError for shapely 1.8.",
      "I've just updated this branch from main.",
      "@ljwolf happy to contribute. Do you have a clear idea, which part of my pr #2062 you would like to leverage? When you say rebasing, do you refer to this branch or my pr branch?",
      "I meant as @martinfleis just did. I think, now, we need to migrate the pygeos-specific code to something that uses shapely 2.0",
      "I think that the best way forward here would be to expose the pygeos functions we need here as GeoSeries methods (something that is on a roadmap anyway) and then use those methods instead of calling pygeos directly. That way, we don't have to deal with shapely/shapely2.0/pygeos mess in here. If I look correctly, the only methods that are missing are\r\n\r\n- `minimum_bounding_circle` - we want this for sure\r\n- `get_coordinates`  - this is a bit borderline but would help here and in downstream in transition from pygeos to shapely 2.0\r\n\r\nThe rest is called either the same or is implemented here but called differently:\r\n- `get_parts` is `explode`.\r\n- `line_interpolate_point` is `interpolate`\r\n- `union_all` is `unary_union`\r\n\r\nThe only tricky part is this line but we can do that one conditionally without affecting the rest.\r\n```py\r\n        substring_splits = pygeos.linestrings(list(zip(points[:-1], points[1:])))\r\n```\r\n\r\nSo I would expose those two functions as methods and then got back here and refactored the code using GeoSeries methods instead of pygeos functions. \r\n",
      "xref #2621 #2010 ",
      "With #2621 and #2624, we should be able to rewrite this using GeoSeries methods completely.",
      "Hi @ljwolf @martinfleis,\r\nI want to reactivate the discussion and briefly ask if my help is needed.\r\nTo briefly refresh: in PR #2062 I implemented the equivalent to R st_make_grid. Somehow this PR never really got reviewed. \r\nWhat the function does in a nutshell: It allows you to create a regular square or hexagonal grid within a polygon boundary.\r\n```\r\nParameters\r\n    ------------\r\n    input_geometry : (Multi)Polygon, GeoSeries, GeoDataFrame\r\n        Polygon within its boundaries the grid is made.\r\n    cell_size : float\r\n        Side length of the square or hexagonal grid cell.\r\n    cell_type : str, one of \"square\", \"hexagon\", default \"square\"\r\n        Grid type that is returned.\r\n    what : str, one of \"centers\", \"corners\", \"polygons\", default \"polygons\"\r\n        Grid feature that is returned.\r\n    offset : tuple\r\n        x, y offset of the grid realtive to lower-left corner of the input\r\n        geometry's bounding box.\r\n    intersect : bool, default True\r\n        If False, the grid is not intersected with the `input_geometry`.\r\n    flat_topped : bool, default True\r\n        If False, the orientation of the hexagonal cells are rotated by 90 degree\r\n        such that a corner points upwards.\r\n```\r\nDepending on the parameter the output is a series of grid corners (orange), grid centers (green), or polygons (blue) (see illustration below.\r\n<img width=\"286\" alt=\"image\" src=\"https://user-images.githubusercontent.com/77250171/202026707-bd214515-f55f-4355-a8c2-cf8f8f645241.png\">\r\n\r\n@ljwolf when I read your code correctly, you start from a regular grid and then \"randomize\" it. Do you think it make sense to reuse my function? @martinfleis would it make sense to add the PR #2062 also to the release?\r\nHappy to also briefly discuss, synchronize over a call if preferred.\r\n\r\n",
      "> Somehow this PR never really got reviewed\r\n\r\nSorry! We have an issue with capacity to review larger PRs... I added it to the next milestone so it is on the radar.\r\n\r\n> I want to reactivate the discussion\r\n\r\nThis PR is now paused, waiting for https://github.com/geopandas/geopandas/pull/2621 and https://github.com/geopandas/geopandas/pull/2624.\r\n\r\n> Do you think it make sense to reuse my function?\r\n\r\nIt would be certainly useful to check the overlap between this and #2197 and ensure that the grid creation is done once and optimally.",
      "@ljwolf I have updated this PR to depend on GeoSeries/GeometryArray methods instead of pygeos, fixed tests, got rid of deprecation warnings and moved the notebook to user guide from examples (plus some minor things, see commit history). \r\n\r\nDo you want to take over again to finish to-do's you had in mind and let me and others do the review? Alternatively, I can fully take over to ensure this gets finished for 0.13.",
      "I made another set of commits trying to finalise this. We now have complete docstrings and test coverage. I have also simplified the code where I could (do checks for valid args on one level only...) and moved `make_grid` to the main namespace. \r\n\r\nThere's one weirdness with the user guide notebook - in the maps with two layers, RTD seems to show only one. Locally, the notebook has both. I may switch to static plots instead.",
      "Hi all,\r\nGlad to see that this PR is moving on.\r\nI would like to briefly draw the attention once again to PR #2197 where I implemented lower level logic of this code, namely simply sampling square and hex grids within a polygon. Similar to the equivalent R function one can either get center points, polygons or corner points.\r\nSee also this comment: https://github.com/geopandas/geopandas/pull/2197#issuecomment-1426892918\r\nIf you decide to push this PR back fine with me. I think it would just be a pity if it's not done consciously.",
      "@ljwolf after some discussions with @jorisvandenbossche , we decided to split this PR intro a sequence of smaller ones to make it possible to review it. \r\n\r\n1. The first bit is in https://github.com/geopandas/geopandas/pull/2860.\r\n2. The second will probably take form of a tooling to create grids as is partially here and partially over in #2197. I'd suggest focusing our first implementation of grid making there. @janmanuelwinkler would you be interested looking into what is here and what have you done in your PR (mostly checking which of the implementations is better) and then review your PR? I'll try to have a look at your code in coming days to give you a specific feedback on what you wrote there.\r\n3. Possibly make some combination of randomness and grids available in a similar way we have here.\r\n",
      "Sounds fine to me to split this! ",
      "Sounds fine to me as well",
      "~~Was the functionality fully implemented with the margin of @martinfleis & @ljwolf, I believe this issue can be closed now since the merging of https://github.com/geopandas/geopandas/pull/2860?~~\r\n\r\nEdit: Seems like not completely."
    ],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5e6ac254a19ac29e066",
    "number": 2358,
    "body": "Bumping required versions of dependencies following the rules defined in #1457 and removed now obsolete compatibility code.\r\n",
    "head_branch": "bump_deps",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DEP: bump required versions of dependecies (#2358)\n\n* DEP: bump required versions of dependecies\r\n\r\n* try fixing envs\r\n\r\n* try fiona post1 in minimal\r\n\r\n* skip unstable estimate_utm_crs (pyproj #887)\r\n\r\n* get pyproj from pip in minimal\r\n\r\n* skip all\r\n\r\n* move pyproj pin to 2.6.1.post1\r\n\r\n* skip unstable utm estimation\r\n\r\n* relax pandas in minimal to avoid regressions\r\n\r\n* pin minimal pandas to 1.0.5\r\n\r\n* update docs"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5e7ac254a19ac29e067",
    "number": 2356,
    "body": "To get a slightly better estimate (but still cheap) of the memory usage (the `np.ndarray.nbytes` for an object dtype array only counts the array of pointers, and not the size of objects it is pointing to). \r\n\r\nThe size of the Python geometry object is fixed (for pygeos at least, 32 bytes on Python 3.9), so also does not yet include an estimate of the size of the coordinate sequences. \r\n\r\nIn principle we could add a `count_coordinates(self.data) * 8` to get a better estimate, but that of course incurs some computation (although a relatively cheap one).",
    "head_branch": "nbytes",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5e8ac254a19ac29e068",
    "number": 2354,
    "body": null,
    "head_branch": "main",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5e9ac254a19ac29e069",
    "number": 2353,
    "body": "~This builds upon https://github.com/geopandas/geopandas/pull/2144 (included as a squashed first commit), so for seeing the actual changes for now in this PR, ignore the first commit (-> [subset of the diff](https://github.com/geopandas/geopandas/pull/2353/files/9a126f533ad7761712da3f9a54f50c3b55946bbd..d39c173d2caf377de74d2322269fdb8b14757201)).~ Rebased now https://github.com/geopandas/geopandas/pull/2144 is merged\r\n\r\nThe idea of this PR is to replace the \"double merge\" approach with a \"take + concat\" approach for the actual joining step. This improves the performance quite a bit.  \r\nFor example, for a point-in-polygon join with Great Britain data (will add the script to https://github.com/geopandas/benchmarks), we get:\r\n\r\n```\r\nimport pandas as pd\r\nimport geopandas\r\nimport pyogrio\r\npolygons = pyogrio.read_dataframe(\"benchmark-data/bdline_gpkg_gb/data/bdline_gb.gpkg\")\r\npoints_df = pd.read_parquet(\"benchmark-data/codepo_gb.parquet\")\r\npoints = geopandas.GeoDataFrame(\r\n    points_df[[\"Postcode\", \"Positional_quality_indicator\"]],\r\n    geometry=geopandas.points_from_xy(points_df.Eastings, points_df.Northings),\r\n    crs=polygons.crs)\r\npoints.sindex\r\n\r\nIn [3]: %timeit geopandas.sjoin(points, polygons, predicate=\"within\")\r\n2.4 s ± 69.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)  # <-- main\r\n1.52 s ± 7.93 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)  # <-- PR\r\n```\r\n\r\nFor the inner join, the change is quite simple (the indices we get from the spatial index query are exactly what we want for an inner join, so we can basically do `pd.concat([left.take(..), right.take(..)], axis=1)`. \r\nBut for left/right join, we need to adjust those indices to get the correct rows for this take, and this is where it unfortunately gets more complicated (the whole `_adjust_indexers` is for this).\r\n",
    "head_branch": "sjoin-perf-frame-join",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "PERF: improve frame_join part of spatial join (#2353)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5e9ac254a19ac29e06a",
    "number": 2352,
    "body": "Internally in pandas methods, often `_constructor` (and thus `GeoDataFrame(..)` is called with already a fully formed BlockManager object without any other arguments (basically just to wrap this data in the class / subclass). In those cases, our `GeoDataFrame` has quite some overhead.\r\n\r\nFor example, making a copy of a GeoDataFrame:\r\n\r\n```\r\nIn [1]: df = geopandas.read_file(geopandas.datasets.get_path(\"naturalearth_lowres\"))\r\n\r\nIn [2]: %timeit df.copy()\r\n681 µs ± 6.06 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)`  # <- main\r\n98.4 µs ± 1.35 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)  # <- PR\r\n```\r\n\r\nThis is about relatively small timings in general, but because this can be called multiple times in an operation, this can actually becomes noticeable (eg in `sjoin` on larger data, where the sjoin was taking 1-2 seconds, this was visible significantly in the profile).",
    "head_branch": "perf-geodataframe-fastpath",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5eaac254a19ac29e06b",
    "number": 2351,
    "body": "I have to admit I am not fully sure what has changed in https://github.com/pandas-dev/pandas/pull/45911 but as a result, `GeoDataFrame.fillna` completely circumvents our custom `GeometryArray.fillna`. But it still seem to work as before, just raising a different error (from `GeometryArray.__setitem__`), so I guess this is fine?\r\n\r\n",
    "head_branch": "fillna",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: allow TypeError in fillna() with pandas main (#2351)\n\n* TST: allow TypeError in fillna() with pandas main\r\n\r\n* leave comment pointing to the issue"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5ebac254a19ac29e06c",
    "number": 2349,
    "body": "This removes the warning we had since 0.6. \r\n\r\nAt point, we may even remove `isna` and `isnull` we inherit from pandas (and call directly). Shall I go ahead or do we want to keep them around to have that note in the `isna` docstring about `isna` vs `is_empty`?",
    "head_branch": "remove_isna_warning",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CLN: remove isna warning (#2349)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5ecac254a19ac29e06d",
    "number": 2343,
    "body": "Closes #2336 \r\n\r\nFollowing the gitter thread of @jorisvandenbossche & @RadMagnus from February, 2.\r\nAdded a section on the [io-page ](https://geopandas.org/en/stable/docs/user_guide/io.html) that explains in more detail how to check which formats are supported by geopandas.read_file by investigating the fiona library.\r\nExplained how to change fiona/drvsupport.py on runtime to include supported drivers that are unexposed (commented out)",
    "head_branch": "doc_Fiona_drivers",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: how to access unexposed drivers from fiona (#2343)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5edac254a19ac29e06e",
    "number": 2340,
    "body": null,
    "head_branch": "tools_crs_cleanup",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CLN: remove CRS functions deprecated in 0.7 (#2340)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5edac254a19ac29e06f",
    "number": 2335,
    "body": "Close #2223\r\n\r\nDone by explicit checking of emptiness and returning nan for empty points. Some performance degradation of `.[xyz]` methods may be expected due to the extra array being prepared and the nonempty check.",
    "head_branch": "fix-empty-points-xy",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Fix error on .[xyz] on GeoSeries with empty points: return nan (#2335)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5eeac254a19ac29e070",
    "number": 2334,
    "body": "Fixes #2092 and also implements half of the desired functionality from this [comment in #1490](https://github.com/geopandas/geopandas/issues/1490#issuecomment-737196449).\r\n\r\nThis change allows to read from a PostGIS table with multiple geometry columns and converts WKB from the columns in `geom_col`.\r\n\r\n**Usage**\r\n\r\n```python\r\nwith Session(engine) as session:\r\n    df = gpd.GeoDataFrame.from_postgis(\r\n        sql=\"SELECT * FROM nybb;\",\r\n        con=session.bind,\r\n        geom_col=[\"the_geom\", \"the_geom_2\"]\r\n    )\r\n```\r\n\r\n**Notes**\r\n\r\n- The first geometry column is set as the active geometry for the resulting GeoDataFrame.\r\n- Backwards-compatible with current interface.\r\n- A new test `test_from_postgis_multiple_geom_col` was added for this functionality.\r\n\r\n**RE: Failed Code-Coverage/Patch Check**\r\n\r\nI just added an additional test (see below) for [geopandas/io/sql.py#L72](https://github.com/geopandas/geopandas/pull/2334/files#diff-04e847f5065b7f375a8ba2f6280ef2c8a6532a0c4735445acda3c39269c9bed6R72) in `geopandas\\io\\tests\\test_sql.py` in an attempt to increase code coverage, but that actually _reduced_ it, so I removed it again.\r\n\r\n```python\r\n    def test_from_postgis_unknown_geom_col(self, connection_postgis, df_nybb):\r\n        con = connection_postgis\r\n        geom_col = \"the_geom\"\r\n        create_postgis(con, df_nybb, geom_col=geom_col)\r\n\r\n        sql = \"SELECT * FROM nybb;\"\r\n        with pytest.raises(ValueError):\r\n            GeoDataFrame.from_postgis(sql, con, geom_col=\"geom_the\")\r\n```",
    "head_branch": "postgis-multiple-geometries",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5efac254a19ac29e071",
    "number": 2332,
    "body": "Closes #2282. This is \"a\" way forward, not necessarily the best one. I think it would probably be cleaner to move `GeoSeries.geometry` (from the GeoPandasBase mixin) to another name, say `GeoSeries._geometry` to just avoid the collision of attributes but there's probably an argument that needs a deprecation cycle (even if I can't a legitmate use for accessing this attribute on a GeoSeries). But this will fix things for now.",
    "head_branch": "fix_loc_regression",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REGR: fix loc single column indexing regression. (#2332)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5f0ac254a19ac29e072",
    "number": 2331,
    "body": "Follow-up on https://github.com/geopandas/geopandas/pull/2299",
    "head_branch": "remove-rc-build",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: remove the temporary pandas RC build (#2331)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5f1ac254a19ac29e073",
    "number": 2329,
    "body": "Related to https://github.com/geopandas/geopandas/issues/2133\r\n\r\nI haven't done it yet but I think it makes sense to update the error thrown here (or indirectly from calling gdf.area without `_geometry_column_name` being present).\r\nhttps://github.com/geopandas/geopandas/blob/76e886ec23ddd12a032c933ab08b18693a8144a1/geopandas/geodataframe.py#L215-L221\r\n\r\nI think it would make sense to change this to something along the lines of (for the _geometry_column_name is None case)\r\n\"No active geometry column is currently set. To use GeoDataFrame geographic(? is there a better word) methods, set a geometry column using `set_geometry`\"\r\nand \r\n\"Active geometry column named self._geometry_column_name is not present in columns. To use  GeoDataFrame geographic methods, assign a value to this column, or update the active geometry column using set_geometry\"\r\n\r\nwhen the name is known. \r\n\r\nI think there's also probably a question about what the geometry column name should be when no geometry data is provided to the init method - it's currently \"geometry\", but it could also be None.\r\n\r\n\r\n",
    "head_branch": "getitem_with_unset_geo_cols",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "API: improve handling of invalid geo column for .geometry (more informative error message) + update getitem (preserve GeoDataFrame if a geometry dtype is present) (#2329)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5f2ac254a19ac29e074",
    "number": 2328,
    "body": "In these final edits, I removed the \"fix\" to the `read_file` method that tried to find an unused column name when a non-geometry called \"geometry\" already existed. \r\nI also added a new parameter to the `read_file` method called `geometry_colname`. This new parameter is used to determine the column name that will store the shapely geometries.\r\nAnd lastly, if the user tries to set the geometry column name to be equal to a name that's already being used in the main attribute table, an error is thrown and the user is asked to use a different value for the `geometry_colname` parameter. \r\n\r\nPS: Sorry for creating a whole new new pull request separate from my previous one. Something weird happened to my Git installation and stuff got kinda funky. This PR is a continuation of [this older PR](https://github.com/geopandas/geopandas/pull/2311) (#2311), which addressed [issue #2310](https://github.com/geopandas/geopandas/issues/2310).",
    "head_branch": "pr/2311",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5f2ac254a19ac29e075",
    "number": 2327,
    "body": "This came up in https://github.com/geopandas/dask-geopandas/issues/138\r\n\r\nWhile I wouldn't consider the spec stable (there are some discussions in https://github.com/opengeospatial/cdw-geo/ as well), I think at this point it is already used enough to say that we will keep some back-compat layer in geopandas to be able to read files written with the current pandas, even if the metadata spec would still change? (after all, the spec is versioned, and should allow this). \r\nIf we want to make this guarantee, I think it should be OK to remove the warning? \r\n\r\ncc @brendan-ward ",
    "head_branch": "parquet-remove-warning",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Remove warning about no stability promise in Parquet/Feather export (#2327)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5f3ac254a19ac29e076",
    "number": 2324,
    "body": "The current `sindex` that is used when pygeos is installed, `PyGEOSSTRTreeIndex`, subclasses the pygeos.STRtree. But we also have a `BaseSpatialIndex` class ourselves that defines the interface. \r\n\r\nConsidering that the STRtree migrated from pygeos to shapely will change its API a bit, I was thinking that in general it seems better and more robust that we don't subclass here, but rather use composition (something we will need to do for `shapely.STRtree` anyway, if we want to keep the `.sindex` interface stable). \r\nIn general this seems the better way to do this if we would allow for multiple SpatialIndex classes backed by different implementations (xref https://github.com/geopandas/geopandas/issues/1344)\r\n\r\ncc @adriangb",
    "head_branch": "strtree-no-subclass",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REF: use composition instead of sublcassing pygeos.STRtree for SpatialIndex (#2324)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5f4ac254a19ac29e077",
    "number": 2323,
    "body": "In general one should be cautious with adding upper pins in package install requirements, but in this case we know for sure that shapely 2.0 _will not_ work with the current codebase (the shapely dev install in the dev build was removed because there were several failures). \r\n\r\nhttps://github.com/geopandas/geopandas/pull/2275 will be needed to actually support shapely 2.0, but I don't see that as a requirements for a 0.11 release. So for now adding a upper pin.",
    "head_branch": "pin-upper-shapely",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DEV: pin shapely < 2 in setup.py (#2323)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5f5ac254a19ac29e078",
    "number": 2322,
    "body": "The `Int64Index` class itself is deprecated (it will just become `Index` in the future), so we need a different way to check the index. I _think_ just checking for integer dtype should be equivalent (RangeIndex also gives a dtype of int64)",
    "head_branch": "fix-depr-index",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "COMPAT: avoid direct usage of pd.Int64Index (#2322)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5f6ac254a19ac29e079",
    "number": 2320,
    "body": "This should fix the CI (this test didn't run on pandas 1.3, and now pandas 1.4 is released the test started running on the minimal build, which doesn't have rtree or pygeos)",
    "head_branch": "ci-pandas-nosindex",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: skip pandas groupby test if no sindex available (#2320)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5f6ac254a19ac29e07a",
    "number": 2319,
    "body": "Attempt to close #2317",
    "head_branch": "ci-numpy-dev",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: ensure numpy nightly is installed in dev build (#2319)\n\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5f7ac254a19ac29e07b",
    "number": 2318,
    "body": "The test function name needs to start with `test_` to be recognized by `pytest`.\r\n\r\nThis test was originally named correctly, but was apparently renamed by accident in PR#654.",
    "head_branch": "test_first_dissolve",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Fix first_dissolve not picked up by pytest (#2318)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5f8ac254a19ac29e07c",
    "number": 2316,
    "body": "Should fix the failing 310-dev environment, we're just now getting warnings from https://github.com/pandas-dev/pandas/pull/45321\r\n\r\n(the change in geoseries is not required to fix CI, but seemed sensible to get all at once)\r\n\r\nI also noticed setting up a local environment that this environment doesn't actually seem to use numpy main, despite in being in the yaml:\r\nhttps://github.com/geopandas/geopandas/blob/cebb5873d04a81bf37376dfb5d4b2adcfe9d87af/ci/envs/310-dev.yaml#L29\r\n\r\nI'll make that a separate issue though.",
    "head_branch": "fix_ci",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: update use of deprecated iteritems to avoid warnings (#2316)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5f9ac254a19ac29e07d",
    "number": 2315,
    "body": null,
    "head_branch": "main",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: expose folium.map kwds as map_kwds in `explore()` (#2315)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5faac254a19ac29e07e",
    "number": 2314,
    "body": null,
    "head_branch": "deprecate_geoseries_fallback",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DEP: remove deprecated fallback to return pd.Series from GeoSeries constructor (#2314)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5fbac254a19ac29e07f",
    "number": 2311,
    "body": "This PR would change the behavior of the `GeoDataFrame.from_features()` method to allow reading GeoJSON strings that contain a column called \"geometry\" in the attribute table. This would address issue #2310.",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5fbac254a19ac29e080",
    "number": 2309,
    "body": "Howdy! :wave:\r\n\r\nI am @readthedocs-assistant and I am sending you this pull request to upgrade the configuration of your Read the Docs project.\r\nYour project will continue working whether or not you merge it, but I recommended you take it into consideration.\r\n\r\nAlso, in case you haven't done it already, remember that you can enable the pull request builds for your project to see the effect of these changes. To do it, [follow the instructions](https://docs.readthedocs.io/en/stable/pull-requests.html), close this pull request, and open it again.\r\n\r\n_*Note*: This tool is in beta phase. Don't hesitate to ping @astrojuanlu and/or @humitos if you spot any problems._\r\n\r\nThe following migrators were applied:\r\n\r\n- Convert the Python version to a string.\r\n\r\nThis makes the configuration valid according to the schema\r\nand protects you from\r\n[\"the Python 3.1 problem\"](https://dev.to/hugovk/the-python-3-1-problem-85g).\r\n\r\n- Migrate to `build.tools` configuration.\r\n\r\nThis uses the new base Docker image based on Ubuntu 20.04 introduced in October 2021\r\nand picks an appropriate Python version for your project\r\n(read [our blog post](https://blog.readthedocs.com/new-build-specification/)\r\nfor details).\r\nNotice that now you can specify the Node.js, Rust, and Go versions as well.\r\n\r\n*Note:* Some system dependencies are not preinstalled anymore,\r\nso this might require manually adding them to `build.apt_packages`\r\n(see [our\r\ndocumentation](https://docs.readthedocs.io/en/stable/config-file/v2.html#build-apt-packages>)).\r\n\r\n- Migrate to Mamba as a drop-in replacement for Conda.\r\n\r\nYour project requested using Mamba instead of Conda for performance reasons.\r\nNow this is included in your configuration\r\nand you can change it without our intervention.",
    "head_branch": "update-rtd-config-assistant",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Update Read the Docs configuration (automatic) (#2309)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5fcac254a19ac29e081",
    "number": 2307,
    "body": "Tiny follow-up on https://github.com/geopandas/geopandas/pull/2303, restructuredtext is picky about having a whitespace line before a list",
    "head_branch": "doc-fixup",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: fixup rst formatting in dissolve docstring (#2307)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5fdac254a19ac29e082",
    "number": 2306,
    "body": "This PR is very similar to https://github.com/geopandas/geopandas/pull/1324 and fixes https://github.com/geopandas/geopandas/issues/2301 (as well as duplicates https://github.com/geopandas/geopandas/issues/1804, https://github.com/geopandas/geopandas/issues/2017, https://github.com/geopandas/geopandas/issues/2186, and https://github.com/geopandas/geopandas/issues/2301).\r\n\r\nIn the spirit of [this logic](https://github.com/pandas-dev/pandas/blob/ab42f85f192ab054a18f94825ced1bb4c1ab7d3f/pandas/core/frame.py#L616-L629), if  a  `DataFrame` is passed to the `GeoDataFrame` constructor, and the `copy` kwarg is not explicitly set by the user, then `copy=True` is set so that the input is not modified.",
    "head_branch": "feat/copy-if-dataframe",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5feac254a19ac29e083",
    "number": 2305,
    "body": "Explicitly flatten the index to avoid a Pandas FutureWarning.\r\nThis is a no-op if the index is already flat.\r\n\r\nFixes #2304",
    "head_branch": "2304-dissolve-futurewarning",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Fix FutureWarning with multiple aggregations in dissolve (#2305)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5ffac254a19ac29e084",
    "number": 2303,
    "body": "Resolves #2302",
    "head_branch": "dissolve-explain-complex-aggfunc",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Document full capabilities of aggfunc argument (#2303)\n\n* Document full capabilities of aggfunc argument\r\n\r\nResolves #2302\r\n\r\n* Apply black formatting\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d5ffac254a19ac29e085",
    "number": 2300,
    "body": "In all the \"latest-conda-forge\" ci envs, we are not pinning pandas and thus getting the latest (except for an outdated pin in the 38 env), so all were using pandas 1.3.x. \r\nI added pins for pandas 1.2 and 1.3 for the py-38 and 39 envs (and then the py-310 env will get the latest pandas 1.4 once that is out). And we already have a specific env that pins to 1.0 and 0.25 (that last one we could probably remove if we bump the minimum required version)",
    "head_branch": "ci-pandas-versions",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: diversify pandas versions in the test environments (#2300)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d600ac254a19ac29e086",
    "number": 2299,
    "body": "And I also changed the dev environment from Python 3.8 -> 3.10",
    "head_branch": "test-pandas-14-rc",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: test against pandas 1.4 release candidate (#2299)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d601ac254a19ac29e087",
    "number": 2298,
    "body": "Closes #2294\r\n\r\nhttps://github.com/geopandas/geopandas/issues/2294 needs to be fixed on the pandas side (https://github.com/pandas-dev/pandas/pull/45363), but adding a test here as well in GeoPandas with the original reproducer (in pandas it's only a test with a dummy subclass)",
    "head_branch": "groupby-apply-bugs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: test groupby apply with function that requires GeoDataFrame attributes (#2298)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d602ac254a19ac29e088",
    "number": 2297,
    "body": "This is a numpy-based implementation of the distance along the Hilbert Curve, similar as we have in [dask-geopandas](https://github.com/geopandas/dask-geopandas/blob/main/dask_geopandas/hilbert_distance.py) but thus not using numba but a vectorized implementation based on the version in GEOS (which is basically https://github.com/rawrunprotected/hilbert_curves)\r\n\r\nWith the version of GEOS / https://github.com/rawrunprotected/hilbert_curves, it was actually trivially to have it run vectorized on a numpy array of discrete coordinates as well (literally the same code).\r\n\r\nI am directly creating a PR in geopandas here, and not in dask-geopandas, since this is a feature we were thinking to move to base geopandas anyway (we can use it here as well to sort geometries).\r\n\r\nThis still needs tests, docs, and hooking it up in the public API, etc.\r\n\r\n",
    "head_branch": "hilbert",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: add distance along the Hilbert Curve (#2297)\n\n* ENH: add distance along the Hilbert Curve\r\n\r\n* fix clip\r\n\r\n* calculate total_bounds from bounds manually (avoid gettings bounds twice)\r\n\r\n* merge in latest version from dask-geopandas\r\n\r\n* expose publicly + add basic tests\r\n\r\n* de-daskify docstring\r\n\r\n* lint\r\n\r\n* add changelog"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d603ac254a19ac29e089",
    "number": 2296,
    "body": "Fixes #2063, and is a redo of #2080.\r\n\r\nFor reference, this is very similar to #2080 when @jorisvandenbossche reviewed it, except without convoluted extra steps to try and make the default column name for to_frame to be `\"geometry\"` instead of `0`- which also had awkward edge cases to still solve.\r\n\r\nAs I said there, I think that if `GeoSeries.to_frame` with no name should produce a GeoDataFrame with geometry col defaulting to \"geometry\", we should just override the default value in to_frame.",
    "head_branch": "geoseries_constructor_expanddim_v2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Define GeoSeries._constructor_expanddim to handle fix to_frame for named geoseries (#2296)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d604ac254a19ac29e08a",
    "number": 2293,
    "body": "This updates the copyright year to read \"2013-2022\" in conf.py.",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Update copyright year to 2022 in conf.py (#2293)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d604ac254a19ac29e08b",
    "number": 2292,
    "body": "Closes #2271, closes #2229\r\n\r\nIn some cases, the output of `join` on line 1697 returns sorted index even though the original one is unsorted. If that happens, we need to sort rows back before assigning the MultiIndex.",
    "head_branch": "2271",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: explode incorrectly expects unsorted index (#2292)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d605ac254a19ac29e08c",
    "number": 2289,
    "body": "Fixes #2287.\r\nWasn't sure on the naming convention for the LooseVersion guard, so I've just copied the logic from https://github.com/geopandas/geopandas/pull/1658/files and hoped that's okay.\r\n\r\nThere is a separate issue that the geometryarray that is now stored in the index loses CRS info, but have kept this focused to fixing CI.",
    "head_branch": "pandas_master_value_counts",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: fix test_value_counts test for pandas 1.4 (#2289)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d606ac254a19ac29e08d",
    "number": 2286,
    "body": "Closes #2283 \r\n> it's good that we didn't end up merging that just before the 0.10 release :)\r\n\r\nSorry about this and the other bug, hopefully there's not more.\r\n\r\nThis one at least is easy to fix, basically exactly what @jorisvandenbossche suggested. The one change is doing an isinstance check on `DataFrame` rather than `GeoDataFrame` -  to get `test_crs.py::test_apply_geodataframe` to work. I suppose this was probably why that check got taken out when I did #2060, it's still a pretty big oversight by me. \r\n\r\nI'm now looking into why that GeoDataFrame -> DataFrame change is neccessary - it means the raw results of apply in pandas aren't preserving the GeoDataFrame although it used to, which probably isn't great because it means the geometry column is becoming an object type column as an intermediate step.\r\n",
    "head_branch": "fix_apply_regression",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REGR: fix bug in apply when returning a series (#2286)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d607ac254a19ac29e08e",
    "number": 2284,
    "body": "Updated existing dev environment file and documentation to resolve #2220 ",
    "head_branch": "update_dev_env",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: contributing guide: point users to environment file to install deps (#2284)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d608ac254a19ac29e08f",
    "number": 2281,
    "body": "This closes #2210, a case where adding a legend for a categorical and using\nmissing_kwds when no data was missing resulted in an UnboundLocalError.\n",
    "head_branch": "issue2210",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "BUG: Handle case where legend=True and missing_kwds for categorical (#2281)\n\n* Handle missing_kwds when no missing data\r\n\r\n* Add basic test that plotting with missing_kwds works\r\n\r\n* Improve test of categorical missing_kwds case\r\n\r\nNeed legend=True for a categorical variable where no missing data."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d609ac254a19ac29e090",
    "number": 2280,
    "body": "Linked to #2133 (but doesn't close it). This PR partially addresses the first point there;\r\n>Decide what to do with results that loose the \"geometry\" column, but still have another geometry dtype column (currently this is a bit inconsistent, __getitem__ gives DataFrame, but most other methods result in an \"invalid\" GeoDataFrame with _geometry_column_name not set)\r\n\r\nby bringing slicing / reindexing methods return type behaviour in sync with __getitem__ - I think consistent behaviour is a better starting point, and that behaviour could be changed later if desired. (I am of the view that matching __getitem__ makes sense in the majority if not all cases.)\r\n\r\nIn migrating this branch across from my earlier tests, I've organised this into 4 cleaner commits to make reviewing a little easier (with the bulk of changes in the first). All tests pass at this point, except `test_geoseries::test_expanddim`, which will be fixed by #2080. \r\n\r\nAdditionally, there are a couple of things I'm that perhaps could be revised, I'll leave them as notes as a review.\r\n\r\nFinally, there is also some code cleanup that can be done as a result of this PR, but I thought I'd leave that as a follow up.",
    "head_branch": "gdf_constructor_continued",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d609ac254a19ac29e091",
    "number": 2277,
    "body": "See https://github.com/geopandas/community/issues/7 for context.\r\n\r\nThe default branch name already has been renamed to `main`; this PR replaces it in the repo source code.",
    "head_branch": "rename-master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DEV: rename master to main (#2277)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d60aac254a19ac29e092",
    "number": 2276,
    "body": "Until https://github.com/geopandas/geopandas/pull/2275 is done, this will otherwise always fail the dev build, which makes we don't really easily notice any other failure.",
    "head_branch": "ci-dev",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: temporarily use released Shapely in the dev build (#2276)\n\n* CI: temporarily use released Shapely in the dev build\r\n\r\n* ensure to use latest numpy if already installed\r\n\r\n* that doesn't work .."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d60bac254a19ac29e093",
    "number": 2275,
    "body": "This makes geopandas compatible with the main branch of Shapely.\r\n\r\nFor now, I took the approach of adding yet another if/else check in the vectorized operations, keeping the pygeos version as well. I already want to test the main branch of Shapely with GeoPandas, but as long as there is not yet a Shapely 2.0 (beta/rc) release, we also want that people can continue to use pygeos to get the speedups. \r\nI think the code additions are not too bad, and once we can require Shapely >= 2.0, we can clean up _both_ the pygeos compat as the old shapely compat.\r\n\r\n~For sindex operations, this is not yet working, as this is waiting on finalizing STRtree in Shapely for 2.0 (https://github.com/shapely/shapely/pull/1251).~\r\n",
    "head_branch": "shapely-2.0",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Make GeoPandas work with Shapely 2.0 (#2275)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d60cac254a19ac29e094",
    "number": 2274,
    "body": "With Shapely 2.0, `Polygon()` will start to return an actual empty Polygon, while now it actually returns an emtpy GeometryCollection. This has some effect on the tests, so already correcting this now. ",
    "head_branch": "tests-empty-polygon",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: fix array tests to use proper empty Polygon (#2274)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d60dac254a19ac29e095",
    "number": 2268,
    "body": "In the new error messages, I've tried to give some guidance about how to fix the errors if people run into them - I'm not sure if this is helpful or overkill - particularly for the `__init__` where refering a user to the documentation might be more helpful.\r\n\r\n\r\n",
    "head_branch": "dep_crs_no_geo_col",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DEP: Assigning CRS to a GeoDataFrame without a geometry column (#2268)\n\n* DEP: convert crs without geom col warnings to errors\r\n\r\n* TST: update tests to now reflect new errors\r\n\r\n* TST: fix tests to still test old behaviour as well"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d60dac254a19ac29e096",
    "number": 2267,
    "body": null,
    "head_branch": "dep_array_compare",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DEP: GeometryArray.almost_equals and GeometryArray.almost_equals_exact (#2267)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d60eac254a19ac29e097",
    "number": 2265,
    "body": "Fixes the problem experienced at https://github.com/geopandas/geopandas/issues/967#issuecomment-708354394, int32 is added to infer_schema and a regression test has been included",
    "head_branch": "fix_issue_967",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d60fac254a19ac29e098",
    "number": 2262,
    "body": "Fixes #2229 ",
    "head_branch": "explode_index_bug",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d610ac254a19ac29e099",
    "number": 2260,
    "body": "feature 1:\r\n    Returns a string explaining the validity or invalidity of the object.\r\nexample:\r\n  >>> from shapely.geometry import Polygon,LineString,Point\r\n  >>> s = geopandas.GeoSeries(\r\n  ...                 [\r\n  ...                     Polygon([(0, 0), (2, 2), (0, 2)]),\r\n  ...                     Polygon([(0, 0), (2, 2), (0, 2), (2, 2)]),\r\n  ...                     LineString([(0, 0), (2, 2)]),\r\n  ...                     LineString([(2, 0), (0, 2)]),\r\n  ...                     Point(0, 1),\r\n  ...                 ],\r\n  ...             )\r\n  >>> s.explain_validity()\r\n  0            Valid Geometry\r\n  1    Self-intersection[0 0]\r\n  2            Valid Geometry\r\n  3            Valid Geometry\r\n  4            Valid Geometry\r\n  dtype: object\r\n\r\nfeature 2:\r\n    Returns a valid representation of the GeoSeries, if it is invalid. If it is valid, the raw GeoSeries will be returned.\r\nexample:\r\n  >>> from shapely.geometry import Polygon,LineString,Point\r\n  >>> s = geopandas.GeoSeries(\r\n  ...                 [\r\n  ...                     Polygon([(0, 0), (2, 2), (0, 2)]),\r\n  ...                     Polygon([(0, 0), (2, 2), (0, 2), (2, 2)]),\r\n  ...                     LineString([(0, 0), (2, 2)]),\r\n  ...                     LineString([(2, 0), (0, 2)]),\r\n  ...                     Point(0, 1),\r\n  ...                 ],\r\n  ...             )\r\n>>> s.make_valid()\r\n0    POLYGON ((0.00000 0.00000, 2.00000 2.00000, 0....\r\n1    MULTILINESTRING ((0.00000 0.00000, 2.00000 2.0...\r\n2        LINESTRING (0.00000 0.00000, 2.00000 2.00000)\r\n3        LINESTRING (2.00000 0.00000, 0.00000 2.00000)\r\n4                              POINT (0.00000 1.00000)\r\ndtype: geometry\r\n>>> s.make_valid().explain_validity()\r\n0    Valid Geometry\r\n1    Valid Geometry\r\n2    Valid Geometry\r\n3    Valid Geometry\r\n4    Valid Geometry\r\ndtype: object\r\n\r\n",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d611ac254a19ac29e09a",
    "number": 2259,
    "body": "Closes #2211.\r\n\r\nAdded new example demonstrating sjoin_nearest including using the optional parameter distance_col.\r\n\r\nMy addition is:\r\n\r\n_Markdown_\r\n> We can also conduct a nearest neighbour join with `sjoin_nearest`.\r\n\r\n_Code_\r\n> pointdf.sjoin_nearest(polydf, how=\"left\", distance_col=\"Distances\")\r\n> \\# Note the optional Distances column with computed distances between each point\r\n> \\# and the nearest polydf geometry.\r\n\r\nOutput in gallery is (pretty printed in gdf):\r\n>\tgeometry\tvalue1\tvalue2\tindex_right\tBoroCode\tBoroName\tShape_Leng\tShape_Area\tDistances\r\n> 0\tPOINT (913175 120121)\t1033296\t793054\t0\t5\tStaten Island\t330470.010332\t1623819823.81\t1479.2910924795774\r\n> 1\tPOINT (932450 139211)\t1071661\t793239\t0\t5\tStaten Island\t330470.010332\t1623819823.81\t0.0\r\n> 2\tPOINT (951725 158301)\t1110026\t793424\t0\t5\tStaten Island\t330470.010332\t1623819823.81\t0.0\r\n> 3\tPOINT (971000 177391)\t1148391\t793609\t2\t3\tBrooklyn\t741080.523166\t1937478507.61\t5075.979291209011\r\n> 4\tPOINT (990275 196481)\t1186756\t793794\t2\t3\tBrooklyn\t741080.523166\t1937478507.61\t22.36146714547065\r\n> 5\tPOINT (1009550 215571)\t1225121\t793979\t1\t4\tQueens\t896344.047763\t3045212795.2\t0.0\r\n> 6\tPOINT (1028825 234661)\t1263486\t794164\t4\t2\tBronx\t464392.991824\t1186924686.49\t0.0\r\n> 7\tPOINT (1048100 253751)\t1301851\t794349\t4\t2\tBronx\t464392.991824\t1186924686.49\t818.9403766556778\r\n> 8\tPOINT (1067375 272841)\t1340216\t794534\t4\t2\tBronx\t464392.991824\t1186924686.49\t25368.108999970773\r\n",
    "head_branch": "example_gallery_sjoin_nearest",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Added sjoin_nearest method to examples gallery. (#2259)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d611ac254a19ac29e09b",
    "number": 2258,
    "body": "feature 1:\r\n    Returns a string explaining the validity or invalidity of the object.\r\nexample:\r\n  >>> from shapely.geometry import Polygon,LineString,Point\r\n  >>> s = geopandas.GeoSeries(\r\n  ...                 [\r\n  ...                     Polygon([(0, 0), (2, 2), (0, 2)]),\r\n  ...                     Polygon([(0, 0), (2, 2), (0, 2), (2, 2)]),\r\n  ...                     LineString([(0, 0), (2, 2)]),\r\n  ...                     LineString([(2, 0), (0, 2)]),\r\n  ...                     Point(0, 1),\r\n  ...                 ],\r\n  ...             )\r\n  >>> s.explain_validity()\r\n  0            Valid Geometry\r\n  1    Self-intersection[0 0]\r\n  2            Valid Geometry\r\n  3            Valid Geometry\r\n  4            Valid Geometry\r\n  dtype: object\r\n\r\nfeature 2:\r\n    Returns a valid representation of the GeoSeries, if it is invalid. If it is valid, the raw GeoSeries will be returned.\r\nexample:\r\n  >>> from shapely.geometry import Polygon,LineString,Point\r\n  >>> s = geopandas.GeoSeries(\r\n  ...                 [\r\n  ...                     Polygon([(0, 0), (2, 2), (0, 2)]),\r\n  ...                     Polygon([(0, 0), (2, 2), (0, 2), (2, 2)]),\r\n  ...                     LineString([(0, 0), (2, 2)]),\r\n  ...                     LineString([(2, 0), (0, 2)]),\r\n  ...                     Point(0, 1),\r\n  ...                 ],\r\n  ...             )\r\n>>> s.make_valid()\r\n0    POLYGON ((0.00000 0.00000, 2.00000 2.00000, 0....\r\n1    MULTILINESTRING ((0.00000 0.00000, 2.00000 2.0...\r\n2        LINESTRING (0.00000 0.00000, 2.00000 2.00000)\r\n3        LINESTRING (2.00000 0.00000, 0.00000 2.00000)\r\n4                              POINT (0.00000 1.00000)\r\ndtype: geometry\r\n>>> s.make_valid().explain_validity()\r\n0    Valid Geometry\r\n1    Valid Geometry\r\n2    Valid Geometry\r\n3    Valid Geometry\r\n4    Valid Geometry\r\ndtype: object\r\n\r\n",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d612ac254a19ac29e09c",
    "number": 2257,
    "body": "add Two features:\r\n1. Returns a string explaining the validity or invalidity of the GeoSeries.\r\nexample: \r\n >>> from shapely.geometry import Polygon,LineString,Point\r\ns = geopandas.GeoSeries(\r\n    [\r\n        Polygon([(0, 0), (2, 2), (0, 2)]),\r\n        Polygon([(0, 0), (2, 2), (0, 2)]),\r\n        LineString([(0, 0), (2, 2)]),\r\n        LineString([(2, 0), (0, 2)]),\r\n        Point(0, 1),\r\n    ],\r\n)\r\n--------------------------------\r\n0            Valid Geometry\r\n1    Self-intersection[0 0]\r\n2            Valid Geometry\r\n3            Valid Geometry\r\n4            Valid Geometry\r\ndtype: object\r\n\r\n2. Returns a valid representation of the GeoSeries, if it is invalid. If it is valid, the raw GeoSeries will be returned.\r\nexample:\r\n>>>from shapely.geometry import Polygon,LineString,Point\r\n        s = geopandas.GeoSeries(\r\n                [\r\n                    Polygon([(0, 0), (2, 2), (0, 2)]),\r\n                    Polygon([(0, 0), (2, 2), (0, 2), (2, 2)]),\r\n                    LineString([(0, 0), (2, 2)]),\r\n                    LineString([(2, 0), (0, 2)]),\r\n                    Point(0, 1),\r\n                ],\r\n            )\r\n        s.make_valid()\r\n        ---------------------------\r\n        0    POLYGON ((0.00000 0.00000, 2.00000 2.00000, 0....\r\n        1    MULTILINESTRING ((0.00000 0.00000, 2.00000 2.0...\r\n        2        LINESTRING (0.00000 0.00000, 2.00000 2.00000)\r\n        3        LINESTRING (2.00000 0.00000, 0.00000 2.00000)\r\n        4                              POINT (0.00000 1.00000)\r\n        dtype: geometry\r\n        \r\n        >>> s.make_valid().explain_validity()\r\n        ---------------------------\r\n        0    Valid Geometry\r\n        1    Valid Geometry\r\n        2    Valid Geometry\r\n        3    Valid Geometry\r\n        4    Valid Geometry\r\n        dtype: object",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d613ac254a19ac29e09d",
    "number": 2255,
    "body": "Adding a note to `explore` user guide regarding the CRS and tiles.\r\n\r\nThe real diff is on lines 61-66, the rest is some Jupyter mess.\r\n\r\nxref #2254",
    "head_branch": "crs_explore_note",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: mention CRS requirement in explore docs (#2255)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d614ac254a19ac29e09e",
    "number": 2250,
    "body": "Update Versioneer to version 0.21",
    "head_branch": "update-versioneer",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "[Bot] Update Versioneer (#2250)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d615ac254a19ac29e09f",
    "number": 2249,
    "body": "Closes #2246",
    "head_branch": "op-deprecation-cleanup",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Replaced instances of deprecated op with predicate (#2249)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d615ac254a19ac29e0a0",
    "number": 2248,
    "body": "Add a GitHub Action workflow that checks once a month if all the Versioneer files are still up to date, and opens a PR if updates are available.\r\n\r\nAlso runs on manual dispatch, if `setup.cfg` or the workflow itself (`versioneer.yml`) is changed.\r\n\r\n",
    "head_branch": "patch-3",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: Create workflow to automatically update Versioneer (#2248)\n\n* CI: Create workflow to automatically update Versioneer\r\n\r\nRuns on manual dispatch, if setup.cfg or the workflow is changed and once a month\r\n\r\n* versioneer CI: Point as base branch to main\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* versioneer CI: Update used actions\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d616ac254a19ac29e0a1",
    "number": 2247,
    "body": "Closes #2211.\r\n\r\nAdded new example demonstrating `sjoin_nearest` including using the optional parameter `distance_col`.\r\n\r\nNot sure why `metadata` and `outputs` names are in a different order in my jupyter JSON but it didn't affect the build locally.",
    "head_branch": "sjoin_nearest_example",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d617ac254a19ac29e0a2",
    "number": 2243,
    "body": "Fixes https://github.com/geopandas/geopandas/issues/2242\r\n\r\nIt allows to have `'properties':null` in a geoJSON and still allow to use it with GeoDataFrame.from_features.\r\nThe geoJSON spec allows to use null for properties: https://geojson.org/geojson-spec.html https://datatracker.ietf.org/doc/html/rfc7946",
    "head_branch": "bugfix_geojson_properties",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: support null properties in GeoJSON (#2243)\n\nCo-authored-by: James McBride <jdmcbr@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d618ac254a19ac29e0a3",
    "number": 2240,
    "body": "Since Fiona is able to write empty files for most drivers, Geopandas shouldn't prevent that.\r\n\r\nCloses #2234.\r\n\r\nI also removed duplicate import statements.",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: convert error upon writing empty df to warning (#2240)\n\n* converted error upon writing empty df to warning\r\n\r\n* updated test to match new behaviour\r\n\r\n* add empty geometry to test dataframe\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d619ac254a19ac29e0a4",
    "number": 2239,
    "body": "fixes #2154 \r\n\r\nThis entails a change in the `fmt` keyword to format tick labels, as colorbars' tick labels have been formatted with old-style formats (like `\"%.3f\"`), until the very recent matplotlib/matplotlib/pull/21542. By the way I wonder if it is desirable to keep \"%.2f\" as default formatting, or to rather not provide one.\r\n\r\nI left a TODO about adding a legend entry for geometries with missing data, which I think would be easier to implement in #2012 once this one is in.\r\n\r\nExample output:\r\n```python\r\nimport geopandas\r\nfrom geopandas.datasets import get_path\r\nworld = geopandas.read_file(get_path('naturalearth_lowres'))\r\nworld.plot(column=\"pop_est\", scheme=\"BoxPlot\", legend=True)\r\n```\r\n![output](https://user-images.githubusercontent.com/31036680/143684456-210df446-8f09-43eb-8fb3-fdb35d943c1a.png)\r\n\r\n\r\n",
    "head_branch": "mapclassify-colorbar",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d619ac254a19ac29e0a5",
    "number": 2238,
    "body": null,
    "head_branch": "actions-mamba",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: use mamba (+mambaforge) for setting up environment (#2238)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d61aac254a19ac29e0a6",
    "number": 2237,
    "body": "Closes https://github.com/geopandas/geopandas/issues/1586",
    "head_branch": "pickle-pygeos",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix reading of pickle files with/without pygeos (#2237)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d61bac254a19ac29e0a7",
    "number": 2233,
    "body": "Closes #2209\r\n\r\nFrom what I could see the intersphinx mapping in `conf.py` already includes matplotlib so hpoing this works with no extra change needed.\r\n\r\nI wasn't sure how to test to see if this would pass through to the documentation so any advice there would be appreciated.",
    "head_branch": "gdf-plot-plt-documentation",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Include links to matplotlib as per #2209 (#2233)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d61cac254a19ac29e0a8",
    "number": 2232,
    "body": "A bit of CI maintenance:\r\n- Run on pushes and pull-requests to maintenance branches (starting with `0.`)\r\n- Lint job: Update to latest patch version [pre-commit/action](https://github.com/pre-commit/action) v2 of (currently [2.0.3](https://github.com/pre-commit/action/releases/tag/v2.0.3))\r\n- Update [codecov/codecov-action](https://github.com/codecov/codecov-action) to v2",
    "head_branch": "patch-2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: Run on maintenance branches, update actions (#2232)\n\n- Run on pushes and pull-requests to maintenance branches (starting with 0.)\r\n- Lint job: Update to latest patch version pre-commit/action@v2.0.3\r\n- Update codecov/codecov-action to v2"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d61dac254a19ac29e0a9",
    "number": 2228,
    "body": "xref https://github.com/python-visualization/folium/pull/1535",
    "head_branch": "folium_main",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: change folium master to main  (#2228)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d61eac254a19ac29e0aa",
    "number": 2227,
    "body": "The `GeoDataFrame.to_parquet` function does not match the signature of [`pandas.DataFrame.to_parquet`](https://github.com/pandas-dev/pandas/blob/a07561e5a33b78cb54d163e81dd7a4444ca41554/pandas/core/frame.py#L2686-L2695), so when the function is called from [`google.cloud.bigquery.client.Client.load_table_from_dataframe`](https://github.com/googleapis/python-bigquery/blob/9a5a888bad569c8c1d8d72994d428ed92fe5ac47/google/cloud/bigquery/client.py#L2669-L2678) with the `engine` keyword, it ends up passing that keyword along to pyarrow, which eventually results in a `TypeError`:\r\n```\r\n  File \"pyarrow/_parquet.pyx\", line 1377, in pyarrow._parquet.ParquetWriter.__cinit__\r\nTypeError: __cinit__() got an unexpected keyword argument 'engine'\r\n```\r\n\r\nWhile `engine` isn't useful for `GeoDataFrame.to_parquet` right now, it must not be passed along.",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: avoid passing engine along to _to_parquet function (#2227)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d61eac254a19ac29e0ab",
    "number": 2225,
    "body": "For https://github.com/geopandas/geopandas/issues/2217\r\n\r\nMany of the tests are already passing!\r\n\r\n- The tests reading from file like objects depends on https://github.com/geopandas/pyogrio/pull/25\r\n- There are still some failures caused by int32 vs int64 in the resulting dataframe (I think that's because pyogrio is \"honoring\" the type in the file, we should see if we can add a keyword to `assert_geodataframe_equal` to be flexible here)\r\n- Of course still needs more keyword handling, tests, docs, etc\r\n\r\nOne question is to what extent we want to \"translate\" our current keywords to pyogrio's, or rather pass-through kwargs as is. For example, currently, I am translating `rows` into `skip_features`/`max_features` for pyogrio.\r\n\r\ncc @brendan-ward ",
    "head_branch": "pyogrio",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: support using pyogrio in read_file / to_file with engine keyword (#2225)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d61fac254a19ac29e0ac",
    "number": 2224,
    "body": "_plot_polygon_collection eliminates empty shapes, but doesn't eliminate corresponding colors.  Operations like intersection that perform cropping can accidentally change colors of remaining shapes.\r\n\r\nHere's a simple demonstration of the problem:\r\n\r\n```python\r\nimport geopandas as gpd\r\nfrom shapely.geometry import box\r\n\r\ns = gpd.GeoSeries([\r\n    box(0,0,1,1),\r\n    box(2,2,3,3),\r\n], index=[\"r\", \"b\"])\r\n\r\n# correct:\r\ns.plot(color=[\"red\", \"blue\"])\r\n\r\n# incorrect: should show blue, but shows red\r\ns2 = s.intersection(box(2,2,4,4))\r\ns2.plot(color=[\"red\", \"blue\"])\r\n```",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: keep colors aligned with shapes, even when empty (#2224)\n\nCo-authored-by: Tyler <tharter@wisc.edu>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d620ac254a19ac29e0ad",
    "number": 2219,
    "body": "Closes #2207",
    "head_branch": "fix-extension-tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST/COMPAT: update GeometryArray getitem error type + fix tests (#2219)\n\n* TST/COMPAT: update GeometryArray getitem error type + fix tests\r\n\r\n* fix doctest for GEOS 3.10"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d621ac254a19ac29e0ae",
    "number": 2218,
    "body": null,
    "head_branch": "hhttps",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: fix link on contributing page (#2218)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d621ac254a19ac29e0af",
    "number": 2216,
    "body": "geopandas.read_file and GeoDataFrame.to_file now support the bool keyword argument \"verbose\"",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d622ac254a19ac29e0b0",
    "number": 2206,
    "body": "I am aware that this may change again soon with the plans to move from `Toblerity` org to `shapely` org but it is good to keep our CI green in the meantime anyway.",
    "head_branch": "shapely_main",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: use shapely main instead of master (#2206)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d623ac254a19ac29e0b1",
    "number": 2205,
    "body": "Also adds a conda environment yaml file for Python 3.10",
    "head_branch": "ci-py3.10",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: Add Python 3.10 to job matrix (#2205)\n\nAlso adds a conda environment yaml file for Python 3.10. This currently uses matplotlib-base instead of the regular matplotlib dependency."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d624ac254a19ac29e0b2",
    "number": 2203,
    "body": "Hi,\r\n\r\nThis PR fixes minor typos found in docstrings.",
    "head_branch": "fix/doc-typos",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Fix minor typos in docstrings (#2203)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d625ac254a19ac29e0b3",
    "number": 2202,
    "body": "Closes #2170.\r\n\r\nHave opted for just handling datetimes for now (not aware of any gis format supporting categorical features).\r\nI've opted not to map the entire schema, it doesn't seem necessary for int and float fields.\r\n\r\nHandling miliseconds is a little bit awkward right now.\r\nProbably also need explicitly check datetimes with timezones.",
    "head_branch": "gpkg_schema_roundtrip",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Round trip I/O of datetime fields for supported formats (#2202)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d626ac254a19ac29e0b4",
    "number": 2200,
    "body": "Closes #1587 \r\n\r\nThis is a first pass at implementing zipping the output of `to_file`. Thus far I've opted to do this based on file extension rather than an argument to `to_file`, as having to deal with the wrong file extension e.g. a `out.gpkg` actually being a zipfile containing a geopackage seems painful and a rather obtuse edge case to handle. \r\n\r\nI perhaps haven't done this the \"proper\" way by using a `vsizip` path to fiona. I've spent a bit of time experimenting with this but haven't been able to make it work. The opening blurb in the fiona docs \"iona can read and write real-world data using multi-layered GIS formats and zipped virtual file systems\" would suggest it's possible, but I can't find any examples online, and the tests for fiona only seem to checking reading zipped files rather than writing.\r\n\r\nThe comments in #1124 also seem to suggest this isn't possible, albeit from a couple of years ago.\r\n\r\nAlso am a bit wary of breaking `to_file` with s3 URIs, so am not attempting to handle the `s3+zip://` case yet (I think this would be a reason to get this working zipping using fiona/ gdal directly, since if you've zipped locally to a temp dir, we'd have to use boto3 directly to upload the zip, rather than letting fiona do all that (I think at least).",
    "head_branch": "save_to_zip",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d626ac254a19ac29e0b5",
    "number": 2197,
    "body": "Differences to `st_make_grid`:\r\n- It is not possible to create rectangular polygons. If rectangular polygons are desired, the input `cell_size` would need to become a tuple. However, the hexagonal grid would then be over specified. I would suggest to split the function into two separate functions, if rectangular arrays should be implemented.\r\n-  The function doesn't take # cells as input. I suggest to either provide `cell_size` or # of cells as input but not both.\r\n\r\nPotential improvements:\r\n- There might be a way to improve performance of the list comprehensions in l. 124/199 using pygeos. I'm not familiar enough with that package and I did not find an immediate solution in the docs.\r\n\r\nFurther comments:\r\n- Despite creating an environment from the `doc/environment.yml`, I needed to install `pandoc` before i could create the documentation. I guess this package should be added to the yml file.\r\n\r\nQuestions:\r\n- Would it be helpful to create a notebook for the documentation?\r\n- Would it make sense to expose the function also as method to the GeoDataFrame and GeoSeries classes?",
    "head_branch": "make-grid",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d627ac254a19ac29e0b6",
    "number": 2195,
    "body": "Is this definition correct?\r\n\r\nI asked something similar with movingpandas recently and wanted to check that is also true here (https://github.com/anitagraser/movingpandas/commit/38e27c3a6331ff08d75b310e8fb702e3b4af5182)",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: distance units in sjoin_nearest (#2195)\n\n* DOC: distance units in sjoin_nearest\r\n\r\n* rm white space\r\n\r\n* Update sjoin.py\r\n\r\n* DOC: move units to description\r\n\r\n* rm white space\r\n\r\n* Update geopandas/tools/sjoin.py\r\n\r\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>\r\n\r\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d628ac254a19ac29e0b7",
    "number": 2192,
    "body": "As mentioned in https://github.com/geopandas/xyzservices/blob/main/CHANGELOG.md#xyzservices-2021100-october-19-2021\r\n\r\n@martinfleis I am not sure if we want to care about being able to run the tests with older xyzservices versions? (or we could change the test a bit to not rely on the exact number)",
    "head_branch": "ci-xyz",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: fix explore() tests for change in CartoDB max zoom level in latest xyzservices (#2192)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d629ac254a19ac29e0b8",
    "number": 2191,
    "body": "Potentially fixes https://github.com/geopandas/geopandas/issues/2187. Just a quick PR to see what CI does with this.",
    "head_branch": "folium-version",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d62aac254a19ac29e0b9",
    "number": 2184,
    "body": "@jorisvandenbossche This is the kind of thing that I have found to be useful when hunting for rare edge cases that can then be boiled down to unit tests.",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d62aac254a19ac29e0ba",
    "number": 2183,
    "body": "There are still more issues in https://github.com/geopandas/geopandas/milestone/19, but releasing is also quick and cheap, so we don't necessarily need to wait until all are done.\r\n\r\nI already included https://github.com/geopandas/geopandas/pull/2177, since that PR is mostly done.\r\n\r\n\r\nAlso closes #2169",
    "head_branch": "changelog-0.10.2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC/RLS: add changelog for 0.10.2 release (#2183)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d62bac254a19ac29e0bb",
    "number": 2181,
    "body": "Fixes #2180\r\n\r\nIt should also fix the CI failures in #2177 ",
    "head_branch": "unary_union_shapely",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: support None in unary_union (shapely) (#2181)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d62cac254a19ac29e0bc",
    "number": 2179,
    "body": "xref https://github.com/geopandas/geopandas/issues/1667#issuecomment-940303204\r\n\r\n",
    "head_branch": "overlay-warning",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: avoid warning from deprecated explode in clip() (#2179)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d62dac254a19ac29e0bd",
    "number": 2177,
    "body": "Fixes #2176 \r\n\r\nI still need to fabricate some tests, this is a very edge case.",
    "head_branch": "overlay_coll",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REGR: overlay keep_geom_type issue with collections of different types (#2177)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d62eac254a19ac29e0be",
    "number": 2175,
    "body": "Closes #2173 ",
    "head_branch": "explore_vmin",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: explore() vmin, vmax ignored if 0 (#2175)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d62eac254a19ac29e0bf",
    "number": 2172,
    "body": "Closes #799\r\n\r\nFixes the situation with `how=\"intersection\"` when gdfs bounds are overlapping but there's no intersection between them.",
    "head_branch": "overlay_empty_sindex",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REGR: fix non-intersecting overlay (#2172)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d62fac254a19ac29e0c0",
    "number": 2166,
    "body": "Fixes #2165 \r\n\r\n@jorisvandenbossche I think that this should work. Will add the test in a minute.",
    "head_branch": "mapclassify_regr",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REGR: mapclassify formatting regression (#2166)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d630ac254a19ac29e0c1",
    "number": 2164,
    "body": "In cases of using `method=\"difference\"` in overlays, we were not applying\r\nthe `keep_geom_type=True` logic. This change makes all overlay methods proceed\r\nthrough that step. Closes #2163.\r\n",
    "head_branch": "issue2163",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "BUG: Use keep_geom_type logic for all overlay methods (#2164)\n\nIn cases of using method=\"difference\" in overlays, we were not applying\r\nthe keep_geom_type logic. This change makes all overlay methods proceed\r\nthrough that step."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d631ac254a19ac29e0c2",
    "number": 2162,
    "body": "This updates the link to Matthew Brett's Pydagogue site, which is now at https://matthew-brett.github.io/pydagogue/.\r\n\r\nThanks, and please let me know if you need anything else!\r\n\r\nSigned-off-by: Hugh Brown (Saint Aardvark the Carpeted) <aardvark@saintaardvarkthecarpeted.com>",
    "head_branch": "docfix-update-link-to-pydagogue",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Update link to Pydagogue site in contributing.rst (#2162)\n\nSigned-off-by: Hugh Brown (Saint Aardvark the Carpeted) <aardvark@saintaardvarkthecarpeted.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d632ac254a19ac29e0c3",
    "number": 2161,
    "body": "Make explode() handle empty singular geom\r\n```python\r\ngs = gpd.GeoSeries(Point())\r\ngs.explode()  # -> AttributeError: 'Point' object has no attribute 'geoms'\r\n```\r\n\r\nThe above example throws an error on line 925, as an empty singular geometry object has `s.type == \"GeometryCollection\"`, but does not have the attribute `geoms`.\r\n\r\nThe proposed change checks if the geom is empty, and thus is passed on to the `else` statement on line 927.",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d632ac254a19ac29e0c4",
    "number": 2159,
    "body": "Fixes bug mentioned in #2158",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d633ac254a19ac29e0c5",
    "number": 2157,
    "body": "Fixes #2156\r\n\r\nThe bbox check makes sense only for `intersection`, not the other overlay options.",
    "head_branch": "overlay_regr",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REGR: avoid bbox check in overlay if how != intersection (#2157)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d634ac254a19ac29e0c6",
    "number": 2151,
    "body": "Add an OGC CRS definition to the GeoJSON dictionary interface in `_to_geo()`, which propagates to `__geo_interface__` and `to_dict()`.\r\nClose #1774.",
    "head_branch": "enh-to-json-crs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: include crs in to_json  (#1774) (#2151)\n\nCo-authored-by: Jan Šimbera <jan.simbera@nanoenergies.cz>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d635ac254a19ac29e0c7",
    "number": 2150,
    "body": "Together with #1984 closes #2141 .",
    "head_branch": "methods",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "API: expose sjoin_nearest, clip and overlay as methods (#2150)\n\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d636ac254a19ac29e0c8",
    "number": 2149,
    "body": "@martinfleis Follow-up on PR #1936 to allow from_xy to reuse indices of input coordinate Series when `x.index is y.index and index is None` (and the same for z if given), to allow one to not specify the index in the typical case when both x and y come from the same dataframe.",
    "head_branch": "enh-geoseries-from-xy",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: GeoSeries.from_xy reuse index from input Series if identical (#1853 contd.) (#2149)\n\nCo-authored-by: Jan Šimbera <jan.simbera@vodafone.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d637ac254a19ac29e0c9",
    "number": 2148,
    "body": "This is based on https://github.com/geopandas/geopandas/pull/1909 (thanks to @bstadlbauer for that!), but only keeping the part about doing the actual clipping for all geometry types together, instead of splitting the original geodataframe in chunks per geometry type, clip those separately, and then concat (+ sort to preserve original order) them again.\r\n\r\nThis should keep the performance improvement of the original PR (and also the MultiPoint bug), but the diff should be a bit easier to follow since it has less other changes.\r\n\r\nWhile doing this, I noticed that I could do the clipping with preserving the original order by setting the intersections with a mask, which avoids concatting / sorting the point/non-point parts. So that's something added compared to https://github.com/geopandas/geopandas/pull/1909",
    "head_branch": "fix-multipoint-clipping",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Fix multipoint clipping / PERF: query for all geometry types at once (#2148)\n\nCo-authored-by: bstadlbauer <11799671+bstadlbauer@users.noreply.github.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d637ac254a19ac29e0ca",
    "number": 2147,
    "body": "Closes https://github.com/geopandas/geopandas/issues/1977\r\n\r\nThis adds a new keyword `return_all=True/False` (with a default of True, so matching the `nearest_all` behaviour). But other ideas for the name of the keyword are certainly welcome as well.\r\n\r\nThis already combines both methods and updates the code/tests using it. Since this adds new functionality (currently unique to geopandas), i.e. using a `max_distance` when only wanting a single return value, I will also need to add new tests for that (still to do).",
    "head_branch": "sindex-nearest",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Combine sindex.nearest/nearest_all in single method (#2147)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d638ac254a19ac29e0cb",
    "number": 2145,
    "body": "This removes the suffix `_how_left` from the names of a few test cases that now test both `how='left'` and `how='inner'` as updated in #2143 \r\n\r\nWith the exception of `test_sjoin_nearest_left`, which was left as is on purpose, this lets us use `_how_right` suffix specifically when testing `how='right'` but otherwise leaves left / inner test cases without a suffix.\r\n\r\n(tiny fix, so if you don't agree just close and don't merge; no need to debate)",
    "head_branch": "rename_sjoin_nearest_tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Rename sjoin_nearest test cases to match implementation (#2145)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d639ac254a19ac29e0cc",
    "number": 2144,
    "body": "Currently, for a typical left/inner `sjoin`, we preserve the index name of the left dataframe, if it is set. But the index of the right dataframe always becomes \"index_right\", even if it has a proper name of its own. I _think_ we should preserve the name if there is one.\r\n\r\nCloses #846",
    "head_branch": "sjoin-right-index",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG/API: also preserve right index name in spatial join (#2144)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d63aac254a19ac29e0cd",
    "number": 2143,
    "body": "Closes #2140\r\n\r\ncc @adriangb ",
    "head_branch": "sjoin-nearest-inner",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: support how=\"inner\" in sjoin_nearest (#2143)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d63bac254a19ac29e0ce",
    "number": 2139,
    "body": "See https://github.com/geopandas/geopandas/issues/2123#issuecomment-927178129\r\n\r\nWe have had several reports with `AttributeError: partially initialized module 'fiona' has no attribute '_loading' (most likely due to a circular import)` or `AttributeError: module 'fiona' has no attribute '_loading'` errors. \r\nThis PR certainly doesn't solve all of those issues (eg I don't expect it fixes the case where import fiona before geopandas helps), but I could verify that it fixes one specific case: if your fiona install is broken, it currently also breaks import geopandas (with the second attribute error). \r\n\r\nThis seems to be due to how fiona importing works: `import fiona` can fail with a clear ImportError, but a subsequent `from fiona import Env` then gives the confusing AttributeError. \r\nAnd because we still tried `from fiona import Env` even if the main fiona import failed, we triggered this error.",
    "head_branch": "fiona-attributeerror",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix importing of Fiona to avoid AttributeError on broken fiona install (#2139)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d63cac254a19ac29e0cf",
    "number": 2138,
    "body": "Closes #2129 (unless there is actually an api discussion and this is somehow a feature and not a bug).\r\n\r\n",
    "head_branch": "fix_constructor_geom_col_set",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: GeoDataFrame(gdf) constructor: preserve geometry column name (#2138)\n\n* BUG: fix and test GH2129\r\n\r\n* CLN: move test to where it it was tested in the past\r\n\r\n* make crs warning tests more explicit\r\n\r\n* add crs mismatch warning in for this case\r\n\r\n* CLN: revise approach to fix a bunch of edge cases\r\n\r\n* Apply suggestions from code review\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* clean up comments\r\n\r\n* Save resetting geom col for gdf input\r\n\r\n* Update geopandas/geodataframe.py\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d63cac254a19ac29e0d0",
    "number": 2137,
    "body": "While running the benchmarks, I've noticed that `mixed` plotting fails. The fixture creation raises `ValueError: cannot set using a list-like indexer with a different length than the value`.\r\n\r\nThe change is only on lines 61, 61, the rest is just `black` formatting.\r\n\r\n<details>\r\n\r\n```py\r\nValueError: cannot set using a list-like indexer with a different length than the value\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n/var/folders/kp/fxnnw89x5qbb9gryn507p03c0000gn/T/ipykernel_11467/436023914.py in <module>\r\n      8 \r\n      9 geoms = g1\r\n---> 10 geoms.iloc[np.random.randint(0, 100, 50)] = g2\r\n     11 geoms.iloc[np.random.randint(0, 100, 33)] = g3\r\n     12 \r\n\r\n/opt/miniconda3/envs/geo_dev/lib/python3.9/site-packages/pandas/core/indexing.py in __setitem__(self, key, value)\r\n    721 \r\n    722         iloc = self if self.name == \"iloc\" else self.obj.iloc\r\n--> 723         iloc._setitem_with_indexer(indexer, value, self.name)\r\n    724 \r\n    725     def _validate_key(self, key, axis: int):\r\n\r\n/opt/miniconda3/envs/geo_dev/lib/python3.9/site-packages/pandas/core/indexing.py in _setitem_with_indexer(self, indexer, value, name)\r\n   1730             self._setitem_with_indexer_split_path(indexer, value, name)\r\n   1731         else:\r\n-> 1732             self._setitem_single_block(indexer, value, name)\r\n   1733 \r\n   1734     def _setitem_with_indexer_split_path(self, indexer, value, name: str):\r\n\r\n/opt/miniconda3/envs/geo_dev/lib/python3.9/site-packages/pandas/core/indexing.py in _setitem_single_block(self, indexer, value, name)\r\n   1966 \r\n   1967         # actually do the set\r\n-> 1968         self.obj._mgr = self.obj._mgr.setitem(indexer=indexer, value=value)\r\n   1969         self.obj._maybe_update_cacher(clear=True)\r\n   1970 \r\n\r\n/opt/miniconda3/envs/geo_dev/lib/python3.9/site-packages/pandas/core/internals/managers.py in setitem(self, indexer, value)\r\n    353 \r\n    354     def setitem(self: T, indexer, value) -> T:\r\n--> 355         return self.apply(\"setitem\", indexer=indexer, value=value)\r\n    356 \r\n    357     def putmask(self, mask, new, align: bool = True):\r\n\r\n/opt/miniconda3/envs/geo_dev/lib/python3.9/site-packages/pandas/core/internals/managers.py in apply(self, f, align_keys, ignore_failures, **kwargs)\r\n    325                     applied = b.apply(f, **kwargs)\r\n    326                 else:\r\n--> 327                     applied = getattr(b, f)(**kwargs)\r\n    328             except (TypeError, NotImplementedError):\r\n    329                 if not ignore_failures:\r\n\r\n/opt/miniconda3/envs/geo_dev/lib/python3.9/site-packages/pandas/core/internals/blocks.py in setitem(self, indexer, value)\r\n   1489             indexer = indexer[0]\r\n   1490 \r\n-> 1491         check_setitem_lengths(indexer, value, self.values)\r\n   1492         self.values[indexer] = value\r\n   1493         return self\r\n\r\n/opt/miniconda3/envs/geo_dev/lib/python3.9/site-packages/pandas/core/indexers.py in check_setitem_lengths(indexer, value, values)\r\n    174                     and len(indexer[indexer]) == len(value)\r\n    175                 ):\r\n--> 176                     raise ValueError(\r\n    177                         \"cannot set using a list-like indexer \"\r\n    178                         \"with a different length than the value\"\r\n\r\nValueError: cannot set using a list-like indexer with a different length than the value\r\n```\r\n\r\n</details>",
    "head_branch": "bench_plotting_mixed",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BENCH: fix plotting fixture (#2137)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d63dac254a19ac29e0d1",
    "number": 2136,
    "body": "Xref https://github.com/geopandas/geopandas/issues/2076#issuecomment-927163830\r\n\r\nThis gives a 3x speed-up in the `sindex.BenchQuery.time_query('intersects', 'points', 'points')` speed-up case (the one with the biggest slowdown). \r\n\r\nIt's in the scalar `query` (not `query_bulk`), so typically you won't call this method many times in a loop like the benchmark does (because you can then use `query_bulk`), but it's an easy fix, so can do that anyway.\r\n\r\ncc @adriangb ",
    "head_branch": "perf-valid-query-predicates",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "PERF: pre-define PyGEOSSTRTreeIndex.valid_query_predicates (#2136)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d63eac254a19ac29e0d2",
    "number": 2135,
    "body": "Closes https://github.com/geopandas/geopandas/issues/2116\r\n\r\nThis removes it altogether. Alternative is put it behind a `if left_df.has_sindex:` check.",
    "head_branch": "sjoin-bounds-check",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "PERF: avoid doing total_bounds calculation in sjoin (#2135)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d63fac254a19ac29e0d3",
    "number": 2134,
    "body": "In preparation of https://github.com/geopandas/geopandas/issues/2076",
    "head_branch": "changelog-0.10",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC/RLS: add changelog for 0.10 release (#2134)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d640ac254a19ac29e0d4",
    "number": 2131,
    "body": "Fixing some formatting issues and minimising the number of warnings emitted by sphinx, so it is easier to actually catch potential issues.\r\n\r\n@jorisvandenbossche One note for the Changelog - when doing nested lists we need to keep a blank line in between, to ensure the RST renders correctly online.",
    "head_branch": "docs_warnings",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: minimise warnings from sphinx (#2131)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d641ac254a19ac29e0d5",
    "number": 2127,
    "body": "Fixes #2126",
    "head_branch": "2126",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: path_effects incorrectly treated in plot (#2127)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d641ac254a19ac29e0d6",
    "number": 2125,
    "body": "Let's start debugging #2124 . The error comes from `nbsphinx` and happened after changes to `scheme`. Commenting out all choropleth plots within Jupyter notebooks.\r\n\r\nCloses #2124",
    "head_branch": "rtd_debug",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: fix RTD builds (#2125)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d642ac254a19ac29e0d7",
    "number": 2122,
    "body": null,
    "head_branch": "test-concurrencty",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d643ac254a19ac29e0d8",
    "number": 2121,
    "body": "Attempt to fix #2121; I'm only 85% sure this will work 😛 ",
    "head_branch": "fix-workflow",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "GHA: Use github.ref instead of github.ref_head in concurrency group (#2121)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d644ac254a19ac29e0d9",
    "number": 2120,
    "body": "https://docs.github.com/en/actions/learn-github-actions/workflow-syntax-for-github-actions#concurrency\r\n\r\nThis avoids workflows from queuing up if a lot of commits are made, e.g. if accepting suggestions in a PR it's common to make 20 commits in <2 minutes -> it can take hours for the last one to finish running since there's a limited number of runners per repo",
    "head_branch": "patch-2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "GHA: cancel existing jobs when new commits are added (#2120)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d645ac254a19ac29e0da",
    "number": 2118,
    "body": "Motivated by the pretty serious performance regression on overlays\r\nI accidentally introduced in #1582, and reported in #2089, here's a new\r\nbenchmark for overlays that makes the regression more apparent than the\r\nexisting overlay benchmarks.\r\n\r\nOn master:\r\n```\r\n[  0.07%] ··· overlay.Countries.time_overlay                                                                        3/5 failed\r\n[  0.07%] ··· ====================== ===========\r\n                       how                      \r\n              ---------------------- -----------\r\n                   intersection        337±6ms  \r\n                      union             failed  \r\n                     identity           failed  \r\n               symmetric_difference     failed  \r\n                    difference        143±0.8ms \r\n              ====================== ===========\r\n\r\n[  0.09%] ··· overlay.ManyPoints.time_overlay                                                                               ok\r\n[  0.09%] ··· ====================== ===========\r\n                       how                      \r\n              ---------------------- -----------\r\n                   intersection        299±4ms  \r\n                      union            510±8ms  \r\n                     identity          524±7ms  \r\n               symmetric_difference   229±0.3ms \r\n                    difference        177±0.7ms \r\n              ====================== ===========\r\n\r\n[  0.11%] ··· overlay.Small.time_overlay                                                                            3/5 failed\r\n[  0.11%] ··· ====================== =============\r\n                       how                        \r\n              ---------------------- -------------\r\n                   intersection       14.6±0.07ms \r\n                      union              failed   \r\n                     identity            failed   \r\n               symmetric_difference      failed   \r\n                    difference        5.20±0.09ms \r\n              ====================== =============\r\n```\r\n\r\nOn #2103:\r\n```\r\n[ 22.22%] ··· overlay.Countries.time_overlay                                                                        3/5 failed\r\n[ 22.22%] ··· ====================== ===========\r\n                       how                      \r\n              ---------------------- -----------\r\n                   intersection        78.9±1ms \r\n                      union             failed  \r\n                     identity           failed  \r\n               symmetric_difference     failed  \r\n                    difference        141±0.7ms \r\n              ====================== ===========\r\n\r\n[ 27.78%] ··· overlay.ManyPoints.time_overlay                                                                               ok\r\n[ 27.78%] ··· ====================== =============\r\n                       how                        \r\n              ---------------------- -------------\r\n                   intersection       9.57±0.01ms \r\n                      union            224±0.4ms  \r\n                     identity           226±1ms   \r\n               symmetric_difference     219±2ms   \r\n                    difference          174±2ms   \r\n              ====================== =============\r\n\r\n[ 33.33%] ··· overlay.Small.time_overlay                                                                            3/5 failed\r\n[ 33.33%] ··· ====================== =============\r\n                       how                        \r\n              ---------------------- -------------\r\n                   intersection        7.22±0.1ms \r\n                      union              failed   \r\n                     identity            failed   \r\n               symmetric_difference      failed   \r\n                    difference        5.14±0.05ms \r\n              ====================== =============\r\n```\r\n\r\nI initially thought the existing benchmarks didn't catch this at all, but I was a bit out of practice with `asv`, and wasn't correctly comparing the branch @jorisvandenbossche is working on with the master branch. ",
    "head_branch": "overlay-benchmarks",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "PERF: Add new overlay benchmarks (#2118)\n\nMotivated by the pretty serious performance regression on overlays\r\nI accidentally introduced in #1582, and reported in #2089, here's a new\r\nbenchmark for overlays that makes the regression more apparent than the\r\nexisting overlay benchmarks."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d645ac254a19ac29e0db",
    "number": 2117,
    "body": "This PR is WIP.\r\n\r\nIssue: https://github.com/geopandas/geopandas/issues/2090\r\n\r\nBasically, the problem is that geopandas assumes that `public` should be the default schema if the `schema` parameter is omitted or set to `None` in `geopandas.GeoDataFrame.to_postgis()`. This is missing a common misconception about postgres in general - The `public` schema is not necessarily the \"default schema\", but rather the \"default schema configured by default\". This can be changed via a `search_path`, which can be set at user or session level. So if you set the search_path at the SQLAlchemy level, Geopandas incorrectly assumes that `public` is where the data should be written to unless explicitly stated. It should use the `search_path` as per the connection.\r\n\r\nI should have done this before, but I went back and made sure that this intended behaviour is also present in pandas. It is. Pandas respects the `search_path` at connection level and does not ever appear to assume `public` to be the default schema.\r\n\r\nThis ended up being a bit tricky, because the `search_path` can actually be set inconveniently or even nonsensically, with schemas included which are non-writeable (for the current role), or even non-existent. So it has to try each one in order until it works. And it can fail for different reasons, including:\r\n\r\n* Schema does not exist\r\n* Schema exists, but is not writeable for the current role\r\n\r\nSo I used exception handling to move along the `search_path` entries, until it breaks off upon finding a valid schema. If nothing works, it raises a `RunfimeError` indicating that the current `search_path` doesn't allow the table to be written anywhere.\r\n\r\nI did not figure out how the PostGIS tests work, they look kind of tricky. So for now everything is just in a single \"test\" which just asserts True. I will work on making proper tests, but I think that the main meat of the changes to `geopandas/io/sql.py` are fixed.",
    "head_branch": "bugfix-2090-use-schema-search_path",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d646ac254a19ac29e0dc",
    "number": 2115,
    "body": "Fixes #1870 \r\n\r\nDecided to have another look at this - was actually trying to construct a simple case to report an issue to Pandas itself as discussed in the above thread. I'm actually not convinced it really is a bug in pandas (more on that below) and so this is a fix in geopandas.\r\n\r\nIt was pretty straightforward to overload convert_dtypes, and I've added tests for some obvious edge cases.\r\n\r\n-----------------------------------------------------------------------\r\n\r\nThis is the example that makes me question whether this is really a bug in pandas / or perhaps whether this use case is supported by pandas:\r\n```python\r\nimport pandas as pd\r\n\r\nclass SubclassedSeries(pd.Series):\r\n    @property\r\n    def _constructor(self):\r\n        return SubclassedSeries\r\n\r\n    @property\r\n    def _constructor_expanddim(self):\r\n        return SubclassedDataFrame\r\n\r\n\r\nclass SubclassedDataFrame(pd.DataFrame):\r\n    @property\r\n    def _constructor(self):\r\n        return SubclassedDataFrame\r\n\r\n    @property\r\n    def _constructor_sliced(self):\r\n        return SubclassedSeries\r\n\r\n\r\ntest_df = SubclassedSeries([1, 2]).to_frame(name='a')\r\ntest_df['b'] = pd.Series([3, 4])\r\nprint(type(test_df['b']))  # = <class '__main__.SubclassedSeries'>\r\n# The type of 'b' is going to be consistently subclassed series\r\n# Issue arises in geopandas because `_constructor_sliced` is not defined, and then getitem promotes\r\n# series up to GeoSeries. Without doing this, I don't think a mix of series types in a df is possible?\r\n```\r\nIn the example case of subclassing pandas (https://pandas.pydata.org/pandas-docs/stable/development/extending.html#subclassing-pandas-data-structures), this kind of problem won't occur, because all columns of the `SubclassedDataFrame` will be returned as `SubclassedSeries`.\r\n\r\nI'm not sure if the pattern of mixed series dtypes (GeoSeries and Series) is used elsewhere, so didn't think it was worth raising on the pandas side.\r\n\r\n\r\n",
    "head_branch": "convert_dtypes_1870",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: convert_dtypes() converts GeoDataFrame to DataFrame (#2115)\n\n* TST: test documenting existing convert dtypes behaviour\r\n\r\n* TST: fix tests, compare to proper reference case\r\n\r\n* BUG: overload convert_dtypes to fix GH1870\r\n\r\n* COMPAT: update tests to handle pandas 1.0 and 0.25\r\n\r\n* DOC: update wording to suggested\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* CLN: simplify to *args and **kwargs following suggestion\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d647ac254a19ac29e0dd",
    "number": 2114,
    "body": "xref #1896",
    "head_branch": "add-doc-style-guide",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Add doc style guide (#2114)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d648ac254a19ac29e0de",
    "number": 2112,
    "body": "The following issue happens, periodically but inconsistently, when geopandas gets imported in a module that contains a function that runs on a dask cluster, although in this case that function does not actually make use of geopandas.\r\n\r\n<details><summary>AttributeError: partially initialized module 'fiona' has no attribute '_loading' (most likely due to a circular import)</summary>\r\n\r\n```python\r\n/home/conda/store/9c828ea9bf6dc65c4cd4f7331f255b67f76ac3534f6383157d0ce0ddc5bdb8e2/lib/python3.8/site-packages/distributed/protocol/pickle.py in loads()\r\n     57 def loads(x):\r\n     58     try:\r\n---> 59         return pickle.loads(x)\r\n     60     except Exception:\r\n     61         logger.info(\"Failed to deserialize %s\", x[:10000], exc_info=True)\r\n\r\n/root/.local/lib/python3.8/site-packages/mypkg/api/df.py in <module>\r\n\r\n/home/conda/store/9c828ea9bf6dc65c4cd4f7331f255b67f76ac3534f6383157d0ce0ddc5bdb8e2/lib/python3.8/site-packages/geopandas/__init__.py in <module>\r\n      5 from geopandas.array import points_from_xy  # noqa\r\n      6 \r\n----> 7 from geopandas.io.file import _read_file as read_file  # noqa\r\n      8 from geopandas.io.arrow import _read_parquet as read_parquet  # noqa\r\n      9 from geopandas.io.arrow import _read_feather as read_feather  # noqa\r\n\r\n/home/conda/store/9c828ea9bf6dc65c4cd4f7331f255b67f76ac3534f6383157d0ce0ddc5bdb8e2/lib/python3.8/site-packages/geopandas/io/file.py in <module>\r\n     10 \r\n     11 try:\r\n---> 12     import fiona\r\n     13 \r\n     14     fiona_import_error = None\r\n\r\n/home/conda/store/9c828ea9bf6dc65c4cd4f7331f255b67f76ac3534f6383157d0ce0ddc5bdb8e2/lib/python3.8/site-packages/fiona/__init__.py in <module>\r\n     83 \r\n     84 import fiona._loading\r\n---> 85 with fiona._loading.add_gdal_dll_directories():\r\n     86     from fiona.collection import BytesCollection, Collection\r\n     87     from fiona.drvsupport import supported_drivers\r\n\r\nAttributeError: partially initialized module 'fiona' has no attribute '_loading' (most likely due to a circular import)\r\n\r\n```\r\n\r\n</details>\r\n\r\nThis seems like a harmless enough change, but feel free to close this PR if the change is undesirable.\r\n",
    "head_branch": "fix_fiona_import",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d649ac254a19ac29e0df",
    "number": 2111,
    "body": "cfr https://github.com/geopandas/dask-geopandas/pull/103#issuecomment-917465318",
    "head_branch": "parquet-read-without-metadata",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix reading Parquet file without metadata (proper error message) (#2111)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d649ac254a19ac29e0e0",
    "number": 2110,
    "body": "fixes #2109 \r\n\r\nWith the following setup:\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nimport geopandas as gpd\r\n\r\nouter_index = (1, 2)\r\nnr_pts = 10000\r\nindex = pd.MultiIndex.from_arrays(\r\n    [[outer_index] * nr_pts, np.arange(nr_pts)],\r\n    names=(\"first\", \"second\"),\r\n)\r\ndf = gpd.GeoDataFrame(\r\n    {\"vals\": np.arange(nr_pts)},\r\n    geometry=[MultiPoint([(x, x), (x, 0)]) for x in range(nr_pts)],\r\n    index=index,\r\n)\r\n```\r\n\r\n, timing `test_df = df.explode()` I get:\r\n`master`: `62.3 ms ± 1.06 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)`\r\n`explode-perf`: `51.4 ms ± 1.47 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)`\r\n",
    "head_branch": "explode-perf",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "PERF: MultiIndex creation in explode (#2110)\n\nGo back to using `from_arrays `instead of `from_tuples` to create the\r\nMultiIndex of the GeoSeries resulting from `explode`."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d64aac254a19ac29e0e1",
    "number": 2107,
    "body": "Closes https://github.com/geopandas/geopandas/issues/2071",
    "head_branch": "feature/storage-options",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Add storage_options to read_parquet (#2107)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d64bac254a19ac29e0e2",
    "number": 2106,
    "body": "Closes #2105",
    "head_branch": "wkb_hex",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Automatically handle hex with shapely in from_wkb (#2106)\n\n* ENH: Automatically handle hex with shapely wkb\r\n\r\n* Update geopandas/tests/test_array.py\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d64cac254a19ac29e0e3",
    "number": 2103,
    "body": "Closes #2089\r\n\r\nThis already separates the two filtering steps (for collections vs normal geometries, first converting collections to normal geometries where possible, and only then filtering the normal geometries). \r\nThen, next steps I still need to do: 1) do the processing of collections only for geometry collections, and 2) avoid dissolve for this (although, if only doing this for a small subset, the performance bottleneck of using dissolve might not be problematic), and 3) add a benchmark for this.",
    "head_branch": "perf-overlay-regression",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "PERF: fix performance regression in overlay keep_geometry_type=True (in checking for GeometryCollection) (#2103)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d64dac254a19ac29e0e4",
    "number": 2102,
    "body": "Improves the performance of dissolve by only performing the necessary unary_unions, treating separately the\r\ngeometries that need to be aggregated and those which do not, as discussed in #2089.\r\n\r\nSome quick benchmarks yielded a ~50x improvement for the GeoDataFrame that is passed to `dissolve` by `overlay` in the example given in #2089, which actually had no geometry to dissolve. I also timed it on the GeoDataFrame  corresponding to the [`overlay` user guide](https://geopandas.org/docs/user_guide/set_operations.html#overlay-countries-example), and obtained a more modest improvement of ~10%.\r\n\r\nI ran some tests and in theory this should almost close the whole gap between before/after the regression discussed in #2089  since `dissolve` now accounts for just a few percents of the runtime of `overlay` in the example mentioned there. ~~However I'm getting contradictory results in my benchmarks which I don't really understand atm, I'll have another look at it later and report what I found.~~ well I was running them in  an environment which didn't have pygeos for some reason, it turns out I get a ~40x improvement!",
    "head_branch": "dissolve-perf",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d64dac254a19ac29e0e5",
    "number": 2101,
    "body": "overlay based on symmetric_difference started [failing](https://github.com/geopandas/geopandas/runs/3515474201?check_suite_focus=true) on pandas master because we used an outer join based on columns full of NaNs. Refactoring the implementation to avoid it.\r\n\r\n",
    "head_branch": "overlay_symm",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: skip tests of in overlay symmetric_difference under pandas 1.3.3 (#2101)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d64eac254a19ac29e0e6",
    "number": 2100,
    "body": "This addresses the 3 places (GeoDataFrame twice and GeoSeries) where supplying crs which conflict with the underlying data was raising a FutureWarning, and switches these over to ValueErrors. Have only changed these as they are marked with `#TODO: raise error in 0.9 or 0.10`, but there are a number of other FutureWarnings throughout the code (the first of which is something that should change in this branch too):\r\n```bash\r\ngrep -rw . -e 'FutureWarning' --exclude *.pyc | cut -d: -f1 | uniq -c\r\n      1 ./doc/source/docs/user_guide/projections.rst\r\n      2 ./geopandas/array.py\r\n      1 ./geopandas/base.py\r\n      2 ./geopandas/geodataframe.py\r\n      5 ./geopandas/geoseries.py\r\n      4 ./geopandas/plotting.py\r\n      1 ./geopandas/sindex.py\r\n      3 ./geopandas/tests/test_array.py\r\n      4 ./geopandas/tests/test_crs.py\r\n      2 ./geopandas/tests/test_geom_methods.py\r\n      4 ./geopandas/tests/test_geoseries.py\r\n      1 ./geopandas/tests/test_sindex.py\r\n      3 ./geopandas/tools/crs.py\r\n      2 ./geopandas/tools/sjoin.py\r\n      2 ./geopandas/tools/tests/test_sjoin.py\r\n      3 ./geopandas/tools/tests/test_tools.py\r\n      1 ./geopandas/_vectorized.py\r\n```\r\nNot sure if there is a desire to address some of these now as well (or at least least thing about how soon they should happen).\r\n\r\nThere is perhaps some sense in dealing with other crs related future warnings all in the same release? Going through the list very quickly, these seem to fit:\r\n- `geodataframe.py` in both `__init__` and `crs`\r\n```python\r\nwarnings.warn(\r\n                \"Assigning CRS to a GeoDataFrame without a geometry column is now \"\r\n                \"deprecated and will not be supported in the future.\",\r\n                FutureWarning,\r\n                stacklevel=2,\r\n            )\r\n```\r\n- `tools/crs.py`\r\n```python\r\n\"explicit_crs_from_epsg is deprecated. \"\r\n        \"You can set the epsg on the GeoDataFrame (gdf) using gdf.crs=epsg\",\r\n```\r\n```python\r\n\"epsg_from_crs is deprecated. \"\r\n        \"You can get the epsg code from GeoDataFrame (gdf) \"\r\n        \"using gdf.crs.to_epsg()\",\r\n```\r\n\r\nIn addition, the GeoSeries warning below has been for just over 2 years now, and seems like a pretty logical change to make.\r\n```\r\n\"\"\"\\\r\n    You are passing non-geometry data to the GeoSeries constructor. Currently,\r\n    it falls back to returning a pandas Series. But in the future, we will start\r\n    to raise a TypeError instead.\"\"\"\r\n```\r\n\r\n\r\n",
    "head_branch": "m-richards/deprecations_for_0.10",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DEP: Switch CRS mismatch future warnings to errors (#2100)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d64fac254a19ac29e0e7",
    "number": 2099,
    "body": "Edit: Marked draft because solution fixes the crash, but spams warnings, and that's not satisfactory really. I need to have another look at this. Also, this is related to #722 and #748.\r\n\r\nFixes #2057.\r\n\r\nCould probably use some input on what the desired fix behaviour is. Currently this avoids the issues of multiple geometry columns by not setting the geometry column and warning, rather than raising. \r\n\r\nOriginally I thought it should raise to be consistent with \r\nhttps://github.com/geopandas/geopandas/blob/4536b9203b0b2ff577d1368e4677ff93a4c82164/geopandas/geodataframe.py#L124-L128\r\nfor the non-multiindex case. But this would break `DataFrame.pivot` and perhaps other methods (although in a nicer, but still confusing way). \r\n\r\nI think the long term solution is for #2060 (or a follow up to it) to it to be done so that stuff like `pivot` will downcast and sidestep this issue (and not have a warning), and then the case of directly using the constructor should actually be an error?\r\n\r\n\r\n",
    "head_branch": "m-richards/gdf_pivot_bug",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d650ac254a19ac29e0e8",
    "number": 2097,
    "body": "Closes #2094 ",
    "head_branch": "faster-hexbin-test",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: speedup hexbin plot with bigger gridsize (#2097)\n\n* TST: speedup hexbin plot with bigger gridsize\r\n\r\n* reduce comment size\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\nCo-authored-by: TLouf <loufthomas@gmail.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d651ac254a19ac29e0e9",
    "number": 2096,
    "body": "The `to_postgis` function was changed to support Geography PostGIS column type as follows:\r\n\r\n- It now respects dtype for geometry column provided by user\r\n- It now infers column type (Geography/Geometry) from the PostGIS database and assigns appropriate dtype if dtype wasn't provided (default)",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d652ac254a19ac29e0ea",
    "number": 2088,
    "body": "Fixes #1763, in the end much simpler than it looked. \r\nFixes #2806\r\n\r\nNot a wholistic fix, there are still probably going to be issues with multi-indexes in other places, but they can be dealt with when they come up.",
    "head_branch": "m-richards/multiindex_crs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Fix GeoDataFrames with MultiIndex as columns do not support CRS (#2088)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d653ac254a19ac29e0eb",
    "number": 2087,
    "body": "Another follow-up on #1819 / #1659 / #1662, catching some more deprecation warnings from the upcoming Shapely 1.8.\r\n\r\n(with this, we don't have any place left where we do `arr[:] = ...` that is not wrapped in a `with ignore_shapely2_warnings():` context, so hopefully we are getting there ;))",
    "head_branch": "shapely-2-deprecations",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Compatibility with 1.8 deprecation warnings (.coords) (#2087)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d653ac254a19ac29e0ec",
    "number": 2086,
    "body": null,
    "head_branch": "test-warnings-2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST/BUG: deal with various warnings from the tests (part 2) (#2086)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d654ac254a19ac29e0ed",
    "number": 2084,
    "body": "Closes #2083 ",
    "head_branch": "version",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REF: replace deprecated distutils LooseVersion with packaging parse (#2084)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d655ac254a19ac29e0ee",
    "number": 2082,
    "body": "Recent sqlalchemy errors loudly when using `postgres` as protocol instead of `postgresql`.",
    "head_branch": "docfix",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: postgres/postgresql protocol change in docs (#2082)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d656ac254a19ac29e0ef",
    "number": 2080,
    "body": "Fixes #2063, and splits of part of what is discussed in #2060",
    "head_branch": "m-richards/geoseries_constructor_expanddim",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d657ac254a19ac29e0f0",
    "number": 2078,
    "body": "These sindex tests were disabled for windows due to appveyor, but we don't actually use appveyor [any more?]. In any case, they pass on windows locally and on CI: https://github.com/m-richards/geopandas/pull/5",
    "head_branch": "m-richards/sindex_tests_windows",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: not using appveyor, perhaps these work on GH actions (#2078)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d658ac254a19ac29e0f1",
    "number": 2075,
    "body": "I lured myself into wanting to fix all the warnings we currently have when running the tests ... Ideally there are no warnings, so we can more easily capture new ones (which we might need to act upon).",
    "head_branch": "test-warnings",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST/BUG: deal with various warnings from the tests (#2075)\n\n* TST: deal with various warnings from the tests\r\n\r\n* Update geopandas/tests/test_plotting.py\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* Update geopandas/tests/test_plotting.py\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* add check_less_precise=True back\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d658ac254a19ac29e0f2",
    "number": 2074,
    "body": "The `cascaded_union` method was already long time deprecated in the docs (both in Shapely as in GeoPandas), but starting with1.8, shapely also actually deprecates it with a warning (https://github.com/Toblerity/Shapely/pull/1025). \r\n\r\nSo this PR removed the use of that attribute in our tests, plus also follows the same change and actually deprecates the property on GeoSeries/GeoDataFrame (so the user gets a more correct warning message).",
    "head_branch": "depr-cascaded-union",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DEPR: actually deprecate cascaded_union in favor of unary_union (#2074)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d659ac254a19ac29e0f3",
    "number": 2073,
    "body": "While looking into some more of the warnings from our tests, I noticed that `GeoSeries([]).isna()` didn't properly return a boolean Series:\r\n\r\n```\r\n>>> geopandas.GeoSeries([]).isna()\r\nGeoSeries([], dtype: geometry)\r\n```\r\n\r\nwhile the result of `isna` should always be boolean.",
    "head_branch": "fix-isna-empty",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: GeoSeries constructor should return Series for empty array with dtype when possible (fix GeoSeries.isna for empty Series) (#2073)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d65aac254a19ac29e0f4",
    "number": 2072,
    "body": "Closes #2013",
    "head_branch": "silence-numpy-warnings",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "COMPAT: suppress numpy1.21 deprecation warnings for Shapely < 1.8 (#2072)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d65bac254a19ac29e0f5",
    "number": 2069,
    "body": "The coordinate order of the `bbox` parameter to `read_file()` is (minx, miny, maxx, maxy), and is documented as such in the docstring.  One of the examples in `read_file()` passes a tuple where minx == maxx == 0, which isn't invalid as an intersecting geometry but seems a bit misleading (or at least it confused me :) ) since the resulting Polygon is shaped like a line rather than a box.\r\n\r\nThis just flips `miny` and `maxx` so that the resulting geometry is rectangular with positive area.",
    "head_branch": "fix-bbox-example",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: modify read_file bbox example so that bbox is shaped like a box (#2069)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d65cac254a19ac29e0f6",
    "number": 2067,
    "body": "Closes #2056.\r\n\r\nCurrently, the logic added to find a common CRS among several `GeoDataFrame`s is overwritten partially by:\r\n\r\nhttps://github.com/gcaria/geopandas/blob/dff88d9c2100b72e27e8626c9d1c0c9948b6e707/geopandas/geodataframe.py#L1410-L1414\r\n\r\nJust as a quick check, adding the commented lines would make the new tests pass, but then the case `axis=1` would fail:\r\n\r\nhttps://github.com/gcaria/geopandas/blob/dff88d9c2100b72e27e8626c9d1c0c9948b6e707/geopandas/tests/test_merge.py#L135-L136\r\n\r\nI had a look at `pandas/core/reshape/concat.py` but could not see a method called that could help setting a CRS for the output `GeoDataFrame` for the case `axis=1` (basically the analogous of `geopandas.array._concat_same_type` for `axis=0`).\r\n\r\n\r\n\r\n\r\n",
    "head_branch": "concat_crs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: pd.concat(axis=0) can override crs information (#2067)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d65cac254a19ac29e0f7",
    "number": 2066,
    "body": "This should fix the failure we got after matplotlib 3.4.3 appeared on conda-forge (https://github.com/geopandas/geopandas/runs/3345624943?check_suite_focus=true#step:5:3000)",
    "head_branch": "fix_matplotlib",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix colorbar issue under matplotlib 3.4.3 (#2066)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d65dac254a19ac29e0f8",
    "number": 2065,
    "body": "Fixes #2064 ",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Use suffixes in sjoin's how==right branch (#2065)\n\n* Use suffixes in how==right\r\n\r\n* add tests\r\n\r\n* slightly nicer formatting\r\n\r\n* slightly nicer formatting\r\n\r\n* add ,\r\n\r\n* Update test_sjoin.py\r\n\r\n* Update test_sjoin.py\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d65eac254a19ac29e0f9",
    "number": 2060,
    "body": "Continues from #2055 with a better approach, fixing #1911 in part (and also the referenced #1856, #1153 and #544).\r\n\r\nThis PR fixes the simple case of no geometry columns in the gdf -> df, with more complicated cases around geometry column but it's not the active geometry column deferred to a follow up PR (see discussion of this below).\r\n\r\nCloses #1911 \r\nCloses #1856 \r\nCloses #1153\r\nCloses #544",
    "head_branch": "m-richards/1911_v2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Losing the geometry column should convert to a DataFrame (#2060)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d65fac254a19ac29e0fa",
    "number": 2055,
    "body": "Work in progress improvement of the conversion of return types to be Geo/ non geo DataFrames/ Series for appropriate cases - \"fixing\" #1911, (and also the referenced #1856, #1153 and #544).\r\n\r\nI realise that there's perhaps too much for one PR here but I'm hoping this at least demonstrates feasibility and triggers some discussion. \r\n\r\nI also realise that this might currently be foregoing some of the wisdom from discussion in those threads over the last four years. This current approach is functional but there is likely more a more elegant solution.\r\n\r\nStill some rough edges at the moment\r\n- New tests probably should probably be grouped with all the other tests for each method, not as a new file, this was just easier to test with. \r\n- Docstrings are probably getting lost in some cases right now\r\n- Some methods are missing (like `convert_dtypes`)\r\n- Overriden index objects probably should not go in the `geodataframe.py` file.\r\n\r\nThere is also some interpretation in what are sensible conversion rules. \r\n- What to do if the geometry column is dropped but there are other GeoSeries in the DataFrame?\r\n    * Currently returning a GeoDataFrame with geometry column of None, but I've just seen here (https://github.com/geopandas/geopandas/pull/553) discussion that just returning a dataframe makes more sense. On reflection that would make more sense, one still needs to do `df.set_geometry()` to get a usable `GeoDataFrame`, and it perhaps makes more sense to use the monkey patched method on a valid DataFrame than to do so on an invalid GeoDataFrame. \r\n    * What about if there is only one column left in the DataFrame and it contains geometry? In this case I think it makes sense to return a GeoDataFrame with the appropriate geometry column set. ",
    "head_branch": "m-richards/1911",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d660ac254a19ac29e0fb",
    "number": 2054,
    "body": null,
    "head_branch": "fix_lint",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "STY: fix flake8 (#2054)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d660ac254a19ac29e0fc",
    "number": 2053,
    "body": "This aims to follow `sindex.query_bulk` in surfacing the `pygeos.STRTree.nearest` interface, as suggested in #1977.\r\n\r\nThe interface at this level should handle shapely geometries (individually or in lists), GeoSeries, GeometryArray or numpy arrays of PyGEOS geometries.\r\n\r\nThis is related to work in #1865, but should be more constrained - it focusses only on adding the `sindex.nearest` method, skipping `nearest_all` as that's included in #1865.\r\n\r\nI've added a couple tests which aim to exercise the interface with the different acceptable objects.",
    "head_branch": "feature/1977-sindex-nearest",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Expose interface to sindex.nearest (#1977) (#2053)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d661ac254a19ac29e0fd",
    "number": 2052,
    "body": "The `objects.inv` of pyarrow package In `intersphinx_mapping` is None, but it is accessible.",
    "head_branch": "add-pyarrow-sphinx-objects.inv-link",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d662ac254a19ac29e0fe",
    "number": 2051,
    "body": "pyepsg this package comes up twice in `intersphinx_mapping`.\r\n\r\nSee below.\r\n\r\n",
    "head_branch": "remove-duplication",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Remove duplicated `intersphinx_mapping` key (#2051)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d663ac254a19ac29e0ff",
    "number": 2050,
    "body": "Fixed several typos using [codespell](https://github.com/codespell-project/codespell). ",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fixed typos (#2050)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d664ac254a19ac29e100",
    "number": 2049,
    "body": null,
    "head_branch": "transform_bounds",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Update estimate_utm_crs to handle crossing the antimeridian with pyproj 3.1+ (#2049)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d664ac254a19ac29e101",
    "number": 2048,
    "body": "Clarifying the meaning of spatial predicates. xref #1574",
    "head_branch": "predicates",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Editing docstrings of spatial predicates (#2048)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d665ac254a19ac29e102",
    "number": 2047,
    "body": "Fixes #1738 ",
    "head_branch": "m-richards/fix_1738",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: support Series.value_counts for geometry dtype (add value_counts to GeometryArray) (#2047)\n\n* TST: updated tests for value_counts\r\n\r\n* BUG: fix GH1738\r\n\r\n* BUG: replace fillna(None) in value counts\r\n\r\n* update extension array tests\r\n\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d666ac254a19ac29e103",
    "number": 2046,
    "body": "Fixes #1230. \r\nAdds tests for pd.concat().\r\n\r\nWording of exceptions could probably use a little work. \r\nCurrently I've added a new test demonstrating undesirable behaviour of pd.concat(... axis=0), which should probably be addressed separately.\r\n",
    "head_branch": "m-richards/fix_1230",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix pd.concat(... axis=1) causing duplicate geometry column names (#2046)\n\n* TST: add failing tests for GH1230\r\n\r\n* BUG: fix geom_col =\"geometry\" case of GH1230\r\n\r\n* TST: expand concat tests\r\n\r\n* BUG: fix bug in __finalize__ where df.geometry was a gdf after concat\r\n\r\n* TST: make duplicate geom col check clearer\r\n\r\n* BUG: check level shape in set_geometry to keep pygeos/shapely errors consistent\r\n\r\n* BUG: address PR comments\r\n\r\n* TST: refactor tests to suggested locations\r\n\r\n* CLN: address review comments"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d667ac254a19ac29e104",
    "number": 2043,
    "body": "",
    "head_branch": "patch-2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: fix typo in a URL (#2043)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d668ac254a19ac29e105",
    "number": 2042,
    "body": "",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Fixed link to notebook with more examples in nbviewer (#2042)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d669ac254a19ac29e106",
    "number": 2040,
    "body": "Added type hints. Please merge this one after the previous type hinting PRs have been merged.\r\nSee #1991\r\n\r\nFixes #1974 ",
    "head_branch": "th-versioneer.py",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d669ac254a19ac29e107",
    "number": 2039,
    "body": "Added type hints.\r\nSee #1991",
    "head_branch": "th-util.py",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d66aac254a19ac29e108",
    "number": 2038,
    "body": "Added type hints.\r\nSee #1991",
    "head_branch": "th-sjoin.py",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d66bac254a19ac29e109",
    "number": 2037,
    "body": "Added type hints.\r\nSee #1991",
    "head_branch": "th-overlay.py",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d66cac254a19ac29e10a",
    "number": 2036,
    "body": "Added type hints.\r\nSee #1991",
    "head_branch": "th-geocoding.py",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d66dac254a19ac29e10b",
    "number": 2035,
    "body": "Added type hints.\r\nSee #1991",
    "head_branch": "th-crs.py",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d66eac254a19ac29e10c",
    "number": 2034,
    "body": "Added type hints.\r\nSee #1991",
    "head_branch": "th-clip.py",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d66eac254a19ac29e10d",
    "number": 2033,
    "body": "Added type hints.\r\nSee #1991",
    "head_branch": "th-test_plotting.py",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d66fac254a19ac29e10e",
    "number": 2032,
    "body": "Added type hints.\r\nSee #1991",
    "head_branch": "th-test_crs.py",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d670ac254a19ac29e10f",
    "number": 2031,
    "body": "Added type hints.\r\nSee #1991",
    "head_branch": "th-plotting.py",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d671ac254a19ac29e110",
    "number": 2030,
    "body": "Added type hints.\r\nSee #1991",
    "head_branch": "th-sql.py",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d672ac254a19ac29e111",
    "number": 2029,
    "body": "Added type hints.\r\nSee #1991",
    "head_branch": "th-file.py",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d672ac254a19ac29e112",
    "number": 2028,
    "body": "Added type hints.\r\nSee #1991",
    "head_branch": "th-arrow.py",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d673ac254a19ac29e113",
    "number": 2027,
    "body": "Added type hints.\r\nSee #1991",
    "head_branch": "th-geoseries.py",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Added type hints - geoseries.py (#2027)\n\nCo-authored-by: Matt Richards <mrichards7@outlook.com.au>\r\nCo-authored-by: Matt Richards <45483497+m-richards@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d674ac254a19ac29e114",
    "number": 2026,
    "body": "Added type hints.\r\nSee #1991",
    "head_branch": "th-geodataframe.py",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d675ac254a19ac29e115",
    "number": 2025,
    "body": "Added type hints.\r\nSee #1991",
    "head_branch": "th__init__.py",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d676ac254a19ac29e116",
    "number": 2024,
    "body": "Added type hints.\r\nSee #1991 ",
    "head_branch": "th-base.py",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d677ac254a19ac29e117",
    "number": 2023,
    "body": "Added type hints.\r\nSee #1991",
    "head_branch": "th-array.py",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d677ac254a19ac29e118",
    "number": 2022,
    "body": "Added type hints.\r\nSee #1991",
    "head_branch": "th_vectorized.py",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d678ac254a19ac29e119",
    "number": 2021,
    "body": "Added type hints.\r\nSee #1991",
    "head_branch": "th_config.py",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d679ac254a19ac29e11a",
    "number": 2020,
    "body": "minor cleanup",
    "head_branch": "py2clean",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REF: remove forgotten python 2 compat code (#2020)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d67aac254a19ac29e11b",
    "number": 2019,
    "body": "Fixes #420\r\n\r\nI am turning values of mapclassify plots into a `Categorical` array and then using categorical plotting which preserves all categories even if there are no values in them. For that reason, I have moved `if categorical:` after `if scheme:`.\r\n\r\n```py\r\nimport geopandas as gpd\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\n\r\n# Get some polygons\r\ndata = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\r\ndata = data[data.continent == \"Africa\"]\r\n\r\n# Create some fake data with different ranges\r\ndata['low_vals'] = np.linspace(0, 0.3, data.shape[0])\r\ndata['mid_vals'] = np.linspace(0.3, 0.7, data.shape[0])\r\ndata['high_vals'] = np.linspace(0.7, 1.0, data.shape[0])\r\ndata.loc[data.index[:20:2], 'high_vals'] = np.nan\r\n\r\n# Create a single set of bins\r\nbins = np.arange(1, 11) / 10 # set bins to 0.10 intervals\r\n\r\n\r\nfig, axs = plt.subplots(1, 3, figsize=(12, 5))\r\nfor e, col in enumerate(['low_vals', 'mid_vals', 'high_vals']):\r\n    data.plot(col, scheme='UserDefined', classification_kwds={'bins':bins}, \r\n              legend=True, ax=axs[e])\r\n```\r\n\r\nThis PR:\r\n\r\n<img width=\"719\" alt=\"Screenshot 2021-07-23 at 23 31 22\" src=\"https://user-images.githubusercontent.com/36797143/126847442-07dbd5a1-50f5-4379-bde6-d1e4f5d7c7d2.png\">\r\n\r\nMaster:\r\n\r\n<img width=\"715\" alt=\"Screenshot 2021-07-23 at 23 31 59\" src=\"https://user-images.githubusercontent.com/36797143/126847475-45e9df7a-2481-4dd1-ab73-8ef694737d18.png\">\r\n\r\ncc @darribas, @dfolch\r\n",
    "head_branch": "preserve_cmap_bins",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      " BUG: preserve color map according to bins (#2019)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d67bac254a19ac29e11c",
    "number": 2016,
    "body": "This PR attempts to link `pyarrow.parquet.write_table` mentioned in the doc string of `to_parquet` to the relevant pyarrow docs page.\r\n\r\nI couldn't get the doc build to show the update locally. It was building the old doc string and I can't work out why.\r\n\r\nThis PR also sorts the packages in intersphinx_mapping to make it easier to add new packages and remove the typo (to to) the the `to_parquet` doc string.",
    "head_branch": "doc-to-parquet",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: pyarrow intersphinx mapping (#2016)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d67bac254a19ac29e11d",
    "number": 2014,
    "body": "Since PyGEOS 0.9, the \"normalize\" parameter was renamed to \"normalized\" for line_interpolate_point and line_locate_point.\r\n\r\nThere are a few [pytest CI warnings](https://github.com/geopandas/geopandas/runs/3074661832#step:6:3101):\r\n>   /usr/share/miniconda/envs/test/lib/python3.8/site-packages/pygeos/linear.py:90: DeprecationWarning: argument 'normalize' is deprecated; use 'normalized'\r\n\r\nThis PR should clear these warnings up, and work with older PyGEOS versions.\r\n\r\nxref https://github.com/pygeos/pygeos/pull/209",
    "head_branch": "dep-normalize",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REF: line_interpolate_point and line_locate_point now use normalized (#2014)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d67cac254a19ac29e11e",
    "number": 2012,
    "body": "fixes #1269 #1379\r\n\r\nHere's a proposal to handle more easily categorical plots and their legends. The main idea is to give the proper label to each collection that we plot, so that the legend can be created automatically by calling `ax.legend` without manually creating handles and labels. This allows lines to be represented by lines, points by points and polygons by squares in the legend directly. Now some may prefer to have each geometry type in its own legend, but I went for the simplest here.\r\n\r\nWhen provided with a `color` that maps values to colors as suggested in the issue, we treat it like a categorical plot with a custom colormap, which makes sense I think. I imagined a user would intuitively try to do the same with all kinds of styling arguments, so I also tried to implement that. \r\n\r\nHere are two example plots:\r\n```python\r\nfrom shapely.geometry import LineString\r\nimport geopandas as geopd\r\n\r\nlinea = LineString([(1, 1), (2, 2), (3, 2), (5, 3)])\r\nlineb = LineString([(3, 4), (5, 7), (12, 2), (10, 5), (9, 7.5)])\r\nlinec = LineString([(3, 3), (5,5), (9, 7.5)])\r\ngdf_lines = geopd.GeoDataFrame(\r\n    [1, 2, None], geometry=[linea, lineb, linec], crs=\"epsg:4326\"\r\n )\r\ngdf_lines[\"type\"] = [\"M\", \"S\", None]\r\n```\r\n\r\n```python\r\ngdf_lines.plot(column='type', color={'M': 'black', 'S': 'r'}, legend=True,\r\n               linewidth=[1, 4], missing_kwds={'color': 'gray'})\r\n```\r\n![Screenshot from 2021-07-18 19-18-34](https://user-images.githubusercontent.com/31036680/126076346-a604be95-0813-4958-bf45-ca0279112f3a.png)\r\n\r\n```python\r\ngdf_lines.plot(column='type', categorical=True, legend=True, linewidth={'S': 4, 'M': 2})\r\n```\r\n![Screenshot from 2021-07-18 19-19-59](https://user-images.githubusercontent.com/31036680/126076381-d552d304-e64d-42e7-9a37-ab18204421ab.png)\r\n\r\nThis is a WIP as I've only adapted `_plot_linestring_collection` for now. Also, I quickly fixed the usage of \"scheme\" but didn't test thoroughly yet, and there are still some broken edge cases, in particular when the style mappings provided to `plot` exclude some of the present categories.\r\n\r\nAnyway I submitted at this stage to get feedback on the approach, so let me know what you think!\r\n",
    "head_branch": "plot-cat-lgd",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d67dac254a19ac29e11f",
    "number": 2007,
    "body": "Fixes #2005 ",
    "head_branch": "geopy22",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REF/TST: replace GeocodeFarm with Photon as a geocoding default (#2007)\n\n* TST: replace GeocodeFarm with Photon\r\n\r\n* change default in geocoding and docs"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d67eac254a19ac29e120",
    "number": 2003,
    "body": "Closes #1988, closes #1208.\r\n\r\nI've set the default to `False` so this does not surprise anybody in the future.\r\nProbably an error or at least a warning  should be raised if `id_as_index=True` but there is no id in the features ?",
    "head_branch": "store_id_from_features",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d67fac254a19ac29e121",
    "number": 2001,
    "body": "Partially reverts geopandas/geopandas#2000, because matplotlib redid some of the refactor (https://github.com/matplotlib/matplotlib/pull/20501)",
    "head_branch": "revert-2000-fix-cb-tests",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Revert \"TST: adapt colorbar tests to matplotlib 3.5 (#2000)\" (#2001)\n\nThis reverts commit ef416188f4186e77d60fc6ba95f0182cf07117e2."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d680ac254a19ac29e122",
    "number": 2000,
    "body": "fixes #1962 \r\n\r\nI ran the tests in two environments, one with matplotlib versions 3.3.4 and the other with 3.5.0.dev1280+g92825fefb, which passed.",
    "head_branch": "fix-cb-tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: adapt colorbar tests to matplotlib 3.5 (#2000)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d680ac254a19ac29e123",
    "number": 1998,
    "body": "Contribution to [#529](https://github.com/geopandas/geopandas/issues/529)",
    "head_branch": "doc-gallery-rasterio-sample",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Rasterio sample example (#1998)\n\n* add rasterio sample example\r\n\r\n* add example data\r\n\r\n* Update doc/source/gallery/geopandas_rasterio_sample.ipynb\r\n\r\n* clean outputs, add thumbnail\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d681ac254a19ac29e124",
    "number": 1996,
    "body": null,
    "head_branch": "doc",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d682ac254a19ac29e125",
    "number": 1995,
    "body": "Since we have a script.py called `_decorator.py`, then we could move all decorators into this script.",
    "head_branch": "decorator",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d683ac254a19ac29e126",
    "number": 1994,
    "body": "Adding a new example to the gallery which describes the usage of matplotlib-scalebar library. Resolves #1597",
    "head_branch": "scale-bar",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Example of matplotlib-scalebar library usage (#1994)\n\n* Adding an example of matplotlib-scalebar\r\n\r\n* Updating version number of matplotlib-scalebar library\r\n\r\n* DOC: Resolving comments for matplotlib-scalebar example\r\n\r\n* formatting, icon\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d684ac254a19ac29e127",
    "number": 1993,
    "body": "fix https://github.com/geopandas/geopandas/runs/2985725996?check_suite_focus=true#step:5:2713",
    "head_branch": "no_crs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: don't use to_crs on GeometryArray without crs (#1993)\n\n* TST, BUG: GeometryArray.crs is empty, can't transform another crs\r\n\r\nfix https://github.com/geopandas/geopandas/runs/2985725996?check_suite_focus=true#step:5:2713\r\n\r\n* TST, BUG: use `Geoseries.set_crs` replace `GeometryArray.to_crs`\r\n\r\n* simplify a bit\r\n\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d685ac254a19ac29e128",
    "number": 1991,
    "body": "## Summary\r\n\r\nAdds type hints and annotations for the vast majority of `geopandas` functions. Many functions were changed for which type hints and annotations were useful. Pre-commit tests passed.\r\n\r\nFixes #1974\r\n\r\n@martinfleis ",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d685ac254a19ac29e129",
    "number": 1989,
    "body": "## Summary\r\n\r\nAdds type hints and annotations for the vast majority of `geopandas` functions. All functions were changed for which type hints and annotations were useful. Pre-commit tests passed.\r\n\r\nFixes #1974\r\n\r\n@martinfleis ",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d686ac254a19ac29e12a",
    "number": 1987,
    "body": "(no idea if this will actually fix it, but just to start testing things)",
    "head_branch": "ci-conda",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: fix activation of the conda environments + switch to conda-incubator/setup-miniconda (#1987)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d687ac254a19ac29e12b",
    "number": 1986,
    "body": "xref #1975\r\n\r\nThis should make CI green (with the exception of dev) again. I would keep the #1975 open because we need to resolve it properly I think.",
    "head_branch": "gpkg_crs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: adapt GPKG tests with undefined CRS (#1986)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d688ac254a19ac29e12c",
    "number": 1985,
    "body": "Combine two `with` to one, and decrease indent for reading.   ",
    "head_branch": "with",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d689ac254a19ac29e12d",
    "number": 1984,
    "body": "There are two GeoDataFrames (df, df2).\r\n\r\nCompare to two different `sjoin` ways:\r\n\r\n1. Functional way: `gpd.sjoin(df, df2)`\r\n2. Object-Oriented way, this pr: `df.sjoin(df2)`\r\n\r\nI would more like the Object-Oriented way.\r\nI thought this way would be easy to use, and the arguments of `left` and `right` would much clear.",
    "head_branch": "sjoin",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "EHN: expose `sjoin` as a `GeoDataFrame` method (#1984)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d689ac254a19ac29e12e",
    "number": 1981,
    "body": "",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: fix misspelling of Plate Carrée (#1981)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d68aac254a19ac29e12f",
    "number": 1979,
    "body": "RTD fails to create the environment now. Removing pins to check how it resolves and whether we really need them, since it may be wiser to use the latest versions of dependencies.\r\n\r\nEDIT: pinned to new versions, it shaves off 5 minutes from the build time.",
    "head_branch": "fix_rtd",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: update RTD env (#1979)\n\n* DOC: unpin RTD env\r\n\r\n* fix for sphinx 4.0\r\n\r\n* pin new versions\r\n\r\n* typo"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d68bac254a19ac29e130",
    "number": 1976,
    "body": "Fixes #1970",
    "head_branch": "akylzhan-patch",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: allow single-column GeoDataFrame in GeometryArray __setitem__ (#1976)\n\n* BUG: iloc indexing Dataframe with only one column (geometry) raises TypeError\r\n\r\n* add tests\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d68cac254a19ac29e131",
    "number": 1963,
    "body": "This fixes #1372, and by association fixes #1960",
    "head_branch": "m-richards/fix_1372",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: GeoDataFrame CRS loss during __setitem__  (#1963)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d68dac254a19ac29e132",
    "number": 1961,
    "body": "Fixing failing docstring examples.\r\n\r\nThey were correctly failing. What I just don't understand is why they started failing now and not sooner. There was literally no difference in environments that could cause the change of behaviour.\r\n\r\nDifferences are the result of a different order of coordinates after overlay from the new GEOS. We had to fix the same thing in tests but it showed up just now in dosctrings. It is strange and I sense some weird bug in our docstring testing.\r\n",
    "head_branch": "docstring_fix",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: fix docstring examples (#1961)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d68eac254a19ac29e133",
    "number": 1959,
    "body": "This makes `read_file` more similar to the API provided by Pandas in `read_csv` et al, and allows for processing large files under limited memory. Notably, I have found that significantly more memory is required to load a large shapefile in one go than to load it in several chunks and concatenate them.\r\n\r\nTo-do:\r\n\r\n- [ ] Test\r\n- [ ] Update documentation",
    "head_branch": "patch-2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d68fac254a19ac29e134",
    "number": 1958,
    "body": "Fixes #1957",
    "head_branch": "proj4",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: fix proj4strings test for PROJ 8.0.1 (#1958)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d690ac254a19ac29e135",
    "number": 1955,
    "body": "This fixes #1849.\r\n\r\nI wasn't quite sure if the test should go where it is - test_geodataframe.py where other geometry renaming tests are, or test_pandas_methods - where other apply tests are, or somewhere else again.\r\n\r\nAlso, I'm not sure but line 1370 of geodataframe seems a bit broad,\r\n`\r\nand any(isinstance(t, GeometryDtype) for t in result.dtypes)\r\n`. Unless I'm missing something `set_crs` only acts on the geometry column of the GeoDataFrame, so would \r\n`\r\nisinstance(result[self._geometry_column_name].dtype, GeometryDtype)\r\n` be more explicit? Kind of a pathological case, so maybe not right to change (or I could just be wrong..). \r\n\r\n\r\n",
    "head_branch": "m-richards/fix_1849",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: active geometry information lost after apply (#1955)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d690ac254a19ac29e136",
    "number": 1954,
    "body": "port from [pandas](https://github.com/pandas-dev/pandas/blob/6925fd04690c94dc1fc03db1e1eddac8d479bef6/pandas/util/_decorators.py#L348-L400)",
    "head_branch": "doc_decorator",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Gather all doc decorator in one (#1954)\n\nport from [pandas](https://github.com/pandas-dev/pandas/blob/6925fd04690c94dc1fc03db1e1eddac8d479bef6/pandas/util/_decorators.py#L348-L400)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d691ac254a19ac29e137",
    "number": 1953,
    "body": "This PR brings the code of https://github.com/martinfleis/geopandas-view exposing the function for interactive plotting via folium as `explore()` method of both GeoSeries and GeoDataFrame. It does not bring backend API (#1904) yet.\r\n\r\nTo-do:\r\n- [x] test methods\r\n- [x] add User Guide documentation\r\n- [x] use `explore` in existing documentation instead of plot in some cases\r\n- [x] fetch `html_attribution` from `xyzservices.TileProvider` once 2021.08 is out with https://github.com/geopandas/xyzservices/pull/60",
    "head_branch": "explore",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: native interactive plotting via folium as `explore()` method (#1953)\n\nCo-authored-by: sangarshanan <sangarshanan1998@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d692ac254a19ac29e138",
    "number": 1952,
    "body": "Related #1947, port API from [pandas](https://github.com/pandas-dev/pandas/blob/619446ac338f0f39f1f09fea1f5222a34b05ece2/pandas/core/accessor.py#L153-L297).",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d693ac254a19ac29e139",
    "number": 1951,
    "body": "",
    "head_branch": "cx-avoid-total-bounds",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "PERF: avoid calculating total_bounds in .cx indexing when not needed (#1951)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d694ac254a19ac29e13a",
    "number": 1949,
    "body": "An old branch that I had lying around, need to update it for the latest sindex API.\r\n\r\n",
    "head_branch": "cx-tree",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d694ac254a19ac29e13b",
    "number": 1948,
    "body": "This updates the doc environment to use the latest version PyGEOS (0.10).",
    "head_branch": "bump_doc_pygeos_version",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Increment pygeos version (#1948)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d695ac254a19ac29e13c",
    "number": 1945,
    "body": "Closes #1937 \r\n\r\nAdditionally ran into other issues when pygeos is not available, see traceback below, which this PR also solves. \r\n\r\n<details>\r\n<summary>Details</summary>\r\n\r\n  ```shell\r\nTraceback (most recent call last):\r\n  File \"/home/daniel/PycharmProjects/geopandas/geopandas/tests/scripting.py\", line 40, in <module>\r\n    explode_pandas_multi_index()\r\n  File \"/home/daniel/PycharmProjects/geopandas/geopandas/tests/scripting.py\", line 20, in explode_pandas_multi_index\r\n    test_df = df.explode()\r\n  File \"/home/daniel/PycharmProjects/geopandas/geopandas/geodataframe.py\", line 1582, in explode\r\n    exploded_geom = df_copy.geometry.explode().reset_index(level=-1)\r\n  File \"/home/daniel/PycharmProjects/geopandas/geopandas/geoseries.py\", line 852, in explode\r\n    index = MultiIndex.from_tuples(index, names=self.index.names + [None])\r\n  File \"/home/daniel/miniconda3/envs/geopandas_dev/lib/python3.9/site-packages/pandas/core/indexes/multi.py\", line 175, in new_meth\r\n    return meth(self_or_cls, *args, **kwargs)\r\n  File \"/home/daniel/miniconda3/envs/geopandas_dev/lib/python3.9/site-packages/pandas/core/indexes/multi.py\", line 537, in from_tuples\r\n    return cls.from_arrays(arrays, sortorder=sortorder, names=names)\r\n  File \"/home/daniel/miniconda3/envs/geopandas_dev/lib/python3.9/site-packages/pandas/core/indexes/multi.py\", line 466, in from_arrays\r\n    return cls(\r\n  File \"/home/daniel/miniconda3/envs/geopandas_dev/lib/python3.9/site-packages/pandas/core/indexes/multi.py\", line 308, in __new__\r\n    result._set_names(names)\r\n  File \"/home/daniel/miniconda3/envs/geopandas_dev/lib/python3.9/site-packages/pandas/core/indexes/multi.py\", line 1433, in _set_names\r\n    raise ValueError(\r\nValueError: Length of names must match number of levels in MultiIndex.\r\n  ```\r\n</details>\r\n\r\n**Output of `geopandas.show_versions()`**\r\n<details>\r\n<summary>Details</summary>\r\n\r\n```\r\nSYSTEM INFO\r\n-----------\r\npython     : 3.9.2 (default, Mar  3 2021, 20:02:32)  [GCC 7.3.0]\r\nexecutable : /home/daniel/miniconda3/envs/geopandas_dev/bin/python\r\nmachine    : Linux-5.4.0-73-generic-x86_64-with-glibc2.31\r\n\r\nGEOS, GDAL, PROJ INFO\r\n---------------------\r\nGEOS       : 3.9.1\r\nGEOS lib   : /home/daniel/miniconda3/envs/geopandas_dev/lib/libgeos_c.so\r\nGDAL       : 3.2.2\r\nGDAL data dir: /home/daniel/miniconda3/envs/geopandas_dev/share/gdal\r\nPROJ       : 8.0.0\r\nPROJ data dir: /home/daniel/miniconda3/envs/geopandas_dev/share/proj\r\n\r\nPYTHON DEPENDENCIES\r\n-------------------\r\ngeopandas  : 0.9.0+24.ga26bde2\r\npandas     : 1.2.3\r\nfiona      : 1.8.18\r\nnumpy      : 1.20.1\r\nshapely    : 1.7.1\r\nrtree      : 0.9.7\r\npyproj     : 3.0.1\r\nmatplotlib : None\r\nmapclassify: None\r\ngeopy      : None\r\npsycopg2   : None\r\ngeoalchemy2: None\r\npyarrow    : None\r\npygeos     : None\r\n\r\n```\r\n</details>\r\n\r\n",
    "head_branch": "bug-explode-gdf-raises-notimplementederror",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix GeoDataFrame.explode with MultiIndex (#1937) (#1945)\n\n* BUG: fix GeoDataFrame.explode with MultiIndex (#1937)\r\n\r\n* use simple function to flatten values"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d696ac254a19ac29e13d",
    "number": 1942,
    "body": "Adding the clarification of the tolerance argument and some additional information about the Douglas-Peucker algorithm. #1905",
    "head_branch": "simplify_clarification",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Editing the docstring of GeoSeries.simplify (#1942)\n\n* Editing the docstring of GeoSeries.simplify\r\n\r\n* Stylistic change in geoseries.simplify docstring\r\n\r\n* More clarification in simplify docstring\r\n\r\n* Minor changes in simplify docstring\r\n\r\n* remove trailing whitespace\r\n\r\n* Removing redundant information from simplify docstring\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d697ac254a19ac29e13e",
    "number": 1941,
    "body": "ref #1896",
    "head_branch": "revise-polygon-plotting-with-folium-example",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: revise plotting polygons with folium gallery example (#1941)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d698ac254a19ac29e13f",
    "number": 1940,
    "body": "I think this is right, based on how a Shapely input is handled, and the bounds doc: (https://shapely.readthedocs.io/en/stable/manual.html#object.bounds).\r\n\r\nhttps://github.com/geopandas/geopandas/blob/a445f979e29ec5180d5fa08660af08305a1a6932/geopandas/io/file.py#L176-L177",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Clarify bbox input to read_file (#1940)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d699ac254a19ac29e140",
    "number": 1938,
    "body": "This should ensure that no matter the kernel specified in kernelspec, RTD always uses default one and doesn't fail.\r\n\r\nI have temporarily allowed RTD for PRs to test this.",
    "head_branch": "kernelspec",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: override kernelspec when executing notebooks (#1938)\n\n* DOC: override kernelspec\r\n\r\n* revert kernelspec used for test"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d699ac254a19ac29e141",
    "number": 1936,
    "body": "First attempt to expose `points_from_xy`.\r\n\r\nNot sure about the naming, but I would find `GeoSeries.points_from_xy` a bit confusing.\r\n\r\nSince this is my first PR, reviews and amendments are most appreciated.\r\n\r\nCloses #1853",
    "head_branch": "enh-geoseries-from-xy",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: expose points_from_xy as a GeoSeries method (#1853) (#1936)\n\nCo-authored-by: Jan Šimbera <jan.simbera@vodafone.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d69aac254a19ac29e142",
    "number": 1935,
    "body": "Closes  #1875 ",
    "head_branch": "bugfix-explode-does-not-preserve-attrs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: preserve attrs in Dataframe.explode (#1875) (#1935)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d69bac254a19ac29e143",
    "number": 1934,
    "body": "#1922 changed Jupyter kernel which broke RTD. Reverting.\r\n\r\nI'll merge this immediately as we do not test this at the moment anyway.",
    "head_branch": "fixkernel",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: fix jupyter kernel (#1934)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d69cac254a19ac29e144",
    "number": 1933,
    "body": "Closes #1930 \r\n\r\nThis will require https://github.com/pandas-dev/pandas/pull/41312 to be merged first",
    "head_branch": "tst-pandas-string-dtype",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG/TST: support parametrized string dtype (#1933)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d69cac254a19ac29e145",
    "number": 1932,
    "body": "This PR rewrites `setup_postgres.sh` with the aim of making it more user friendly running locally\r\n\r\n- It is moved from from `./ci/envs` to a more appropriate `./ci/scripts` location\r\n- The script stops if PGUSER or PGPORT are not set, as these should be required\r\n- PGPORT is added as a variable, which is handy if the default 5432 is already in use\r\n- PGDATA is moved from $HOME/var/db to (e.g.) /tmp/postgres.XcSUgV  via `mktemp -d`\r\n- Messages are displayed to stop the server / clean-up PGDATA, i.e. after tests are run\r\n- In the CI, the script is run rather than sourced\r\n\r\nTo use from Ubuntu with Miniconda3:\r\n```\r\nconda create -f ci/envs/38-latest-conda-forge.yaml\r\nconda activate test\r\nconda install postgis -c conda-forge\r\n\r\nexport PGUSER=postgres\r\nexport PGPORT=5436\r\nsh ci/scripts/setup_postgres.sh\r\n\r\npytest geopandas/io/tests/test_sql.py\r\n\r\n# these commands were shown by script\r\npg_ctl -D /tmp/postgres.kOVib3 stop\r\nrm -rf /tmp/postgres.kOVib3\r\n\r\nconda deactivate\r\nconda remove --name test --all\r\n```",
    "head_branch": "tst-postgres2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: add PGPORT env var, rewrite setup_postgres.sh to scripts dir (#1932)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d69dac254a19ac29e146",
    "number": 1931,
    "body": "Closes  #1929\r\n\r\nThis PR follows the changes done in #1926 and adds other relevant API links to the [intersphinx mapping](https://github.com/geopandas/geopandas/blob/0d38f10a9507bba80ed23b91c697a74fe95250cd/doc/source/conf.py#L337). In addition, updates the links in the docs under [User Guide](https://geopandas.org/docs/user_guide.html)  and [Advanced Guide](https://geopandas.org/docs/advanced_guide.html) sections.\r\n\r\n- Adds links to the documentations of relevant API's (based on [dependencies](https://github.com/geopandas/geopandas/blob/master/environment.yml))\r\n- Updates the links for the documentations of the [User Guide](https://geopandas.org/docs/user_guide.html)  and [Advanced Guide](https://geopandas.org/docs/advanced_guide.html) sections (rst files are located under [user_guide](https://github.com/geopandas/geopandas/tree/master/doc/source/docs/user_guide) folder)\r\n",
    "head_branch": "doc-intersphinx-api-links",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Relevant API links for intersphinx mapping (#1931)\n\n* DOC: added API links to intersphinx mapping\r\n\r\n* DOC: updated mergingdata.rst links\r\n\r\n* DOC: updated aggregation_with_dissolve.rst links\r\n\r\n* DOC: updated data_structures.rst links\r\n\r\n* DOC: updated geocoding.rst links\r\n\r\n* DOC: updated geometric_manipulations.rst links\r\n\r\n* DOC: updated indexing.rst links\r\n\r\n* DOC: updated io.rst links\r\n\r\n* DOC: updated projections.rst links\r\n\r\n* DOC: updated set_operations.rst links\r\n\r\n* DOC: updated mapping.rst links\r\n\r\n* DOC: updated missing_empty.rst links\r\n\r\n* DOC: updated geoplot intersphinx links\r\n\r\n* DOC: make 'unary_union' attr instead of method\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* DOC: remove link to GeoDataFrame.geometry\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* DOC: convert pandas indexers to attrs instead of methods\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* DOC: convert indexer 'cx' to attr instead of method\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* DOC: refer GeoSeries.buffer instead of shapely buffer\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* DOC: make 'unary_union' attr instead of method on missing_empty.rst\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* DOC: refer to DataFrame.merge instead of pandas.merge\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* DOC: link pyproj.CRS\r\n\r\n* DOC: changed API links to 'stable' from 'latest'\r\n\r\n* DOC: fixed separator length\r\n\r\n* DOC: uppercase CRS in pyproj.crs\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d69eac254a19ac29e147",
    "number": 1928,
    "body": "Hi! \r\n\r\nI had a look into the details of integrating fast rectangle clipping into geopandas. As suggested, I added `clip_by_rect()` to `GeoSeries` (and `GeoDataFrame` respectively). I did so via adding it as a vectorized method (to `_vectorized`) to `GeometryArray`. Both regular Shapely as well as PyGeos are supported.\r\n\r\nIt would be nice if #1909 could be merged before I would make the necessary changes in `geopandas.tools.clip()`.\r\n\r\nI am still unsure about the signature of the added function, whether it should be `.clip_by_rect(rectangle)` with `rectangle` being a 4 item tuple, or `.clip_by_rect(minx, miny, max, maxy)`. The one-arguemt option would have the advantage of being able to reuse a lot of the \"generic\" code already present for intersections, etc (both in implementation and testing). \r\nThe four argument version would be more similar to what Shapely and PyGeos do. What would your preference be here? \r\n\r\nCloses #1902 ",
    "head_branch": "add-fast-rectangle-clipping",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Add fast rectangle clipping using `.clip_by_rect()` (#1928)\n\n* TST: Add test for rectangle clipping\r\n\r\n* ENH: Add `GeometryArray().clip_by_rect()`\r\n\r\n* ENH: Add `GeoPandasBase().clip_by_rect()`\r\n\r\nCloses #1902\r\n\r\n* Change signatures to use tuple rectangle\r\n\r\n* Change signatures to use tuple rectangle\r\n\r\n* Raise exception when shapely < 1.7\r\n\r\nException is raised as `shapely.ops.clip_by_rect` was introduced in shapely 1.7\r\n\r\n* Reorder tests to make them easier to group\r\n\r\n* Parameterize all test which use single_rectangle_df to also test with bounds\r\n\r\n* Paramterize test with larger single rectangle\r\n\r\n* Add bounding box clip capability to clip using .clip_by_rect()\r\n\r\n* Add documentation for `.clip_by_rect()` and changes in `clip()`\r\n\r\n* Skip clip tests if shapely < 1.7\r\n\r\n* Improve test coverage\r\n\r\n* Remove shapely >1.7 compatibility checks\r\n\r\nCan be removed as #2358 bumped shapely to \">= 1.7\"\r\n\r\n* Apply suggestions from code review\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* Only check for empty geometries after `.clip_by_rect()`\r\n\r\n* Move changes to `clip.py` to its own PR\r\n\r\n* Change docstring of `base.clip_by_rect()` according to PR comments\r\n\r\n* add interpshinx links\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d69fac254a19ac29e148",
    "number": 1926,
    "body": "This doc PR add hyperlinks from the user-guide to the API. It also adds hyperlinks to the pandas docs.\r\n\r\nBefore: https://geopandas.org/docs/user_guide/mergingdata.html\r\n\r\n![Screenshot from 2021-04-30 14-26-32](https://user-images.githubusercontent.com/17162724/116738155-166d2a00-a9c0-11eb-91fa-83b96f2408a7.png)\r\n\r\nafter with the Blue sections being clickable:\r\n\r\n![Screenshot from 2021-04-30 14-27-11](https://user-images.githubusercontent.com/17162724/116738295-41577e00-a9c0-11eb-92e6-7f18712f8d15.png)\r\n\r\n",
    "head_branch": "doc-hyperlinks",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: hyperlink to API in merging section (#1926)\n\nCo-authored-by: Ray Bell <ray.bell@dtn.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6a0ac254a19ac29e149",
    "number": 1925,
    "body": "I'll confess I was slow to read the text and my eyes tend to drift and follow instructions in the code blocks. The small doc PR adds cd doc in the instructions to make it easier to copy-paste instructions in the future.",
    "head_branch": "doc-contributing",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add cd doc in code block (#1925)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6a1ac254a19ac29e14a",
    "number": 1922,
    "body": "Complements [the example page about adding a background map to plots](https://geopandas.org/gallery/plotting_basemap_background.html) with the new layers functionality of `contextily`, shamefully copying from [its introduction guide](https://contextily.readthedocs.io/en/latest/intro_guide.html#Using-transparent-layers), with the changes introduced in geopandas/contextily#114. Not much but I thought that'd make a good first PR since I'd been following that PR in `contextily` and wanted to give visibility to this feature. \r\n\r\nIn passing I changed the use of the deprecated `url` kwarg of `contextily.basemap` to `source`, adopted the same naming for `contextily` as in its docs(`cx`), and added a plot to show that projecting to Mercator wasn't always necessary.",
    "head_branch": "contextily-layers",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: document contextily layers functionality (#1922)\n\n* DOC: document contextily layers functionality\r\n\r\n* DOC: restructured background map example\r\n\r\n- Explain CRS matching better\r\n- Renamed projected df\r\n- Add sections to better reflect that projecting to mercator is not\r\nmandatory\r\n- Change the sections title levels to match other examples of the\r\ngallery\r\n\r\n* DOC: reduced line length in md\r\n\r\n* DOC: remove last empty cell from basemap example"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6a1ac254a19ac29e14b",
    "number": 1921,
    "body": "This is basically a revert of https://github.com/geopandas/geopandas/pull/1092, and should no longer be needed.",
    "head_branch": "ci-unpin-python",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: unpin python in 3.7 build (#1921)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6a2ac254a19ac29e14c",
    "number": 1920,
    "body": "I wanted to do something fancy with a global map which would store common complex types and return a lambda on how to handle them, with the intention of falling back to `__repr__` but it started to seem unfeasible because of base types.\r\n\r\nI am also not sure if there are some other totally serializable types (like numpy datatypes?) which might get tripped up by this.\r\n\r\nMy alternative is to explicitly check for these problematic data types and cast them accordingly, which gets a bit ugly.\r\n\r\nI added kwargs to distinguish between UNIX and ISO time, as well as between WKB and WKT, but have not yet added the logic to handle the latter of both.\r\n\r\nThe method for converting to UNIX time was based on it [apparently being the recommended way of doing so in the pandas docs, even if it isn't the fastest](https://stackoverflow.com/questions/54313463/pandas-datetime-to-unix-timestamp-seconds)\r\n\r\nAlso no tests because this is very WIP",
    "head_branch": "bugfix/time-geom-json-serialization",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6a3ac254a19ac29e14d",
    "number": 1919,
    "body": "Fixes #1918",
    "head_branch": "arrow_ci",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: fix arrow CI using defaults (#1919)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6a4ac254a19ac29e14e",
    "number": 1916,
    "body": "Revision includes:\r\n\r\n- Sentence level changes\r\n- Typos\r\n- Removal of redundant info\r\n\r\nref #1896",
    "head_branch": "doc-plotting-with-folium-example",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: revise plotting with folium example (#1916)\n\n* DOC: revise plotting with folium example\r\n\r\n* DOC: edit example description\r\n\r\n* Revert \"DOC: revise plotting with folium example\"\r\n\r\nThis reverts commit 58ad279dbc9d0030550566b27035b5e783a9291f.\r\n\r\n* DOC: revise plotting with folium example\r\n\r\nThis commit also include feedback actions."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6a5ac254a19ac29e14f",
    "number": 1913,
    "body": "The main fix here is to pass CI tests, which seem to have been broken for a few weeks. Reading the error message:\r\n\r\n> sqlalchemy.exc.ArgumentError: The argument passed to Dialect.has_table() should be a <class 'sqlalchemy.engine.base.Connection'>, got <class 'sqlalchemy.engine.base.Engine'>. Additionally, the Dialect.has_table() method is for internal dialect use only; please use ``inspect(some_engine).has_table(<tablename>>)`` for public API use\r\n\r\nA second fix is from a warning message:\r\n\r\n> test_sql.py:67: SADeprecationWarning: Calling URL() directly is deprecated and will be disabled in a future release.  The public constructor for URL is now the URL.create() method.\r\n\r\nCloses #1910 ",
    "head_branch": "tst-postgres",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: use public API to fix several issues with sqlalchemy (#1913)\n\n* Use inspect(some_engine).has_table(tablename)\r\n * Use URL.create() instead of calling URL() directly"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6a5ac254a19ac29e150",
    "number": 1909,
    "body": "This fixes #1908 and also completely refactors `geopandas.clip()` to reduce complexity.",
    "head_branch": "fix-multipoint-clipping",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6a6ac254a19ac29e151",
    "number": 1907,
    "body": "Added a small section in User Guide - Mapping and plotting tools called Other map customization. This section covers the set_axis_off method. #524",
    "head_branch": "set-axis-off",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: set_axis_off method in User Guide (#1907)\n\n* DOC: set_axis_off method in user guide\r\n\r\nAdded tiny section in User Guide - Mapping and plotting tools called Other map customization. This section covers the set_axis_off method. #524\r\n\r\n* Update User Guide - Mapping and Plotting Tools\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* Update mapping.rst\r\n\r\n* Update doc/source/docs/user_guide/mapping.rst\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6a7ac254a19ac29e152",
    "number": 1900,
    "body": "Closes #1894",
    "head_branch": "fix-duplicate-column-name-to-json",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix to_json/to_file when DataFrame duplicate columns (#1894) (#1900)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6a8ac254a19ac29e153",
    "number": 1899,
    "body": "Created test suite for overlay based on wiki example.\r\n\r\nCloses #533",
    "head_branch": "overlay",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: create test suite for overlay based on wiki example (#533) (#1899)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6a9ac254a19ac29e154",
    "number": 1895,
    "body": "Closes #1713 ",
    "head_branch": "REF-1713-remove-heuristic-guessing-CRS-projected",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: use crs.is_projected and heuristic as fallback (#1713) (#1895)\n\n* ENH: use crs.is_projected and heuristic as fallback (#1713)\r\n\r\n* apply PR suggestions\r\n\r\n* increase test coverage per PR suggestions"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6aaac254a19ac29e155",
    "number": 1891,
    "body": "* ~~Move `_vectorized._isna` and `array._isna` to a common function stored in a new `_util` module.~~ Combine `array._isna` and `_vectorized._isna` into single `_vectorized.isna`.\r\n* In `array.from_wkb` and `array.from_wkt` check input values  for all kinds of NAs with `isna` rather than `is None` (Fixes part of #1879)\r\n* ~~In `array.to_wkb` and `array.to_wkt` check geometries for all kinds of NAs with `isna` rather than `is None`~~ Removed per comment\r\n* Add `np.nan` and `pd.NA` to missing values in tests of `array.from_wkb`, `array.from_wkt`, ~~`array.to_wkb`, `array.to_wkt`~~",
    "head_branch": "from-wkt-na",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Improve NA handling in to/from wkb/t (#1891)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6aaac254a19ac29e156",
    "number": 1890,
    "body": "Closes #1889 ",
    "head_branch": "feature-1889-add-missing-methods-to-doc",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Add from_wkt, from_wkb, to_wkt, to_wkb to API reference (#1889) (#1890)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6abac254a19ac29e157",
    "number": 1886,
    "body": "Includes minor changes on the sentence level, punctuation, and a few typos.\r\n\r\nI haven't seen a style guide for the Geopandas documentation, but I would recommend adapting the highlights from [Google's developer documentation style guide](https://developers.google.com/style/highlights).",
    "head_branch": "doc-introduction-to-geopandas",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: revise intro to geopandas notebook (#1886)\n\n* DOC: revise intro to geopandas notebook\r\n\r\n* DOC: fix typo and use 'spatial relation'\r\n\r\n* DOC: remove kernel metadata"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6acac254a19ac29e158",
    "number": 1885,
    "body": "With the [super built-in function](https://docs.python.org/3/library/functions.html#super), there is currently a mixture of \"old\" and \"new\" styles used throughout geopandas, where the later is described by [PEP 3135](https://www.python.org/dev/peps/pep-3135/) and approved in 2007 for Python 3.0. This PR transitions most uses of super to the simpler style.\r\n\r\nTwo exceptions that should remain untouched are in `geopandas/geoseries.py` at [L185-L186](https://github.com/geopandas/geopandas/blob/f5c54edfaac04b42ea45557466e3819cbbb2499f/geopandas/geoseries.py#L185-L186) and [L224-L225](https://github.com/geopandas/geopandas/blob/f5c54edfaac04b42ea45557466e3819cbbb2499f/geopandas/geoseries.py#L224-L225). These situations are unique, as the object in the second parameter varies.\r\n\r\n",
    "head_branch": "pep-3135",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "MAINT: use super() as described by PEP 3135 (#1885)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6adac254a19ac29e159",
    "number": 1880,
    "body": "This resolves, specifically, the case of #1879 where input contains any of Pandas' standard representations for missing data (NA, NaN) in addition to None, and PyGEOS is disabled or not installed. It does not resolve the error when PyGEOS is installed/enabled.",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6aeac254a19ac29e15a",
    "number": 1878,
    "body": "Skipping a new test from pandas master to make CI green again.",
    "head_branch": "skip_test",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: skip pandas master fillna test (#1878)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6aeac254a19ac29e15b",
    "number": 1877,
    "body": "Deprecating support of python 3.6 and pandas 0.24.\r\n\r\nThe current dependency versions requirements, following [NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html) assuming the release of 0.10 in July 2021:\r\n\r\n- Python 3.7+\r\n- pandas 0.25+\r\n- shapely 1.6+\r\n- fiona 1.8+\r\n- matplotlib 3.1+\r\n- pyproj 2.2+\r\n- numpy 1.18+",
    "head_branch": "dependencies_drop",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DEP: deprecate python 3.6 and pandas 0.24 (#1877)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6afac254a19ac29e15c",
    "number": 1876,
    "body": "Allowing to expand user, including Path objects. \r\n\r\nCloses #1664\r\n",
    "head_branch": "add_expand_user",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: support ~ (home dir) expansion in file paths ( #1664) (#1876)\n\nCo-authored-by: ImanolUr <imanol@live-eo.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6b0ac254a19ac29e15d",
    "number": 1873,
    "body": "Numpy renamed their `master` branch to `main`, which broke our dev CI environment. ",
    "head_branch": "numpy_main",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: use numpy main instead of master branch (#1873)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6b1ac254a19ac29e15e",
    "number": 1872,
    "body": "Compat with changes in https://github.com/pygeos/pygeos/pull/263#\r\n\r\nccing @brendan-ward ",
    "head_branch": "pygeos-valid-predicate-fix",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "MAINT: use BinaryPredicate Enum for PyGEOS predicates (#1872)\n\n* MAINT: use BinaryPredicate Enum for PyGEOS predicates\r\n\r\n* commmit something to make ci rerun"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6b2ac254a19ac29e15f",
    "number": 1871,
    "body": "allow to retrieve pandas behaviour by not returning a multiindex\r\n\r\nCloses #1859\r\nCloses #1751",
    "head_branch": "explode_to_pandas_behaviour",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: add keywords to control explode index #1751 (#1871)\n\nCo-authored-by: ImanolUr <imanol@live-eo.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6b3ac254a19ac29e160",
    "number": 1869,
    "body": "hvPlot supports GeoPandas data objects natively, extending them with interactive plotting functionality, and so should be listed in the ecosystem section. Also fixed various typos and grammar issues in that file.",
    "head_branch": "hvplot",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Add hvPlot to ecosystem (#1869)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6b4ac254a19ac29e161",
    "number": 1865,
    "body": "This is a really rough pass for now, not much in the way of tests or docs, just trying to get some general feedback on the shape of the implementation as well as timelines to incorporate it (eg. wait for a PyGEOS release).\r\n\r\nThis addresses the following:\r\n- Closes #1096 \r\n- Closes #1271  (replaces)\r\n\r\nSome questions I have:\r\n- Do we want to support the `max_distance` parameter via `nearest_all`? I think @brendan-ward can best weigh in on this.\r\n- Do we want to cook up a \"reasonable\" implementation for `rtree`, like we did with `query_bulk`? I'd say no, in that case we mainly did it because that logic already existed in `sjoin` so really we were reshuffling things to get a cleaner implementation, not inventing anything new. This relates to #1509\r\n- Is there any particular way we want to choose which is the index and which is the input geometries? I went with the simplest I could think of, but there's probably better choices for performance. Again, I think @brendan-ward  is probably the best person for this.\r\n- How much testing do we want for this feature? My sense is that not much should be needed since `_basic_checks` and `_frame_join` are already extensively tested, and the actual nearest logic is tested in PyGEOS.\r\n",
    "head_branch": "sindex-nearest",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: sjoin_nearest (#1865)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6b4ac254a19ac29e162",
    "number": 1864,
    "body": "* Use geom_equals or geom_almost_equals consistently\r\n* Reuse repeated code to generate AssertionError by taking it outside if/else block\r\n* Only check equality once instead of three times by generating a boolean series and reusing it\r\n\r\nCloses #1863",
    "head_branch": "fix-gs-assertion",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Refactor geopandas.testing._check_equality (GH1863) (#1864)\n\n* Refactor geopandas.testing._check_equality\r\n\r\n* Use geom_equals or geom_almost_equals consistently\r\n* Reuse repeated code to generate AssertionError\r\n* Only check equality once instead of three times\r\n\r\n* Make mask helper functions private\r\n\r\n* Add test case"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6b5ac254a19ac29e163",
    "number": 1862,
    "body": "These are just some minor changes, but happy to revise the docs in more detail on a regular basis. \r\n\r\nAlso happy to help out with new documentation content.\r\n\r\nPlease let me know if there is anything that is prioritized.",
    "head_branch": "doc-typos",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: fix typos in contributing guide (#1862)\n\n* DOC: fix typo in contributing section\r\n\r\n* DOC: make minor changes in 'Updating the Doc' section\r\n\r\n* DOC: remove whitespace\r\n\r\nCo-authored-by: Andreas Eliasson <andreas.eliasson@geodata.no>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6b6ac254a19ac29e164",
    "number": 1860,
    "body": "",
    "head_branch": "df_plot",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: remove df from plot docstring (#1860)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6b7ac254a19ac29e165",
    "number": 1858,
    "body": "xref https://github.com/geopandas/geopandas/issues/1776#issuecomment-787486170\r\n\r\nThis copies the template from pandas to ensure the API docstring page gets built properly. \r\nThe reason for the custom template is (IIRC) because sphinx otherwise splits the `geopandas.GeoDataFrame` and `plot` parts incorrectly.\r\n\r\nIt doesn't yet fully show up like a function (eg in the overview page it is listed as `GeoDataFrame.plot` and not ``GeoDataFrame.plot(..)``), but the rest of the generated page looks good (uses the correct docstring. \r\nThe full fix entails a bit more sphinx hackery, like pandas does here: https://github.com/pandas-dev/pandas/blob/f4b67b5eafca7310235cb4b037978739d0e3e52e/doc/source/conf.py#L551-L564\r\n\r\nBut this fix should be sufficient for now I think.\r\n",
    "head_branch": "docs-plot-accessor",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: fix API reference page for GeoDataFrame.plot accessor (#1858)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6b8ac254a19ac29e166",
    "number": 1857,
    "body": "Still need to add tests, but this should fix the pandas plotting issue (https://github.com/geopandas/geopandas/issues/1776#issuecomment-787487017).\r\n\r\nThe underlying cause is in the first place that the subset of columns that gets selected by pandas when preparing to plot (without a geometry column) still is a GeoDataFrame (-> opened https://github.com/geopandas/geopandas/issues/1856). And then on my fix for apply fails for such a GeoDataFrame without geometry column.",
    "head_branch": "fix-apply-no-geometry",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fixup GeoDataFrame.apply in case there is no geometry column (#1857)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6b8ac254a19ac29e167",
    "number": 1855,
    "body": "Removing an example using geoplot which fails (both locally and on RTD).",
    "head_branch": "geoplot_issue",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: remove faulty geoplot Voronoi example (#1855)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6b9ac254a19ac29e168",
    "number": 1854,
    "body": "Temporarily hide docs from menus until there's some contents in it.",
    "head_branch": "hide_roadmap",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: hide roadmap from docs (#1854)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6baac254a19ac29e169",
    "number": 1851,
    "body": "Closes #1708",
    "head_branch": "add_overlay_sjoin_bounds_checks",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Add bounds checks to sjoin, overlay (#1851)\n\n* ENH: Add bounds checks to sjoin, overlay (#1708)\r\n\r\n* fix sjoin and add test that checks for the bug.\r\n\r\n* add test in overlay to check for duplicated columns\r\n\r\n* linting\r\n\r\n* fix overlay and test so it does not return duplicated columns\r\n\r\n* Update geopandas/tools/overlay.py\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* remove unnecessary param\r\n\r\nCo-authored-by: ImanolUr <imanol@live-eo.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6bbac254a19ac29e16a",
    "number": 1850,
    "body": "The binder button in docs creates an incorrect environment at the moment since it uses `environment.yml`, which is meant to be for development and as such does not include geopandas.\r\n\r\nI have renamed the existing `environment.yml` to `environment-dev.yml` and created a new `environment.yml` with all dependencies required to run all examples in docs.",
    "head_branch": "binder_env",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: set up binder environment (#1850)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6bcac254a19ac29e16b",
    "number": 1848,
    "body": "xref https://github.com/geopandas/geopandas/issues/902\r\n\r\nAdding the same logic we added for GeoSeries (https://github.com/geopandas/geopandas/pull/1478) to GeoDataFrame as well",
    "head_branch": "geodataframe-apply",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: try to preserve CRS in GeoDataFrame.apply (#1848)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6bcac254a19ac29e16c",
    "number": 1847,
    "body": "@martinfleis as a test, I copied the docstrings out of the RTreeIndex into a base class, and added those back to the RTreeIndex class with a decorator. And then only included this base class in the sindex.rst API docs.\r\n\r\nOf course, if we want this, we need to generalize the docstrings a bit to suite both implementations. The question is if we want to keep the actual docstrings of the 2 concrete implementations more specific, which is possible, but then it doesn't really lead to a deduplication of docstrings in the code (and only in the online documentation)",
    "head_branch": "doc-sindex",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: only include common spatial index interface in the docs (#1847)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6bdac254a19ac29e16d",
    "number": 1846,
    "body": "Closes #1842 \r\nNeeds more testing.",
    "head_branch": "lazy_crs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6beac254a19ac29e16e",
    "number": 1845,
    "body": "See description in #1844.\r\n\r\nCloses #1844",
    "head_branch": "dissolve-observed",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Add groupby kwargs to dissolve (#1845)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6bfac254a19ac29e16f",
    "number": 1843,
    "body": "That's an optional dependency that is missing",
    "head_branch": "show-versions",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add pygeos to geopandas.show_versions() (#1843)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6c0ac254a19ac29e170",
    "number": 1839,
    "body": "",
    "head_branch": "changelog-090",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC/RLS: update changelog for the 0.9.0 release (#1839)\n\nCo-authored-by: James McBride <jdmcbr@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6c0ac254a19ac29e171",
    "number": 1838,
    "body": "Trying to find a way to make RTD build green.\r\n\r\nCloses #1835 ",
    "head_branch": "rtd_debug",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: debug readthedocs and nbsphinx (#1838)\n\n* don't execute\r\n\r\n* list examples\r\n\r\n* try with executed notebooks\r\n\r\n* build intro, add pygeos\r\n\r\n* auto build\r\n\r\n* build the same as currently\r\n\r\n* remove kernel name\r\n\r\n* add few more\r\n\r\n* revert choro\r\n\r\n* add rest\r\n\r\n* remove kernelspec\r\n\r\n* clear choropleths\r\n\r\n* build choropleths, clear choro_legends\r\n\r\n* clear introduction\r\n\r\n* remove kernelspec\r\n\r\n* clean meta\r\n\r\n* execute choro_legends\r\n\r\n* always execute + exceptions\r\n\r\n* fix cartopy plot"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6c1ac254a19ac29e172",
    "number": 1837,
    "body": "xref #1835 \r\n\r\nThis is how the environment resolves on my ubuntu 18.04.",
    "head_branch": "rtd_pin",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: pin doc environment for RTD (#1837)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6c2ac254a19ac29e173",
    "number": 1836,
    "body": "I just noticed that Readme is using figures stored in examples, so I am just updating links.",
    "head_branch": "readme",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: fix links in readme (#1836)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6c3ac254a19ac29e174",
    "number": 1834,
    "body": "Closes #1833 ",
    "head_branch": "jsonpath",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: fix path to remote gejson (#1834)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6c4ac254a19ac29e175",
    "number": 1831,
    "body": "I am not fully sure if it's solvable otherwise, but the big \"0+untagged.50.g3ba3c75\" on https://geopandas.readthedocs.io/en/latest/index.html is not that nice, so one option is to simply remove the version (the version is accessible in the readthedocs widget).\r\n\r\nAn alternative could be to replace it with something like \"latest\" with some sphinx/jinja magic in case it's from an unreleased version.\r\n\r\nDo we want to add something more to the title than just \"GeoPandas\"? ",
    "head_branch": "doc-title",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: remove the \"dirty\" from version on home page title (#1831)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6c4ac254a19ac29e176",
    "number": 1830,
    "body": "Maybe closes #1829 (can't reproduce it locally, so also can't test if this helps. But this seems wrong in any case)",
    "head_branch": "fix-covers",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6c5ac254a19ac29e177",
    "number": 1828,
    "body": "Fixes #1572\r\n\r\nPart of the original issue was fixed in #1677, the rest is here.",
    "head_branch": "empty_plotting",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REGR: ignore empty geometries in plot (#1828)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6c6ac254a19ac29e178",
    "number": 1826,
    "body": "Closes #1818\r\n\r\nThis adds `normalize` capabilities. For now I only added it to our assert_.. functions. Eventually we might also want to add it to the GeometryArray/GeoSeries, but for that I would like to wait on Shapely including it (https://github.com/Toblerity/Shapely/pull/1090/)\r\n\r\nNormalizing the geometries fixes most of the overlay tests, only the NYBB tests are still failing (here the differences with GEOS 3.9 are bigger than just some coordinate order). Not sure what the best way to solve this is. We can skip the geometry equality check for now with GEOS 3.9 (we already check area and bounds, and that passes), and later re-produce the expected files with GEOS 3.9",
    "head_branch": "geos39-normalize",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: add normalize option to assert methods + fix tests for GEOS 3.9 (#1826)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6c7ac254a19ac29e179",
    "number": 1825,
    "body": "Fixes #1781",
    "head_branch": "quote-identifier",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Add quotes to tablename in COPY (#1825)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6c8ac254a19ac29e17a",
    "number": 1824,
    "body": "",
    "head_branch": "replace-_mapclassify_choro",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6c9ac254a19ac29e17b",
    "number": 1819,
    "body": "Follow-up on https://github.com/geopandas/geopandas/pull/1659 and https://github.com/geopandas/geopandas/pull/1662, also catching the deprecation warning for `len(..)`",
    "head_branch": "shapely-depr-len",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Compatibility with Shapely 1.8 deprecation warnings (__len__) (#1819)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6c9ac254a19ac29e17c",
    "number": 1817,
    "body": "Closes #1791 \r\n\r\nThe actual plot is still looking good, it's only the testing code that is failing.\r\n\r\nIt seems that the order of the axes in `Figure.axes` changed. Previously, it was first the subplot axes and then the colorbar axes. Now it's switched. I am not fully sure what the robust way is of getting this ax ..",
    "head_branch": "tests-mpl-master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: fix tests with matplotlib master (#1817)\n\n* TST: fix tests with matplotlib master\r\n\r\n* also fix legend height test + more robust method to get specific axes object\r\n\r\n* fix robust helper method for old matplotlib\r\n\r\n* typo"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6caac254a19ac29e17d",
    "number": 1815,
    "body": "Test for https://github.com/geopandas/geopandas/pull/1811#issuecomment-770837759",
    "head_branch": "ci-fiona",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: force fiona version to 1.8.13 for minimal build (#1815)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6cbac254a19ac29e17e",
    "number": 1811,
    "body": "Check for a specific warning instead of generic number in buffer CRS warning. It currently fails since pygeog 0.8 and numpy 1.20 raise the following warning (fixed in pygeos 0.9)\r\n\r\n```\r\n  /opt/miniconda3/envs/test/lib/python3.7/site-packages/pygeos/constructive.py:165: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\n  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n    np.bool(single_sided),\r\n```\r\n\r\nhttps://github.com/geopandas/geopandas/runs/1803069757?check_suite_focus=true#step:7:2826",
    "head_branch": "np_warn",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: check exact warning (#1811)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6ccac254a19ac29e17f",
    "number": 1809,
    "body": "closes #1805\r\n\r\nthis solution filters the arrays before being passed into pygeos and then inserts `None` into the array at the indices where null values are found. Probably not the best way to handle it for pygeos, but I think [this issue will eventually deal with the problem](https://github.com/pygeos/pygeos/issues/231). Not sure if the idea would be to leave it to pygeos to fix the problem and then implement something like this or if this is a feasible working solution for the time being. Any suggestions would be much appreciated, thanks.",
    "head_branch": "1805-missing-coordinates",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6cdac254a19ac29e180",
    "number": 1808,
    "body": "The code was getting bloated so I felt like wrapping those repeated lines into a function, but i could undo if you don't agree.\r\n\r\nCloses #1795",
    "head_branch": "improve_assert_messages",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: expand assert messages in assert_geoseries_equal (#1808)\n\n* expanded assert messages. Refactor of duplicated code\r\n\r\n* black formatted\r\n\r\n* fix forgotten if\r\n\r\n* fix forgotten ifs\r\n\r\n* reformat code, add indeces to error and full first geometries\r\n\r\n* fix typo\r\n\r\n* expand tests and check for error message\r\n\r\n* truncate string\r\n\r\nCo-authored-by: ImanolUr <imanol@live-eo.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6cdac254a19ac29e181",
    "number": 1806,
    "body": "The copyright states 2013-2019, but the project looks like it's still being updated as of 2021. This PR changes the end copyright date to 2021.",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Update copyright year (#1806)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6ceac254a19ac29e182",
    "number": 1802,
    "body": "Closes #1799 ",
    "head_branch": "1799-overlay-make_valid",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Add back make_valid to overlay and use to skip the buffer(0) calls (#1802)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6cfac254a19ac29e183",
    "number": 1801,
    "body": "This corrects for removal of `VALID_QUERY_PREDICATES` in #1698, which breaks the sindex benchmarks.\r\n\r\nQuery predicates are now a property on the instance of a sindex backend class.  To get these up front, we have to first create a non-empty instance of the sindex.",
    "head_branch": "fix_sindex_benchmarks",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Fix sindex query predicates used in benchmarks (#1801)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6d0ac254a19ac29e184",
    "number": 1798,
    "body": "Fixes #1704 (probably not completely)\r\n\r\nI went for the easy fix (which still addresses the initial message of the issue), so that I could ask some clarifying questions.\r\n\r\nThe message below seems to suggest that when not passing the data argument (or passing `None`) to the GeoSeries constructor:\r\n\r\n1.  there should be no warning raised\r\n2.  a GeoSeries should still be returned.\r\n\r\nIs this correct ?\r\n\r\n> Thanks for the notice! This is indeed something worth fixing. Not only because of this, but also to avoid that warning we raise during (and potential deprecation in the future).\r\n```\r\nFutureWarning:     You are passing non-geometry data to the GeoSeries constructor. Currently,\r\n    it falls back to returning a pandas Series. But in the future, we will start\r\n    to raise a TypeError instead.\r\n```\r\n> Our constructor should check for this case and return proper GeoSeries in this case:\r\n>https://github.com/geopandas/geopandas/blob/cdb42821ababcf29b6f7f94dd66fa9cb5a8f6071/geopandas/geoseries.py#L103\r\n\r\n_Originally posted by @martinfleis in https://github.com/geopandas/geopandas/issues/1704#issuecomment-729994155_\r\n\r\n",
    "head_branch": "fix_geoseries_initialisation",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Create unintialized GeoSeries (#1798)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6d1ac254a19ac29e185",
    "number": 1797,
    "body": "Locally this seems to work",
    "head_branch": "gha-release",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "GHA: ensure to upload sdist to GitHub release (#1797)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6d1ac254a19ac29e186",
    "number": 1796,
    "body": "",
    "head_branch": "backport-for-0.8",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix pygeos geom types mapping (#1644)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6d2ac254a19ac29e187",
    "number": 1794,
    "body": "",
    "head_branch": "ci-test",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: remove pygeos from builds using defaults channel (not compatible with pygeos 0.9) (#1794)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6d3ac254a19ac29e188",
    "number": 1792,
    "body": "This should avoid issues like https://github.com/geopandas/geopandas/issues/1778 where having an older version of pygeos installed causes geopandas to stop working (if you explicitly set the option to use pygeos, it will still give an error that the version if too old).\r\n\r\nI didn't check what version we actually require, but 0.6 is certainly too old, since `query_bulk` was only added in 0.7. And 0.8 is already a few months old, so that seems fine. ",
    "head_branch": "check-pygeos-version",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Only use pygeos is a recent version is installed (#1792)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6d4ac254a19ac29e189",
    "number": 1790,
    "body": "Skipping another pandas ExtensionArray test not supported on geometries.\r\n\r\nxref  (pandas-dev/pandas#38733)",
    "head_branch": "sorting_tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: skip pandas EA test (pandas #38733) (#1790)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6d5ac254a19ac29e18a",
    "number": 1787,
    "body": "closes #1765 \r\n\r\nthis was pretty much spelled out in the issue, the only place I could find to build a test was in the GeometryArray in `test_array.py` which required the instantiation of a z attr in the `points_no_missing ` list, there may be a cleaner way to do it, but it didn't seem to break any other tests. ",
    "head_branch": "1765-geoseries-z",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6d5ac254a19ac29e18b",
    "number": 1785,
    "body": "Closes #1784",
    "head_branch": "1784/array-to-crs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REF: Implement to_crs and estimate_utm_crs in GeometryArray (#1785)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6d6ac254a19ac29e18c",
    "number": 1775,
    "body": "A first possible step towards https://github.com/geopandas/geopandas/issues/1313\r\n\r\nI did this a while ago, so thought to at least open it as a PR. \r\nWhile this already works fine as is, I think the main question is if we actually want to test this / allow to run our tests without fiona (to make it a proper optional dependency). Because given how *many* of our tests use fiona to read in a test dataset, it might be a bit invasive to change this. ",
    "head_branch": "lazy-fiona",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DEP: lazily import fiona only when used (to make it possible to not have it installed) (#1775)\n\n* DEP: lazily import fiona only when used (to make it possible to not have it installed)\r\n\r\n* fix test"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6d7ac254a19ac29e18d",
    "number": 1773,
    "body": "- [x] closes ##1765\r\n- [x] Ensure all linting tests pass\r\n",
    "head_branch": "impl_geoser_z",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: add GeoSeries.z attribute (#1773)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6d8ac254a19ac29e18e",
    "number": 1770,
    "body": "Closes #1758",
    "head_branch": "rtree_wheels",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Update rtree wheel information in installation instructions (#1770)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6d9ac254a19ac29e18f",
    "number": 1767,
    "body": "Skipping new extension array test `test_argreduce_series` since we do not support sorting in `GeometryArray`. \r\nThis should make CI green again.",
    "head_branch": "ci_sorting",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: skip test_argreduce_series (#1767)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6d9ac254a19ac29e190",
    "number": 1766,
    "body": "Fixes #1717\r\n\r\nI've fixed the tests where there were different lengths of actual and expected colors for the `_check_colors` function (sometimes a length was zero which means there was nothing actually being checked).\r\nIn order to avoid this situation I've also added a simple `assert` in `_check_colors`.\r\n\r\nPlease let me know if there is something that doesn't make sense even though the tests \"are working\".",
    "head_branch": "fix_plotting_tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Fix plotting tests (#1766)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6daac254a19ac29e191",
    "number": 1762,
    "body": "There are apparently workarounds to handle this, but they aren't pretty: https://stackoverflow.com/questions/10669099/italicize-text-containing-a-link\r\n\r\n@martinfleis I see you have some other documentation PRs, so you may want to take a quick look at this.",
    "head_branch": "docs/italics",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: italics can't be nested in links (#1762)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6dbac254a19ac29e192",
    "number": 1759,
    "body": "Adding missing contents to the new documentation. About, Community, Ecosystem + introductory blurbs. I have also started splitting User Guide into User and Advanced Guides as per the proposal in #1505.\r\n\r\nAfter #1731 is merged I'll also move examples from `Getting Started` section to `Documentation` where it belongs.\r\n\r\nWith the rest of PRs, the new webpage is almost ready to be released. One final thing is a roadmap, where I'll need more of your input.",
    "head_branch": "doc_texts",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: documentation pages, ecosystem (#1759)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6dcac254a19ac29e193",
    "number": 1757,
    "body": "This is the first pass on the Introduction to GeoPandas notebook, which will live in Getting Started (https://geopandas.readthedocs.io/en/latest/getting_started/introduction.html). \r\n\r\nIt is intentionally quite short to avoid unnecessary overlaps with the User Guide. The aim is to introduce the concepts before going into the specifics. It assumes basic knowledge of pandas.\r\n\r\nI am open to suggestions regarding its contents since the way how people use GeoPandas quite differ. \r\n",
    "head_branch": "tutorial",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: first pass on the Introduction to GeoPandas (#1757)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6ddac254a19ac29e194",
    "number": 1755,
    "body": "There is a small typo in doc/source/docs/user_guide/projections.rst.\n\nShould read `recommend` rather than `recommenend`.\n\n\nSemi-automated pull request generated by\nhttps://github.com/timgates42/meticulous/blob/master/docs/NOTE.md",
    "head_branch": "bugfix_typo_recommend",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: fix simple typo, recommenend -> recommend (#1755)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6ddac254a19ac29e195",
    "number": 1753,
    "body": "This should fix the CI failure with pandas master. \r\n\r\nI have fixed an expansion of scalar geometry which was mistakenly seen as a list and reimplemented `__contains__` following pandas example with a difference of switching the check (we have `(self == item).any()` whilst pandas `(item == self).any()`). To be honest, I am not sure how come that pandas implementation works with the switched order :).\r\n\r\npandas implementation for a reference:\r\n\r\nhttps://github.com/pandas-dev/pandas/blob/6e1802312b019a061209f3bd75b12a039457f14e/pandas/core/arrays/base.py#L358-L373",
    "head_branch": "contains_ga",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: implement custom __contains__ for GeometryArray (#1753)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6deac254a19ac29e196",
    "number": 1750,
    "body": "A relatively random batch of docstring updates.\r\n\r\nCloses #1716\r\nCloses #1571\r\nCloses #991",
    "head_branch": "tools_docs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: documentation improvements (#1750)\n\n* docstring changes\r\n\r\n* cx\r\n\r\n* notes\r\n\r\n* ci fix\r\n\r\n* skip check\r\n\r\n* updates based on the review\r\n\r\n* Update geopandas/base.py\r\n\r\nCo-authored-by: Flavin <flavinj@gmail.com>\r\n\r\n* typo\r\n\r\nCo-authored-by: Flavin <flavinj@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6dfac254a19ac29e197",
    "number": 1749,
    "body": "Adding `sindex` and its methods to the API documentation, including docstring examples.\r\n\r\nCloses #1479",
    "head_branch": "sindex_docs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: document sindex API (#1749)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6e0ac254a19ac29e198",
    "number": 1747,
    "body": "Closes #1745\r\nCloses #1746\r\n\r\nMoving conditions into `__setstate__` and `__getstate__` to make sure it reacts to `geopandas.options.use_pygeos = False`.\r\n\r\n_edit:_ I have also included a patch for #1746 now. Since `pygeos.STRtree` cannot be pickled now, it is ignored during pickling and `_sindex` is set to `None` during un-pickling.",
    "head_branch": "shapely_pickle",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REGR: fix pickle issues (#1747)\n\n* fix shapely pickling\r\n\r\n* test\r\n\r\n* fix 1746\r\n\r\n* explain\r\n\r\n* fix tests\r\n\r\n* try with fixture\r\n\r\n* fix tests on windows"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6e1ac254a19ac29e199",
    "number": 1744,
    "body": "Overrides `ExtensionArray.shift` in `GeometryArray` to preserve the `crs`.\r\n\r\nI considered an alternative implementation of overriding `_from_sequence`. That's what `ExtensionArray.shift` calls to make a new array and where the CRS is lost. (see https://github.com/pandas-dev/pandas/blob/653f6944eba664d19e8d93e850340ac039ec452e/pandas/core/arrays/base.py#L677-L692). So I figured if I could preserve the CRS there, it would fix this issue in `shift` but also potentially other places where `_from_sequence` is used. The problem is `_from_sequence` is a class method, not an instance method. So even though it is called with `self._from_sequence` it doesn't actually have access to anything within `self` and thus doesn't have the `crs`. It is possible to make a custom descriptor that would give `_from_sequence` a class method implementation and an instance method implementation, thus preserving the existing behavior if called with `GeometryArray._from_sequence` and adding new behavior if called with `self._from_sequence` on an instance. But that seems like a bit much considering that overriding `shift` is so simple.\r\n\r\nCloses #1648 ",
    "head_branch": "1648/shift",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Override shift in GeometryArray to preserve CRS (#1744)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6e2ac254a19ac29e19a",
    "number": 1737,
    "body": "We (pysal) have released new `mapclassify` which comes with a new streamlined API which replaces our `_mapclassify_choro` so we don't have to deal with it within geopandas. I'd say it is a nice cleanup.\r\n\r\nMy question - are we fine with requiring mapclassify 2.4.0 for geopandas 0.9.0? I'd say it is fine since it is a relatively lightweight optional dependency. If not I can keep `_mapclassify_choro` around for backward compatibility (but in that case I'd rather wait with this PR until it can be removed).\r\n\r\nCloses #1669 ",
    "head_branch": "mc_api",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REF: replace _mapclassify_choro with new API (#1737)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6e2ac254a19ac29e19b",
    "number": 1733,
    "body": "Follow-up on #1617 \r\n\r\nAs before, this mostly focuses on examples section. Further adaptations of descriptions and linking via `See also` will come later.",
    "head_branch": "doc_examples",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: another batch of docstring examples (#1733)\n\n* docstring examples\r\n\r\n* fix buffer\r\n\r\n* Apply suggestions from code review\r\n\r\nCo-authored-by: Flavin <flavinj@gmail.com>\r\n\r\n* Update geopandas/base.py\r\n\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>\r\n\r\n* use matplotlib plot directive\r\n\r\nCo-authored-by: Flavin <flavinj@gmail.com>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6e3ac254a19ac29e19c",
    "number": 1731,
    "body": "Switching examples gallery from `sphinx_gallery` to `nbsphinx`. All examples we had are now shown in the documentation. Some of them need some care but I'll take care about that in follow-up PRs. This is implementing new technical solution only. `myst-nb` has been replaced by `myst-parser` to have only one extension parsing notebooks (`nbsphinx`).\r\n\r\n- gallery looks the same (with thumbnails)\r\n- all examples are Jupyter notebooks now\r\n- all are within `doc/source/gallery` - there is no way to load them from original `examples` folder\r\n- all are executed by sphinx to get fresh outputs\r\n- all can be run interactively on mybinder\r\n- interactivity (folium) works\r\n- links to existing examples in gallery are still the same\r\n\r\nI have temporarily unpinned the environment, because I am adding new dependencies and we need to update them anyway. Will pin them again in one of the future PRs based on what rtd picks.\r\n\r\nCloses #280\r\nCloses #1254",
    "head_branch": "gallery",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: use Jupyter examples via nbsphinx gallery (#1731)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6e4ac254a19ac29e19d",
    "number": 1729,
    "body": "See https://github.com/geopandas/geopandas/issues/1728\r\n\r\nFirst commit to add CI (and to see failures), will further add commits with some fixes.",
    "head_branch": "numpy-dev",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix compatilibilty with numpy 1.20.0 (#1729)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6e5ac254a19ac29e19e",
    "number": 1725,
    "body": "Reading the docs, trying to learn the tool, I noticed the typo in the spelling of South America.\r\n\r\nForgive the extremely pedantic PR!",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Fixing a typo in \"South America\" (#1725)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6e6ac254a19ac29e19f",
    "number": 1721,
    "body": "",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: remove misplaced curly bracket from projection.rst (#1721)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6e7ac254a19ac29e1a0",
    "number": 1720,
    "body": "As in the title, this PR is a work in progress. Black and flake8 have not yet been run. I'll run them when the changes are deemed satisfactory.\r\n\r\nI have given no special attention to the onoing \"MultiIndex vs. Duplicate Index\" debate, just added a snippet to naively forward the inputs to pandas if the geom col is not None and not the geometry column name.\r\n\r\nHowever this could raise another interesting question - I often have two geometry-type columns in a geodataframe for alternate representations, and sort of \"activate and deactivate\" them as I please. Maybe it's not the best practice but nothing stops me from doing it. If the data type of the column is a shapely geometry, but is not the \"active\" geometry column, should it be geometrically or non-geometrically exploded?\r\n\r\nRelated to https://github.com/geopandas/geopandas/issues/1140 and https://github.com/geopandas/geopandas/issues/1719",
    "head_branch": "bugfix/explode-pandas-override-1140",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: fallback to DataFrame.explode() when the specified column is not the geometry column (#1720)\n\n* WIP: Added check to GeoDataFrame.explode() to see if it should fall back to the default pandas method of the same name\r\n\r\n* Will geometrically explode if the column dtype is geometry, and defaults to active geometry column if left as None\r\n\r\n* changed type check to isinstance\r\n\r\n* moved explode() definition from GeoPandasBase to GeoSeries\r\n\r\n* Removed ignore_index from explode() args\r\n\r\n* cleanup\r\n\r\n* black\r\n\r\n* skipif\r\n\r\n* skipif pandas 024\r\n\r\n* added test for epxlode pandas fallback when column param is provided as arg instead of kwarg\r\n\r\n* Using assert_geodataframe_equal instead of assert_frame equal and test column param supplied as arg or kwarg in both cases per function (ignore_index=True or False)\r\n\r\n* blacken + docs\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6e7ac254a19ac29e1a1",
    "number": 1714,
    "body": "Closes #1712 ",
    "head_branch": "1712/gdf-init-kwargs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REF: Add geometry and crs to GDF.__init__ signature (#1714)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6e8ac254a19ac29e1a2",
    "number": 1710,
    "body": "* Add `GeoSeries.to_wkt`, `GeoSeries.to_wkb` to encode geometries and return pandas `Series`\r\n* Add `GeoSeries.from_wkt`, `GeoSeries.from_wkb` ~~static~~ class methods to construct `GeoSeries` from encoded geometries\r\n* Add `GeoDataFrame.to_wkt`, `GeoDataFrame.to_wkb` to encode all columns in the gdf with type `geometry` and return pandas `DataFrame`\r\n* ~~Add keyword args `wkt` and `wkb` to `GeoDataFrame` constructor. These function similarly to the `geometry` kwarg but first decode the values.~~ Removed. Added example for constructing `GeoDataFrame` with wkb/t by first constructing `GeoSeries`.\r\n\r\nCloses #1680\r\nCloses #1689 \r\n",
    "head_branch": "1680/wkt-wkb-functions",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Integrate to/from wkt/wkb functions into public API (#1710)\n\n* Add GeoSeries to_wkt and to_wkb methods\r\n\r\n* Add hex=False kwarg to existing from_wkb functions\r\n\r\n* Add GeoSeries from_wkt and from_wkb methods\r\n\r\n* Add wkt, wkb, and wkb_hex kwargs to GeoDataFrame constructor\r\n\r\n* Add GeoDataFrame to_wkt and to_wkb methods\r\n\r\n* Remove _export_wkb method from arrow in favor of GeoDataFrame to_wkb\r\n\r\n* Shorten line lengths to satisfy linter\r\n\r\n* Apply black reformatting\r\n\r\n* Remove most references to WKB hex. shapely supports it, pygeos does not.\r\n\r\n* Remove docstring examples of GeoSeries.to_wkb and GeoSeries.from_wkb, as docstrings interpreted as source code are not allowed to contain null bytes\r\n\r\n* Change GeoSeries from_wkb/t from staticmethod to classmethod and return using cls\r\n\r\n* Allow GeoSeries.from_wkb/t to accept Series input, and test that\r\n\r\n* Remove GeoDataFrame.__init__ wkt and wkb kwargs\r\n\r\n* Use GeoSeries.from_wkt in example\r\n\r\n* Keep index of Series passed to GeoSeries.from_wkb/t\r\n\r\n* Apply suggestions from code review\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* Add one-liner docstring to _from_wkb_or_wkt and see also to from_wkb and from_wkt\r\n\r\n* Reindex instead of raise ValueError when passing index to from_wkb/t with series\r\n\r\n* Expose hex and kwargs in to_wkb/t methods\r\n\r\n* update example\r\n\r\n* Fix lint error\r\n\r\n* preserve index of passed series\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6e9ac254a19ac29e1a3",
    "number": 1706,
    "body": "Tests are down due to https://github.blog/changelog/2020-10-01-github-actions-deprecating-set-env-and-add-path-commands/\r\n\r\nThis is an attempt to fix that.",
    "head_branch": "fix_gha_add",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: fix conda setup (#1706)\n\n* CI: fix conda setup\r\n\r\n* fix env variables\r\n\r\n* another attempt\r\n\r\n* fix echo"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6eaac254a19ac29e1a4",
    "number": 1705,
    "body": "Pandas to_sql accepts a sqlalchemy connection or an engine or a string.\r\nOur current implementation of write_postgis requires a sqlalchemy\r\nengine, so making the variable name and documentation reflect that more\r\nunambiguously can help avoid confusion. xref #1699",
    "head_branch": "issue1669",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6ebac254a19ac29e1a5",
    "number": 1703,
    "body": "Adding an environment with Python 3.9 to be tested on ubuntu.",
    "head_branch": "py39",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: add Python3.9 to CI matrix (#1703)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6ecac254a19ac29e1a6",
    "number": 1702,
    "body": "Fixes #1657.\r\n\r\nShould the edits of this pull request be accepted, they would need to be merged with the ones in #1694. \r\nWhat's the procedure in cases like that ? Should I submit a single pull request that closes the two issues ?\r\n\r\nAlso, should a test about plotting empty geometries be added ?",
    "head_branch": "fix_plot_empty_geometries",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REG: Do not attempt to plot empty geometries (#1702)\n\n* Do not attempt to plot empty geometries. Fixes #1657\r\n\r\n* Add test for plotting of empty geometry\r\n\r\n* Add warning when plotting GeoSeries with only empty geometries\r\n\r\n* Add test for plotting GeoSeries with only empty geometry\r\n\r\nCo-authored-by: Giacomo Caria <gcaria@loholt1.ipsl.polytechnique.fr>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6ecac254a19ac29e1a7",
    "number": 1698,
    "body": "Closes #1696 ",
    "head_branch": "sindex-error-handling",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH/MAINT: Let wrappers handle valid predicates (#1698)\n\n* Let wrappers handle valid predicates\r\n\r\n* Check for error in tests\r\n\r\n* Allow None for pygeos\r\n\r\n* set syntax duuuhh\r\n\r\n* replace query bulk predicate check\r\n\r\n* Remove error handling changes\r\n\r\n* Add tests; make valid_preds a class method\r\n\r\n* make things just a property"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6edac254a19ac29e1a8",
    "number": 1694,
    "body": "Fixes #1679.",
    "head_branch": "fix_plot_multipoints_value_based_colors",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Expand values as colors only once when plotting MultPoints (#1694)\n\n* Expand values as colors only once. Fixes #1679\r\n\r\n* Fix test_multipoints when using values as colors\r\n\r\n* Add comment about expansion of values\r\n\r\nCo-authored-by: Giacomo Caria <gcaria@loholt1.ipsl.polytechnique.fr>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6eeac254a19ac29e1a9",
    "number": 1693,
    "body": "Resolves #1672\r\n\r\nThis is pending the upcoming 0.9 release of pygeos.  For testing purposes here, this instead checks to see if that function is availalbe in `pygeos`.  This should probably be switched to a strict version check once 0.9 is released.\r\n\r\n\r\nTODO:\r\n~~Add specific tests for original labeled index values~~ (existing tests probably sufficient)\r\n* [x] Update pygeos version check on release of pygeos 0.9\r\n* [ ] Add changelog entry\r\n\r\n",
    "head_branch": "faster_explode",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: integrate pygeos.get_parts for faster explode() (#1693)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6efac254a19ac29e1aa",
    "number": 1690,
    "body": "Crossref #1627 \r\n\r\nThis isn't pretty. But it is (1) temporary (until Shapely 2.0 and/or `sindex_backend` becomes a user-configurable parameter just like `crs`) and (2) minimum diff/LOC changes necessary (I think).",
    "head_branch": "deprecate-has_sindex",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST/MAINT: Deprecation of has_sindex (#1690)\n\n* Hacky deletion of has_sindex\r\n\r\n* remove unused imports"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6f0ac254a19ac29e1ab",
    "number": 1689,
    "body": "movedd wkt and wkb function from array.py to geoseries.py",
    "head_branch": "Ervin66-patch-2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6f0ac254a19ac29e1ac",
    "number": 1688,
    "body": "movedd wkt and wkb function from array.py to geoseries.py",
    "head_branch": "revert-1-Ervin66-patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6f1ac254a19ac29e1ad",
    "number": 1687,
    "body": "moved from array.py to geoseries method",
    "head_branch": "publicize-wkt-and-wkb-as-geoseries-methods",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6f2ac254a19ac29e1ae",
    "number": 1686,
    "body": "Per @ocefpaf comment here: https://github.com/geopandas/geopandas/issues/982#issuecomment-720506732,\nadd the conda-forge geopandas-feedstock as part of the installation\ntemplate.\n",
    "head_branch": "conda-forge-in-install-template",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6f3ac254a19ac29e1af",
    "number": 1685,
    "body": "xref https://github.com/geopandas/geopandas/issues/982#issuecomment-720506732\r\n\r\n> b/c conda-forge issues on geopandas installation are quite common, maybe we should add the feedstock link and a message on the issue template to guide people there.",
    "head_branch": "c_f_note",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "GH: link geopandas-feedstock for conda-forge issue (#1685)\n\n* GH: link geopandas-feedstock for conda-forge issue\r\n\r\n* the"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6f4ac254a19ac29e1b0",
    "number": 1677,
    "body": "Closes #1039",
    "head_branch": "polygon-patch",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DEP: No longer rely on descartes, use own version of PolygonPatch (#1677)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6f4ac254a19ac29e1b1",
    "number": 1676,
    "body": "The dev build was failing related to matplotlib, which started to support array-like argument for the `alpha` style keyword (see https://matplotlib.org/devdocs/users/next_whats_new/alpha_array.html), but which we explicitly tested that it raised an error.\r\n\r\nAlso enabling the dev github actions build to be visible if there are failures, since we currently don't have any (we can always skip it again if there turn up failures we can't directly fix).",
    "head_branch": "mpl-tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST/ENH: support array-like alpha + fix plotting tests for matplotlib dev version (#1676)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6f6ac254a19ac29e1b2",
    "number": 1674,
    "body": "This is very much WIP, but I'd like to hear your thoughts on the API (@jorisvandenbossche, @brendan-ward, @ljwolf, @jdmcbr). \r\n\r\nThis PR implements `intersects_any` and `intersects_matrix` methods (and their analogies for other predicates). We don have `s.intersects(s2)` which is row-wise. I have myself explained this on SO way too many times after people assumed that it checks it a geometry from `s` intersects _any_ geometry from `s2`.\r\n\r\n`intersects_any` does exactly that - checks if a geometry intersects any geometry from other geoseries.\r\n\r\n```python\r\n>>> from random import randint\r\n>>> import geopandas as gpd\r\n>>> from shapely.geometry import Point\r\n\r\n>>> pts = [Point(randint(0, 100), randint(0, 100)) for _ in range(100)]\r\n>>> polys = [Point(randint(0, 100), randint(0, 100)).buffer(5, cap_style=3) for _ in range(100)]\r\n\r\n>>> pt = gpd.GeoSeries(pts)\r\n>>> pl = gpd.GeoSeries(polys)\r\n\r\n>>> pt.intersects_any(pl)\r\n0      True\r\n1      True\r\n2      True\r\n3     False\r\n4     False\r\n      ...  \r\n95     True\r\n96    False\r\n97     True\r\n98    False\r\n99     True\r\nLength: 100, dtype: bool\r\n```\r\n\r\n`intersects_matrix` gives you a list of integer indices of all geometries which are intersected. Here we could also return the original index values (ideally give an option?).\r\n\r\n```python\r\n>>> pt.intersects_matrix(pl)\r\n0             [11]\r\n1             [98]\r\n2     [64, 12, 62]\r\n3             None\r\n4             None\r\n          ...     \r\n95        [12, 46]\r\n96            None\r\n97            [54]\r\n98            None\r\n99            [40]\r\nLength: 100, dtype: object\r\n```\r\n\r\nBoth are just wrapping `GeoSeries.sindex.bulk_query` to a convenient user-facing function. \r\n\r\nWhat are your thoughts on this API? Is it okay as three separate methods (`intersects`, `intersects_any`, `intersects_matrix`) or should we rather keep it all within `intersects` and control the output using some arguments? Or keep `intersects` as is and merge the two new into one with an argument?\r\n\r\nThe relevant discussion here #972 (+ we talked about this during the last dev meeting). \r\n\r\nOnce we agree on API I'll go ahead and do the rest to have it ready for 0.9.\r\n\r\nCloses #972",
    "head_branch": "binary_matrix",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6f6ac254a19ac29e1b3",
    "number": 1673,
    "body": "Closes #1647 \r\n\r\nThe lines I've added suppress the warning when calling both `__repr__` and `total_bounds`.\r\nThis is not exactly the fix what was asked in the issue, but I have noticed that `total_bounds` could already return silently nans before this edit.\r\n\r\nMaybe a warning message about returning nans can be printed for both cases ?",
    "head_branch": "remove_warning_repr_empty_geoseries",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Suppress warning when calling repr of empty GeoSeries (#1673)\n\nCo-authored-by: Giacomo Caria <gcaria@loholt1.ipsl.polytechnique.fr>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6f7ac254a19ac29e1b4",
    "number": 1670,
    "body": "This fixes #1634.\r\n\r\nIf categories are passed as a Series, call `.reindex()` so the index matches the data index when plotting.",
    "head_branch": "bug-fix",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: categories passed as a series are not properly sorted (#1670)\n\n* add regression test\r\n\r\n* reindex if column is a Series when plotting\r\n\r\n* remove unnecessary import\r\n\r\n* add test for pd.Series colors w/o index too\r\n\r\nCo-authored-by: Nick Hand <nicholas.adam.hand@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6f8ac254a19ac29e1b5",
    "number": 1668,
    "body": "Closes #750\r\n\r\nAdding a boolean keyword `align` to all methods based on `_binary_geo` and `_binary_op`. We currently automatically align both GeoSeries when doing e.g. `s.intersects(s2)`. Sometimes (most of the time probably), this is not the behaviour we want, hence this PR allows `s.intersects(s2, align=False)` which compares rows based on their order.\r\n\r\nI have also expanded documentation of affected methods to make sure that their behaviour is clear, row-wise. Most of the PR are examples, the code change is few lines.\r\n\r\nAlso closes #1829 and closes #1701",
    "head_branch": "align",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: add a keyword to control alignment in binary operations and predicates (#1668)\n\n* align keyword\r\n\r\n* tests\r\n\r\n* first set of docstrings\r\n\r\n* docstrings\r\n\r\n* docs\r\n\r\n* shapely test\r\n\r\n* fix condition\r\n\r\n* fix project test\r\n\r\n* docstring changes per review"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6f9ac254a19ac29e1b6",
    "number": 1666,
    "body": "With the latest changes in pydata-sphinx-theme providing CSS variables as an entry to override theme aspects, we can simplify our custom.css a bit (note, not yet to merge, as this is not yet released)",
    "head_branch": "docs-css-variables",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: use CSS variables to customize sphinx theme (#1666)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6faac254a19ac29e1b7",
    "number": 1662,
    "body": "Follow-up on https://github.com/geopandas/geopandas/pull/1659\r\n\r\nThis further fixes warnings about trying to convert a geometry to an array (`np.array(geom)` instead of `np.array(geom.coords)`). This again mostly happens under the hood in numpy, so adding it to the context manager I added in #1659",
    "head_branch": "shapely2.0-compat",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Compatibility with Shapely 1.8 deprecation warnings (array interface, asShape) (#1662)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6fbac254a19ac29e1b8",
    "number": 1659,
    "body": "I had hoped this being less involved, but apparently, even with our workaround of \r\n\r\n```\r\nout = np.empty(.., dtype=object)\r\nout[:] = [...]\r\n```\r\n\r\nto avoid that numpy expands Multi-part geometries upon array construction, the above snippet *still* triggers the warning about Multi-part geometries no longer being iterable (not really sure why, since numpy doesn't actually iterate through them in that case to create the result, but internally in numpy it still happens). \r\n\r\nSo therefore, I added a context manager around all those cases where we create a ndarray in this way, and for shapely 1.8 it supresses this warning, otherwise it is a no-op context manager.",
    "head_branch": "shapely2.0-compat",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Compatibility with Shapely 1.8 deprecation warnings (iteration) (#1659)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6fbac254a19ac29e1b9",
    "number": 1658,
    "body": "closes #1654\r\n\r\nCan use some additional tests (eg to also test flags), but putting it out here to check if this is working.",
    "head_branch": "update-finalize",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: support pandas' new .attrs functionality (#1658)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6fcac254a19ac29e1ba",
    "number": 1655,
    "body": "`GeoSeries.explode()` does not preserve CRS. Fixed.\r\n\r\nTo reproduce a bug:\r\n\r\n```python\r\nnybb = gpd.read_file(gpd.datasets.get_path('nybb'))\r\nnybb.geometry.explode().crs\r\n```",
    "head_branch": "explode_crs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REGR: CRS lost in GeoSeries.explode()"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6fdac254a19ac29e1bb",
    "number": 1651,
    "body": "This PR adds one step to CI, checking docstring examples using `pytest` as suggested in #1617. That involves a bit more changes than I initially expected, notably required import of `pytest` on top of every file with examples to avoid the necessity to do `import geopandas` in every single example.\r\n\r\nI have added one step to CI checking only docstrings, using pytest plugin `pytest-doctestplus` which allows checking docstrings only. It is run in a single environment, as those with missing dependencies are failing (naturally).\r\n\r\nYou don't have to check the actual docstrings as changes included in this PR are minimal to make doctest pass.",
    "head_branch": "examples",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC/CI: enable doctest (#1651)\n\n* inital doctest work\r\n\r\n* doctest\r\n\r\n* skip from_file\r\n\r\n* test docstring with postgis only\r\n\r\n* use doctest-plus\r\n\r\n* c-f\r\n\r\n* conditional imports\r\n\r\n* revert\r\n\r\n* revert conda\r\n\r\n* fixture to conftest.py\r\n\r\n* minimise changes, verbose output\r\n\r\n* remove blank line\r\n\r\n* revert pandas doc"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6feac254a19ac29e1bc",
    "number": 1650,
    "body": "I forgot to add it after #1617.",
    "head_branch": "rtd_toggle",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add sphinx-toggleprompt to red environment (#1650)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6ffac254a19ac29e1bd",
    "number": 1646,
    "body": "Closes #1528\r\n\r\nDepends on release of pyproj 3+, but figured it wouldn't hurt to get the review process started.",
    "head_branch": "estimate_utm",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Add estimate_utm_crs method to GeoSeries and GeoDataFrame (#1646)\n\n* ENH: Add estimate_tum_crs method to GeoSeries and GeoDataFrame\r\n\r\n* Add examples & expect release in 0.9\r\n\r\n* undo changes in CI\r\n\r\n* Update geopandas/geoseries.py\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* pytest.mark.skipif\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* Update geopandas/geodataframe.py\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* more skipif\r\n\r\n* use pyproj to transform bounds\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d6ffac254a19ac29e1be",
    "number": 1644,
    "body": "Continuation of #1641. Pygeos now put `-1` back, just as `MISSING`. This should be backward compatible.\r\n\r\nref https://github.com/pygeos/pygeos/pull/204",
    "head_branch": "geomtypes",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix pygeos geom types mapping (#1644)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d700ac254a19ac29e1bf",
    "number": 1641,
    "body": "Fixes #1640\r\n\r\nPyGEOS now returns -1 for missing geometry on geom_type check. Adding it to our mapping. Since it is fixing a bunch of failing tests, I guess no new tests are needed.",
    "head_branch": "pygeos_geom_types",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix geom types codes for pygeos (#1641)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d701ac254a19ac29e1c0",
    "number": 1639,
    "body": "Keeping pygeos installed from github master only in dev environment. The recent change on pygeos master killed our CI.",
    "head_branch": "pygeos_conda",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: keep pygeos master in dev environment only (#1639)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d702ac254a19ac29e1c1",
    "number": 1638,
    "body": "The `gdf.to_postgis` method/helpers were calling `.begin()`, which is not compatible between `Engine`s and `Connection`s (unfortunately...). This adds a little extra logic to ensure we retrieve the right value. This supports wrapping `to_postgis` calls within a larger transaction/connection.\r\n\r\nI also replaced the (to be [deprecated in 1.14](https://github.com/sqlalchemy/sqlalchemy/blob/cea03be/doc/build/changelog/unreleased_14/4755.rst)) `run_callable` use. Even though `Connectable.has_table` method will also be deprecated, the `dialect` one doesn't seem to be.\r\n\r\nHmm, test failures seem unrelated(?)",
    "head_branch": "fix-to-postgis-conn",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: support for sqlalchemy connections in to_postgis to support external transactions (#1638)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d703ac254a19ac29e1c2",
    "number": 1637,
    "body": "As discussed in #390, the id property in geojson generated with to_json\r\nmay not be all that meaningful (frequently just an arbitrary row number\r\nin a dataframe). The option to disable writing ids without meaning is\r\ngiven here with a new argument `drop_id`, set to `False` by default.",
    "head_branch": "issue390",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Make the id property in to_json optional (#1637)\n\n* Make the id property in to_json optional\r\n\r\nAs discussed in #390, the id property in geojson generated with to_json\r\nmay not be all that meaningful (frequently just an arbitrary row number\r\nin a dataframe). The option to disable writing ids without meaning is\r\ngiven here with a new argument `drop_id`, set to `False` by default.\r\n\r\n* Add to_json tests when only geometry column\r\n\r\n* Fix linting error\r\n\r\n* Improved docstring on drop_id option\r\n\r\n* Fix merge conflict leftover\r\n\r\n* Set id key first in iterfeatures\r\n\r\n* Update geopandas/geodataframe.py\r\n\r\n* Update geopandas/geodataframe.py\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d704ac254a19ac29e1c3",
    "number": 1636,
    "body": "When I added `GeoSeries.apply` in #1478, I apparently forgot one keyword that the pandas version has\r\n\r\nTo fix https://github.com/jsignell/dask-geopandas/issues/18, ",
    "head_branch": "fix-apply",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix overridden GeoSeries.apply method to accept convert_dtype keyword (#1636)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d704ac254a19ac29e1c4",
    "number": 1633,
    "body": "On Travis we had a cron schedule to run tests daily, to catch potential issues. Setting the same on GHA.",
    "head_branch": "gha_cron",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: schedule daily tests (#1633)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d705ac254a19ac29e1c5",
    "number": 1632,
    "body": "Changing CI instructions mentioning Travis to GitHub Actions. I have also renamed the folder with test environments to avoid confusion in the future.",
    "head_branch": "gha_notes",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC/CI: remove Travis from docs and paths (#1632)\n\n* DOC/CI: remove Travis from docs and paths\r\n\r\n* use envs\r\n\r\n* fix\r\n\r\n* typo\r\n\r\n* how to trigger check"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d706ac254a19ac29e1c6",
    "number": 1631,
    "body": "Fixes #1615 \r\n\r\nCorrectly assess `is_ring` based on geometry type. Directly for LineString and LinearRing, as the exterior for Polygon. No other geometry can return True by definition.",
    "head_branch": "1615",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: is_ring returns False even for all LineStrings and LinearRings (#1631)\n\n* BUG: fix is_ring\r\n\r\n* warning, clean pygeos\r\n\r\n* Update geopandas/_vectorized.py\r\n\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>\r\n\r\n* conditional warning\r\n\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d707ac254a19ac29e1c7",
    "number": 1629,
    "body": "Adding `codecov.yml` to avoid unintentional failure of the coverage check. There are common cases where codecov reports 100% coverage of the patch, but a decrease of coverage of the project (usually by 0.X%), causing check failure. We now require at least 95% coverage and allow 0.2% drop.\r\n\r\nI still don't know why a bot does not comment, but it could be fixable via reconnecting Codecov integration in settings. cc @jorisvandenbossche \r\n\r\nCloses #1628 ",
    "head_branch": "codecov",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: codecov yml (#1629)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d708ac254a19ac29e1c8",
    "number": 1627,
    "body": "Addresses point 1. in #1529.",
    "head_branch": "public-spatial-index-check",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: add public has_sindex method (#1627)\n\n* add public sindex_generated method to GeoDataFrame, GeoSeries and GeometryArray\r\n\r\n* add docstring\r\n\r\n* doc suggestions\r\n\r\n* PR feedback\r\n\r\n* revert docstring\r\n\r\n* geometry -> geom\r\n\r\n* edit docstring\r\n\r\n* Update geopandas/array.py\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* formatting\r\n\r\n* PR feedback\r\n\r\n* Update base.py\r\n\r\n* add to api docs\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d708ac254a19ac29e1c9",
    "number": 1626,
    "body": "Closes #1525",
    "head_branch": "deprecate-op",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REF/MAINT: deprecate sjoin op param in favor of predicate (#1626)\n\n* deprecate op param\r\n\r\n* remove line\r\n\r\n* rename op -> predicate in docs\r\n\r\n* Test for collision and unknown kwargs\r\n\r\n* Update geopandas/tools/sjoin.py\r\n\r\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>\r\n\r\n* Update geopandas/tools/sjoin.py\r\n\r\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>\r\n\r\n* PR feedback\r\n\r\n* fix typo\r\n\r\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d709ac254a19ac29e1ca",
    "number": 1625,
    "body": "Address points 2 & 3 of #1529. Point 1 requires unrelated changes to `Base` to check if it has a geometry column, then if that column has a spatial index generated or not.",
    "head_branch": "sindex-empty-check",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: speed up emptiness and size checks for rtree (#1625)\n\n* speed up emptiness and size checks for rtree\r\n\r\n* add self.leaves comment\r\n\r\n* Update sindex.py"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d70aac254a19ac29e1cb",
    "number": 1620,
    "body": "I for one keep forgetting to blacken my code prior to submitting a PR which wastes CI resources needlessly...\r\n\r\nIf usage of `pre-commit` was forced upon me I could have skipped this as `black` would be run automatically.\r\n\r\nThis PR is prompted by me forgetting to blacken my code during #1610... ",
    "head_branch": "rdmolony-add-precommit-prompt-to-contributing-docs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d70bac254a19ac29e1cc",
    "number": 1619,
    "body": "Closes #1540",
    "head_branch": "overload-from-dict",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Overload from_dict to accept crs and geometry (#1619)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d70cac254a19ac29e1cd",
    "number": 1618,
    "body": "Closes #1573",
    "head_branch": "to_crs_none",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Handle missing geometry with to_crs and shapely (#1618)\n\n* BUG: Handle missing geometry with to_crs and shapely\r\n\r\n* remove pygeos compat stuff in tests"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d70cac254a19ac29e1ce",
    "number": 1617,
    "body": "The first batch of docstring examples. More to come in follow-up PRs.",
    "head_branch": "examples",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Docstring examples (#1617)\n\n* GeoSeries examples\r\n\r\n* GeoSeries examples\r\n\r\n* GeoDataFrame examples\r\n\r\n* missed one\r\n\r\n* base examples\r\n\r\n* review changes\r\n\r\n* toggleprompt\r\n\r\n* brendan's comments\r\n\r\n* further comments"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d70dac254a19ac29e1cf",
    "number": 1613,
    "body": "Closes #1606\r\n\r\nDue to adding `a` to the `GeoJSON` driver, the GeoJSON test was no longer skipped (https://github.com/Toblerity/Fiona/commit/79e1b5a2caf8cdcf525b6ee255215e0ab12dc8fc). It failed because one of the geometries was not exactly the same. This addresses the issue.",
    "head_branch": "tst_append",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Use less precise option for testing appending to file (#1613)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d70eac254a19ac29e1d0",
    "number": 1610,
    "body": "# Old Behaviour\r\n\r\nI ran ` gpd.tools.geocode(addresses, provider=\"here\", apikey=\"<KEY>\")` on a `GeoSeries` called `addresses` and `geopandas` failed at:\r\n\r\n```python-traceback\r\n~/.cache/pypoetry/virtualenvs/drem-TFRFQYJy-py3.8/lib/python3.8/site-packages/geopandas/tools/geocoding.py in _prepare_geocode_result(results)\r\n    170 \r\n    171     for i, s in results.items():\r\n--> 172         address, loc = s\r\n    173 \r\n```\r\n\r\nWith...\r\n\r\n```python-traceback\r\nTypeError: cannot unpack non-iterable NoneType object\r\n```\r\n\r\nSo `geopandas.tools.geocode._prepare_geocode_result` failed when `s` in above example is `None` as it expects a Tuple such as `(`None, None)` that it can unpack.\r\n\r\n# New Behaviour \r\nIt now succeeds when `s` is `None` or `(None, None)` and two tests have been implemented to ensure that `geocode` passes in both of the above cases.",
    "head_branch": "rdmolony-test-geocode-suceeds-when-none-returned",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Geocode Fails When results.value is None (#1610)\n\nPreviously geopandas.tools.geocode._prepare_geocode_result\r\nfails when result is None as it expects a Tuple (such as (None, None))\r\nthat it can unpack and cannot unpack a NoneType object."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d70fac254a19ac29e1d1",
    "number": 1609,
    "body": "xref #1607\r\n\r\nIt doesn't support everything, but it does support the main 3 and raises an error when the extension is undetermined. I think the error will be very helpful to prevent https://github.com/geopandas/geopandas/issues/1607#issuecomment-688488076.",
    "head_branch": "auto_driver",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Add basic driver detection for to_file (#1609)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d710ac254a19ac29e1d2",
    "number": 1605,
    "body": "Address #1518 \r\n\r\nand update choro legend example with bracket removal option",
    "head_branch": "add_mapclassify_legend_option",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: add option to remove bracket from mapclassify legend (#1605)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d711ac254a19ac29e1d3",
    "number": 1602,
    "body": "Fixes #1593\r\n\r\nReturn a more meaningful error when an existing column is passed in `rename_geometry` \r\nadded some tests for the same",
    "head_branch": "bug-rename-geometry",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Check for duplicate column name in rename_geometry (#1602)\n\n* check for duplicate column name in rename_geometry\r\n\r\n* use fstring instead of %s"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d711ac254a19ac29e1d4",
    "number": 1600,
    "body": "Fixes #1565\r\n\r\nAs for the other pull request, any feedback is welcome since I'm a beginner.\r\n\r\n",
    "head_branch": "fix-warning-plot-empty-series",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Warning when missing_kwds provided but no areas missing data (#1600)\n\n* Do not plot empty series for missing_kwds. Fix #1565\r\n\r\n* Remove extra space between words\r\n\r\nCo-authored-by: Giacomo Caria <g.caria@student.unimelb.edu.au>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d712ac254a19ac29e1d5",
    "number": 1599,
    "body": "Fixes #1565 \r\n\r\nAs for the other pull request, any feedback is welcome since I'm a beginner.",
    "head_branch": "fix-warning--missing_kwds",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d713ac254a19ac29e1d6",
    "number": 1598,
    "body": "Fixes #1570 \r\n\r\nI'm a beginner and I've chosen this simple fix to start contributing. I'd be happy to receive any feedback about the pull request I've just submitted !",
    "head_branch": "fix-typeError-exception",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      " BUG: Fix TypeError exception message in clip (#1598)\n\nCo-authored-by: Giacomo Caria <g.caria@student.unimelb.edu.au>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d714ac254a19ac29e1d7",
    "number": 1596,
    "body": "Closes #1175",
    "head_branch": "fiona_reproject",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Add example using Fiona to re-project (#1596)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d714ac254a19ac29e1d8",
    "number": 1595,
    "body": "I originally added an function `def is_utm(crs)` in the example as well based on [CRS.utm_zone](https://github.com/pyproj4/pyproj/blob/9389f9db058283679ca9f672f6f8798817ad753a/pyproj/crs/crs.py#L979-L990), but I thought it was pretty complex and probably better to just do this. Thoughts?",
    "head_branch": "utm_zone",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Use the CRS.utm_zone property to identify UTM CRS (#1595)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d715ac254a19ac29e1d9",
    "number": 1594,
    "body": "Simple fix to correct a little bit of docstring that I saw during usage.",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Correct set_geometry docstring for ``drop`` default. (#1594)\n\nCo-authored-by: Dave Rench McCauley <drench@kinetica.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d716ac254a19ac29e1da",
    "number": 1590,
    "body": "Closes #1589",
    "head_branch": "black-update",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Linting: update and pin black version (#1590)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d717ac254a19ac29e1db",
    "number": 1588,
    "body": "",
    "head_branch": "fix-tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG/TST: fix failing tests with dev versions of pandas and matplotlib (#1588)\n\n* BUG/TST: fix failing tests with dev versions of pandas and matplotlib\r\n\r\n* fixup"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d718ac254a19ac29e1dc",
    "number": 1584,
    "body": "As a followup to #899, it would be nice to highlight this function, as\nwell as other useful information, when users are creating new bug\nreports or requests for new features. These are copied and very lightly\nedited from the templates used by pandas.\n",
    "head_branch": "add-issue-templates",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Create issue bug report and enhancement templates (#1584)\n\n* Create issue bug report and enchancement templates\r\n\r\nAs a followup to #899, it would be nice to highlight this function, as\r\nwell as other useful information, when users are creating new bug\r\nreports or requests for new features. These are copied and very lightly\r\nedited from the templates used by pandas.\r\n\r\n* Add header for `show_versions` in issue template\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* Add templates for questions and installation issues\r\n\r\n* Add references to GIS stack exchange\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* Add suggestion to look at installation issue in issue template\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d718ac254a19ac29e1dd",
    "number": 1583,
    "body": "Resolves #1555. In cases where legend_kwds was being passed, we were\r\nupdating legend_kwds with the cax/ax passed in on that function call.\r\nWithin a loop over multiple axes, this meant placing all colorbars on\r\nthe first placed axis. This just creates a copy of legend_kwds, when\r\nplaced, so we don't update in place.",
    "head_branch": "issue1555a",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "BUG: Copy legend_kwds so we don't update inplace (#1583)\n\nResolves #1555. In cases where legend_kwds was being passed, we were\r\nupdating legend_kwds with the cax/ax passed in on that function call.\r\nWithin a loop over multiple axes, this meant placing all colorbars on\r\nthe first placed axis. This just creates a copy of legend_kwds, when\r\nplaced, so we don't update in place."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d719ac254a19ac29e1de",
    "number": 1582,
    "body": "The approach here is to apply an explode operation after the result of\r\nthe overlay, then filter by geom types, and apply a dissolve based on\r\nthe level of the index from the explode representing the original\r\ngeometry groupings.",
    "head_branch": "issue1581",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Keep geoms within geometry collections after overlay (#1582)\n\n* BUG: Keep geoms within geometry collections after overlay\r\n\r\nThe approach here is to apply an explode operation after the result of\r\nthe overlay, then filter by geom types, and apply a dissolve based on\r\nthe level of the index from the explode representing the original\r\ngeometry groupings.\r\n\r\n* Add test for geom collection from overlay\r\n\r\nOverlays with complex geometries could produce geometry collections that\r\nwould be dropped with keep_geom_type=True. This tests that such cases\r\nreturn the geometries that correspond to geom_type with\r\nkeep_geom_type=True.\r\n\r\n* Update geopandas/tools/overlay.py\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d71aac254a19ac29e1df",
    "number": 1580,
    "body": "Following #219 and our discussion on twitter, I have made a proof of a concept of IO based on `pyshp`. It seems to work without any struggles, apart from encoding. Fiona does some automatic detection, so I have implemented something similar using `chardet`. If there's no issue with encoding, it is not even used.\r\n\r\nUsing `naturalearth_lowres` as a benchmark:\r\n\r\nfiona saves file in `66 ms ± 6.75 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)`\r\npyshp saves file in `45.1 ms ± 12.6 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)`\r\n\r\nfiona reads file in `35.8 ms ± 2.47 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)`\r\npyshp reads file in `96.2 ms ± 3.82 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)` but has to guess encoding\r\npyshp reads file in `27.2 ms ± 2.35 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)` if I pass encoding (or if I save df as utf-8).\r\n\r\nThere's still some work on specification of fields to match DataFrame, but it looks that we could have shapefile IO in pure python.\r\n",
    "head_branch": "pyshp",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d71bac254a19ac29e1e0",
    "number": 1579,
    "body": "Adding source files for a logo (SVG) as well as exported PNG plus a page to docs.\r\n\r\nCloses #786, closes #1405, closes #938",
    "head_branch": "logo",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Add logo (#1579)\n\n* DOC: Add logo\r\n\r\n* favicon"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d71cac254a19ac29e1e1",
    "number": 1578,
    "body": "Adding Github Actions workflow which pushes tagged release to PyPI automatically.\r\n\r\n@jorisvandenbossche to make this work, I need you to add [PyPI API token](https://pypi.org/help/#apitoken) to `secrets` as `PYPI_PASSWORD`.\r\n\r\nThe release checklist would then be following (I'll update wiki once we merge):\r\n\r\n<details>\r\nReleasing:\r\n\r\n* Make an empty release commit: ``git commit --allow-empty -m 'RLS: v0.2.1'``\r\n* Tag the commit using an annotated tag. ``git tag -a v0.2.1 -m \"Version 0.2.1\"``\r\n* Push the RLS commit ``git push upstream master``\r\n* Also push the tag! ``git push upstream --tags ``\r\n* Create sdist: ``python setup.py sdist``\r\n* Make github release (ensure to add the sdist as asset)\r\n\r\nPackaging:\r\n\r\n* update on conda-forge should be done automatically once the github release is made\r\n* update on PyPI should be done automatically once the github release is made (GitHub Action)\r\n* update docs on readthedocs (trigger any build, to trigger that the new tag / version gets added)\r\n* send announcement (based on the github release notes)\r\n\r\nUpdate geopandas.org with the latest docs as well (push to gh-pages branch)\r\n</details>\r\n\r\nNote to the checklist: I think that RTD does not have to be triggered manually.",
    "head_branch": "pypi",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "GHA: Automatic release to GitHub and PyPI (#1578)\n\nalso create github release (thanks to pysal)\r\n\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d71dac254a19ac29e1e2",
    "number": 1577,
    "body": "@martinfleis this adds a redirect for the old pages",
    "head_branch": "redirects",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add redirects for old pages (#1577)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d71dac254a19ac29e1e3",
    "number": 1576,
    "body": null,
    "head_branch": "pytest-xdist",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "MAINT/TST: Add GitHub actions tests for single workflow cross-platform testing (#1576)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d71eac254a19ac29e1e4",
    "number": 1575,
    "body": "Fix `environment.yml` to make RTD build again. ",
    "head_branch": "fix_rtd",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: fix rtd (#1575)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d71fac254a19ac29e1e5",
    "number": 1568,
    "body": "Resolves #1380\r\n\r\nIf no column is passed to `GeoDataFrame.dissolve()`, whole GeoDataFrame is considered a single group and all geometries are dissolved to a single one. It is done using a `__dummy` column. Since `aggfunc` needs to be passed to `groupby`, we can't create gdf directly using `unary_union` and `agg` (e.g. `DataFrame.agg('first)` and `DataFrame.groupby.agg('first)` are different methods).",
    "head_branch": "dissolve_none",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: allow GeoDataFrame.dissolve(by=None) (#1568)\n\n* ENH: dissolve(by=None)\r\n\r\n* use array"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d720ac254a19ac29e1e6",
    "number": 1566,
    "body": "The geodataframe that resulsts from a clipping operations should\nretain the geometry column from the input geodataframe, rather than\nusing the default geom col name \"geometry\". Resolves #1563",
    "head_branch": "issue1563",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Set clipped gdf geometry name based on input (#1566)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d721ac254a19ac29e1e7",
    "number": 1564,
    "body": "Following #1505, this PR implements new design and structure of GeoPandas documentation. Furthermore, it introduces usage of `MyST` markdown. Now for a few new pages, in the future likely for bigger chunks of the source.\r\n\r\nThe live version of the new docs (easier for review I'd say) is available here: https://martinfleis.github.io/geopandas_docs/\r\n\r\nNote that before merging, we have to figure out #1405.\r\n\r\nA lot of pages are currently in progress with temporary contents, but I needed them now to have the structure in place.\r\n\r\nNote: spatial indices and their methods are missing, because they need bigger changes of docstrings - will come later. ",
    "head_branch": "pydata_theme",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Restructured documentation, use pydata-sphinx-theme (#1564)\n\n* use pydata theme\r\n\r\n* structure\r\n\r\n* fix links\r\n\r\n* adapt colors\r\n\r\n* getting started\r\n\r\n* buttons\r\n\r\n* buttons\r\n\r\n* rename, use myst, fill stuff\r\n\r\n* myst to env\r\n\r\n* cleanup\r\n\r\n* covered_by\r\n\r\n* review comments\r\n\r\n* fix link\r\n\r\n* use api"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d722ac254a19ac29e1e8",
    "number": 1560,
    "body": "Closes #1548",
    "head_branch": "empty-gdf-crs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: ensure CRS object also for empty GeoDataFrame (#1560)\n\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d722ac254a19ac29e1e9",
    "number": 1557,
    "body": "",
    "head_branch": "docs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: update mapclassify doc links (#1557)\n\n* [DOC] update mapclassify doc link\r\n\r\n* Update mapclassify doc link in source"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d723ac254a19ac29e1ea",
    "number": 1554,
    "body": "The change here is pretty simple; it raises a warning if the `keep_geom_type` option in the overlay results in any geometries being dropped. I'm totally open to the possibility that this isn't generally necessary/useful. However, as motivation, I'll mention my experience this morning. I was looking at the results of an overlay between two sets of vector layers that were generated from rasters with very similar but not quite identical transforms. When performing an overlay, there appeared to many sets of intersecting areas that weren't retained. The left panel below shows the two sets of polygons plotted on top of one another, and the right shows the result of an overlay with `how='intersection'` and `keep_geom_type=True`. \r\n\r\n![image](https://user-images.githubusercontent.com/666108/89075243-9af82280-d332-11ea-87f9-9ab62a22e0d6.png)\r\n\r\nUpon further inspection, I realized this was because many of the visible purple polygons on the left were connected to linestrings that corresponded to very slight offsets in the borders of the two sets of vectors, resulting in a geometry collection geom type rather than a polygon or multipolygon. With the change in this PR, I would have seen the following on running this overlay:\r\n\r\n```\r\nIn [3]: gdf_intersection = gpd.tools.overlay(gdf1, gdf2, how=\"intersection\")\r\n/usr/local/bin/ipython3:1: UserWarning: `keep_geom_type=True` in overlay resulted in 51 dropped geometries.\r\n  #!/usr/bin/python3\r\n```",
    "head_branch": "geom-type-warning",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Add warning if keep_geom_type drops geometries during overlay (#1554)\n\n* Add warning if keep_geom_type drops geometries during overlay\r\n\r\n* Expand keep_geom_type warning message\r\n\r\n* Add test for keep_geom_type dropping geoms\r\n\r\n* Set keep_geom_type=None by default\r\n\r\nWith True, no warning raised. With None, will drop geoms of other types,\r\nbut warn the user.\r\n\r\n* Update geopandas/tests/test_overlay.py\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d724ac254a19ac29e1eb",
    "number": 1553,
    "body": "While trying to figure out an issue with an overlay returning surprising results, I realized that the `make_valid` argument in overlay wasn't actually used anywhere. I can imagine some cases where there would be some utility in that, but let's remove it in the meantime. A question though: do we need to provide a deprecation warning first for removing an argument that hasn't actually been doing anything (and a quick search through history makes it unclear whether it has ever done anything, but I'm not sure\r\nabout that).",
    "head_branch": "remove-make-valid",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CLN: Remove unused make_valid argument (#1553)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d725ac254a19ac29e1ec",
    "number": 1545,
    "body": "Closes #1542\r\n\r\nPin mapclassify coming from pip to 2.2.0. Newer requires pandas 1.0.",
    "head_branch": "ci_fix",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: pin mapclassify (#1545)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d726ac254a19ac29e1ed",
    "number": 1544,
    "body": "Closes #1543 \r\nCloses #1541 \r\n\r\nFixed condition to check for pandas 1.1.0 version and added `ValueError` as an option for `idxmax`.",
    "head_branch": "fix_-1543",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Fix CI for pandas 1.1.0 (#1544)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d726ac254a19ac29e1ee",
    "number": 1539,
    "body": "When I ran `make html` in doc during #1532 and #1533\r\nand _build was generated.  I noticed that there is no\r\ndoc/source/_build in master so removed this\r\ndirectory after building html prior to committing.\r\n\r\nIn the case that this directory should be ignored I've added\r\na line to .gitignore.  Otherwise please ignore this PR!",
    "head_branch": "add-ignore-doc-source-build-to-gitignore",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d727ac254a19ac29e1ef",
    "number": 1538,
    "body": "Resolves #1536\r\n\r\nThis removes the test of reading multiple columns from parquet.  On `pyarrow<=0.17` requesting multiple columns was silently ignored and only unique columns were read.  On `pyarrow>=1.0` it raises a `ValueError`.\r\n\r\nIn either case, geopandas should propagate the behavior from the associated pyarrow version; there is no need for a test of this behavior here.",
    "head_branch": "issue1536",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Remove failing test of duplicate columns on read of parquet (#1538)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d728ac254a19ac29e1f0",
    "number": 1535,
    "body": "Fixes #1531.\r\n\r\nThis allows for more general file-like objects to be used than just those deriving from `TextIOBase`.\r\n\r\nIt also attempts to infer if a local file should be treated as a zip file and automatically adds a `zip://` scheme to the path. This is so that there is no longer a difference in how local and remote zipped files are handled.\r\n\r\n~~The part of #1531 that it does not cover is the difference between how compound URLs are handled with respect to remote data. GeoPandas currently does not use the vsicurl OGR virtual filesystem, but instead downloads the data and feeds the bytes to fiona. I'm not sure which is better at the moment.~~\r\n\r\n~~TODO: write tests~~",
    "head_branch": "more-general-file-like-objects",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Allow for more general file-like objects to be used when opening files. (#1535)\n\n* Allow for more general file-like objects to be used when opening files.\r\n\r\n* Add a zip scheme to a local path if it is missing on a .zip file. This\r\nallows similar zip inference to happen for remote and local files.\r\n\r\n* Add tests using file-like objects and for inferring zip file.\r\n\r\n* Make fsspec an optional dep for CI.\r\n\r\n* Handle case where windows drive names are present.\r\n\r\n* Add test using GDAL-style vsi path.\r\n\r\n* Try to increase test coverage a bit.\r\n\r\n* Handle case where an archive path is included for a zip\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* Fix fiona-style path handling for zip archives.\r\n\r\n* Remove debug log.\r\n\r\n* Remove remote fsspec test as mostly-redundant.\r\n\r\n* Simplify reading of bytes by using BytesCollection everywhere. At some\r\npoint it may be better to move to the more-supported\r\nMemoryFile/ZipMemoryFile.\r\n\r\n* Add fsspec example to the io docs.\r\n\r\n* Slight reorg of zip scheme logic.\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d729ac254a19ac29e1f1",
    "number": 1533,
    "body": "Following on from pull request discussion in #1425\r\n\r\n> \"... read through pandas contribution guide - should have done before - and found commit message convention that geopandas uses which could copy into geopandas' contribution guide if desired\"\r\n\r\nI believe (though may be mistaken!) that geopandas follows the pandas commit message conventions so I've just copied across 'em across to the end of the `contributing to geopandas` docs as I was a little lost (for more reasons than this one!) during #1425",
    "head_branch": "rdm-add-doc-commit-message-conventions",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Copy pandas commit message conventions (#1533)\n\n* DOC: Copy pandas commit message conventions\r\n\r\nFollowing on from pull request discussion\r\nin #1425\r\n\r\n* Rename geopandas to GeoPandas\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* Remove triple whitespace\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* Remove triple whitespace again\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* Change reference to refer to\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d72aac254a19ac29e1f2",
    "number": 1532,
    "body": "Following @martinfleis suggestion in #1425 \r\n\r\n> \"if you'd like to update contributing guide based on pandas one, you are welcome to do so. Especially the section on `Updating your pull request` is helpful as we often ask contributors to do that.\"",
    "head_branch": "rdm-add-doc-how-update-pull-request",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d72aac254a19ac29e1f3",
    "number": 1524,
    "body": "",
    "head_branch": "fix_docstring",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: fix docstring (#1524)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d72bac254a19ac29e1f4",
    "number": 1520,
    "body": "",
    "head_branch": "0.8.x",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC/RLS: changelog for 0.8.1 (#1519)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": true,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d72cac254a19ac29e1f5",
    "number": 1519,
    "body": "",
    "head_branch": "whatsnew-081",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC/RLS: changelog for 0.8.1 (#1519)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d72dac254a19ac29e1f6",
    "number": 1514,
    "body": "Some new tests were added in pandas master, and we don't support argmin/argmax methods (we don't support min/max sorting related methods generally).",
    "head_branch": "test-argmax-argmin",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: skip argmin/argmax extension array tests (#1514)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d72eac254a19ac29e1f7",
    "number": 1512,
    "body": "For issue #1489. Now when `aspect=None`, the aspect won't be changed. Also, before this, `aspect=\"equal\"` actually does nothing, which means it assumes that the original aspect of `ax` is always `equal`. I suppose this is probably mostly right, better to be explicit.",
    "head_branch": "option_keep_original_aspect",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Add `aspect=None` option to plotting, to keep the original aspect. (#1512)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d72fac254a19ac29e1f8",
    "number": 1511,
    "body": "I would still need to add tests (adding a few tiny pickle files written by older versions included in the repo), but testing this locally and it seems not *that* complex to add a compatibility layer here.\r\n\r\nCloses #1503",
    "head_branch": "fix-pickling",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix un-pickling of GeoDataFrames written by older geopandas versions (#1511)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d72fac254a19ac29e1f9",
    "number": 1500,
    "body": "1. iterfeatures changes secondary geometries to wkt (if objects in columns are shapely Basegeometries)\r\n\r\n2. convert_type function recognises such geometriess in io.file.infer_schema (geometry dtype) and represents them in fiona schema as 'str'\r\n\r\n3. reading back as string is no problem (but no backconversion)\r\n\r\n4. tests in test_geodataframe.py write a gdf with secondary geometry and read it back as wkt string\r\n",
    "head_branch": "write-support-multiple-geometries",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d730ac254a19ac29e1fa",
    "number": 1499,
    "body": "Closes #1491",
    "head_branch": "travis_doc_link_fix",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Travis doc link fix (#1499)\n\n* Update CONTRIBUTING.md\r\n\r\nchanged getting started url\r\n\r\n* Update contributing.rst\r\n\r\nchanged getting started with travis link"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d731ac254a19ac29e1fb",
    "number": 1498,
    "body": "Filter warning about geometry column not holding geometries when writing to postgis, as the dtype conversion is intentional.\r\n\r\nFixes #1497 ",
    "head_branch": "filter-warning",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Ensure no warning about geometry column not holding geometries when writing to postgis (#1498)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d732ac254a19ac29e1fc",
    "number": 1496,
    "body": "fixed both links in contributing.md and in doc/source/contributing.rst\r\n\r\nCloses #1491 ",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d733ac254a19ac29e1fd",
    "number": 1492,
    "body": "Updated CI and requirements as per #1457, removed compatibility layers for older pandas and fiona.\r\n\r\nThis also removes support for Python 3.5.",
    "head_branch": "drop_old_deps",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DEP: drop support for older versions of dependencies (#1492)\n\n* change requirements\r\n\r\n* ci\r\n\r\n* remove compatibility layers\r\n\r\n* ci recipe\r\n\r\n* ci versions\r\n\r\n* version in setup.py"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d733ac254a19ac29e1fe",
    "number": 1487,
    "body": "Closes #1486 \r\n\r\nI've also added test which loops through all available classifiers except `UserDefined` and checks if everything passes.",
    "head_branch": "regr_sampled_plot",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REGR: *Sampled plotting scheme fails (#1487)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d734ac254a19ac29e1ff",
    "number": 1485,
    "body": "We need to expand those docs (certainly the part about databases), but this PR is doing something minimal: add a section about Parquet/Feather, and move the mention of read_postgis/to_postgis into its own section (for the rest are mainly newline changes by wrapping the existing text)",
    "head_branch": "docs-io",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add sections for PostGIS and Parquet/Feather to io.rst docs (#1485)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d735ac254a19ac29e200",
    "number": 1483,
    "body": "xref https://github.com/geopandas/geopandas/pull/1173, closes #1158\r\n\r\n* This ensures to respect the actual `categories` if a categorical column is specified for `column` (so both all its values (not only the ones present in the data) and its order)\r\n* At the same times cleans up a bit the current code to determine the categories and the integer `values` using pandas' Categorical\r\n\r\ncc @martinfleis \r\n\r\n ",
    "head_branch": "plot-categorical",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: honor categories of categorical column in df.plot() (#1483)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d736ac254a19ac29e201",
    "number": 1482,
    "body": "Add example for:\r\n\r\n- `geom_type`\r\n- `bounds`\r\n- `total_bounds`",
    "head_branch": "improve_documentation",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: docstring examples geom_type, bounds, total_bounds (#1482)\n\n* add docstring example for is_empty\r\n\r\n* add docstring examples\r\n\r\n* fix docstrings"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d737ac254a19ac29e202",
    "number": 1478,
    "body": "Closes #1351\r\n\r\n- When the result of `GeoSeries.apply` is a new GeoSeries, set back the original CRS\r\n- Provide a keyword to override this default behaviour to set a different CRS (in case you eg transformed the geometries)\r\n\r\nQuestions / todo's:\r\n\r\n- The keyword is now named `crs`, and you can pass a CRS object to override the default. However:\r\n  - It could also have a more explicit name like `preserve_crs` or `result_crs`. Having a more specific keyword might be useful for `apply` (because other keywords are passed through to the applied `func`, and the more \"common\" the keyword, the higher the chance somebody is already using it), on the other hand `crs` is consistent with other places (like the GeoSeries constructor).\r\n  - In principle it could also accept a value like `False` to not try to preserve the crs, even if the result is a GeoSeries. But personally I am fine with the current behaviour. \r\n- Add docstring for `apply`\r\n\r\n\r\ncc @martinfleis ",
    "head_branch": "apply-crs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: try to preserve CRS in GeoSeries.apply (#1478)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d738ac254a19ac29e203",
    "number": 1476,
    "body": "See https://github.com/geopandas/geopandas/pull/1469",
    "head_branch": "string-astype",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: astype('string') (#1476)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d738ac254a19ac29e204",
    "number": 1475,
    "body": "Warns a user that a geodataframe column exceeds 10 characters and will be truncated when saving to shapefile\r\n\r\nresolves #1417 ",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Adds warning for .shp column length limit (#1475)\n\n* Adds warning for .shp column length limit\r\n\r\nWarns user that a geodataframe column exceeds 10 characters\r\nand will be truncated when saving to shapefile.\r\n\r\n* Adds warning for .shp column length limit\r\n\r\nWarns user that a geodataframe column exceeds 10 characters\r\nand will be truncated when saving to shapefile.\r\n\r\n* Fixes style issues that caused CI failure\r\n\r\n* Update geopandas/io/tests/test_file.py\r\n\r\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>\r\n\r\n* Adds warning for .shp column length limit\r\n\r\nWarns user that a geodataframe column exceeds 10 characters\r\nand will be truncated when saving to shapefile.\r\n\r\n* Fixes style issues that caused CI failure\r\n\r\n* Adds stack level and ESRI Shapefile to to_file warning\r\n\r\n* Typo fix\r\n\r\n* black\r\n\r\n* flake8\r\n\r\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d739ac254a19ac29e205",
    "number": 1474,
    "body": "Let me know if the example isn't clear enough.",
    "head_branch": "improve_documentation",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add docstring example for is_empty (#1474)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d73aac254a19ac29e206",
    "number": 1471,
    "body": "Pass `suffixes` in pandas merge as a tuple.\r\n\r\nref https://github.com/geopandas/geopandas/issues/1432#issuecomment-643599958",
    "head_branch": "overlay_tuple",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "suffixes as tuple (#1471)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d73bac254a19ac29e207",
    "number": 1470,
    "body": "This applies the structure discussed in #1463. This should make it easier to further develop `sjoin` in the future. Please feel free to suggest other names, docstrings or arrangements, mine are somewhat arbitrary.",
    "head_branch": "refactor-sjoin",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REF: refactor sjoin as per #1463 (#1470)\n\n* REF: refactor sjoin as per #1463\r\n\r\n* PR comments + variablize OPs\r\n\r\n* rename var\r\n\r\n* PR feedback\r\n\r\n* Note new op values in docs\r\n\r\n* doc fixes\r\n\r\n* finish line"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d73cac254a19ac29e208",
    "number": 1469,
    "body": "xref https://github.com/geopandas/geopandas/issues/1432/#issuecomment-643599958",
    "head_branch": "astype-string",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix astype('string') (#1469)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d73cac254a19ac29e209",
    "number": 1468,
    "body": "",
    "head_branch": "changelog-0.8.0",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC/RLS: start changelog for 0.8.0 release (#1468)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d73dac254a19ac29e20a",
    "number": 1467,
    "body": "Small follow-up on https://github.com/geopandas/geopandas/pull/1428 that I noticed when running the tests:\r\n\r\n* Don't show our own deprecation warning for empty sindex when from inside sjoin\r\n* Fix some warnings about CRS mismatch coming from the tests",
    "head_branch": "sjoin-warnings",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CLN: clean-up warning from sjoin and in tests (#1467)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d73eac254a19ac29e20b",
    "number": 1465,
    "body": "ref #766\r\n\r\nGave a shot at extending pandas PlotAccessor to allow non-geographic pandas plots like plot.scatter(), box(), etc without having to convert the geodataframe back to a dataframe . It was pretty cool how this can be further extended to allow interactive plots as discussed in the linked issue. I have also been trying out something similar here https://geopatra.readthedocs.io/en/latest/geopatra.html\r\n\r\nLooking forward to some feedback & improvements :)\r\n\r\nEDIT: seems like pandas PlotAccessor is only available in `pandas>0.24/0`",
    "head_branch": "geoplot-accessor",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Add GeoPlot accessor (#1465)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d73fac254a19ac29e20c",
    "number": 1462,
    "body": "Towards #1452 ",
    "head_branch": "enh-1452-2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: add covered_by() method for GeoSeries (#1462)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d740ac254a19ac29e20d",
    "number": 1460,
    "body": "Towards #1452. I've added the `covers` method to GeoSeries. This is my first contribution to geopandas so happy to hear if this needs more work. \r\n\r\nEdit: the docstring update might need more work, I was trying to create a link for https://lin-ear-th-inking.blogspot.com/2007/06/subtleties-of-ogc-covers-spatial.html but it's long enough to violate PEP8 if I place it directly in the `covers` docstring. ",
    "head_branch": "enh-1452",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Add covers() method to GeoSeries (#1460)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d740ac254a19ac29e20e",
    "number": 1456,
    "body": "Example inspired by the pandas DataFrame docstring",
    "head_branch": "improve_documentation",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Add example in GeoDataFrame docstring (#1456)\n\n* add example in GeoDataFrame docstring\r\n\r\n* Update GeoDataFrame docstring\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d741ac254a19ac29e20f",
    "number": 1453,
    "body": "Update documentation link to point to `contextily` in the `geopandas` organisation.",
    "head_branch": "fix_docs_contextily_link",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Link to the canonical geopandas/contextily repo (#1453)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d742ac254a19ac29e210",
    "number": 1451,
    "body": "Closes #1420",
    "head_branch": "geoseries-equals",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: override the .equals() method from pandas to correct isinstance (#1451)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d743ac254a19ac29e211",
    "number": 1450,
    "body": "Numpydoc requires the exact correct name (\"Examples\"), otherwise it doesn't show up, eg https://geopandas.readthedocs.io/en/latest/reference/geopandas.read_postgis.html",
    "head_branch": "postgis-example",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: correct Examples rubric titles (#1450)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d744ac254a19ac29e212",
    "number": 1448,
    "body": "Closes #1335\r\n\r\nAdded support for `pandas.NA` as a missing value in our `_isna` function.",
    "head_branch": "isna_pdna",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: support pd.NA value as missing value (#1448)\n\n* support pd.NA\r\n\r\n* skip tests\r\n\r\n* doctsring, check"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d744ac254a19ac29e213",
    "number": 1447,
    "body": "",
    "head_branch": "typo",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Fix a typo in a CRS mismatch warning (#1447)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d745ac254a19ac29e214",
    "number": 1446,
    "body": "Closes #1354 \r\n\r\nImplements the same check and message we have in `array`. ",
    "head_branch": "clip_crs_check",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: consistent CRS mismatch check (#1446)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d746ac254a19ac29e215",
    "number": 1445,
    "body": "Fixes #1393 \r\n\r\nIf there is a column `'level_1'` present in GeoDataFrame, it will fail with `NotImplementedError`. We are using automatically created `level_1` column within explode, so I am renaming potentially conflicting column to `'__level_1'` and then back. ",
    "head_branch": "explode_1393",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: explode() fails if 'level_1' is in columns (#1445)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d747ac254a19ac29e216",
    "number": 1444,
    "body": "Crossref #1439.\r\n\r\nThis does the following (roughly steps 1 & 2 in #1439):\r\n1. Drop the `objects` parameter completely.\r\n2. Move the management of the spatial index to `GeometryArray`.\r\n\r\nI don't expect this to be merged until after 0.8.0, but I'm submitting for some preliminary feedback.",
    "head_branch": "move-sindex-to-geometryarray",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REF: Move sindex to GeometryArray (#1444)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d748ac254a19ac29e217",
    "number": 1443,
    "body": "To test whether this is now solved (cfr https://github.com/conda-forge/pyarrow-feedstock/issues/104)",
    "head_branch": "retry-parquet-appveyor",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: remove skip for Parquet tests on AppVeyor (#1443)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d749ac254a19ac29e218",
    "number": 1441,
    "body": "",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Fix typos in mergingdata.rst (#1441)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d749ac254a19ac29e219",
    "number": 1440,
    "body": "As discussed in #1439, I think it would be best to deprecate the `objects` parameter. This makes a warning for using it. Hopefully this will be a good first step in that direction.",
    "head_branch": "objects-warn",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DEP: Warn about deprecation of sindex.intersection objects parameter (#1440)\n\n* warn about deprecation of objects parameter\r\n\r\n* add warning check\r\n\r\n* PR feedback\r\n\r\n* fix tests warning match"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d74aac254a19ac29e21a",
    "number": 1438,
    "body": "Closes #1436.",
    "head_branch": "sindex-error-handling",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "MAINT: Unify spatial index error and empty handling (#1438)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d74bac254a19ac29e21b",
    "number": 1435,
    "body": "@brendan-ward with your hard work from https://github.com/geopandas/geopandas/pull/1180, adding additional Feather support is now actually a breeze ;) \r\n(the diff is even a bit larger because git doesn't correctly see how the original function was split).\r\n\r\nThe existing `_to_parquet` is renamed to `_geopandas_to_arrow` with all logic up to having the pyarrow table, and then `_to_parquet` and `_to_feather` have their (little) custom logic to write that table to parquet or feather file, respectively. \r\nAnd a similar pattern for the reader.\r\n\r\nI think most of the tests can also be parameterized. I already did this for one (the basic roundtrip one).\r\n\r\nAnd maybe can rename `parquet.py` to `arrow.py`\r\n\r\nCloses #1409 ",
    "head_branch": "feather",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: add Feather IO support (#1435)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d74cac254a19ac29e21c",
    "number": 1431,
    "body": "Currently CRS is lost when calling `astype`:\r\n```\r\ngdf = gpd.read_file(gpd.datasets.get_path('nybb'))\r\n\r\ngdf.crs\r\n<Projected CRS: EPSG:2263>\r\nName: NAD83 / New York Long Island (ftUS)\r\nAxis Info [cartesian]:\r\n- X[east]: Easting (US survey foot)\r\n- Y[north]: Northing (US survey foot)\r\nArea of Use:\r\n- name: USA - New York - SPCS - Long Island\r\n- bounds: (-74.26, 40.47, -71.8, 41.3)\r\nCoordinate Operation:\r\n- name: SPCS83 New York Long Island zone (US Survey feet)\r\n- method: Lambert Conic Conformal (2SP)\r\nDatum: North American Datum 1983\r\n- Ellipsoid: GRS 1980\r\n- Prime Meridian: Greenwich\r\n\r\ngdf.astype({\"BoroCode\": str}).crs\r\n# None\r\n```\r\n\r\nSeems safe enough to just pull from the existing value?",
    "head_branch": "astype_crs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d74dac254a19ac29e21d",
    "number": 1430,
    "body": "Currently, we are removing empty geometries before creating the tree. This causes the indexing to be off it there is an empty geometry anywhere but the last index (the current tests only check a single empty geometry, i.e. the last index). I fixed this and added a test.\r\n\r\n~Where things get a tad more complicated is dealing with empty geometries in calculating the \"size\" of the spatial index. Empty geometries are not inserted into the tree, but pygeos still counts them towards the size of `pygeos.strtree.STRtree`. I think this behavior makes more sense than passing in an array of size 100 with 1 empty geometry and getting back a spatial index size of 99 (which is what rtree is currently doing). Thus I modified the `size` property in the rtree wrapper to return the size of the geometry array, not the number of leaf nodes in the tree. I also renamed `self._geometries` -> `self.geometries` in `RTreeIndex` to further unify the interface.~\r\n\r\n~I think the only reason I was removing the empty geometries in `PyGEOSSTRTreeIndex` was to match the `size` reported by `RTreeIndex`.~\r\n\r\nEdit: further testing shows that this was wrong. `len(pygeos.strtree.STRtree)` does _not_ count empty/None geometries.",
    "head_branch": "fix-PyGEOSSTRTreeIndex-indexing",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Fix PyGEOSSTRTreeIndex indexing with scattered empty geometries. (#1430)\n\n* BUG: Fix PyGEOSSTRTreeIndex indexing with scattered empty geometries.\r\n\r\n* undo rename\r\n\r\n* adjust size calc for rtree\r\n\r\n* test fix for segfault\r\n\r\n* revert changes to size property\r\n\r\n* revert name change\r\n\r\n* Revert \"revert name change\"\r\n\r\nThis reverts commit 163d31603567ae1dac1aefeb7014736e9fd43a63.\r\n\r\n* add note\r\n\r\n* clarify failure\r\n\r\n* rename test"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d74eac254a19ac29e21e",
    "number": 1429,
    "body": "Pandas has changed behaviour of `groupby` on ExtensionArray, which in our case returns GeoSeries if the function is applied to geometry. From my perspective, this is a bug fix on pandas side.\r\n\r\nI just fixed our tests which were failing on this using pandas master.",
    "head_branch": "groupby_geoseries",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: GroupBy change on pandas master (#1429)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d74eac254a19ac29e21f",
    "number": 1428,
    "body": "PR for query_bulk in overlay, crossfref #1404 \r\n\r\nBenchmarks:\r\n| before      | after      | ratio | test                                                   | pygeos installed? |\r\n|-------------|------------|-------|--------------------------------------------------------|-------------------|\r\n| 328±80ms    | 266±30ms   | ~0.81 | overlay.Countries.time_overlay('difference')           | Y                 |\r\n| 327±80ms    | 247±80ms   | ~0.76 | overlay.Countries.time_overlay('difference')           | N                 |\r\n| 724±20ms    | 731±70ms   | 1.01  | overlay.Countries.time_overlay('identity')             | Y                 |\r\n| 805±20ms    | 988±200ms  | ~1.23 | overlay.Countries.time_overlay('identity')             | N                 |\r\n| 181±20ms    | 203±30ms   | ~1.12 | overlay.Countries.time_overlay('intersection')         | Y                 |\r\n| 261±5ms     | 280±20ms   | 1.07  | overlay.Countries.time_overlay('intersection')         | N                 |\r\n| 587±40ms    | 614±100ms  | 1.05  | overlay.Countries.time_overlay('symmetric_difference') | Y                 |\r\n| 573±10ms    | 595±60ms   | 1.04  | overlay.Countries.time_overlay('symmetric_difference') | N                 |\r\n| 752±100ms   | 672±50ms   | ~0.89 | overlay.Countries.time_overlay('union')                | Y                 |\r\n| 791±7ms     | 1.04±0.08s | ~1.31 | overlay.Countries.time_overlay('union')                | N                 |\r\n| 10.00±0.4ms | 9.84±0.3ms | 0.98  | overlay.Small.time_overlay('difference')               | Y                 |\r\n| 9.72±0.3ms  | 12.8±5ms   | ~1.31 | overlay.Small.time_overlay('difference')               | N                 |\r\n| 42.1±5ms    | 45.2±4ms   | 1.07  | overlay.Small.time_overlay('identity')                 | Y                 |\r\n| 42.5±5ms    | 44.6±20ms  | 1.05  | overlay.Small.time_overlay('identity')                 | N                 |\r\n| 18.7±3ms    | 17.4±3ms   | 0.93  | overlay.Small.time_overlay('intersection')             | Y                 |\r\n| 18.7±3ms    | 14.3±0.9ms | ~0.76 | overlay.Small.time_overlay('intersection')             | N                 |\r\n| 28.4±3ms    | 27.7±1ms   | 0.98  | overlay.Small.time_overlay('symmetric_difference')     | Y                 |\r\n| 28.2±3ms    | 27.2±8ms   | 0.96  | overlay.Small.time_overlay('symmetric_difference')     | N                 |\r\n| 42.3±5ms    | 41.3±7ms   | 0.98  | overlay.Small.time_overlay('union')                    | Y                 |\r\n| 41.1±6ms    | 34.1±3ms   | ~0.83 | overlay.Small.time_overlay('union')                    | N                 |\r\n\r\nBenchmarks were taken at c5d9e90a1cb9eee95a24eb04d593b24108cd6ce2",
    "head_branch": "overlay-query-bulk",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Implement sindex.query_bulk in overlay (#1428)\n\n* fix test\r\n\r\n* pre-index geometries\r\n\r\n* more vec\r\n\r\n* minimal diff\r\n\r\n* remove pygeos import\r\n\r\n* simplify"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d74fac254a19ac29e220",
    "number": 1427,
    "body": "Quick PR to implement the new spatial index capabilities in clip.",
    "head_branch": "query-clip",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Implement sindex query in clip (#1427)\n\n* Implement query in clip\r\n\r\n* cleanup\r\n\r\n* add benchmarks"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d750ac254a19ac29e221",
    "number": 1426,
    "body": "To ensure we don't by accident add a hard requirement (and this way can also test error messages for an optional dependency not being present)",
    "head_branch": "ci-no-deps",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: add a build without optional dependencies (#1426)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d751ac254a19ac29e222",
    "number": 1425,
    "body": "Following on from discussion in #1424 I've attempted to implement suggested changes.  This implementation may not be ideal so please feel free to ignore if not up to standard.\r\n\r\n(see new error message at bottom)\r\n\r\n---\r\n\r\n# Example\r\n\r\n```python\r\nfrom shapely.geometry import Polygon\r\nimport geopandas as gpd\r\n\r\ncoords1 = ((0, 0), (0, 5), (2.5, 2.5))\r\ngdf1 = gpd.GeoDataFrame({'geometry': [Polygon(coords1)]})\r\ncoords2 = ((1, 0), (0, 6), (2.5, 2.5))\r\ngdf2 = gpd.GeoDataFrame({'geometry': [Polygon(coords2)]})\r\n\r\ngpd.sjoin(gdf1, gdf2)\r\n```\r\n# Old error message for rtree\r\n\r\n```python-traceback\r\n\r\n/home/wsl-rowanm/miniconda3/envs/elec/lib/python3.8/site-packages/geopandas/base.py:104: UserWarning: Cannot generate spatial index: Missing package `rtree`.\r\n  warn(\"Cannot generate spatial index: Missing package `rtree`.\")\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n/mnt/c/users/rowanm/documents/codema_elec/src/codema_elec/preprocess/test.py in <module>\r\n      7 gdf2 = gpd.GeoDataFrame({'geometry': [Polygon(coords2)]})\r\n      8 \r\n----> 9 gpd.sjoin(gdf1, gdf2)\r\n\r\n~/miniconda3/envs/elec/lib/python3.8/site-packages/geopandas/tools/sjoin.py in sjoin(left_df, right_df, how, op, lsuffix, rsuffix)\r\n    133     else:\r\n    134         # tree_idx_df == 'left'\r\n--> 135         idxmatch = right_df.geometry.apply(lambda x: x.bounds).apply(\r\n    136             lambda x: list(tree_idx.intersection(x)) if not x == () else []\r\n    137         )\r\n\r\n~/miniconda3/envs/elec/lib/python3.8/site-packages/pandas/core/series.py in apply(self, func, convert_dtype, args, **kwds)\r\n   3846             else:\r\n   3847                 values = self.astype(object).values\r\n-> 3848                 mapped = lib.map_infer(values, f, convert=convert_dtype)\r\n   3849 \r\n   3850         if len(mapped) and isinstance(mapped[0], Series):\r\n\r\npandas/_libs/lib.pyx in pandas._libs.lib.map_infer()\r\n\r\n~/miniconda3/envs/elec/lib/python3.8/site-packages/geopandas/tools/sjoin.py in <lambda>(x)\r\n    134         # tree_idx_df == 'left'\r\n    135         idxmatch = right_df.geometry.apply(lambda x: x.bounds).apply(\r\n--> 136             lambda x: list(tree_idx.intersection(x)) if not x == () else []\r\n    137         )\r\n    138         idxmatch = idxmatch[idxmatch.apply(len) > 0]\r\n\r\nAttributeError: 'NoneType' object has no attribute 'intersection'\r\n```\r\n\r\n# New error message for rtree\r\n```python-traceback\r\n\r\n/Users/rowanm/Documents/cloned-code/pandapower/geopandas_rdmolony/geopandas/sindex.py:38: UserWarning: Spatial indexes require either `rtree` or `pygeos`.\r\n  warn(\"Spatial indexes require either `rtree` or `pygeos`.\")\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-1-de3cd84fb5a1> in <module>\r\n      7 gdf2 = gpd.GeoDataFrame({'geometry': [Polygon(coords2)]})\r\n      8 \r\n----> 9 gpd.sjoin(gdf1, gdf2)\r\n\r\n~/Documents/cloned-code/pandapower/geopandas_rdmolony/geopandas/tools/sjoin.py in sjoin(left_df, right_df, how, op, lsuffix, rsuffix)\r\n     80     package='rtree'\r\n     81     if find_spec(package) is None:\r\n---> 82         raise ImportError(\r\n     83             f\"{package} must be installed to use sjoin\\n\\n\"\r\n     84             \"See installation instructions at https://geopandas.org/install.html\"\r\n\r\nImportError: rtree must be installed to use sjoin\r\n\r\nSee installation instructions at https://geopandas.org/install.html\r\n```",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Better error for rtree dependency in sjoin (#1425)\n\n* Add rtree>=0.8 as a dependency to setup.py\r\n\r\n* Undo rtree dependency\r\n\r\n* Require rtree to be installed in sjoin\r\n\r\n* Remove comma from dependencies in setup.py\r\n\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>\r\n\r\n* Replace importlib.util.findspec with HAS_RTREE\r\n\r\nfindspec was used to check if rtree was installed\r\nHAS_RTREE in geopandas._compat already does this\r\nso can import it in geopandas.tools.sjoin instead\r\n\r\n* Remove f-string from rtree dependency check\r\n\r\n* Test raises error if rtree not installed\r\n\r\n* Remove whitespace below TestSpatialJoin\r\n\r\n* Replace HAS_RTREE with fixture\r\n\r\n* Replace fixture with if statement in test_sjoin\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\n\r\n* Reformat with black & delete HAS_RTREE fixture\r\n\r\n* (Actually) remove HAS_RTREE fixture\r\n\r\n* fix test\r\n\r\nCo-authored-by: = <user.email>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d752ac254a19ac29e223",
    "number": 1424,
    "body": "Geopandas version: 0.7.0\r\n\r\n`rtree` is required for  Geopandas' sjoin and is doesn't seem to be a depenency when installing Geopandas with pip hence this pull request\r\n\r\n(I'm still a bit of a noob with regards to pull requests etc so hope this fixes the issue...  Thanks for all your work with Geopandas, it's an incredible library)\r\n\r\n---\r\n\r\n# Minimal example\r\nGeopandas' sjoin operation currently fails for the following:\r\n\r\n```python\r\nfrom shapely.geometry import Polygon\r\nimport geopandas as gpd\r\n\r\ncoords1 = ((0, 0), (0, 5), (2.5, 2.5))\r\ngdf1 = gpd.GeoDataFrame({'geometry': [Polygon(coords1)]})\r\ncoords2 = ((1, 0), (0, 6), (2.5, 2.5))\r\ngdf2 = gpd.GeoDataFrame({'geometry': [Polygon(coords2)]})\r\n\r\ngpd.sjoin(gdf1, gdf2)\r\n```\r\n\r\n```python-traceback\r\n/home/wsl-rowanm/miniconda3/envs/elec/lib/python3.8/site-packages/geopandas/base.py:104: UserWarning: Cannot generate spatial index: Missing package `rtree`.\r\n  warn(\"Cannot generate spatial index: Missing package `rtree`.\")\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n/mnt/c/users/rowanm/documents/codema_elec/src/codema_elec/preprocess/test.py in <module>\r\n      7 gdf2 = gpd.GeoDataFrame({'geometry': [Polygon(coords2)]})\r\n      8 \r\n----> 9 gpd.sjoin(gdf1, gdf2)\r\n\r\n~/miniconda3/envs/elec/lib/python3.8/site-packages/geopandas/tools/sjoin.py in sjoin(left_df, right_df, how, op, lsuffix, rsuffix)\r\n    133     else:\r\n    134         # tree_idx_df == 'left'\r\n--> 135         idxmatch = right_df.geometry.apply(lambda x: x.bounds).apply(\r\n    136             lambda x: list(tree_idx.intersection(x)) if not x == () else []\r\n    137         )\r\n\r\n~/miniconda3/envs/elec/lib/python3.8/site-packages/pandas/core/series.py in apply(self, func, convert_dtype, args, **kwds)\r\n   3846             else:\r\n   3847                 values = self.astype(object).values\r\n-> 3848                 mapped = lib.map_infer(values, f, convert=convert_dtype)\r\n   3849 \r\n   3850         if len(mapped) and isinstance(mapped[0], Series):\r\n\r\npandas/_libs/lib.pyx in pandas._libs.lib.map_infer()\r\n\r\n~/miniconda3/envs/elec/lib/python3.8/site-packages/geopandas/tools/sjoin.py in <lambda>(x)\r\n    134         # tree_idx_df == 'left'\r\n    135         idxmatch = right_df.geometry.apply(lambda x: x.bounds).apply(\r\n--> 136             lambda x: list(tree_idx.intersection(x)) if not x == () else []\r\n    137         )\r\n    138         idxmatch = idxmatch[idxmatch.apply(len) > 0]\r\n\r\nAttributeError: 'NoneType' object has no attribute 'intersection'\r\n```\r\n\r\nHelpfully the solution to the problem is to install rtree as stated at the start of the traceback and at this [Stackoverflow thread](https://stackoverflow.com/questions/59985197/geopandas-sjoin-nonetype-object-has-no-attribute-intersection)",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d752ac254a19ac29e224",
    "number": 1423,
    "body": "Fix for https://github.com/geopandas/geopandas/issues/1358\r\n\r\nThe reference for `.. automethod:: geopandas.GeoSeries.overlaps` was missing on doc/source/reference.rst file.\r\nAlso, I've added the Parameters description to the function declaration docstring in geopandas/base.py  \r\n",
    "head_branch": "issue-#1358",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Adding geopandas.Series overlaps method in documentation (#1423)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d753ac254a19ac29e225",
    "number": 1421,
    "body": "This is the next step for #1404.\r\n\r\nBenchmarks:\r\n| before <master> | after <sjoin-query-bulk> | ratio | test                     | pygeos installed |\r\n|-----------------|--------------------------|-------|--------------------------|------------------|\r\n| 9.51±0.1s       | 178±1ms                  | ~0.02 | time_sjoin('contains')   | Y                |\r\n| 8.40±0.4s       | 7.25±0.02s               | ~0.86 | time_sjoin('contains')   | N                |\r\n| 9.09±0.06s      | 592±9ms                  | 0.07  | time_sjoin('intersects') | Y                |\r\n| 7.80±0.01s      | 11.0±0.1s                | ~1.41 | time_sjoin('intersects') | N                |\r\n| 1.14±0.02s      | 585±4ms                  | 0.51  | time_sjoin('within')     | Y                |\r\n| 7.94±0.2s       | 11.5±0.06s               | ~1.45 | time_sjoin('within')     | N                |\r\n\r\nWe could keep a lot of the existing logic in place to avoid the slowdown without pygeos, but the way it is now reduces the complexity of the module considerably and I think will be easier to manage going forward.\r\n\r\nIf we did decide to keep the existing logic, I would like to split up `sjoin` into several functions, similar to #1271.",
    "head_branch": "sjoin-query-bulk",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: use query_bulk in sjoin (#1421)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d754ac254a19ac29e226",
    "number": 1419,
    "body": "Fix newly captured flake8 issues causing master to fail. https://travis-ci.org/github/geopandas/geopandas/jobs/686107588\r\n",
    "head_branch": "flake8",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "STYLE: fix flake8 issues (#1419)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d755ac254a19ac29e227",
    "number": 1415,
    "body": "Closes #1414 \r\n\r\nEnsures that writing to PostGIS table works when `if_exists=\"append\"` and table does not exist. \r\n\r\nChanges:\r\n- Conduct the sql-query to retrieve the SRID of a table only if table exists. \r\n- add test for the above, as well as, testing that appending to table with different CRS throws an error.\r\n\r\n ",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "FIX: Ensure writing to PostGIS table works when \"appending\" and table does not exist yet (#1415)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d756ac254a19ac29e228",
    "number": 1413,
    "body": "Adapt `from_shapely` to allow single geometry on input. That is what pandas master `TestConstructors.test_series_constructor_scalar_with_index` tries to do and fails. ",
    "head_branch": "from_shapely_scalar",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: fix test_series_constructor_scalar_with_index (#1413)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d756ac254a19ac29e229",
    "number": 1412,
    "body": "Pandas added `test_value_counts_with_normalize` to ExtensionArray tests. Skipping as we do not support value_counts on geometry.",
    "head_branch": "value_counts",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      " TST: skip test_value_counts_with_normalize (#1412)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d757ac254a19ac29e22a",
    "number": 1411,
    "body": "Fixes  #1410\r\n\r\nThe way this PR works now, this is a hard breaking change from `GeometryArray.equals` to `GeometryArray.geom_equals` and adds deprecation warning for `equals_exact` and `almost_equals`. This terminology is consistent with what we already have in GeoSeries. \r\n\r\nSince pandas introduced `ExtensionArray.equals`, I think it is best to support that - that is why hard breaking change. We could, in theory, wrap `equals` and keep it as our `geom_equals` with deprecation warning, to allow for smoother transition, but since GeometryArray is not really part of public API as GeoSeries is, I think this should be okay.",
    "head_branch": "equals",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "COMPAT: GeometryArray.equals -> geom_equals (#1411)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d758ac254a19ac29e22b",
    "number": 1407,
    "body": "Making our internal io functions, which are then linked to GeoDataFrame as methods, internal. \r\n\r\nSee https://github.com/geopandas/geopandas/pull/1406#issuecomment-623987622\r\n\r\n> @jorisvandenbossche Now, you somewhat have the same issue with `read_file`, `read_postgis` etc as well, as we don't want people to use that from `geopandas.io.sql`..., but rather from the top-level. But at least there it is the exact same function.\r\n\r\nSince these are the same things, we can keep it as it is now. If we change them, then we can switch to private with deprecation later.",
    "head_branch": "private_io",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "API: privacy of geopandas.io (#1407)\n\n* private write_postgis\r\n\r\n* private to_file\r\n\r\n* test deprecation warning\r\n\r\n* read_* private\r\n\r\n* tests\r\n\r\n* fix remaining cases"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d759ac254a19ac29e22c",
    "number": 1406,
    "body": "Small follow-up on https://github.com/geopandas/geopandas/pull/1248",
    "head_branch": "postgis-reference",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add read_postgis/to_postgis to reference docs (#1406)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d75aac254a19ac29e22d",
    "number": 1402,
    "body": "* Binary wheels for shapely have been available since version 1.7.0\r\n* Correction to `sjoin` default for `op`",
    "head_branch": "doc",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: corrections / updates (#1402)\n\n* Binary wheels for shapely have been available since version 1.7.0\r\n* Correction to sjoin default for op"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d75aac254a19ac29e22e",
    "number": 1401,
    "body": "The next step in integration of `pygeos.strtree`. xref https://github.com/geopandas/geopandas/issues/1404\r\n\r\nA couple of notes:\r\n1. I included sorting for now, but am happy to remove it if it adds too much complexity.\r\n2. I included support for other predicates (and tests, it works) but will be happy to remove it for now if we want to do that separately.\r\n\r\nA general comment:\r\nI think it would be cool to have a spatial index abstract base class that lives inside of `sindex.py` that starts to sketch out what API we expect for spatial indexes. Any thoughts on that are welcome.\r\n\r\nCCing @jorisvandenbossche  @martinfleis  @brendan-ward ",
    "head_branch": "sindex-bulk-query",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Add query and query_bulk to sindex (#1401)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d75bac254a19ac29e22f",
    "number": 1398,
    "body": "",
    "head_branch": "from_features",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: add test_from_features_geom_interface_feature, modify variable names used in from_features"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d75cac254a19ac29e230",
    "number": 1396,
    "body": "",
    "head_branch": "add_geofeather_geoparquet",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d75dac254a19ac29e231",
    "number": 1391,
    "body": "#1389",
    "head_branch": "ci-postgis",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: set up postgresql/postgis on Travis (#1391)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d75eac254a19ac29e232",
    "number": 1390,
    "body": "Pygeos is in Conda Forge, so that needs to be added.\r\nI also added running with and without Pygoes, which as of right now is a very useful benchmark.",
    "head_branch": "asv-pygeos",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add conda-forge to asv.conf.json. (#1390)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d75fac254a19ac29e233",
    "number": 1388,
    "body": "Deprecating set operators ('&', '|', '^', and '-'). To be removed in v0.9.\r\n\r\nref #1255",
    "head_branch": "depr_set_operators",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DEPR: add DeprecationWarning to set operators ('&', '|', '^', and '-') (#1388)\n\n* DEPR: add DeprecationWarning to set operators ('&', '|', '^', and '-')\r\n\r\n* fix warnings"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d75fac254a19ac29e234",
    "number": 1385,
    "body": "Fix for [Multi-part Lines getting same color but dissimilar width #1384](https://github.com/geopandas/geopandas/issues/1384)\r\n\r\nCloses #1384",
    "head_branch": "plot-multi-shapes",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Pass style_kwds to parts of multipart geometry (#1385)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d760ac254a19ac29e235",
    "number": 1383,
    "body": "ref #1268 \r\n\r\nAlso added some tests for different things along the way.",
    "head_branch": "usecols",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Support ignore_geometry option with read_file, test ignore_fields (#1383)\n\n* ENH: Add option to read subset of columns in read_file\r\n\r\n* Add support for ignore_geometry & for geometries with __geo_interface__\r\n\r\n* ensure duplicate columns are duplicated\r\n\r\n* update code to only fix ignore_geometry load\r\n\r\n* added test_read_file__ignore_all_fields\r\n\r\n* ignore column order in test_from_features_geom_interface_feature\r\n\r\n* add skip for FIona < 1.8 for ignore_fields/geometry\r\n\r\n* Add ignore_geometry example\r\n\r\n* not isinstance GeoDataFrame\r\n\r\n* limit changes for ignore geometry\r\n\r\n* modify from_features to require geometry; update docstring in read_file about optionally returning pandas.Dataframe & make docstring numpydoc compliant\r\n\r\n* Add note in example about returning pandas dataframe\r\n\r\n* revert from_features changes"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d761ac254a19ac29e236",
    "number": 1378,
    "body": "Added warning message for `distance`, `buffer` and `interpolate` if geometry is in geographic CRS. Eventually would be great to have at least `distance` returning great circle value, but that is a bit more complicated as pyproj can do only point-point distance atm.\r\n\r\nDid I miss any other methods when it makes sense to warn?\r\n\r\nref #1095 and #942",
    "head_branch": "chek_projected",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Warn about geographic projection in distance-based methods (#1378)\n\n* ENH: Warn about geographic projection in distance-based methods\r\n\r\n* use repr in warning, add stacklevel\r\n\r\n* change message, add area, length, supress warnings\r\n\r\n* dont raise for buffer(0)\r\n\r\n* use function to clean up, add test\r\n\r\n* fix double space\r\n\r\n* inlcude check for centroid"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d762ac254a19ac29e237",
    "number": 1377,
    "body": "Closes #1369 \r\n\r\nMove check for CRS mismatch for binary methods to GeometryArray level from GeoSeries level as discussed in #1339.",
    "head_branch": "crs_check",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Move CRS mismatch check to GeometryArray level (#1377)\n\n* ENH: Move CRS mismatch check to GeometryArray level\r\n\r\n* add test\r\n\r\n* change warning\r\n\r\n* revert to_string (None)\r\n\r\n* condition\r\n\r\n* use repr\r\n\r\n* add stacklevel, filter"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d763ac254a19ac29e238",
    "number": 1376,
    "body": "Closes #1095, ref #942\r\n\r\nSupport for geodesic area and length for geometries in geographic CRS. If you call `area` or `length` on geometry in geographic CRS, it currently returns non-sense as it expects planar projected geometry.\r\n\r\n```py\r\ndf = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\r\ndf.area\r\n\r\n0         1.639511\r\n1        76.301964\r\n2         8.603984\r\n```\r\n\r\nI have implemented CRS check for both `area` and `length` and `pyproj` implementation for both if the geometry is in geographic CRS, so the result on this PR is following (in sq.m).\r\n\r\n```py\r\ndf.area\r\n\r\n0      1.928997e+10\r\n1      9.327458e+11\r\n2      9.627060e+10\r\n```\r\n\r\nThis requires pyproj 2.3.0, so I have now bumped requirements, but I can also do version check if we want to keep 2.2.0.",
    "head_branch": "geog_area_peri",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d764ac254a19ac29e239",
    "number": 1375,
    "body": "Closes #1374 \r\n\r\nIn case of setting geometry column using `None`, we should create either empty GeometryArray as in the following case of GeometryArray of `None` with crs inherited from df.\r\n\r\n```py\r\ngdf = gpd.GeoDataFrame()\r\ngdf.crs = 4326\r\ngdf['geometry'] = None\r\n```\r\n\r\nOn master, `gdf.geometry` returns Series, this PR returns GeoSeries with CRS.",
    "head_branch": "fix_1374",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: CRS not propagated to GeometryArray based on scalar (#1375)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d764ac254a19ac29e23a",
    "number": 1373,
    "body": "Closes #1364 \r\n\r\nFix tests for `sjoin(... how='right', op='within')` using pandas master, which now returns gdf of the same order as the original one. This behaviour is essentially a fix of current incorrect result.\r\n\r\nI have changed only tests to sort expected df. As this is a very minor issue which is now fixed by pandas, I don't think we have to make fix on our side to make sure that the behaviour is the same with older pandas.",
    "head_branch": "sjoin_tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: fix sjoin test for pandas master (#1373)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d765ac254a19ac29e23b",
    "number": 1371,
    "body": "to reflect recent added functionality",
    "head_branch": "updated-layover-docs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Updated overlay docstring (#1371)\n\n* Added check for empty intersection and added tests\r\n\r\n* Updated Doctstring for overlay method\r\n\r\n* Untangled branches\r\n\r\n* Update geopandas/tools/overlay.py\r\n\r\nmaking linter happy\r\n\r\nCo-Authored-By: Joris Van den Bossche <jorisvandenbossche@gmail.com>\r\n\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d766ac254a19ac29e23c",
    "number": 1367,
    "body": "Closes https://github.com/geopandas/geopandas/issues/1360",
    "head_branch": "travis-proj7",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: turn off network usage in test_transform for PROJ>=7 (#1367)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d767ac254a19ac29e23d",
    "number": 1365,
    "body": "Bugfix and tests for https://github.com/geopandas/geopandas/issues/1363\r\n\r\nPlease review and comment if possible; I'm new to this",
    "head_branch": "improved-empty-clip",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: return empty gdf for empty result of clip (#1365)\n\n* Added check for empty intersection and added tests\r\n\r\n* use iloc\r\n\r\n* fix broken test\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d768ac254a19ac29e23e",
    "number": 1359,
    "body": "Fixes issue geopandas#1350 \"DOC: update read_postgis docstring for CRS changes\"\r\n\r\nCloses #1350",
    "head_branch": "Bo-Deng-doc-contribution",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Update read_postgis docstring for CRS changes (#1359)\n\n* Update read_postgis docstring for CRS changes \r\n\r\nFixes issue #1350 \"DOC: update read_postgis docstring for CRS changes\"\r\n\r\n* Update geopandas/io/sql.py\r\n\r\n* Update geopandas/io/sql.py\r\n\r\n* docstring formatting\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d768ac254a19ac29e23f",
    "number": 1348,
    "body": "`six` is no longer a dependency as we do not support python 2 anymore. It is still listed in docs.",
    "head_branch": "six",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: remove six as a depenency (#1348)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d769ac254a19ac29e240",
    "number": 1343,
    "body": "Followup to #1154\r\n\r\nImplements PyGEOS' STRTree with a compatibility wrapper. Also reworks compatibility flags to allow dynamic switching from PyGEOS to rtree.\r\n\r\nMy proposal would be to have this in for ~1 minor version (or maybe until 1.0) and then drop rtree in favor of PyGEOS . We're still going to need the compatibility layer to convert GeoSeries to arrays and such, but maybe at that point support for tuples of bounds as well as the `intersection` and `contains` methods can be dropped.\r\n\r\nFailing overlay tests are due to #1337 / #1338.\r\n\r\nEdit: added a hacky fix for `TestPygeosWraper`. Will think of a better way.",
    "head_branch": "pygeos-sindex-wrapper",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Add pygeos based spatial index (#1343)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d76aac254a19ac29e241",
    "number": 1342,
    "body": "Quick fix, warnings is not being imported but is used on [line 73/74](https://github.com/geopandas/geopandas/blob/5d1181af6bcca88351d84bb63fc0fbe0e32ce055/geopandas/_compat.py#L73).",
    "head_branch": "hotfix/compat-warnings-import",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Fix warning import (#1342)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d76bac254a19ac29e242",
    "number": 1339,
    "body": "Closes #1193, closes #1340, closes #1362, closes #1366\r\n\r\nThis moves CRS attribute from GeoDataFrame and GeoSeries to GemetryArray level. It allows us to have multiple geometry columns with different CRS and also making easy access to CRS for array-level methods like `area` or `distance` to implement those for geographic projections using `pyproj.Geod`.\r\n\r\nPOC at the moment, but everything seems to be working. Few conditions deserve a bit of simplification, I tried to make it explicit so far to cover all possibilities.\r\n\r\nI'll post more information and consequences of this (plus few points for discussion) later, I just want to see CI now. \r\n\r\n~Requires #1336 (code of that is included here to make it work for now).~ (merged)\r\n\r\ntodo:\r\n- [x] docstrings\r\n- [x] documentation\r\n- [x] cleanup of conditions in `GeoDataFrame` and `set_geometry`\r\n- [x] agree on CRS priority\r\n- [x] `assert_geodataframe` should check CRS for all columns (use `assert_geoseries_equal` for all geoseries)\r\n- [x] propagate crs to array during `iloc, loc`\r\n- [x] preserve CRS for array-level operations (buffer...)\r\n- [x] complete tests\r\n- [x] deprecation of CRS if no geometry is set\r\n",
    "head_branch": "crs_array",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: move CRS to GeometryArray level (#1339)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d76cac254a19ac29e243",
    "number": 1338,
    "body": "This fixes #1337. Unfortunately, I am not sure what we can do about testing the MultiPolygon results.",
    "head_branch": "overlay-sorting",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d76dac254a19ac29e244",
    "number": 1336,
    "body": "Closes #1192 \r\n\r\nWhen accessing geometry dtype column, geopandas currently returns GeoSeries only for active geometry. This PR checks for GeometryDtype and returns GeoSeries for all columns containing GeometryArray.\r\n\r\n```\r\ndf = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres')) \r\ndf['centroids'] = df.geometry.centroid   \r\ndf.dtypes   \r\n\r\npop_est          int64\r\ncontinent       object\r\nname            object\r\niso_a3          object\r\ngdp_md_est     float64\r\ngeometry      geometry\r\ncentroids     geometry\r\ndtype: object\r\n\r\ntype(df['geometry']) \r\ngeopandas.geoseries.GeoSeries\r\n\r\ntype(df['centroids']) \r\ngeopandas.geoseries.GeoSeries\r\n```",
    "head_branch": "1192_return_geoseries",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: return GeoSeries when accessing GeometryDtype columns (#1336)\n\n* ENH: return GeoSeries when accessing GeometryDtype columns\r\n\r\n* change testing\r\n\r\n* assert_geoseries_equal check_dtype=True"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d76dac254a19ac29e245",
    "number": 1332,
    "body": "If geodataframe has no geometry column set, `iterfeatures()` will fail with no indication why that happened. I am just adding a tiny check to raise an informative error if there is no set geometry.\r\n\r\n+ one minor type found along the way.",
    "head_branch": "iterfeatures_check",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: informative error in iterfeatures if no geometry set (#1332)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d76eac254a19ac29e246",
    "number": 1329,
    "body": "Tried to support reading of file-like objects using geopandas, looking for feedback and suggestions \r\nRef #388 and #1323\r\n",
    "head_branch": "read-filelike-objects",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Read filelike objects (#1329)\n\n* Read TextIOBase objects with geopandas\r\n\r\n* Split test for different file objects\r\n\r\n* Skip pytest if fiona<1.8\r\n\r\n* revert argname, add test for tempfile and update docstring\r\n\r\n* Add docs for reading file like objects\r\n\r\n* style\r\n\r\n* minor doc styling\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d76fac254a19ac29e247",
    "number": 1328,
    "body": "Added missing methods and functions to reference API. This was initially part of #1254, but I am splitting it as this can be merged immediately.  \r\n\r\nCloses #1052, closes #805",
    "head_branch": "doc_methods",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add missing methods to reference (#1328)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d770ac254a19ac29e248",
    "number": 1326,
    "body": "Fixing one of the issues with testing with pandas master after pandas started to raise different error message.\r\n\r\nAt the same time, I am moving DEV CI environment to allowed failures on Travis, so we don't get red CI for all our PRs due to changes in pandas master which broke unrelated things.",
    "head_branch": "fix_ci",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: allow failures on DEV CI (#1326)\n\n* CI, TST: fix test, allow failures on DEV CI\r\n\r\n* revert adding ValueError\r\n\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d771ac254a19ac29e249",
    "number": 1324,
    "body": "Fixes #1179 \r\nMake modification to the copy of the data instead of the original, ",
    "head_branch": "patch-2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d771ac254a19ac29e24a",
    "number": 1319,
    "body": "This is a patch for #1223. It should be fixed in pandas (https://github.com/pandas-dev/pandas/pull/31113), but in the meantime this seems to resolve the issue as workaround of sorting/reseting index doesn't always work.\r\n\r\ncc @seizethedata",
    "head_branch": "explode",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d772ac254a19ac29e24b",
    "number": 1318,
    "body": "Fixes #1307, fixes #1315 .\r\n\r\nThis allows for sjoin to succeed when one of the joined geodataframes cannot generate a spatial index (either due to an empty GDF, or due to all empty rows).",
    "head_branch": "fix-join-on-empty-column",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Fix sjoin on empty column (#1318)\n\n* Allow spatial joins on empty columns to succeed, returning no matches on\r\nthe predicate operation.\r\n\r\n* Allow sjoin to succeed on joining with an empty GeoDataFrame."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d773ac254a19ac29e24c",
    "number": 1312,
    "body": "Closes #1310 \r\n\r\n`total_bounds` should ignore missing and empty geometries as they do not have any spatial extent and return extent of existing geometries instead of returning array of NaNs. See #1310 for details. As `total_bounds` is a property, there is no way to give a choice to filter out missing geoms, so I'd say the correct way to handle it is ignoring them. Moreover, it was implemented like that in the beginning, than changed during refactoring, I'd say unintentionally as there is no discussion on the topic.\r\n",
    "head_branch": "nan_bounds",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: ignore NaNs in total_bounds if there is geometry  (#1312)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d774ac254a19ac29e24d",
    "number": 1309,
    "body": "Closes #1308 \r\n\r\nMinor fix for clip to ensure that empty GeoSeries is returned if mask is not overlapping with original GeoSeries. Now it raises error as we expect GeoDataFrame there.",
    "head_branch": "clipfix",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: clip GeoSeries by non-overlapping mask raises error (#1309)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d775ac254a19ac29e24e",
    "number": 1306,
    "body": "closes #1305\r\n\r\nUsed [recommonmark](https://github.com/readthedocs/recommonmark) to render CHANGELOG.md in the docs, so the changes are automatically reflected. \r\n\r\nI added the changelog to User Guide, lemme know if that is fine or if there is any other convention and also changed the title of CHANGELOG.md, if that is ok\r\n\r\nLet me know if I need to make any changes",
    "head_branch": "changelog-to-docs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Add changelog to docs (#1306)\n\n* Add changelog to docs\r\n\r\n* Remove extra newline\r\n\r\n* Move Changelog to Reference Guide in docs"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d776ac254a19ac29e24f",
    "number": 1304,
    "body": "Fixes #884 \r\n\r\nI'm not sure if this is overkill for **every** update \"in place\". For example, `.set_index(inplace=True)` doesn't really need to invalidate the spatial index? I could also just do it for `sort_values` which directly relates to the issue. Open to ideas!\r\n\r\nSome context: I also came across this thread about deprecating the `inplace` param for ones that actually still do a copy operation under the hood (https://github.com/pandas-dev/pandas/issues/16529)",
    "head_branch": "koshy-update-inplace",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: add test to ensure updating a GeoDataFrame inplace invalidates the spatial index if needed (#1304)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d777ac254a19ac29e250",
    "number": 1302,
    "body": "Addresses #1301 ",
    "head_branch": "i1301",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: add labels keyword for schemed plot (#1302)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d777ac254a19ac29e251",
    "number": 1300,
    "body": "Closes #1296 ",
    "head_branch": "points_from_xy",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Same points_from_xy at toplevel as in array (#1300)\n\n* Same points_from_xy at toplevel as in array\r\n\r\n* Update docstring"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d778ac254a19ac29e252",
    "number": 1299,
    "body": "xref https://github.com/geopandas/geopandas/pull/1297#issuecomment-586748219.\r\n\r\nThere is some discussion in https://github.com/numpy/numpydoc/issues/215 about this. TL;DR: sphinx 2.0 changed the way they format field lists in the Parameters section in the resulting html, which broke how many themes rendered docstrings. \r\nThe numpydoc issues has several cross links from projects dealing with this. Here, I copied the mimimal css from sphinx' basic.css to fix the most pressing display issue (the fact that there is no space between the parameter and its type, see eg https://geopandas.readthedocs.io/en/v0.6.0/reference.html#geopandas.GeoSeries.contains)\r\n\r\nThe relevant (unsolved) issue on rtd's side: https://github.com/readthedocs/sphinx_rtd_theme/issues/746",
    "head_branch": "docs-docstring-style",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: fix docstring styling with sphinx > 2 (#1299)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d779ac254a19ac29e253",
    "number": 1298,
    "body": "",
    "head_branch": "changelog-0.7",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "RLS/DOC: add changelog for 0.7.0 release (#1298)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d77aac254a19ac29e254",
    "number": 1297,
    "body": "Also, fixed some cases where an extra space between the parameter and the `:` were causing issues in the docs.\r\n\r\nNote: I didn't run black on the `conf.py` in the `doc` folder as it would have redone the entire file and cluttered up the commit.",
    "head_branch": "crs_docs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Fix intersphinx mapping with pyproj docs (#1297)\n\n* DOC: Fix intersphinx mapping with pyproj docs\r\n\r\n* pyproj.crs.CRS -> pyproj.CRS; add back space around ' : '\r\n\r\n* minor fix\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d77bac254a19ac29e255",
    "number": 1295,
    "body": "This should fix the failing tests on pandas-master (pandas added some new tests related to setitem with slicing, that were failing in geopandas)",
    "head_branch": "setitem-tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix setitem with slices (#1295)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d77bac254a19ac29e256",
    "number": 1292,
    "body": "Still WIP, need to further fill in further sections. And are there other potential useful sections?\r\n\r\ncc @martinfleis @snowman2 ",
    "head_branch": "docs-crs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add upgrade guide for GeoPandas 0.7 / pyproj 2 / PROJ 6 (#1292)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d77cac254a19ac29e257",
    "number": 1290,
    "body": "Implementation of #1121 and the first utilisation of brand new pyproj.CRS 🎉.\r\n\r\n`.plot()` now automatically determines whether GeoSeries (or GeoDataFrame) is in geographic or projected CRS and calculates aspect for geographic using `1/cos(s_y * pi/180)` with s_y the y coordinate of the mean of y-bounds of GeoSeries. This leads to better representation of the actual shapes than current hard-coded 'equal' aspect. It is just a minor visual thing, but note that it changes the default behaviour. Implementation is ported from R package `sf`.\r\n\r\nYou can control the behaviour using new `set_aspect` (matching matplotlib `ax.set_aspect`) keyword, which can be set to `'auto'` (default new behaviour explained above), 'equal' (current) or float which is then passed to `ax.set_aspect()`. Terminology is the same used within [matplotlib](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_aspect.html).\r\n\r\nCan be merged for 0.7.0 as an illustration of the new pyproj.CRS abilities or we can keep it for 0.8.0, there is no rush.\r\n\r\nIllustrations:\r\n\r\n`world[world.name == 'Canada'].plot()`\r\n\r\nCurrent:\r\n![Unknown-1](https://user-images.githubusercontent.com/36797143/74092372-b3416000-4aba-11ea-9cbb-298ea27aba38.png)\r\n\r\nNew:\r\n![Unknown](https://user-images.githubusercontent.com/36797143/74092362-9e64cc80-4aba-11ea-88f1-cdaacf0e7e47.png)\r\n\r\nYou can imitate current behaviour using \r\n`world[world.name == 'Canada'].plot(set_aspect='equal')`\r\n\r\nCloses #1121\r\n\r\ncc @rsbivand",
    "head_branch": "plotaspect",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: scaling y-axis for plots in geographic CRS (#1290)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d77dac254a19ac29e258",
    "number": 1289,
    "body": "As discussed in #1286, the fact that GeoDataFrame can contain various objects, while standard GIS formats can't, can be confusing on using `to_file()`. I have added a note to the documentation explaining the issue. \r\n\r\nCloses #1286",
    "head_branch": "doc-tofile",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Add note on field types to io (#1289)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d77eac254a19ac29e259",
    "number": 1288,
    "body": "Added Code of Conduct for GeoPandas Project based on [Project Jupyter's version](https://github.com/jupyter/governance/blob/master/conduct/code_of_conduct.md) as agreed in #978. You can see the changes by comparing with the first commit on this branch containing the original text.\r\n\r\nWe have to do couple of things:\r\n\r\n- [x] decide who will be on the Code of Conduct committee. These people will receive email sent to specific email address set up for the purpose of reporting/questions and from the form.\r\n- [x] set-up email address. At the moment I have used conduct@geopandas.org but we can go with geopandas-conduct@googlegroups.com as Dask has. I am not sure what are the options with our domain.\r\n- [x] set-up reporting form. I can do that once we'll know the committee, based on Jupyter's example.\r\n\r\n\r\nCloses #978",
    "head_branch": "codeofconduct",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add a Code of Conduct (#1288)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d77fac254a19ac29e25a",
    "number": 1284,
    "body": "I don't think this will fix the readthedocs issues, but updating the versions is probably useful anyway.",
    "head_branch": "doc-update-env",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: update environment.yml file + clean build (#1284)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d77fac254a19ac29e25b",
    "number": 1283,
    "body": "Companion with https://github.com/geopandas/geopandas/pull/1282",
    "head_branch": "whatsnew-063",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add changelog for 0.6.3 (#1283)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d780ac254a19ac29e25c",
    "number": 1282,
    "body": "Going to do a quick bug fix release with those two fixes",
    "head_branch": "0.6.x-backports",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix python 2 compatibility"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d781ac254a19ac29e25d",
    "number": 1280,
    "body": "cc @martinfleis ",
    "head_branch": "setitem-nullable",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "COMPAT: update GeometryArray setitem to handle pandas1.0 nullable keys (#1280)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d782ac254a19ac29e25e",
    "number": 1279,
    "body": "Fixes #1149, which was already closed but IMO could stand to be re-opened :)\r\n\r\ncc @martinfleis",
    "head_branch": "patch-3",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "API: Only raise TypeError for non-geometry in fillna if there are missing values (#1279)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d783ac254a19ac29e25f",
    "number": 1274,
    "body": "CI is failing with pandas master due to a changed error message in the extension array tests",
    "head_branch": "test-pd-master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Update ExtensionDtype error message to follow pandas master (#1274)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d784ac254a19ac29e260",
    "number": 1272,
    "body": "I improved the utility function to check the indexer in pandas a bit (https://github.com/pandas-dev/pandas/pull/31150), which should make it simpler to use here ",
    "head_branch": "pd-indexers",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Update GeometryArray.__getitem__ for pandas 1.0 changes (#1272)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d784ac254a19ac29e261",
    "number": 1271,
    "body": "This PR is based on the discussion in issue [#1096](https://github.com/geopandas/geopandas/issues/1096). The conversation seemed to die without a real consensus, so I tried to take a general idea and package it into something concrete.\r\n\r\nThe main things I think should be discussed are:\r\n\r\n1. API. I'm not dead set on this one. It's simple (only the `report_dist` parameter is added, compatibility is preserved) but @martinfleis had proposed making nearest a pseudo-option when using `op=\"intersection\"`.\r\n2. Using the rtree spatial index to pre-determine intersecting geometries. From my testing, this is not worth it, but I only tested with small datasets.\r\n3. Use of `how=\"right\"` in conjunction with `op=\"nearest\"`. Since nearest isn't as clean mathematically as `intersection` or `within`/`contains`, `how=\"right\"` doesn't make as much sense as it does with those. I'm not a fan of having to add that warning/check during the final join operation.\r\n4. Integration into sjoin. The way I structured things, it's basically saying:\r\n    ```python3\r\n    if op==\"nearest\":\r\n        # do new stuff\r\n    else:\r\n       # do all of the old stuff\r\n    ```\r\n    While `nearest` is a departure from the existing `op` (which map directly to binary predicates), it doesn't feel nicely integrated to have to split the logic up like this.\r\n\r\nThank you all for your patience on this PR, it's my first one for this project.",
    "head_branch": "sjoin-nearest",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d785ac254a19ac29e262",
    "number": 1258,
    "body": "Closes https://github.com/geopandas/geopandas/issues/1257, xref https://github.com/pandas-dev/pandas/pull/30308\r\n\r\ncc @martinfleis ",
    "head_branch": "array-boolean-indexing",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix GeometryArray indexing with pandas boolean array (pandas 1.0 compat) (#1258)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d786ac254a19ac29e263",
    "number": 1256,
    "body": "`pandas.util.testing` is deprecated and do not work anymore. (https://github.com/pandas-dev/pandas/pull/30620)\r\n\r\nI have just changed imports to follow new path.",
    "head_branch": "pandas_testing",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: pandas.util.testing -> pandas.testing (#1256)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d787ac254a19ac29e264",
    "number": 1255,
    "body": "Fixes #81\r\n\r\nSet operators currently worked on GeoSeries but not on GeoDataFrame. \r\n\r\n```py\r\na = GeoSeries(...)\r\nb = GeoDataFrame(...)\r\n\r\na.intersection(b)  # Okay\r\nb.intersection(a)  # Okay\r\na & b  # Okay\r\nb & a # Error\r\n```\r\n\r\nGeoDataFrame now supports operators as well using its geometry column.",
    "head_branch": "binary-operators_81",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Set operators are inconsistently handled (#1255)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d788ac254a19ac29e265",
    "number": 1254,
    "body": "There has been long ongoing issue with majority of examples not being included in docs as they were Jupyter notebooks instead of .py files prepared for sphinx gallery extension. I have now changed the way how examples are handled.\r\n\r\n- all examples are Jupyter notebooks now\r\n- all are within `doc/source` - there is no way to load them from original `examples` folder\r\n- all are executed by sphinx to get fresh outputs\r\n- all can be run interactively on mybinder\r\n- interactivity (folium) works\r\n- links to existing examples in gallery are still the same\r\n\r\nThe downward is a bit more complicated diff for `.ipynb` files than `.py`. But I think that Jupyter notebooks are better way forward that sphinx-gallery py files.\r\n\r\n~I have also added missing methods to reference guide.~ (see #1328)\r\n\r\nrelated to #1076, closes #280",
    "head_branch": "docs_nb",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d789ac254a19ac29e266",
    "number": 1253,
    "body": "- Addresses #1087\r\n- As mapclassify will always be more, or as, recent than pysal, removing the latter as an optional dependency.\r\n\r\nCloses #1281, closes #1087",
    "head_branch": "legendkwds",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: choropleth legend formatting (#1253)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d789ac254a19ac29e267",
    "number": 1252,
    "body": "Fixes #1216 \r\n\r\nHaving GeoSeries with MultiIndex, GeoSeries.reset_index() returned pandas DataFrame not GeoDataFrame as I would expect in such a case.\r\n\r\nI have used `GeoSeries._constructor_expanddim` as @jorisvandenbossche mentioned. As a result, `to_frame` also returns GeoDataFrame if called on GeoSeries which makes sense to me (it was a DataFrame).",
    "head_branch": "1216_reset_index",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: GeoSeries.reset_index() gives DataFrame not GeoDataFrame (#1252)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d78aac254a19ac29e268",
    "number": 1251,
    "body": "Fixes #1223 \r\n\r\nAs explained in #1223, pd.concat has a problem merging gdfs with non-unique keys if they are not sorted. \r\n\r\nI have replaced concat with merge and stored order to resort gdf it in the end. Using merge is slightly faster than concat in this case (not needed `df_copy.sort_index(inplace=True)`).\r\n",
    "head_branch": "explode_bug",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d78bac254a19ac29e269",
    "number": 1250,
    "body": "#1231 and #1240 are caused by wrong encoding detection. I have added a note to docs mentioning that it may happen and how to fix it.\r\n\r\nCloses #1231  ",
    "head_branch": "docs_encoding",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: explain encoding in to_file, read_file (#1250)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d78cac254a19ac29e26a",
    "number": 1248,
    "body": "Closes #595, relates to #189, #440, #457, #546.\r\n\r\nAdds a method `GeoDataFrame.to_postgis()` for writing data from GeoDataFrame to PostGIS.  \r\n\r\n- Supports the same functionalities as Pandas, i.e. you can also use \"replace\" and \"append\" when pushing the GeoDataFrame to PostGIS. \r\n- When appending, the crs of the GeoDataFrame and the target table needs to match.\r\n\r\nExample:\r\n```\r\nIn [1]: data = gpd.read_file(\"https://gist.githubusercontent.com/HTenkanen/456ec4611a943955823a65729c9cf2aa/raw/be56f5e1e5c06c33cd51e89f823a7d770d8769b5/ykr_basegrid.geojson\")\r\nIn [2]: engine = create_engine(\"postgresql+psycopg2://myuser:mypwd@localhost:5432/mydb\")\r\nIn [3]: data.to_postgis(con=engine, name='test_table', if_exists='replace')\r\n```",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Add method to write GeoDataFrame to PostGIS (#1248)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d78dac254a19ac29e26b",
    "number": 1244,
    "body": "Shapely have changed the behaviour of boolean representation of empty geometries (https://github.com/Toblerity/Shapely/pull/812) which broke our `_binary_geo`. I have made the condition used there more explicit to avoid the issue.",
    "head_branch": "shapely_17",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: reflect changes in bool(geom) in shapely 1.7 (#1244)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d78eac254a19ac29e26c",
    "number": 1243,
    "body": "I have added conda-forge environment with python 3.8 to both appveyor and travis to have it covered. I was not able to make it work with conda defaults yet.",
    "head_branch": "py38",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: test python 3.8 (#1243)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d78eac254a19ac29e26d",
    "number": 1242,
    "body": "It would be good to also test with the development version of Shapely, so adding that here.",
    "head_branch": "ci-shapely-master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: test with shapely master (#1242)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d78fac254a19ac29e26e",
    "number": 1237,
    "body": "This should fix the failure on the pandas master build (due to https://github.com/pandas-dev/pandas/pull/30247)",
    "head_branch": "fix-dtype-test",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: make dtype error message compatible with pandas (#1237)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d790ac254a19ac29e26f",
    "number": 1232,
    "body": "Closes #1221\r\n\r\nThe issue with rtree mentioned in #1221 and patched in #1227 has been fixed in https://github.com/Toblerity/rtree/pull/127. Reverting our tests back as it now fails again. \r\n\r\n@jorisvandenbossche do you want to check for 0.9.0 and 0.9.1 and use the patch for these versions only? I have removed it altogether as rtree now comes as 0.9.2.",
    "head_branch": "rtree_back",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: revert tests for sindex (#1232)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d791ac254a19ac29e270",
    "number": 1229,
    "body": "Closes https://github.com/geopandas/geopandas/issues/1004\r\n\r\nA simple test for appending to a Shapefile is included. It shouldn't be necessary to test for non-matching schemas when appending, because [Fiona does that](https://fiona.readthedocs.io/en/latest/manual.html#appending-data-to-existing-files):\r\n\r\n> The record you write must match the file’s schema. You’ll get a ValueError if it doesn’t.\r\n\r\nIt doesn't look like there's a more user-friendly list of which formats support appending than in the code: https://github.com/Toblerity/Fiona/blob/master/fiona/drvsupport.py",
    "head_branch": "to_file_append",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Allow appending from to_file (#1229)\n\n* ENH: Allow appending from to_file\r\n\r\n* Add simple shp appending test\r\n\r\n* Remove unused test parameters\r\n\r\n* Revise tests\r\n\r\n* style\r\n\r\n* mention fiona.supported_drivers\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d792ac254a19ac29e271",
    "number": 1228,
    "body": "Closes #1224 ",
    "head_branch": "zorder-docs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Add zorder example to docs (#1228)\n\n* Add zorder examples to docs\r\n\r\n* Remove matplotlib and make suggested changes\r\n\r\n* Remove empty line\r\n\r\n* Made the suggested minor changes\r\n\r\n* Change line format\r\n\r\nCo-Authored-By: Martin Fleischmann <36797143+martinfleis@users.noreply.github.com>\r\n\r\n* Save the plots with savefig"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d792ac254a19ac29e272",
    "number": 1227,
    "body": "See https://github.com/geopandas/geopandas/issues/1221, this should at least make CI green again.",
    "head_branch": "rtree-error",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: fix tests to work with rtree 0.9 (#1227)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d793ac254a19ac29e273",
    "number": 1226,
    "body": "Just a tiny change to provide better error messages when optional plotting dependencies are missing. Sometimes people struggle to understand - https://stackoverflow.com/questions/58416539/geopandas-importerror-the-descartes-package-is-required-for-plotting-polygons-i.",
    "head_branch": "plotting_error",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: informative errors for missing matplotlib and descartes (#1226)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d795ac254a19ac29e274",
    "number": 1225,
    "body": "Added support for GeometryCollections and LinearRings in `.plot()` for both GeoSeries and GeoDataFrame. As you can see, it first decomposes GeometryCollections  in `plot_dataframe` and then explodes MultiGeometries in `plot_XX_collection` as it did till now. I was thinking about decomposing everything at once, but since we can get MultiGeometry inside GeometryCollection,  we would have to do the check twice anyway. This way is seems to be more understandable for future maintenance.\r\n\r\nAs I am using `_flatten_multi_geoms` to decompose both Multi and GeometryCollections now, I have slightly changed it, so we can select what to decompose. And as we already returned multiindex instead of actual values, I have removed color attribute.\r\n\r\nLinearRings are easy, they can be plotted exactly the same way as LineStrings.\r\n\r\nCloses #953",
    "head_branch": "geometry_collection_plot",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: support GeometryCollection and LinearRing in plotting (#1225)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d795ac254a19ac29e275",
    "number": 1222,
    "body": "",
    "head_branch": "nkorinek-sliver-functionality",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d796ac254a19ac29e276",
    "number": 1220,
    "body": "Closes #1200 \r\n\r\nThis adds support of pandas Int64 (nullable integer dtype) to `infer_schema`, allowing GeoDataFrame with Int64 column to be saved to file.\r\n\r\nI am closing #1200 which meant to carry the whole schema and reuse it on save, but this proved to be tricky as it is extremely sensitive to any change of gdf.\r\n\r\n",
    "head_branch": "support_int64",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Support nullable integer data type in to_file (#1220)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d797ac254a19ac29e277",
    "number": 1218,
    "body": "The 0.4.0 release of `geoplot` made some breaking API changes. Specifically, the default colormap behavior has changed from categorical to continuous, and the `k` parameter has been replaced with direct use of `mapclassify`, which allows for finer-grained control.\r\n\r\nThis PR brings the `plotting_with_geoplot.py` example in the `geopandas` documentation inline with the new API signature.",
    "head_branch": "update-geoplot-docs-again",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Update geoplot documentation (#1218)\n\n* Update.\r\n\r\n* Update geoplot pin to 0.4.0.\r\n\r\n* Update per comments."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d798ac254a19ac29e278",
    "number": 1217,
    "body": "I noticed there was something wrong with the last plot on this page: https://geopandas.readthedocs.io/en/latest/gallery/cartopy_convert.html \r\nI first thought it was not working, but it's actually just that the centroids are \"hidden\" behind the countries polygons. Which can be fixed with providing a \"zorder\" (not ideal a user needs to do this though)",
    "head_branch": "doc-cartopy-zorder",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: specify zorder when combining cartopy and geopandas (#1217)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d799ac254a19ac29e279",
    "number": 1215,
    "body": "Hi all,\r\n\r\nHave amended the documentation slightly to try to fix issue [1186](https://github.com/geopandas/geopandas/issues/1186). If this is overkill as compared to the rest of the documentation, please let me know, as it might go into a bit too much detail compared to the rest.\r\n\r\nLooking forward to your feedback,\r\n\r\nRegards,\r\n\r\nTim.\r\n\r\nCloses #1186",
    "head_branch": "proposed-fix-1186",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add example of appending GeoSeries (#1215)\n\n* changing doc/source/mergingdata.rst to propose fix for issue 1186\r\n\r\n* append docs\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d799ac254a19ac29e27a",
    "number": 1212,
    "body": "",
    "head_branch": "whatsnew-062",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC/RLS: add changelog for 0.6.2 (#1212)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d79aac254a19ac29e27b",
    "number": 1211,
    "body": "Passing array of tuples (aka list of lists), `np.take` in plotting flattens the array causing the error, reported in https://github.com/pysal/splot/issues/83. I thought that it is the same bug as #1178 but this one was slightly different. Both caused by changes in #1119 though. \r\n\r\nIt should be fixed now, including tests.\r\n\r\n_(there is so many options how to pass colors...)_",
    "head_branch": "fix_nptake",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Passing array of RGBA tuples to color parameter in .plot() throws error (#1211)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d79bac254a19ac29e27c",
    "number": 1210,
    "body": "Also added notes on which packages are needed for which parts of\ngeopandas functionality outside of the core requirements.",
    "head_branch": "update-dev-requirements",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add pre-commit and black to dev requirements (#1210)\n\n* Add pre-commit and black to dev requirements\r\n\r\nAlso added notes on which packages are needed for which parts of\r\ngeopandas functionality outside of the core requirements.\r\n\r\n* Add environment.yml, remove requirements.txt\r\n\r\n* Update reqs per Joris's comments\r\n\r\n* pyproj 2.2.0\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d79cac254a19ac29e27d",
    "number": 1209,
    "body": "@martinfleis starting some backports for a 0.6.2 release",
    "head_branch": "backports-062",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC/RLS: add changelog for 0.6.2 (#1212)\n\n(cherry picked from commit 1132cc8f526b29795820895d4f99890421b8b3fd)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": true,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d79dac254a19ac29e27e",
    "number": 1206,
    "body": "Temporary fix for failing tests. conda defaults now comes with GEOS 3.8.0 which apparently no longer raises an error while doing `poly.is_simple` if poly is empty. In the [changelog](https://github.com/libgeos/geos/blob/master/NEWS), I assume the change is in `Improve general predicate, overlay, and buffer performance`. I am not sure how does this affect behaviour of overlay though.",
    "head_branch": "geos380",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: fix test_unary_predicates for GEOS 3.8 (#1206)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d79dac254a19ac29e27f",
    "number": 1205,
    "body": "Closes #1199.\nAlso added gpkg to the drivers to test reading/writing.",
    "head_branch": "issue1199",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Add tests of pathlib.Path for file i/o (#1205)\n\n* Add tests of pathlib.Path for file i/o (Closes #1199).\r\n* Also added gpkg to the drivers to test reading/writing."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d79eac254a19ac29e280",
    "number": 1202,
    "body": "While looking at the diff of https://github.com/geopandas/geopandas/pull/1201 (thanks @martinfleis !), I noticed that there was actually a type in the original test which made we were not testing matplotlib correctly.",
    "head_branch": "fix-api-tst",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: fix api test (no import) for matplotlib (#1202)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d79fac254a19ac29e281",
    "number": 1201,
    "body": "I just randomly came across todo I missed previously. `test_no_additional_imports` now updated for python 3 only.",
    "head_branch": "test_py3",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Update test_no_additional_imports for py3 (#1201)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7a0ac254a19ac29e282",
    "number": 1200,
    "body": "Following the discussion in #1185, I have drafted a PR which saves schema during `read_file` to `gdf.schema` and then during `to_file` checks if the original schema for each column is still applicable. If so, it uses it, if not it infers new one based on the dtype as we do it now.\r\n\r\nI am pretty sure that there will be some corner cases which are not covered here, but I wanted to have this PR opened so we can discuss the implementation. But for the cases described in #1185 and earlier in #177, this should work.\r\n\r\n```\r\npath = gpd.datasets.get_path('nybb')\r\ngdf = gpd.read_file(path)\r\ngdf.schema  # original schema from fiona\r\n\r\n{'properties': OrderedDict([('BoroCode', 'int:4'),\r\n              ('BoroName', 'str:32'),\r\n              ('Shape_Leng', 'float:19.11'),\r\n              ('Shape_Area', 'float:19.11')]),\r\n 'geometry': 'Polygon'}\r\n```\r\n\r\n```\r\ngpd.io.file.infer_schema(gdf)\r\n{'geometry': 'MultiPolygon',\r\n\r\n 'properties': OrderedDict([('BoroCode', 'int:4'),\r\n              ('BoroName', 'str:32'),\r\n              ('Shape_Leng', 'float:19.11'),\r\n              ('Shape_Area', 'float:19.11')])}\r\n```\r\n\r\nOn master:\r\n```\r\ngpd.io.file.infer_schema(gdf)\r\n\r\n{'geometry': 'MultiPolygon',\r\n 'properties': OrderedDict([('BoroCode', 'int'),\r\n              ('BoroName', 'str'),\r\n              ('Shape_Leng', 'float'),\r\n              ('Shape_Area', 'float')])}\r\n```\r\n\r\nCloses #1185 ",
    "head_branch": "carry_schema",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7a1ac254a19ac29e283",
    "number": 1198,
    "body": "Fixes #1178 \r\n\r\nI have added `is_color_like` check before checking for list-like in `color` argument, so if we pass RGBA tuple it gets assigned directly to all geometries instead of expecting that it is a list.",
    "head_branch": "1178",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Passing RGBA tuple to color parameter in .plot() throws error (#1198)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7a2ac254a19ac29e284",
    "number": 1197,
    "body": "Closes https://github.com/geopandas/geopandas/issues/1190",
    "head_branch": "GH1190-filtering-index-type",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix index type in filtering/take or creation of empty GeoDataFrame (#1197)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7a2ac254a19ac29e285",
    "number": 1196,
    "body": "Closes https://github.com/geopandas/geopandas/issues/1195, closes https://github.com/geopandas/geopandas/issues/1184",
    "head_branch": "GH1195-empty-geoseries-bounds",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix bounds/total_bounds for empty GeometryArray/GeoSeries (#1196)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7a3ac254a19ac29e286",
    "number": 1191,
    "body": "This PR is proposing a metadata specification for saving geospatial vector data in [Parquet files](https://parquet.apache.org/). To use it in GeoPandas, but we want to describe it so it can potentially also be recognized / used by other packages / software.\r\n\r\nCurrently, this proposes to save the following metadata in a `\"geo\"` key in the parquet's file key-value metadata:\r\n\r\n- For all geometry columns: the name of the column and its CRS\r\n- The name of the primary geometry column\r\n- Some additional information about the version and the library that created this file / metadata\r\n\r\n---\r\n\r\nPer comments in #1180, this is a separate PR for reviewing the metadata specification to be used for saving `parquet` files with appropriate details to read back into a `GeoDataFrame`.\r\n\r\nFor those following along, there are comments in #1180 that shaped this.  See [this comment](https://github.com/geopandas/geopandas/pull/1180#issuecomment-548784939) for more details about the goals of this metadata.\r\n\r\nOnce the spec is approved here, we'll implement it in #1180\r\n\r\nI was not sure where this documentation belonged, so it is currently in an orphaned RST page.  I need guidance on where this should be placed in the docs.  Under `Developers` section?  It felt too specific to add to `io.rst` (we can add general usage of read / write for parquet there).\r\n\r\n(I'm not able to build RST previews locally, so hopefully no RST issues here)",
    "head_branch": "parquet_schema",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7a4ac254a19ac29e287",
    "number": 1188,
    "body": "Fixes #1187 ",
    "head_branch": "fix_word",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: fix typo in spatial join (#1188)\n\n* fix typo\r\n\r\n* fix typo 'to' - 'two'\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7a5ac254a19ac29e288",
    "number": 1183,
    "body": "Following the decision done in #1031, GeoPandas 0.6 is the last version supporting Python 2.\r\n\r\nThis PR removes code which is not needed. All cases of `six` use as well as `__future__`.\r\n\r\nI'll remove python 2 from CI in the next commit, I just want to see if it properly fails :). I'll also add mention of Python 3 only support to contributing docs. \r\n\r\nCloses #1031",
    "head_branch": "removepy2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CLN: Remove Python 2 support (#1183)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7a6ac254a19ac29e289",
    "number": 1181,
    "body": "Resolves #897 ",
    "head_branch": "docs/read_zipfile",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Add docs for using read_file on a ZIP file (#1181)\n\n* Add docs for using read_file on a ZIP file\r\n\r\n* Add docs for opening ZIP files with folders and multiple datasets\r\n\r\n* Fix wording of docs"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7a6ac254a19ac29e28a",
    "number": 1180,
    "body": "This PR adds support for reading and writing GeoDataFrames to `parquet` files, based in part on initial development by @darcy-r (https://github.com/darcy-r/geoparquet-python).\r\n\r\nIn summary, any geometry columns present are converted to `WKB` format for serialization in `parquet`.  We retain their original column names throughout.\r\n\r\nWe use metadata in the `parquet` file to store the CRS (JSONified `dict`), primary geometry column name, and a list of all geometry column names.  This functionality supports GeoDataFrames with multiple geometry columns.\r\n\r\nThis metadata is stored in a `geo` key in the metadata, and should support interoperability with R.\r\n\r\nThis approach leverages the existing `parquet` support from `pandas` but overrides the read / write functions so that we can handle the geospatial specific stuff.\r\n\r\nNote: I only provided an implementation using `pyarrow`, as it does not appear that `fastparquet` provides an API that allows us to read / write metadata.  However, I used the same overall approach as is used in `pandas` to make it easier to add `fastparquet` support at a later time, if such functionality becomes available.\r\n\r\nWe may completely remove `feather` support from this PR and wait for better support from `pyarrow` for writing metadata with CRS and geometry column names, per [comment in #651](https://github.com/geopandas/geopandas/issues/651#issuecomment-540941499)\r\n\r\n(for now please ignore the `feather` implementation, it has not yet been standardized with the `parquet` approach)\r\n\r\nI'd like to run some benchmarks comparing `parquet` to `feather` before we decide to keep / remove `feather` support.\r\n\r\nresolves #651",
    "head_branch": "add_geofeather_geoparquet",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Add parquet IO support (#1180)\n\n* WIP: initial migration of geofeather into geopandas\r\n\r\n* WIP: initial implementation of parquet support for geometries\r\n\r\n* Refactored approach to retain same geometry column names\r\n\r\n* fix CI errors\r\n\r\n* Fix CI errors, improve test coverage\r\n\r\n* Py2.7 CI fix for decoding binary strings\r\n\r\n* Remove feather support (for now) and address PR comments\r\n\r\n* Make primary geometry column more clear\r\n\r\n* Address PR comments, allow parameter overrides\r\n\r\n* Refactor to_paquet(), read_parquet() per PR feedback\r\n\r\n* Migrate to column-level CRS metadata\r\n\r\n* Refactored parqut I/O to align with latest parquet metadata spec\r\n\r\n* Use GeometryArray in read_parquet to set crs directly\r\n\r\n* Updated parquet I/O per PR feedback\r\n\r\n* Update parquet I/O per PR feedback\r\n\r\n* Fix fstrings in compat\r\n\r\n* Undo whitespace autoformatting in .travis.yml\r\n\r\n* Add stability warning for parquet metadata spec\r\n\r\n* Revert pyarrow version for travis\r\n\r\n* Add classmethod from_parquet and fix skips for pyarrow\r\n\r\n* TEMP: add test for pandas parquet I/O for appveyor\r\n\r\n* Add test for parquet columns parameter repeated column names\r\n\r\n* try to fix appveyor\r\n\r\n* add to reference\r\n\r\n* add pyarrow to show_versins\r\n\r\n* skip parquet tests on windows\r\n\r\n* try again to skip parquet tests on windows\r\n\r\n* remove from_parquet classmethod\r\n\r\n* undo space\r\n\r\n* Updates per metadata spec PR feedback\r\n\r\n* Update parquet metadata to match spec, make io methods private\r\n\r\n* Add warning for initial parquet implementation\r\n\r\n* Add basic read / write benchmarks for parquet\r\n\r\n* Add whitespace to make CI happy\r\n\r\n* Ignore parquet warnings in tests except where testing the warnings\r\n\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7a7ac254a19ac29e28b",
    "number": 1177,
    "body": "",
    "head_branch": "array-cleanup",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CLN: minor GeometryArray + test cleanup (#1177)\n\n* make polygons valid + don't rely on identity for check\r\n* use unary_union method from GeometryArray"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7a8ac254a19ac29e28c",
    "number": 1176,
    "body": "Part of #107 ",
    "head_branch": "add/docstring",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add docstring for geodataframe.py merge function (#1176)\n\n* DOC: add docstring for geodataframe.py merge function\r\n\r\n* Fix underline lengths to match headlines"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7a9ac254a19ac29e28d",
    "number": 1173,
    "body": "Fixes #893\r\n\r\nIntroducing new argument for `gdf.plot()`. Now we can explicitly set categories for categorical plot passing list-like object to `categories=None`. We can control their order (#1158) or include some which are not present in the actual subplot (#893). List-like object has to include all categories present in the values being plotted.\r\n\r\nUsing the example from #893:\r\n\r\n```py\r\n# create sample data\r\np1 = Polygon([(0.5, 0.5), (1, 0.5), (1, 1), (0.5, 1)])\r\np2 = Polygon([(0, 0), (0.5, 0), (0.5, 0.5), (0, 0.5)])\r\np3 = Polygon([(0, 0.5), (0.5, 0.5), (0.5, 1), (0,1)])\r\ngdf = gpd.GeoDataFrame({\"c1\" : [\"feature1\",\"feature2\",\"feature3\"],\r\n                        \"c2\" : [\"feature2\",\"feature3\",\"feature3\"]},\r\n                       geometry=gpd.GeoSeries((p1,p2,p3)))\r\n\r\n# colormap\r\nhmap = colors.ListedColormap(['lightgrey', 'red', 'lightblue'])\r\n\r\n# ploting\r\nfig, ax = plt.subplots(ncols=2)\r\ngdf.plot(column=\"c1\", legend=True, categorical=True, cmap=hmap, ax=ax[0])\r\ngdf.plot(column=\"c2\", legend=True, categorical=True, cmap=hmap, ax=ax[1], \r\n         categories=[\"feature1\",\"feature2\",\"feature3\"]\r\n)\r\n```\r\n\r\nBefore:\r\n![Unknown](https://user-images.githubusercontent.com/36797143/67115529-5aca1800-f1d6-11e9-9635-618a8ee54ca4.png)\r\nNow:\r\n![Unknown-1](https://user-images.githubusercontent.com/36797143/67115595-7c2b0400-f1d6-11e9-9980-82b2148171fa.png)\r\n\r\nChange of the order of categories:\r\n```py\r\ngdf.plot(column=\"c1\", legend=True, cmap=hmap,\r\n         categories=[\"feature2\",\"feature1\",\"feature3\"])\r\n```\r\n![Unknown-2](https://user-images.githubusercontent.com/36797143/67115715-beecdc00-f1d6-11e9-881f-da3461f55a40.png)\r\n",
    "head_branch": "1159",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: pass list-like as categories to plot (#1173)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7aaac254a19ac29e28e",
    "number": 1170,
    "body": "Resolves #898 ",
    "head_branch": "docs/transparent",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Add example docs for plotting transparent polygons (#1170)\n\n* Add example docs for plotting transparent polygons\r\n\r\n* Add explanation for plotting transparent polygons\r\n\r\n* Update doc/source/mapping.rst\r\n\r\nCo-Authored-By: Martin Fleischmann <36797143+martinfleis@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7aaac254a19ac29e28f",
    "number": 1169,
    "body": "",
    "head_branch": "ignore",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Update gitignore: add vscode, pytest/mypy cache (#1169)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7abac254a19ac29e290",
    "number": 1168,
    "body": "Also added autodoc for `set_geometry` method as it was missing and needed for data sructure docs.",
    "head_branch": "doc_links",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: update data structure docs with links to classes/methods (#1168)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7acac254a19ac29e291",
    "number": 1163,
    "body": "Fixes #1162 \r\n\r\nFixes incorrect legend. When there is only one value, there is no way to put correct colorbar (no way to set min/max). In that case, categorical legend is used instead. Used colormap is the same as before (as it would be categorical=False).\r\n\r\n```py\r\nN = 10\r\npoints = gpd.GeoSeries(Point(i, i) for i in range(N))\r\nvalues = np.arange(N)\r\ndf = gpd.GeoDataFrame({\"geometry\": points, \"values\": values})\r\ndf['one'] = 6\r\ndf.plot('one', legend=True)\r\n```\r\n\r\nCurrent (wrong) behaviour:\r\n![Unknown-5](https://user-images.githubusercontent.com/36797143/66847381-30c0ed80-ef6b-11e9-8a64-eb142e7e7b68.png)\r\n\r\n\r\nFixed behaviour:\r\n![Unknown-4](https://user-images.githubusercontent.com/36797143/66847214-ed667f00-ef6a-11e9-8f7d-7e3520de9e9a.png)\r\n",
    "head_branch": "1162",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7adac254a19ac29e292",
    "number": 1160,
    "body": "Closes #1157 \r\n\r\nOpening PR so you can see the code and recommend changes. If you like the implementation, I can add some tests.",
    "head_branch": "filter_load",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: add support for filtered loading with open_file using mask and rows (#1160)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7aeac254a19ac29e293",
    "number": 1159,
    "body": "Fixes #1074 \r\n\r\nFixed missing support for MultiIndex in `sjoin`.\r\n\r\n~As a bonus, `sjoin` now returns the name of the original index instead of None, so the index is preserved intact. In master we have hard-coded `joined.index.name = None` even though we claim than index of left (or right) df is preserved. So this is a slight change of behaviour, but it seems to be fixing what was initially intended but never implemented.~ merged in #1150 ",
    "head_branch": "multiindex_sjoin",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: spatial join error for MultiIndex (#1159)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7aeac254a19ac29e294",
    "number": 1156,
    "body": "I have added support for missing data to the `plot_dataframe`. It does change the default behaviour because I believe that our current handling of missing data is wrong. \r\n\r\nIt mirrors what QGIS does by default. Features with missing values are ignored as we do not know which style they should have. Currently we assign the first colour of cmap, but that is incorrect. You can set the style for missing values in newly introduced `missing_kwds`, including a label for the legend.\r\n\r\nExamples of proposed behaviour are here https://gist.github.com/martinfleis/62d48a607d1cf4dc7d67841b3f3e8792.\r\n\r\nI have not added tests and docs yet, as I want to make sure that we are okay with this change as it is not fully backward compatible (you get different plot). Unlike on master, mapclassify also ignores missing values, so e.g., `quantiles` are different (but correct, I'd say).\r\n\r\nQuestions to discuss:\r\n- are we okay with ignoring missing values in the plot?\r\n- are we okay with ignoring missing values in `scheme`? \r\n- how to include missing data legend alongside with colorbar?\r\n\r\nCloses #695",
    "head_branch": "plot_missing",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: support for missing data plotting (#1156)\n\n* ENH: support for missing data plotting\r\n\r\n* Tests\r\n\r\n* Docs\r\n\r\n* Changes based on review\r\n\r\n* clean tests\r\n\r\n* better docstring"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7afac254a19ac29e295",
    "number": 1154,
    "body": "Closes https://github.com/geopandas/geopandas/issues/1155\r\n\r\nProof of concept using `pygeos` for the element-wise spatial operations of GeometryArray (and thus GeoSeries/GeoDataFrame). ~~Right now this still needs a branch in pygeos (https://github.com/caspervdw/pygeos/pull/45).~~\r\n\r\nWith those changes, all tests are passing.\r\n\r\nIt are relatively few changes, and part of them can also be applied on master first.\r\n\r\n--- \r\n\r\nEDIT: I now moved most of the \"compatibility layer\" into a `_vectorized.py` file. So there the switch is done between pygeos vectorized function or our in house \"looping over shapely objects\" code. This gives a bigger diff, but for the shapely ops, it is mostly a copy paste from array.py to _vectorized.py. \r\n\r\n",
    "head_branch": "pygeos",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: (optionally) use pygeos for vectorized GeometryArray operations (#1154)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7b0ac254a19ac29e296",
    "number": 1152,
    "body": "Closes https://github.com/geopandas/geopandas/issues/1144",
    "head_branch": "astype-no-geometry",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: allow astype to work on invalid GeoDataFame + fix astype(object) (#1152)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7b1ac254a19ac29e297",
    "number": 1151,
    "body": "Closes https://github.com/geopandas/geopandas/issues/1149",
    "head_branch": "EA-fillna",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: allow specifying np.nan in fillna (#1151)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7b2ac254a19ac29e298",
    "number": 1150,
    "body": "This is a partial solution toward #846, as described in [this comment](https://github.com/geopandas/geopandas/issues/846#issuecomment-540248972)\r\n\r\nThis retains the index name of the \"primary\" data frame in the join.  For left and inner joins, this is the left data frame; for right joins, this is the right data frame.\r\n\r\nIncludes modifications to test fixtures to make sure that index names are passed consistently into the tests, and includes a specific test to ensure that the expected index name passes through to the result.\r\n\r\nNOTE: in the case of right joins, the index name will now be `None` if the original right data frame's index name was `None`, instead of `index_right`.  This may be breaking change for anyone that relied on the name being `index_right` after this operation, especially if they later did a `reset_index()` and expected to use that column by that name.\r\n\r\nThis does not rename the column created from the non-primary data frame's index, because that would be a larger breaking change.\r\n",
    "head_branch": "issue846",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Retain primary index name in sjoin (#1150)\n\n* Partial solution toward #846\r\n\r\n* And now with more _style_\r\n\r\n* TST: merge tests from #1159"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7b2ac254a19ac29e299",
    "number": 1147,
    "body": "xref https://github.com/geopandas/geopandas/issues/1145\r\n\r\nIt doesn't close that issue, but it does solve the `astype` part that we have control over on the geopandas side.",
    "head_branch": "astype-str-multi",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix astype(str) for Multi-geometries (#1147)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7b3ac254a19ac29e29a",
    "number": 1143,
    "body": "This let's you put geometries inside a dask dataframe.\r\n\r\n```python\r\nIn [3]: import geopandas\r\nwo\r\nIn [4]: import dask.dataframe as dd\r\n\r\nIn [5]: world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\r\n\r\nIn [6]: ddf = dd.from_pandas(world, 2)\r\n\r\nIn [7]: ddf\r\nOut[7]:\r\nDask DataFrame Structure:\r\n              pop_est continent    name  iso_a3 gdp_md_est  geometry\r\nnpartitions=2\r\n0               int64    object  object  object    float64  geometry\r\n89                ...       ...     ...     ...        ...       ...\r\n176               ...       ...     ...     ...        ...       ...\r\nDask Name: from_pandas, 2 tasks\r\n\r\nIn [8]: ddf['geometry']\r\nOut[8]:\r\nDask Series Structure:\r\nnpartitions=2\r\n0      geometry\r\n89          ...\r\n176         ...\r\nName: geometry, dtype: geometry\r\nDask Name: getitem, 4 tasks\r\n\r\nIn [9]: ddf['geometry'].head()\r\nOut[9]:\r\n0    MULTIPOLYGON (((180.00000 -16.06713, 180.00000...\r\n1    POLYGON ((33.90371 -0.95000, 34.07262 -1.05982...\r\n2    POLYGON ((-8.66559 27.65643, -8.66512 27.58948...\r\n3    MULTIPOLYGON (((-122.84000 49.00000, -122.9742...\r\n4    MULTIPOLYGON (((-122.84000 49.00000, -120.0000...\r\nName: geometry, dtype: geometry\r\n```\r\n\r\nxref #461. I don't think it can close it. There's an open API discussion\r\n\r\n1. Adding a `.geo` accessor to DataFrame / Dask DataFrame (implementation wise, this is quite easy for pandas. For dask, things using map_partitions is easy. Something other operations may be trickier).\r\n2. There may be value in using the spatial data to partition the dask dataframe.",
    "head_branch": "dask",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7b4ac254a19ac29e29b",
    "number": 1139,
    "body": "I actually wrote tests in https://github.com/geopandas/geopandas/pull/1057 for the new options code, but apparently I forgot to \"git add\" it ;)",
    "head_branch": "tests-config",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: add tests for new options (#1139)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7b5ac254a19ac29e29c",
    "number": 1138,
    "body": "Fixes #944\r\n\r\nTakes care of intersection with empty geometry. I will add tests for this specific case tomorrow.",
    "head_branch": "fix-sjoin",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix sjoin with empty geometry (#1138)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7b6ac254a19ac29e29d",
    "number": 1137,
    "body": "Closes https://github.com/geopandas/geopandas/issues/1098",
    "head_branch": "docs-missing-empty",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add docs on missing and empty geometries (#1137)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7b7ac254a19ac29e29e",
    "number": 1135,
    "body": "Closes #1125",
    "head_branch": "pyproj_install",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: update installation information about pyproj (#1135)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7b7ac254a19ac29e29f",
    "number": 1134,
    "body": "Closes https://github.com/geopandas/geopandas/issues/1130\r\n\r\nWe already had this fix in a few places, but not yet consistently in all places.",
    "head_branch": "intersection-bug",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix geometry methods to handle single MultiGeoms output (#1134)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7b8ac254a19ac29e2a0",
    "number": 1133,
    "body": "Preparing for actual 0.6.0 release (will keep this open until we actually do the release).",
    "head_branch": "changelog-0.6.0",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "RLS/DOC: update changelog for final 0.6.0 release (#1133)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7b9ac254a19ac29e2a1",
    "number": 1132,
    "body": "`geoseries != geoseries` was raising an error on master. \r\n\r\nThis should also solve the error on Travis in the DEV (pandas master) build",
    "head_branch": "array-equality",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix != operation (#1132)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7baac254a19ac29e2a2",
    "number": 1128,
    "body": "Hi Again @jorisvandenbossche \r\n\r\nAddressing: https://github.com/geopandas/geopandas/issues/821 \r\n\r\nThis PR is the beginning of adding the clip module to geopandas. As i began to copy things over, i noticed that the data used in our vignette uses data downloaded with an earthpy function. So I will need to refactor it to work here. @nkorinek is actually working on that here: \r\n\r\nhttps://github.com/earthlab/earthpy/pull/414\r\n\r\nSo this is also a WIP PR. so far tests for this module are working just fine but I want to see what CI has to say as well. I noticed some of the other tests are failing locally but they have nothing to do with what i am adding here. Excited to see this functionality in GeoPandas!! \r\nThis pr complements #1127 where i'm updating docs as I contribute. \r\n\r\nplease say the word if something needs to be changed, fixed, etc!! \r\n\r\nCloses #956, closes #821\r\n",
    "head_branch": "add-clip",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Add clip function (#1128)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Nathan Korinek <nako1890@colorado.edu>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7bbac254a19ac29e2a3",
    "number": 1127,
    "body": "Hi @jorisvandenbossche et al!! i'm working on pulling together the clip module for you following this discussion here: https://github.com/geopandas/geopandas/issues/821\r\n\r\nin doing this i noticed some inconsistencies in the docs and made a few tweaks. If you'd like a separate issue please say the word. This is labeled as WIP because i'd like to ensure you are ok with the submission first and will add to it as i continue to contribute and find other typos and such! \r\n\r\nI have a question for you. In the contributing guidelines, the steps do not seem to include installing `pytest`. it is not in the dev requirements file nor is it mentioned in the contributing setup instructions yet it's used. Do you want to add a line that says `conda install -c conda-forge pytest` ?\r\n\r\nAlso do you want to add a line about setting up black and flake 8 as a commit hook? I may just be missing something!! here is a start to my edits however. i just updated the conda instructions given conda now uses `conda activate` for windows and mac rather than `source` or just `activate` for Windows. Happy to edit if this is not what you'd like to see in the docs!! \r\n\r\n",
    "head_branch": "update-docs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Update Contributing Guidelines (#1127)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7bbac254a19ac29e2a4",
    "number": 1126,
    "body": "xref https://github.com/pandas-dev/pandas/pull/28389",
    "head_branch": "easize",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add shape and ndim for array compat (#1126)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7bcac254a19ac29e2a5",
    "number": 1124,
    "body": "Fixes #1118.\r\n\r\nI tried to add a better test, but couldn't come up with anything that didn't require cloud storage credentials in the test suite (the `zip` and `tar` VSIs don't support output like this, apparently). So I've settled for testing that the utility works as expected, and verified locally that this allows, e.g., writing GeoJSON to s3.",
    "head_branch": "vfs-check",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Don't convert to absolute path in to_file to preserve VFS paths (#1124)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7bdac254a19ac29e2a6",
    "number": 1123,
    "body": "## Motivation\r\nPandas allows to read rows from a database connection in chunks with the `chunksize` parameter to the functions `read_sql()`, `read_sql_table()` and `read_sql_query()`.\r\nThis is useful for parallelization of data processing in producer/consumer schemes, e.g. where a queue should be filled with chunks of data.\r\nUnder the hood this is handled by sqlalchemy's `fetchmany(chunksize)`.\r\nIt would be very useful to have this functionality in geopandas as well.\r\n\r\n## Description of changes\r\n\r\n### `geopandas/io/sql.py`\r\n* Moved all DataFrame postprocessing and the conversion to a GeodDataFrame from `read_postgis()` to the new function `_df_to_geodf()`\r\n* Analogous to the implementaion of pandas' `read_sql()` functions,\r\n    * the complete data is read into a single dataframe and then transformed into a geodataframe in the absence of `chunksize`, as before.\r\n    * If `chunksize` is set, `pd.read_sql()` returns a generator that produces DataFrames. Then another generator, adding _df_to_geodf() is wrapped around it to yield the GeoDataFrames in chunks.\r\n* The new `chunksize` parameters has been documented in the Docstrings.\r\n\r\n### `geopandas/geodataframe.py`\r\n* The new `chunksize` parameter was also added to `GeoDataFrame.from_postgis()` for consistent behaviour (where it is just passed to `read_postgis()`).\r\n* The new `chunksize` parameters has been documented in the Docstrings.\r\n\r\n### Tests\r\nTests have been implemented for the new `chunksize` parameter for `GeoDataFrame.from_postgis()` and `io.sql.read_postgis()`. `chunksize` has been set to 10, which is hopefully reasonable for the real tests.",
    "head_branch": "postgis_chunksize",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Read from postgis in chunks (#1123)\n\nCo-authored-by: Oliver Schillinger <oliver.schillinger@innogy.com>\r\nCo-authored-by: James McBride <jdmcbr@gmail.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7beac254a19ac29e2a7",
    "number": 1122,
    "body": "- Closes #1036\r\n- Closes #65",
    "head_branch": "always_xy",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add always_xy for pyproj>=2.2.0; skip transformations when CRS exact same (#1122)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7bfac254a19ac29e2a8",
    "number": 1120,
    "body": "Closes #1112 \r\n\r\nAdds `black` and `flake8` as pre-commit hooks.\r\n\r\nAlso runs `black` on the codebase, and fixes `flake8` issues.",
    "head_branch": "1112-black-precommit",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Clean string concatenations after Black"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7c0ac254a19ac29e2a9",
    "number": 1119,
    "body": "As reported earlier, passing a list-like of colors to gdf.plot() will not match rows if there are multipart geometries. That should be fixed now. \r\n\r\nFixes #1075, fixes #730",
    "head_branch": "multipolycolor",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: pass list-like colors to Multi- geometry (#1119)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7c0ac254a19ac29e2aa",
    "number": 1111,
    "body": "Addresses https://github.com/geopandas/geopandas/issues/1100\r\n\r\n@martinfleis this at least adds it back with the exact same behaviour as before. \r\n\r\nI am not fully sure what to do further (leave it as is, deprecate it). ",
    "head_branch": "reenable-any-all",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Re-enable GeoSeries.any/all (#1111)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7c1ac254a19ac29e2ab",
    "number": 1110,
    "body": "Following the discussion in #821, this PR will eventually allow overlay for all types of geometries. The current implementation is robust enough to work with minimal changes. The main block in the master is use of `buffer(0)` at some points, causing LineStrings and Points collapse into empty geometries. I think there was an intention to use it only optionally as there is `make_valid=True` argument, which is actually unused.\r\n\r\nThe only failing test is a bit corner case, we should decide what to do with. In the following example, master returns two Polygons, while this PR the same Polygons,  but also one LineString and two (identical) Points. In theory, the second case is correct, in practice it is the question if it is the intended result.\r\n\r\n```\r\ns2 = gpd.GeoSeries([Polygon([(1, 1), (3, 1), (3, 3), (1, 3)]),\r\n                    Polygon([(3, 3), (5, 3), (5, 5), (3, 5)])])\r\ndf2 = gpd.GeoDataFrame({'col2': [1, 2], 'geometry': s2})\r\n\r\npolys3 = gpd.GeoSeries([Polygon([(1, 1), (3, 1), (3, 3), (1, 3)]),\r\n                        Polygon([(-1, 1), (1, 1), (1, 3), (-1, 3)]),\r\n                        Polygon([(3, 3), (5, 3), (5, 5), (3, 5)])])\r\ndf3 = gpd.GeoDataFrame({'geometry': polys3, 'col3': [1, 2, 3]})\r\n\r\nov = gpd.overlay(df3, df2)\r\n```\r\n```\r\n   col3  col2                             geometry\r\n0     1     1  POLYGON ((3 1, 1 1, 1 3, 3 3, 3 1))\r\n1     2     1                LINESTRING (1 1, 1 3)\r\n2     3     1                          POINT (3 3)\r\n3     1     2                          POINT (3 3)\r\n4     3     2  POLYGON ((5 3, 3 3, 3 5, 5 5, 5 3))\r\n```\r\n\r\nSecond issue might be the fact, that overlay of two geometry types often returns GeoSeries with mixed geometries. As this result is correct and GeoDataFrame has no issue with it, user needs to be aware of the fact that it needs to be separated before saving to file.\r\n\r\nBefore I'll do any further work on this, I'd like to have an agreement how it should behave in the cases above (and probably other I haven't found yet).",
    "head_branch": "overlay_geoms",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: allow overlay for all geometry types (#1110)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7c2ac254a19ac29e2ac",
    "number": 1108,
    "body": "Fixes empty plot object being shown in example page for the documentation, introduced in PR #1105. See: https://geopandas.readthedocs.io/en/latest/gallery/create_geopandas_from_pandas.html#from-wkt-format",
    "head_branch": "fix_example_plot",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: fix plotting in 'pandas to geopandas' example (#1108)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7c3ac254a19ac29e2ad",
    "number": 1107,
    "body": "Addressing #1106 ",
    "head_branch": "get_versions_typo",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "correcting minor typo in _versions.py (#1107)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7c4ac254a19ac29e2ae",
    "number": 1105,
    "body": "Fixes #1060 , added another plot to confirm visually.",
    "head_branch": "fix_WKT_order_in_example",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: fixed WKT order in `create_geopandas_from_pandas` example (#1105)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7c5ac254a19ac29e2af",
    "number": 1104,
    "body": "I have cleaned code a bit by removing which were necessary for older pandas (<0.17). Everything seems to work without these pieces. I have also implemented `pd.api.types.is_list_like` in `_set_geometry` which I found as a TODO in the code during the cleaning. I can split it into two PRs, but it seems not necessary as all edits are basically keeping up with pandas development.\r\n\r\nCloses #1070\r\n\r\n",
    "head_branch": "del_copy",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REF: remove unnecessary fixes for older pandas, use pandas is_list_like (#1104)\n\n* REF: remove unnecessary fixes for older pandas\r\n\r\n* Update doc/source/reference.rst\r\n\r\nCo-Authored-By: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7c5ac254a19ac29e2b0",
    "number": 1103,
    "body": "Temporarily disabling `27-latest-defaults`. It currently fails, due to the error I was not able to track back (no idea what has changed), but which is out of our hands.\r\n\r\n```\r\nfrom urllib2 import urlopen as _urlopen    \r\nurl = (\"https://raw.githubusercontent.com/geopandas/geopandas/master/examples/null_geom.geojson\")       \r\n_urlopen(url)\r\n```\r\n\r\nFails with\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/martin/anaconda3/envs/test/lib/python2.7/urllib2.py\", line 154, in urlopen\r\n    return opener.open(url, data, timeout)\r\n  File \"/Users/martin/anaconda3/envs/test/lib/python2.7/urllib2.py\", line 429, in open\r\n    response = self._open(req, data)\r\n  File \"/Users/martin/anaconda3/envs/test/lib/python2.7/urllib2.py\", line 447, in _open\r\n    '_open', req)\r\n  File \"/Users/martin/anaconda3/envs/test/lib/python2.7/urllib2.py\", line 407, in _call_chain\r\n    result = func(*args)\r\n  File \"/Users/martin/anaconda3/envs/test/lib/python2.7/urllib2.py\", line 1241, in https_open\r\n    context=self._context)\r\n  File \"/Users/martin/anaconda3/envs/test/lib/python2.7/urllib2.py\", line 1198, in do_open\r\n    raise URLError(err)\r\nurllib2.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:727)>\r\n```",
    "head_branch": "ci_disable",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: disable 27-latest-defaults (#1103)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7c6ac254a19ac29e2b1",
    "number": 1102,
    "body": "This PR exposes the kwargs of matplotlib.pyplot.colorbar to plot().  The following example demonstrates its use for horizontal colorbars located at the bottom.\r\n\r\n```\r\nfrom mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\r\nimport geopandas as gp\r\nimport matplotlib.pyplot as plt\r\n\r\ndf = gp.read_file(\"g2g14vz.shp\")\r\n\r\n\r\ncmap = \"inferno\"\r\n\r\nfig, (ax1, ax2) = plt.subplots(1, 2)\r\n\r\n# With horizontal colorbar\r\ndivider = make_axes_locatable(ax1)\r\ncax1 = divider.append_axes(\"bottom\", size=\"5%\", pad=0)\r\n\r\ndf.plot(column=\"AREA_HA\", cmap=cmap, ax=ax1, cax=cax1, legend=True, cbar_kwds={\"orientation\": \"horizontal\"}, vmin=0, vmax=2000)\r\n\r\n# With vertical colorbar\r\ndivider2 = make_axes_locatable(ax2)\r\ncax2 = divider2.append_axes(\"bottom\", size=\"5%\", pad=0)\r\n\r\ndf.plot(column=\"AREA_HA\", cmap=cmap, ax=ax2, cax=cax2, legend=True, vmin=0, vmax=2000)\r\n\r\nplt.savefig(\"colorbar_test.png\")\r\n```\r\n![colorbar_test](https://user-images.githubusercontent.com/259530/63091501-d2719180-bf5e-11e9-93c5-3933dec15bf6.png)\r\n",
    "head_branch": "add_cbar_kwargs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: pass legend_kwds to colorbar when relevant (#1102)\n\n* expose colorbar kwargs\r\n\r\n* add linebreak\r\n\r\n* merge legend_kwds and cbar_kwd\r\n\r\n* move legend_kwds init\r\n\r\n* extend docstring\r\n\r\n* fix typo\r\n\r\n* modify docstring\r\n\r\n* add test for colorbar kwargs\r\n\r\n* fix argument name\r\n\r\n* add documentation\r\n\r\n* docs minor edit"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7c7ac254a19ac29e2b2",
    "number": 1101,
    "body": "Closes #1003 (Alternative to #998 )\r\n\r\nRelated to:\r\n#943\r\n#245\r\n#65\r\n#1036 \r\n#316",
    "head_branch": "crs_pyproj22",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: updated to use pyproj.CRS & pin pyproj >= 2.2.0 (#1101)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7c8ac254a19ac29e2b3",
    "number": 1099,
    "body": "",
    "head_branch": "whatsnew-0.6.0",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add initial changelog for 0.6.0 (#1099)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7c9ac254a19ac29e2b4",
    "number": 1097,
    "body": "",
    "head_branch": "show-versions-old-pyproj",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix show_versions() for pyproj 1.9.6 (#1097)\n\n* also fix gdal version"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7c9ac254a19ac29e2b5",
    "number": 1094,
    "body": "Currently, the GeometryArray is not that useful if you have big (Multi)Polygons, because the default implementation does not do any truncation of the WKT strings.\r\n\r\nEg \r\n\r\n```\r\ndf = geopandas.read_file(geopandas.datasets.get_path(\"naturalearth_lowres\"))\r\ndf.geometry.array\r\n```\r\n\r\ngives a huge unusable repr. \r\n\r\nSo therefore falling back to the shapely reprs (ala `<shapely.geometry.multipolygon.MultiPolygon object at 0x7f8abec050b8>`), until we have a better solution for truncating the strings, if we want that (the `Series/DataFrame` repr already does this automatically, so this is only for `GeometryArray`, so not super high priority)",
    "head_branch": "repr-geometry-array",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Use shapely repr instead of WKT in repr of GeometryArray (#1094)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7caac254a19ac29e2b6",
    "number": 1093,
    "body": "Closes #899 \r\n\r\nAdded info on GDAL, GEOS and PROJ to show_versions.\r\n\r\nI have to admit that merge of #918 was a bit premature as I decided to extend it shortly after that. Nevermind. show_versions in this PR:\r\n\r\n```\r\nSYSTEM INFO\r\n-----------\r\npython     : 3.7.3 | packaged by conda-forge | (default, Jul  1 2019, 14:38:56)  [Clang 4.0.1 (tags/RELEASE_401/final)]\r\nexecutable : /Users/martin/anaconda3/envs/guide/bin/python\r\nmachine    : Darwin-18.6.0-x86_64-i386-64bit\r\n\r\nGEOS, GDAL, PROJ INFO\r\n---------------------\r\nGEOS       : 3.7.2\r\nGEOS lib   : /Users/martin/anaconda3/envs/guide/lib/libgeos_c.dylib\r\nGDAL       : 2.4.2\r\nGDAL dir   : /Users/martin/anaconda3/envs/guide/share/gdal\r\nPROJ       : 6.1.0\r\nPROJ dir   : /Users/martin/anaconda3/envs/guide/share/proj\r\n\r\nPYTHON DEPENDENCIES\r\n-------------------\r\ngeopandas  : 0.5.0+40.g638768c\r\npandas     : 0.25.0\r\nfiona      : 1.8.6\r\nnumpy      : 1.17.0\r\nshapely    : 1.6.4.post2\r\nrtree      : 0.8.3\r\npyproj     : 2.2.1\r\nmatplotlib : 3.1.1\r\nmapclassify: 2.1.1\r\npysal      : 2.0.0\r\ngeopy      : 1.20.0\r\npsycopg2   : None\r\ndescartes  : None\r\n```\r\n\r\n ",
    "head_branch": "geosgdalversions",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: show_versions including GDAL, GEOS, PROJ (#1093)\n\n* ENH: show_versions including GDAL, GEOS, PROJ\r\n\r\n* Add try/except\r\n\r\n* exception handling\r\n\r\n* update tests\r\n\r\n* update tests"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7cbac254a19ac29e2b7",
    "number": 1092,
    "body": "Try to fix Travis CI, xref https://github.com/scipy/scipy/issues/10637",
    "head_branch": "fix-ci",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: pin python to 3.7.3 (pip install issues with 3.7.4) (#1092)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7ccac254a19ac29e2b8",
    "number": 1091,
    "body": "Fixes #869\r\n\r\n`norm` keyword currently doesn't persist for all subplots (see original issue). This behaviour should be fixed now.\r\n\r\nImplements solution by @ImportanceOfBeingErnest outlined in the issue.",
    "head_branch": "persist_norm",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: norm not persisting when using subplots  (#1091)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7cdac254a19ac29e2b9",
    "number": 1090,
    "body": "",
    "head_branch": "docs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: update mapclassify url and tooling for dash/zeal docs (#1090)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7cdac254a19ac29e2ba",
    "number": 1089,
    "body": "In current version, if you use normalisation, colorbar does not represent true color scheme as it is always normalized linear between min and max. This PR fixes the behaviour and normalises colorbar using the same scheme, so the results should match. \r\n\r\nIt should resolve issue like https://github.com/geopandas/geopandas/issues/697#issuecomment-515499696 . \r\n\r\n\r\n```\r\ngdf = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\r\ngdf['random'] = np.random.gamma(2, 2, len(gdf)) - 2\r\n\r\nvmin, vmax, vcenter = gdf.random.min(), gdf.random.max(), 0\r\ndivnorm = colors.DivergingNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\r\n\r\ngdf.plot(column='random', cmap='RdBu', legend=True, norm=divnorm)\r\n```\r\nBefore:\r\n![before](https://user-images.githubusercontent.com/36797143/62839290-183d0a00-bc80-11e9-9a90-085a6c7595c4.png)\r\nAfter:\r\n![after](https://user-images.githubusercontent.com/36797143/62839291-1d9a5480-bc80-11e9-872b-fdde276bd04a.png)\r\n\r\nCloses #697 ",
    "head_branch": "cbar",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: colorbar did not match normalised colors (#1089)\n\n* BUG: colorbar should use normalization\r\n\r\n* TST: add test\r\n\r\n* Update test for older matplotlib\r\n\r\n* blacken\r\n\r\n* style fix\r\n\r\n* fix tests"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7ceac254a19ac29e2bb",
    "number": 1088,
    "body": "Updated contextily example to use `add_basemap` from contextily 1.0. However, I would wait with merging until contextily 1.0.0 is stable as `pip install contextily` now installs 0.99.0 which does not work with this example.\r\n\r\nCloses #1077\r\n",
    "head_branch": "ctx_ex",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: update contextily example (#1088)\n\n* DOC: update contextily example\r\n\r\n* Split optional/default"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7cfac254a19ac29e2bc",
    "number": 1085,
    "body": "Related to the \"strict GeoSeries constructor\" bullet point in https://github.com/geopandas/geopandas/issues/1000  and also related to https://github.com/geopandas/geopandas/issues/53\r\n\r\nThis *seems* to work (I am not 100% sure that pandas does not expect an actual class in `_constructor`, but our tests seem to indicate it works)",
    "head_branch": "strict-geoseries-constructor",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "API: deprecate GeoSeries fallback to return Series for non-geometry data (#1085)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7d0ac254a19ac29e2bd",
    "number": 1084,
    "body": "Closes https://github.com/geopandas/geopandas/issues/1078\r\n\r\nThe pandas bug itself is described at https://github.com/pandas-dev/pandas/issues/27785.",
    "head_branch": "bug-apply-1078",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: workaround in GeoSeries constructor for pandas loc bug (#1084)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7d1ac254a19ac29e2be",
    "number": 1083,
    "body": "It was failing again: https://readthedocs.org/projects/geopandas/builds/9472564/\r\n\r\nI updated everything to the latest version. Workflow: remove all version specifiers, create an environment as is done on RTD with `conda env create --name latest --file doc/environment.yml` (ensure to use flexible channel priority, as this is also the config on RTD), and then from `conda list` of the created environment, use the versions as how they are installed. ",
    "head_branch": "fix-readthedocs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC/RTD: update readthedocs environment (#1083)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7d1ac254a19ac29e2bf",
    "number": 1082,
    "body": "As pointed out in #1081, `pysal` package includes codebase of `mapclassify`. If `pysal` is installed but `mapclassify` not, this PR will use `pysal.viz.mapclassify` to get scheme in plotting.\r\n\r\nNot sure how to test it though, maybe having mapclassify in one env and pysal in other?\r\n\r\nCloses #1081",
    "head_branch": "pysal",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: allow pysal alongside mapclassify for plotting scheme (#1082)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7d2ac254a19ac29e2c0",
    "number": 1080,
    "body": "Moving a bunch of additional array tests from the geopandas-cython branch to master, now we have the GeometryArray (ExtensionArray) in master as well.\r\n\r\n",
    "head_branch": "array-tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: add additional GeometryArray tests (#1080)\n\nTests from the geopandas-cython branch.\r\n\r\nCo-authored-by: Matthew Rocklin <mrocklin@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7d3ac254a19ac29e2c1",
    "number": 1079,
    "body": "Test to see if this fixed the travis build, see also https://github.com/conda-forge/fiona-feedstock/issues/135",
    "head_branch": "fix-ci",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: use defaults for py36 build (#1079)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7d4ac254a19ac29e2c2",
    "number": 1073,
    "body": "For context, see https://github.com/conda-forge/segregation-feedstock/pull/2#issuecomment-514687151\r\n\r\nExample failing build: https://travis-ci.org/geopandas/geopandas/jobs/564925601#L514",
    "head_branch": "ci-failure-zstd",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: add zstd as dependency to fix conda-forge problem with latest fiona / gdal"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7d5ac254a19ac29e2c3",
    "number": 1072,
    "body": "Closes https://github.com/geopandas/geopandas/issues/1042",
    "head_branch": "cleanup-cx",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CLN: implement CoordinateIndexer .cx without using pandas internals (#1072)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7d5ac254a19ac29e2c4",
    "number": 1071,
    "body": "This PR establishes support for measurement values.\r\nWith Fiona support for M-values on the way, this prevents Measurements values for the supported geometries from being treated as z coordinates and places them in a separate column field on the geodataframe.\r\nI am certain that the code can be further optimized, or perhaps re-written to provide a more native  support for the functionality, so I'll be looking forward to hearing your suggestions!",
    "head_branch": "polyline-M-support",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7d6ac254a19ac29e2c5",
    "number": 1065,
    "body": "Some of the examples do not work with modern tools, and some of the outputs have changed.\r\n\r\nThese are now revised and refreshed.",
    "head_branch": "py3",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: refresh with Python 3 syntax, and modern outputs (#1065)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7d7ac254a19ac29e2c6",
    "number": 1063,
    "body": "Updated geopandas.org to match recent 0.5.1 release.",
    "head_branch": "gp_org_051",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: update geopandas.org to 0.5.1 (#1063)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": true,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d7d8ac254a19ac29e2c7",
    "number": 1062,
    "body": "Attempt to close https://github.com/geopandas/geopandas/issues/601 (see also the discussion there), takes some tests from https://github.com/geopandas/geopandas/pull/582 (from the geopandas-cython branch, as this is behaviour we can already have in master).\r\n\r\nThis PR is certainly still work in progress (it needs eg more tests), but already wanted to put it up for discussion.\r\n\r\nI thought this initially was going to be a relatively easy issue, but it seems it is a deeper change as I had expected. \r\nBasically, the current data model in geopandas somewhat assumes you don't have missing values, only empty geometries (but imperfectly). For example, `GeoSeries.align` introduces empty geometries for non-matching indexes where the pandas version introduces NaNs (but, the GeoDataFrame version also uses NaNs ...). We also had a `GeoSeries._can_hold_na` defined to False, which lead `GeoSeries.dropna` to never drop something, while at the same time `GeoSeries.isna` actually took missing values into account next to empty geometries, giving an isna and dropna methods which were in conflict with each other.\r\n\r\nCurrently, doing something like `s1.intersection(s2)`, where s1 and s2 are non-aligned GeoSeries objects, the alignment would introduce empty geometries, ensuring the actual intersection operation works (as currently, many of the geospatial methods will fail if you have missing values).\r\n\r\nI still think it is best to separate those two concepts of missing and empty. And to also follow the pandas behaviour more closely for introducing missing values instead of empty geometries when alignment occurs (assuming we fix all geospatial methods to work with missing values correctly).\r\n\r\nIf we do that separation, an important question is how to get there. Do we do a hard break, or do we try to do it with a deprecation? \r\n\r\nI am currently tempted to do a hard break, as deprecating it seems complex (it would need new keyword to opt in into the future behaviour in several places (isna, dropna, align, ..), but in principle also all geospatial methods like intersection that does alignment ..\r\n\r\nI personally think alignment is rather uncommon for *geometry columns* (not in general in pandas), but I also never really worked with data that lead to those cases, so hard to judge for me.",
    "head_branch": "clean-up-missing-empty",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "API: separate concepts of 'missing' and 'empty' geometries (#1062)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7d9ac254a19ac29e2c8",
    "number": 1061,
    "body": "Recent PRs involving update of docs #1058 https://github.com/geopandas/geopandas/issues/1052#issuecomment-511123455 suggest that our contributing guidelines for that part are insufficient. I have expanded it a bit, to make clear that it is not strictly required to run `make html` and that it might be needed to use environment.yml for env creation before doing that.",
    "head_branch": "docs_instructions",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Expand contributing/documentation (#1061)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7daac254a19ac29e2c9",
    "number": 1059,
    "body": "Currently `to_file` can write a shapefile, but the index is lost, unless the user knows to do `.reset_index().to_file('foo.shp')`.\r\n\r\nThis PR keeps the index in the shapefile export for these situations [updated to current PR]:\r\n* If the index has a name defined\r\n* If the index is a MultiIndex\r\n* <s>If the index is different than a default range index (0, 1, 2, ...)</s>\r\n* <s>If there are no columns, since shapefiles need to have at least one column</s>\r\n* If the index has a non-integer data type",
    "head_branch": "reset-index",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: to_file should write index in certain cases (#1059)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7daac254a19ac29e2ca",
    "number": 1058,
    "body": "This is solve #1053.",
    "head_branch": "add-rename_geometry-method",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: add rename_geometry() method  (#1058)\n\n* adding rename_geometry method and test\r\n\r\n* adding inplace and updating the example doc and tests accordingly'\r\n\r\n* fixing inplace in rename_geometry\r\n\r\n* Update geopandas/geodataframe.py\r\n\r\nminor styling change\r\n\r\nCo-Authored-By: Martin Fleischmann <36797143+martinfleis@users.noreply.github.com>\r\n\r\n* Update geopandas/geodataframe.py\r\n\r\nstyling change\r\n\r\nCo-Authored-By: Martin Fleischmann <36797143+martinfleis@users.noreply.github.com>\r\n\r\n* Update geopandas/geodataframe.py\r\n\r\nstyling change\r\n\r\nCo-Authored-By: Martin Fleischmann <36797143+martinfleis@users.noreply.github.com>\r\n\r\n* Update geopandas/geodataframe.py\r\n\r\nstyling change\r\n\r\nCo-Authored-By: Martin Fleischmann <36797143+martinfleis@users.noreply.github.com>\r\n\r\n* Update geopandas/tests/test_geodataframe.py\r\n\r\nstyling change\r\n\r\nCo-Authored-By: Martin Fleischmann <36797143+martinfleis@users.noreply.github.com>\r\n\r\n* Update geopandas/geodataframe.py\r\n\r\nCo-Authored-By: Martin Fleischmann <36797143+martinfleis@users.noreply.github.com>\r\n\r\n* adding reference document\r\n\r\n* Update geopandas/geodataframe.py\r\n\r\nCo-Authored-By: Martin Fleischmann <36797143+martinfleis@users.noreply.github.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7dbac254a19ac29e2cb",
    "number": 1057,
    "body": "This is an experiment to show that it is now possible to control the number of decimals to show in the representation of the geometries in a Series/DataFrame.\r\n\r\nOn master:\r\n\r\n```\r\nIn [3]: df = geopandas.read_file(geopandas.datasets.get_path('naturalearth_cities')) \r\n\r\nIn [4]: df.head()\r\nOut[4]: \r\n           name                                     geometry\r\n0  Vatican City  POINT (12.45338654497177 41.90328217996012)\r\n1    San Marino    POINT (12.44177015780014 43.936095834768)\r\n2         Vaduz  POINT (9.516669472907267 47.13372377429357)\r\n3    Luxembourg  POINT (6.130002806227083 49.61166037912108)\r\n4       Palikir  POINT (158.1499743237623 6.916643696007725)\r\n\r\nIn [5]: df = geopandas.read_file(geopandas.datasets.get_path('nybb'))\r\n\r\nIn [6]: df.head() \r\nOut[6]: \r\n   BoroCode       BoroName     Shape_Leng    Shape_Area                                           geometry\r\n0         5  Staten Island  330470.010332  1.623820e+09  (POLYGON ((970217.0223999023 145643.3322143555...\r\n1         4         Queens  896344.047763  3.045213e+09  (POLYGON ((1029606.076599121 156073.8142089844...\r\n2         3       Brooklyn  741080.523166  1.937479e+09  (POLYGON ((1021176.479003906 151374.7969970703...\r\n3         1      Manhattan  359299.096471  6.364715e+08  (POLYGON ((981219.0557861328 188655.3157958984...\r\n4         2          Bronx  464392.991824  1.186925e+09  (POLYGON ((1012821.805786133 229228.2645874023...\r\n```\r\n\r\nWith this PR:\r\n\r\n```\r\nIn [4]: df = geopandas.read_file(geopandas.datasets.get_path('naturalearth_cities'))\r\n\r\nIn [5]: df.head()\r\nOut[5]: \r\n           name                   geometry\r\n0  Vatican City  POINT (12.45339 41.90328)\r\n1    San Marino  POINT (12.44177 43.93610)\r\n2         Vaduz   POINT (9.51667 47.13372)\r\n3    Luxembourg   POINT (6.13000 49.61166)\r\n4       Palikir  POINT (158.14997 6.91664)\r\n\r\nIn [6]: df = geopandas.read_file(geopandas.datasets.get_path('nybb'))\r\n\r\nIn [7]: df.head()\r\nOut[7]: \r\n   BoroCode       BoroName     Shape_Leng    Shape_Area                                           geometry\r\n0         5  Staten Island  330470.010332  1.623820e+09  MULTIPOLYGON (((970217.022 145643.332, 970227....\r\n1         4         Queens  896344.047763  3.045213e+09  MULTIPOLYGON (((1029606.077 156073.814, 102957...\r\n2         3       Brooklyn  741080.523166  1.937479e+09  MULTIPOLYGON (((1021176.479 151374.797, 102100...\r\n3         1      Manhattan  359299.096471  6.364715e+08  MULTIPOLYGON (((981219.056 188655.316, 980940....\r\n4         2          Bronx  464392.991824  1.186925e+09  MULTIPOLYGON (((1012821.806 229228.265, 101278...\r\n```\r\n\r\nI often need to think that we show way too many decimals (see also https://www.xkcd.com/2170/ for a nice illustration). Those decimals are typically not informative anymore, and it also makes the geometry column wider than it needs to be (at least for Points, for linestrings/polygons you will still quickly bump to the max col width).\r\n\r\nThis PR controls the number of decimals. Currently to 5 for lon/lat values or 3 otherwise (i.e. 1 mm for projected coordinates), using a very simple heuristic to decide in which case we are, but we can certainly discuss the best defaults.\r\n\r\nSome questions:\r\n\r\n- Is this useful?\r\n- What would be good defaults?\r\n- Will this not be confusing? \r\n  (eg if two Points are not equal due to some floating point difference, that might get hided. Although you have the same when working with floats in pandas ..)\r\n- If we do it, it should probably be configurable? (so the user can overwrite the rounding_precision)\r\n\r\nBTW, this PR also makes the \"MULTIPOLYGON\" more explicit (compared to the  `(POLYGON ..`), but that's a change we can do anyway regardless of doing the rounding_precision or not.",
    "head_branch": "repr-rounded",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Show less coordinate decimals in Series repr of geometries (#1057)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7dcac254a19ac29e2cc",
    "number": 1056,
    "body": "",
    "head_branch": "changelog-0.5.1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add changelog for 0.5.1 (#1056)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7ddac254a19ac29e2cd",
    "number": 1054,
    "body": "Readthedocs is failing currently due to the update of geoplot example, which was not reflected in the environment file.\r\nIt may fail for some time anyway as GDAL on conda-forge is broken at this moment. (https://github.com/conda-forge/gdal-feedstock/issues/303) Travis for this PR will probably fail as well.",
    "head_branch": "update_geoplot",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: update geoplot version for rtd environment (#1054)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7deac254a19ac29e2ce",
    "number": 1050,
    "body": "Starting a branch to cherry-pick commits for the bug fix release",
    "head_branch": "0.5.x-update",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add changelog for 0.5.1 (#1056)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": true,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7dfac254a19ac29e2cf",
    "number": 1049,
    "body": "Closes https://github.com/geopandas/geopandas/issues/1045",
    "head_branch": "compat-pytest",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Avoid importing pytest in main geopandas import (#1049)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7dfac254a19ac29e2d0",
    "number": 1048,
    "body": "Closes https://github.com/geopandas/geopandas/issues/1047",
    "head_branch": "test-1047",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: test GeoSeries constructor fallback in case of list-like scalars (#1048)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7e0ac254a19ac29e2d1",
    "number": 1046,
    "body": "See https://github.com/geopandas/geopandas/pull/1044",
    "head_branch": "doc-fixes",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: fix dataset usage from geoplot (#1046)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7e1ac254a19ac29e2d2",
    "number": 1044,
    "body": "Some minor renovations to the `geoplot` example gallery in the documentation necessitated by the `geoplot@0.3.0` release. Also cleans up some code here or there.",
    "head_branch": "update-geoplot-docs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Update geoplot docs. (#1044)\n\n* Update.\r\n\r\n* Updates per comments.\r\n\r\n* Update."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7e2ac254a19ac29e2d3",
    "number": 1043,
    "body": "Some additional tests from https://github.com/geopandas/geopandas/pull/835",
    "head_branch": "more-tests3",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: additional asserts in constructor tests (#1043)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7e3ac254a19ac29e2d4",
    "number": 1038,
    "body": "This PR started originally to fix a case of the GeoDataFrame constructor to preserve the name of a GeoSeries. So when doing `GeoDataFrame(..data.., geometry=GeoSeries(geoms, name='my_geom'))`, to result in a GeoDataFrame with a 'my_geom' geometry column (on master this currently gives 'geometry' ignoring the name of the GeoSeries).\r\n\r\nBut to fix this, I started looking at the `set_geometry` method (which is being used by the GeoDataFrame constructor). And also noticed that the method is not fully well defined / documented.\r\n\r\n- When specifying the name of an existing column, the original geometry column is kept but the \"active geometry\" column is swapped to the specified column\r\n  - However, with `drop=True`, the old geometry column is replaced with the new (so dropping one column). But, now, we don't use the specified name as the geometry column name, but fall back to the default 'geometry' -> should we preserve the specified name here?\r\n\r\n- When specifying actual geometry values, the original geometry column gets replaced with the new values\r\n  - Currently, we don't preserve the name of the passed values (if they have a name, i.e. a (Geo)Series). This is what this PR started with fixing.\r\n  - But if the values have a name, it can also be an option to keep the original geometry column intact (not necessarily the default, but people could do `drop=False` to keep the original one)\r\n\r\nSee also https://nbviewer.jupyter.org/gist/jorisvandenbossche/61ba4b240a2060ec7dafdead84e13371 for a notebook exploring those options of `set_geometry`.\r\n\r\nThoughts?",
    "head_branch": "set-geometry",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7e3ac254a19ac29e2d5",
    "number": 1034,
    "body": "",
    "head_branch": "mcfix",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7e4ac254a19ac29e2d6",
    "number": 1033,
    "body": "",
    "head_branch": "mapclassify-compat",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Handle breakage due to mapclassify 2.1.0 deprecation (#1033)\n\nCo-authored-by: Serge Rey <sjsrey@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7e5ac254a19ac29e2d7",
    "number": 1032,
    "body": "Attempt to fix https://github.com/geopandas/geopandas/issues/1022, and something we should do anyway to make the approach similar as on Travis (for now trying to use the same env files as for travis, but could make specific ones for appveyor if needed)",
    "head_branch": "appveyor-setup",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: use conda environment files for Appveyor builds (#1032)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7e6ac254a19ac29e2d8",
    "number": 1030,
    "body": "This is a rebase of a selection of commits from the [geopandas-cython branch](https://github.com/geopandas/geopandas/tree/geopandas-cython) on current master. This will be cleaner than going forward with the geopandas-cython branch (the original idea) and backporting everything from master in there (since a lot has changed). \r\nNot everything is included (certain fixes were no longer relevant now the internals are based on the ExtensionArray interface), and I also removed all Block related code.\r\n\r\n\r\nFor now it still includes a squash of the ExtensionArray refactor (https://github.com/geopandas/geopandas/pull/835). Once that work is merged the coming week, I will rebase this again.\r\n\r\nxref https://github.com/geopandas/geopandas/issues/473, https://github.com/geopandas/geopandas/pull/472",
    "head_branch": "geopandas-cython-new",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7e7ac254a19ac29e2d9",
    "number": 1029,
    "body": "",
    "head_branch": "conda-4.7",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: re-enable conda 4.7 (#1029)\n\nCo-Authored-By: Mike Sarahan <msarahan@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7e8ac254a19ac29e2da",
    "number": 1024,
    "body": "See https://github.com/pandas-dev/pandas/issues/27035",
    "head_branch": "skip-flaky-test",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: pin conda to 4.6"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7e8ac254a19ac29e2db",
    "number": 1023,
    "body": "Some additional tests from PRs that were merged in the cython branch, for which the fix is no longer relevant for master (eg because it already works, or the fix was specific to the custom block), but we still can add the tests to master (#583, #591, #596, https://github.com/geopandas/geopandas/pull/515)",
    "head_branch": "more-tests2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: additional tests (#1023)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7e9ac254a19ac29e2dc",
    "number": 1021,
    "body": "",
    "head_branch": "pytest-config",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: pytest configuration (#1021)\n\n* TST: pytest configuration\r\n\r\n* continue with second appveyor build"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7eaac254a19ac29e2dd",
    "number": 1020,
    "body": "Retake of earlier PR https://github.com/geopandas/geopandas/pull/572 (from the cython branch) but for the master branch now.",
    "head_branch": "geoseries-constructor",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "GeoSeries to return Series when non-geometry data are passed (#572) (#1020)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7ebac254a19ac29e2de",
    "number": 1016,
    "body": "Some tests I wrote in the process of the refactor (https://github.com/geopandas/geopandas/pull/835) that were already passing on master.",
    "head_branch": "more-tests2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: additional constructor and getitem tests (#1016)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7ecac254a19ac29e2df",
    "number": 1015,
    "body": "This should make CI green again.",
    "head_branch": "remove-select-test",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: remove select test (removed in pandas 0.25.0) (#1015)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7ecac254a19ac29e2e0",
    "number": 1012,
    "body": "Introduce an `ignore_errors` option for geopandas.read_file that when True will simply ignore features that cause a ValueError exception.\r\n\r\n---\r\n\r\nI'm using GeoPandas to process a bunch of GPX files generated from a Garmin Vista HCx. Many of these seem to contain track segments that look something like this:\r\n\r\n```\r\n  <trkseg>\r\n   <trkpt lat=\"42.384411\" lon=\"-71.162963\">\r\n    <ele>12.134</ele>\r\n    <time>2019-05-29T12:56:44Z</time>\r\n   </trkpt>\r\n  </trkseg>\r\n```\r\n\r\nShapely doesn't like lines with a single point (who does?), so trying to use `geopandas.read_file` with these files will often result in:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/lars/.local/share/virtualenvs/gps-TT0qNP_P/lib/python3.7/site-packages/geopandas/io/file.py\", line 96, in read_file\r\n    gdf = GeoDataFrame.from_features(f_filt, crs=crs, columns=columns)\r\n  File \"/home/lars/.local/share/virtualenvs/gps-TT0qNP_P/lib/python3.7/site-packages/geopandas/geodataframe.py\", line 233, in from_features\r\n    d = {'geometry': shape(f['geometry']) if f['geometry'] else None}\r\n  File \"/home/lars/.local/share/virtualenvs/gps-TT0qNP_P/lib/python3.7/site-packages/shapely/geometry/geo.py\", line 42, in shape\r\n    return MultiLineString(ob[\"coordinates\"])\r\n  File \"/home/lars/.local/share/virtualenvs/gps-TT0qNP_P/lib/python3.7/site-packages/shapely/geometry/multilinestring.py\", line 52, in __init__\r\n    self._geom, self._ndim = geos_multilinestring_from_py(lines)\r\n  File \"/home/lars/.local/share/virtualenvs/gps-TT0qNP_P/lib/python3.7/site-packages/shapely/geometry/multilinestring.py\", line 134, in geos_multilinestring_from_py\r\n    geom, ndims = linestring.geos_linestring_from_py(obs[l])\r\n  File \"shapely/speedups/_speedups.pyx\", line 152, in shapely.speedups._speedups.geos_linestring_from_py\r\nValueError: LineStrings must have at least 2 coordinate tuples\r\n```\r\n\r\nWith this PR, you can set `ignore_errors` to `True` and geopandas will simply skip features that result in a ValueError:\r\n\r\n```\r\ndata = geopandas.read_file('filename.gpx', ignore_errors=True)\r\n```",
    "head_branch": "feature/ignore_errors",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7edac254a19ac29e2e1",
    "number": 1009,
    "body": "Added `astype` to override function from base `pandas` class. Following code should now return a geodataframe as opposed to a pandas dataframe. \r\nFixes #1006 :\r\n\r\n```\r\nimport geopandas\r\n\r\ndf = geopandas.read_file(geopandas.datasets.get_path('nybb'))\r\n\r\nprint(type(df))\r\n\r\ndf2 = df.astype({'BoroCode': str})\r\n\r\nprint(type(df2))\r\n```\r\n",
    "head_branch": "branch",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: override astype to ensure a GeoDataFrame is returned (#1009)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7eeac254a19ac29e2e2",
    "number": 1008,
    "body": "Attempt to address #1007 ",
    "head_branch": "add_affine_transform_method",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      " ENH: Add affine_transform method to GeoSeries (#1008)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7efac254a19ac29e2e3",
    "number": 1002,
    "body": "Preparation for the ExtensionArray work, which will require at least pandas 0.23 (released May 15, 2018), see second bullet point in https://github.com/geopandas/geopandas/issues/1000. \r\nAt the same time also bumped matplotlib to 2.0.1 (May 2017).\r\n\r\n",
    "head_branch": "ci-update-060",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Update minimal dependencies for pandas (>=0.23.4) and matplotlib (>=2.0.1) (#1002)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7f0ac254a19ac29e2e4",
    "number": 998,
    "body": "Needs tests for new version & probably needs current tests fixed.\r\nMuch to do here, but it is a start.",
    "head_branch": "class_crs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7f1ac254a19ac29e2e5",
    "number": 995,
    "body": "Another preparation PR for moving to ExtensionArrays (WKB will be useful for factorizing, WKT for repr), and those methods will also be useful in general.\r\n\r\nFor now not exposed top-level, only in the `array` module (except for the already existing `points_from_xy` which I moved there).",
    "head_branch": "array-constructors",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: add constructors / converters for shapely, WKT and WKB (#995)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7f1ac254a19ac29e2e6",
    "number": 993,
    "body": "Another part of https://github.com/geopandas/geopandas/pull/835, in preparation to make GeometryArray an actual ExtensionArray. \r\nThis PR already moves the implementations out of base.py to a GeometryArray class (which for now is just holder of those methods, without other functionality) in array.py.\r\n\r\nIt might not look like a that useful refactor on its own, but will make the diff for the ExtensionArray PR smaller.",
    "head_branch": "refactor-array",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REF: move element-wise geo ops to array class (#993)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7f2ac254a19ac29e2e7",
    "number": 987,
    "body": "Just a tiny update to include 2019 in copyright.\r\n\r\nI am going to merge, as there is basically nothing to review.",
    "head_branch": "docs_year",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: updated year in copyright\n\nDOC: updated year in copyright in documentation"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7f3ac254a19ac29e2e8",
    "number": 986,
    "body": "An attempt to update docs on geopandas.org via GH pages mentioned by @jdmcbr. I hope I got it right now, but it would be nice to have it as an actual mirror of stable ReadTheDocs version of docs. This is a bit hassle.",
    "head_branch": "update_gh_pages",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Update docs for 0.5.0 (#986)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": true,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d7f4ac254a19ac29e2e9",
    "number": 985,
    "body": "Try to fix the failing CI (not sure what update to Anaconda changed this)",
    "head_branch": "fix-travis",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: too old fiona installed on py3.5-minimal build (#985)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7f5ac254a19ac29e2ea",
    "number": 984,
    "body": "This should fix the version check error we are seeing on readthedocs (can't reproduce it locally, but it is fixed in the latest geoplot anyway, xref https://github.com/ResidentMario/geoplot/issues/72)",
    "head_branch": "doc-geoplot-version",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC/BLD: update geoplot version in readthedocs environment (#984)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7f6ac254a19ac29e2eb",
    "number": 981,
    "body": "",
    "head_branch": "test-warnings",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: remove some deprecation warnings triggered by the tests (#981)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7f7ac254a19ac29e2ec",
    "number": 979,
    "body": "See https://github.com/geopandas/geopandas/issues/812",
    "head_branch": "doc-add-doi",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add Zenodo doi to README (#979)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7f8ac254a19ac29e2ed",
    "number": 977,
    "body": "Better list different communication channels (eg the fact that we have a mailing list .. :))\r\n\r\n(inspired by the xarray readme https://github.com/pydata/xarray/) ",
    "head_branch": "doc-mailing-list",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add different communication channels to README/docs (#977)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7f8ac254a19ac29e2ee",
    "number": 976,
    "body": "See eg the result of the spatial join in this example: https://geopandas.readthedocs.io/en/v0.4.0/mergingdata.html#spatial-joins\r\n\r\nDue to some changes in the pandas display machinery (default option for the number of columns changed from 20 to \"whathever fits on one line\"), the output is not always shown. Therefore setting it here manually to the old setting, and also increasing the width a bit.",
    "head_branch": "doc-ipython-pandas-display",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: set pandas display options to ensure non-truncated output (#976)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7f9ac254a19ac29e2ef",
    "number": 975,
    "body": "I started off this way in #907, then switched to nominatim, but our\ncurrent usage appears to be a violation of the nominatim terms of\nservice. Geocodefarm doesn't seem perfect, but given my reading of their\nterms of service, I think using it in our examples in docs is okay.",
    "head_branch": "nominatim-to-geocodefarm",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Switch geocoding default to geocodefarm (#975)\n\nI started off this way in #907, then switched to nominatim, but our\r\ncurrent usage appears to be a violation of the nominatim terms of\r\nservice. Geocodefarm doesn't seem perfect, but given my reading of their\r\nterms of service, I think using it in our examples in docs is okay."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7faac254a19ac29e2f0",
    "number": 973,
    "body": "Some of the builds on defaults are still using fiona 1.7, but pinning this explicitly in the env files to make sure we keep testing it for now, also if the packages would get updated.",
    "head_branch": "testing-old-fiona",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST/CI: pin a few builds to older fiona version (#973)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7fbac254a19ac29e2f1",
    "number": 971,
    "body": "Our tests are broken with proj.4 6 / pyproj 2 (see https://github.com/pyproj4/pyproj/issues/269 for context). \r\nSo updating the tests here to just make sure they are correctly working and passing with the latest pyproj (without any change to optimally use the changes in pyproj 2, that's already done in another PR). \r\n\r\nAnd while at it, I isolated the `to_crs` related tests in a separate file, with the intent to add some more extensive testing of the current functionality.",
    "head_branch": "test-proj6",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST/CI: update CRS tests + ensure compatibility with proj.4 6 / pyproj 2 (#971)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7fcac254a19ac29e2f2",
    "number": 970,
    "body": "Since matplotlib is an optional requirement, this allows to also runs the tests with only the base dependencies.",
    "head_branch": "test-skip-matplotlib",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: skip plotting tests if matplotlib is not installed (#970)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7fcac254a19ac29e2f3",
    "number": 969,
    "body": "Addressing #529 by providing a Jupyter Notebook with both folium and geopandas is used.",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Adding Example for interactive point plot with folium (#969)\n\n* Adding example for Plotting with Folium\r\n\r\n* Adding HeatMap in plotting with folium example\r\n\r\n* Adding HeatMap in plotting with folium example\r\n\r\n* Updating and tried to fix the issue.\r\n\r\n* Update examples/plotting_with_folium.ipynb\r\n\r\nCo-Authored-By: Martin Fleischmann <36797143+martinfleis@users.noreply.github.com>\r\n\r\n* Updated and made the suggested changes\r\n\r\n* Delete ne_110m_admin_0_countries.zip"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7fdac254a19ac29e2f4",
    "number": 968,
    "body": "The buffer resolution has to be an int. Passing a float will result in:\r\n\r\n```ArgumentError: argument 4: <class 'TypeError'>: wrong type```",
    "head_branch": "byrman_buffer-resolution",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: buffer resolution is an int, not a float (#968)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7feac254a19ac29e2f5",
    "number": 962,
    "body": "Closes https://github.com/geopandas/geopandas/issues/963\r\n\r\nSince version 2.0.0 pyproj have a new way to optimize transformation.\r\nI don't know a lot about geopandas to maybe i did it wrong but the last version of pyproj make the transformation a lot slower (about 100 000 times slower).\r\nsee https://pyproj4.github.io/pyproj/html/optimize_transformations.html for more information.\r\n\r\nso this PR intend to fix the performance loss",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "PERF: Optimize pyproj >= 2.1 transformations  (#962)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d7ffac254a19ac29e2f6",
    "number": 958,
    "body": "Attempt to address #529 \r\n ",
    "head_branch": "add_folium_example",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add gallery example of polygon plot with folium (#958)\n\nadd explanation of re-projection\r\n\r\nre-run example with geopandas 0.5.0"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d800ac254a19ac29e2f7",
    "number": 954,
    "body": "Update links to point at `shapely.readthedocs.io` and `fiona.readthedocs.io` to avoid the 404 page found on `toblerity.org` in the current documentation.",
    "head_branch": "update-outdated-links",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix broken links to Shapely and Fiona docs (#954)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d801ac254a19ac29e2f8",
    "number": 949,
    "body": "- remove py27 dev build (pandas master no longer supports python 2.7) and replace with pandas 0.23 build\r\n- py37 dev build: move installing pandas and matplotlib master to separate steps in travis yml file (otherwise the conda create step takes too long)\r\n- remove conda-forge/label/dev label for fiona (was still installing the rc instead of actual released version)",
    "head_branch": "update-ci",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: update travis builds (#949)\n\n- remove py27 dev build (pandas master no longer supports python 2.7) and replace with pandas 0.23 build\r\n- py37 dev build: move installing pandas and matplotlib master to separate steps in travis yml file (otherwise the conda create step takes too long)\r\n- remove conda-forge/label/dev label for fiona (was still installing the rc instead of actual released version)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d801ac254a19ac29e2f9",
    "number": 948,
    "body": "",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Minor typo fix (#948)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d802ac254a19ac29e2fa",
    "number": 946,
    "body": "This is in response to issue #746 . Note that it will only work for drivers that support datetime fields; eg GPKG and not ESRI Shapefile. ",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d803ac254a19ac29e2fb",
    "number": 935,
    "body": "Hopefully fixes https://github.com/conda-forge/fiona-feedstock/issues/121",
    "head_branch": "strict_channel",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: update miniconda version (#935)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d804ac254a19ac29e2fc",
    "number": 934,
    "body": "",
    "head_branch": "test-docs-environment",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "DOC/BLD: readthedocs version 2 config file (#934)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d805ac254a19ac29e2fd",
    "number": 933,
    "body": "See https://github.com/ResidentMario/geoplot/issues/69: depending on how the data are subsampled, we stumble into a potential bug in geoplot. So fixing the random state with a working one to prevent this.",
    "head_branch": "docs-geoplot-random-error",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: fix random state in geoplot voronoi example to prevent random errors (#933)\n\nSee ResidentMario/geoplot#69: depending on how the data are subsampled, we stumble into a potential bug in geoplot. So fixing the random state with a working one to prevent this."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d806ac254a19ac29e2fe",
    "number": 932,
    "body": "This seems to ensure that readthedocs passes the environment creation step. \r\n(lately, this has been failing, in a similar way as https://github.com/rtfd/readthedocs.org/issues/5220. I assume that conda takes too much resources when solving the environment. Taking the approach of xarray of pinning all libraries seems to solve it)",
    "head_branch": "test-docs-environment",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "DOC: pin versions in readthedocs environment.yml file (#932)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d806ac254a19ac29e2ff",
    "number": 931,
    "body": "A recent change on pandas master (https://github.com/pandas-dev/pandas/pull/25272) made it so that `isna` now preserves the subclass (resulting in a boolean GeoSeries, which caused the current failures on travis for pandas master).\r\n\r\nIt might still be changed on the pandas side before a release, but ensuring it on the GeoPandas side with this fix (so our builds are green, and also it shouldn't cause any harm even if the pandas behaviour would be changed back).",
    "head_branch": "isna-series",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Ensure GeoSeries.isna is always a Series and not GeoSeries (#931)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d807ac254a19ac29e300",
    "number": 930,
    "body": "This was deprecated in numpy 1.16 and prints a warning on every invocation.\r\nThe function was just a thin wrapper around .item() since a long time(Maybe forever, not sure about that), so this should have no impact on people using older versions.",
    "head_branch": "np116",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "COMPAT: use .item() instead of deprecated np.asscalar() (#930)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d808ac254a19ac29e301",
    "number": 929,
    "body": "",
    "head_branch": "changelog-041",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: changelog for 0.4.1 bugfix release (#929)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d809ac254a19ac29e302",
    "number": 926,
    "body": "Expanding the installation docs in the hope to make them clearer / have less installation problems.\r\n\r\ncc @ocefpaf @jdmcbr ",
    "head_branch": "doc-install-rework",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: rework installation docs (#926)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d80aac254a19ac29e303",
    "number": 922,
    "body": "Addresses #544 and complements #896 to give us a lower friction pathway from df to gdf and back again.\r\n\r\nShould `preserve_points` also attempt to preserve the z coords? If so, what's the best way to get that from the points?\r\n\r\n",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d80aac254a19ac29e304",
    "number": 920,
    "body": "",
    "head_branch": "patch-3",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d80bac254a19ac29e305",
    "number": 919,
    "body": "",
    "head_branch": "patch-2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: update fiona / shapely links (#919)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d80cac254a19ac29e306",
    "number": 918,
    "body": "Actioning Issue #899. Based upon code https://github.com/pandas-dev/pandas/blob/master/pandas/util/_print_versions.py.",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: show_versions added (#918)\n\n* show_versions added\r\n\r\n* Redo based on sklearn\r\n\r\n* Added optional deps\r\n\r\n* optional to tests\r\n\r\n* fix old mapclassify"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d80dac254a19ac29e307",
    "number": 917,
    "body": "",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix readme doc formatting (#917)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d80eac254a19ac29e308",
    "number": 916,
    "body": "This is a fix for #881 \r\n\r\nIt simply wraps the reading code in a `with fiona_env()` block, like in `to_file()`.",
    "head_branch": "read-file-with-fiona-env",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Read in a fiona.Env() block to make sure GDAL_DATA is set (#916)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d80fac254a19ac29e309",
    "number": 914,
    "body": "Closes https://github.com/geopandas/geopandas/issues/912\r\n\r\ncc @martinfleis ",
    "head_branch": "bug-empty-result",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: unary/binary geo ops with all-empty result raise error (#914)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d80fac254a19ac29e30a",
    "number": 913,
    "body": "Background: https://github.com/Toblerity/Fiona/issues/714.",
    "head_branch": "sgillies-fiona-crs",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "COMPAT: fwd and bkwd compatibility with fiona CRS (#913)\n\nBackground: https://github.com/Toblerity/Fiona/issues/714."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d810ac254a19ac29e30b",
    "number": 909,
    "body": "I have added just a couple of examples of reading / writing files to docs as it was a bit empty. I made examples of keywords usage for driver as well as layer (GeoPackage).",
    "head_branch": "io_docs_examples",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "added examples (#909)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d811ac254a19ac29e30c",
    "number": 907,
    "body": "I hesitated to do this before for the docs, but it is nice to have the\r\ndefault provider be one that works without an API key (which is now\r\nrequired for google). The downside of this is that geocodefarm has only\r\nbeen an option since May 2018, so if someone tries just running the\r\nexamples and doesn't have prior experience, they'll get a crash due\r\nto a missing provider rather than a crash due a missing API key.",
    "head_branch": "use-geocodefarm",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Set geocodefarm as default geocoding service (#907)\n\nSet nominatim as default geocoding service"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d812ac254a19ac29e30d",
    "number": 906,
    "body": "As raised in #822, may be useful to have the postgis port settings more\r\ngeneric.",
    "head_branch": "pgport-env",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Make port settable or gettable from env (#906)\n\n* TST: Make port settable or gettable from env\r\n\r\nAs raised in #822, may be useful to have the postgis port settings more\r\ngeneric.\r\n\r\n* Add other postgres env settings too\r\n\r\n* Add more documentation on postgis test setup"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d813ac254a19ac29e30e",
    "number": 905,
    "body": "Centralizes all IO tests (now some in `test_io.py`, and some in `test_geodataframe.py`), and splits between read_file/to_file tests and sql tests. Plus some pytest clean-up.\r\n\r\nFor the rest it is a pure copy paste, there should be no actual change to the tests itself.",
    "head_branch": "testing-file",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: reorganize IO tests (#905)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d813ac254a19ac29e30f",
    "number": 904,
    "body": "Pandas 0.24 changed default lineterminator\r\nto os.linesep (so OS dependent now).",
    "head_branch": "ci-fix-windows",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: fix to_csv test on Windows (#904)\n\nPandas 0.24 changed default lineterminator\r\nto os.linesep (so OS dependent now)."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d814ac254a19ac29e310",
    "number": 903,
    "body": "Travis CI tests were failing recently for one specific build, see https://github.com/conda-forge/gdal-feedstock/issues/261\r\n\r\nFixed by removing the pin of matplotlib to 1.5.3 (but added `gdal=2.3` to keep at older gdal version). \r\n\r\nAlso added `nomkl` to have a built with numpy/openblas from conda-forge (not that it should matter though).",
    "head_branch": "ci-fix-travis",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: fix the conda-forge env with pd 0.20 (remove pin of old matplotlib) (#903)\n\nTravis CI tests were failing recently for one specific build, see https://github.com/conda-forge/gdal-feedstock/issues/261\r\n\r\nFixed by removing the pin of matplotlib to 1.5.3 (but added `gdal=2.3` to keep at older gdal version). \r\n\r\nAlso added `nomkl` to have a built with numpy/openblas from conda-forge (not that it should matter though)."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d815ac254a19ac29e311",
    "number": 900,
    "body": "According to #898 I started by adding a hint to the API documentation.\r\n\r\nI could also add an example to the examples section but I will not have time until the end of February.\r\n\r\nIf it is easy for anybody, so just go ahead, otherwise I will make a proposal in March. I think it would be good to keep the world map but I do not have a second map to plot onto. Any ideas?",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d816ac254a19ac29e312",
    "number": 896,
    "body": "Following discussion at #833 this PR is adding `points_from_xy()` function to convert coordinates stored in the separate columns (or other objects) to `shapely.Point` to be used as `geometry`. \r\n\r\nI just wasn't sure where to put the function (and the test) as it is a bit independent function not so much related to GeoDataFrame or GeoSeries. It is in geodataframe.py as it is designed to be used while creating geometry for GeoDataFrame.\r\n\r\n**From longitudes and latitudes** example has been updated to use this new function a well.",
    "head_branch": "points_from_xy",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH Provide API to convert x, y(, z) coordinates to geometry (#896)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d817ac254a19ac29e313",
    "number": 894,
    "body": "This PR aims at solving issue #702 , and it is directly inspired from reviews done in PR #704 by @jdmcbr .\r\n\r\nThe point is to improve colormap representation when plotting a GeoDataFrame feature. On master we get oversized colormaps next to main plot:\r\n![insee_population_bkp](https://user-images.githubusercontent.com/15051098/50889386-23813c00-13f8-11e9-8dc7-dfac8352d24e.png)\r\n\r\nThe `geopandas` new version after PR gives:\r\n![insee_population](https://user-images.githubusercontent.com/15051098/50889422-35fb7580-13f8-11e9-871b-48f2e37f2a6c.png)\r\n\r\nBefore calling the `gdf.plot(.)` method, we have to write the following lines:\r\n```\r\nimport matplotlib.pyplot as plt\r\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\r\nfig, ax = plt.subplots(1, 1)\r\ndivider = make_axes_locatable(ax)\r\ncax = divider.append_axes(\"right\", size=\"5%\", pad=0.2) # depends on the user needs\r\n```\r\nHence goes the GeoDataFrame feature plotting:\r\n```\r\ngdf.plot(\"feature\", ax=ax, cax=cax, legend=True)\r\n```\r\n\r\nThis new behavior allows to tune the colormap, without including the tuning process directly into `geopandas` source code.",
    "head_branch": "standardize_colorbar",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Consider a new plotting artist for improving colormap legends (#894)\n\n* Consider a new plotting artist for improving colormap legends\r\n\r\n* test: add a unit test for verifying legend height\r\n\r\n* plotting: manage 'cax' argument without 'ax' one\r\n\r\n* test: add a missing 'abs(.)' function to cax height test\r\n\r\n* doc: complete 'mapping.rst' with details about the choropleth legends\r\n\r\n* Update mapping.rst\r\n\r\nMake explanation of colorbar example more concise"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d818ac254a19ac29e314",
    "number": 892,
    "body": "Docs were failing because expected failure was unexpectedly not failing.\r\n:)\r\nAlso minor changes to postgis doc in order to quiet warning.",
    "head_branch": "restore-geoplot-doc",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Add geoplot example back to doc (#892)\n\nDocs were failing because expected failure was unexpectedly not failing.\r\n:)\r\nAlso minor changes to postgis doc in order to quiet warning."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d818ac254a19ac29e315",
    "number": 891,
    "body": "Change of the dataset (#808) was merged without updating `test_legend` and `test_classification_kwds`. I have changed expected values to match new data. This is also causing other failure of checks other recent PRs. ",
    "head_branch": "plotting_tests_newdata",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "fixed expected values to match new dataset (#891)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d819ac254a19ac29e316",
    "number": 890,
    "body": "Just created a moderate sized series and frame and tested reading and\r\nwriting.",
    "head_branch": "io-benchmarks",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add very basic benchmarks for file reading/writing (#890)\n\n* Add very basic benchmarks for file reading/writing\r\n\r\nJust created a moderate sized series and frame and tested reading and\r\nwriting.\r\n\r\n* Add benchmarks for other file extensions"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d81aac254a19ac29e317",
    "number": 889,
    "body": "Currently due to an installation problem (https://github.com/conda-forge/geoplot-feedstock/pull/5#issuecomment-450808839), the example is not running. \r\nBut even when the latest geoplot is used, it will fail for some time due to the `__pysal_choro` -> `_mapclassify_choro` rename.",
    "head_branch": "doc-build",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: temp allow failure in geoplot example gallary (#889)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d81bac254a19ac29e318",
    "number": 888,
    "body": "The request to google is frequently (always?) failing in the past few\r\nmonths, so use geocodefarm instead for the example of how to use\r\ngeocoding in geopandas.",
    "head_branch": "geocoding-docs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Use geocodefarm rather than google for example (#888)\n\nThe request to google is frequently (always?) failing in the past few\r\nmonths, so use geocodefarm instead for the example of how to use\r\ngeocoding in geopandas."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d81cac254a19ac29e319",
    "number": 887,
    "body": "I started looking at the issue raised in #881, and realized there was a\r\nsomewehat extraneous codepath with `fiona.open` in the geoseries\r\n`read_file` method. This gives one fewer place to make\r\nupdates to use `fiona.Env()`.\r\n\r\nIt seems a little more natural to me to use the\r\n`io.file.read_file` method here, but the adjoining two class methods are\r\nimporting from geodataframe and using the methods on `GeoDataFrame`\r\nobjects, so I followed suit here.",
    "head_branch": "geoseries-read",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CLN: Use read_file from geodataframe in geoseries (#887)\n\nI started looking at the issue raised in #881, and realized there was a\r\nsomewehat extraneous codepath with `fiona.open` in the geoseries\r\n`read_file` method. This gives one fewer place to make\r\nupdates to use `fiona.Env()`.\r\n\r\nIt seems a little more natural to me to use the\r\n`io.file.read_file` method here, but the adjoining two class methods are\r\nimporting from geodataframe and using the methods on `GeoDataFrame`\r\nobjects, so I followed suit here."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d81cac254a19ac29e31a",
    "number": 885,
    "body": "Rationale: This will help in installing geopandas on python3.7 even without conda. Currently it is broken due to very old release of pyproj (it was last released in January, 2016). The pyproj was being called in only 5 lines throughout the code base.\r\n```shell\r\ngeopandas/tools/crs.py\r\n1:import pyproj\r\n53:    with open(os.path.join(pyproj.pyproj_datadir, 'epsg')) as f:\r\n\r\ngeopandas/geoseries.py\r\n6:import pyproj\r\n300:        proj_in = pyproj.Proj(self.crs, preserve_units=True)\r\n301:        proj_out = pyproj.Proj(crs, preserve_units=True)\r\n302:        project = partial(pyproj.transform, proj_in, proj_out)\r\n```\r\nand these functionality can easily be obtained from `fiona`.\r\n\r\nFurthermore, reduction in dependency, always reduces the project cost. \r\n\r\n## Fixes #793 ",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d81dac254a19ac29e31b",
    "number": 883,
    "body": "Current implementation of ``overlay`` returns results without resetting index.",
    "head_branch": "correct-overlay",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Correct overlay result index (#883)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d81eac254a19ac29e31c",
    "number": 878,
    "body": "Changes in #770 wrong behaviour of `mn = values.min() if vmin is None else vmin` and `mx = values.max() if vmax is None else vmax` which lead to wrong colours during plotting. \r\n\r\nPrevious version was passing Series, which ignores NaNs in min() and max(). Now it is passing numpy array which returns NaN for min() and max() (if there are any).\r\n\r\nResolves #877 ",
    "head_branch": "plot-nan",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Ignore NaN in setting mn and mx (#877) (#878)\n\n* ignore nan in setting mn and mx\r\n\r\n* test if vmin vmax set correctly for array with NaN\r\n\r\n* test compatible with older versions\r\n\r\n* reference to issue and shorter assert in test"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d81fac254a19ac29e31d",
    "number": 876,
    "body": "Following #872 and responding to #235 and #357, I have added access to all mapclassify schemes. It is possible to pass kwargs in classification_kwds dict in the exactly same way as it is for legend_kwds. k can be passed as normal argument (same as now)(will be ignored if scheme does is not k-based) or in classification_kwds. If both will be passed, latter will overwrite former. \r\n\r\nI have also added simple test to check if args were passed. Hope you will find it useful, those issues are quite old, I just felt it could be easily done.",
    "head_branch": "classification-schemes",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Access to all mapclassify schemes including keywords (#235, #357) (#876)\n\n* access to all mapclassify schemes including keywords (#235, #357)\r\n\r\n* test for classificaition_kwds\r\n\r\n* scheme docstring to get rid of selection of schemes\r\n\r\n* Explicit list of possible schemes in docstring\r\n\r\n* New classification schemes in docs (and changed PySAL to mapclassify)\r\n\r\n* import all mapclassify clasifiers instead passing them explicitly\r\n\r\n* inspect compatible with python 2\r\n\r\n* fix getargspec for python 2.7\r\n\r\n* minor update of docs"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d820ac254a19ac29e31e",
    "number": 874,
    "body": "",
    "head_branch": "changelog-0.5",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC/RLS: start changelog for the 0.5.0 release (#874)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d821ac254a19ac29e31f",
    "number": 873,
    "body": "IPython 7.0 now makes sphinx stop the full doc build if an unexpected warning or error happens in one of the examples. There is an option to restore the old behaviour (to only print the tracebacks), which is IMO more useful (you at least see all errors, and not only the first one).",
    "head_branch": "doc-ipython-continue",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: continue doc build on warnings/errors in examples (#873)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d821ac254a19ac29e320",
    "number": 872,
    "body": "Fix to #721 \r\n\r\nPySAL, which is being used for classification of choropleth maps is changing its structure (http://pysal.org/about.html). Instead of depending on the full PySAL we can now use package mapclassify directly. Currently used pysal.esda.mapclassify will be soon deprecated. \r\n\r\nDuring this edit, I have also added option to use Fisher_Jenks_Sampled scheme, which can be useful for large datasets.",
    "head_branch": "mapclassify",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Use mapclassify instead of PySAL due to change of PySAL structure. (#872)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d822ac254a19ac29e321",
    "number": 871,
    "body": "Rename keys to col in docstring to correspond with method signature",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: fix param name for GeoDataFrame.set_geometry (#871)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d823ac254a19ac29e322",
    "number": 870,
    "body": "Closes #867\r\n\r\nFiona is now able to write `GeoDataFrame`s having multiple geometry types\r\nThis PR tries to integrate this Fiona feature into geopandas\r\n\r\nsee issue #867 for more information.\r\n\r\nEssentially:\r\n\r\n1. I added some unit tests on `geopandas.to_file` and `geopandas.io.file.infer_schema` functions\r\n1. I reworked `geopandas.io.file.infer_schema` to support `GeoDataFrame`s having heterogeneous geometries\r\n\r\nHere is a summary of `geopandas.io.file.infer_schema` and `geopandas.to_file` behavior changes (using `GeoJSON` or `GPKG` ogr driver):\r\n\r\n| gdf geometries | `infer_schema` former behavior | `infer_schema` new behavior | `to_file` former behavior | `to_file` new behavior |\r\n| --- | --- | --- | --- | --- |\r\n| `Point` | returns `\"Point\"` | returns `\"Point\"` | writes to file | writes to file |\r\n| `Point` and `MultiPoint` |  returns `\"Point\"` | returns `[\"Point\", \"MultiPoint\"]` | raises `fiona.errors.GeometryTypeValidationError` with message `Record's geometry type does not match collection schema's geometry type: 'MultiPoint' != 'Point'` | writes to file |\r\n| `Point` and `Polygon` |  returns `None` | returns `[\"Point\", \"Polygon\"]` | raises `ValueError` with message `Geometry column cannot contain mutiple geometry types when writing to file.` | writes to file |\r\n| `Point` and `None` |  returns `\"Point\"` | returns `\"Point\"` | writes to file | writes to file |\r\n| `None` |  returns `None` | returns `\"Unknown\"` | raises `ValueError` with message `Geometry column cannot contain mutiple geometry types when writing to file.` | writes to file |\r\n",
    "head_branch": "write-gdf-having-mixed-geometries",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: write GeoDataFrame with mixed geometry types (#870)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d824ac254a19ac29e323",
    "number": 864,
    "body": "Fix for #863 .\r\nI referred to @jorisvandenbossche 's code very much.\r\nI implemented three different na strategies (null, drop, keep).\r\nUnder my PC environment, the speed improvement was nearly nine times as follows.\r\n\r\n%timeit list(df.iterfeatures())\r\nBefore: 3.36 s ± 225 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\r\nAfter : 375 ms ± 14.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\r\n\r\n(The same condition as @jorisvandenbossche 's [Notebook](http://nbviewer.jupyter.org/gist/jorisvandenbossche/3bea109e0622fa5e3f90eecdc496c816) )",
    "head_branch": "Improve_iterfeatures_performance",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "PERF: Improve iterfeatures performance (#864)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d825ac254a19ac29e324",
    "number": 860,
    "body": "It adds the argument `parse_dates`. The default value is None.\r\n\r\nI just add the possibility you have pandas `read_sql` function to specify columns for date parsing to geopandas `read_postgis` function.\r\n\r\nI didn't add any test because I was not sure if it was required for such a small change. I'm also unsure of how to do it but if you give me hints I will do it.",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: parse date for read_postgis (#860)\n\n* ENH: parse date for read_postgis\r\n\r\n* ENH: parse date for from_postgis"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d826ac254a19ac29e325",
    "number": 859,
    "body": "I made interiors method return None for non-polygons.\r\nThis is the matter written in TODO of base.py.\r\n\r\nCurrently, bool value is returned when GeoSeries contains non polygon.\r\nThis state was not intended by method, and I attempted to correct it.\r\n",
    "head_branch": "interiors_method_corresponding_to_non-polygons",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Make interiors method correspond to non-polygons (#859)\n\n* Make interiors method correspond to non-polygons\r\n\r\n* Add warnings to non-polygon and convert to list\r\n\r\n* Re-worded interiors warning for non-Polygons"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d826ac254a19ac29e326",
    "number": 857,
    "body": "```python\r\nimport geopandas, pysal\r\ndf = geopandas.read_file(pysal.examples.get_path('south.dbf'))\r\n# works now\r\ndf.to_file('./test_promotion.gpkg', promote=True, driver='GPKG')\r\n# fails with the multi-type\r\ndf.to_file('./test_promotion.gpkg', promote=False, driver='GPKG')\r\n```\r\nWhile this is possible, I'm still not quite sure why QGIS is able to do this without forcing everything into multipolygon types. Maybe we can do this right by building a better schema? not sure yet, but wanted to post this up so the discussion from #834 continues. ",
    "head_branch": "promote_multis",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d827ac254a19ac29e327",
    "number": 856,
    "body": "Though GIS databases allow missing geometry values, `from_postgis` breaks when it encounters them.\r\nThese patches fix `from_postgis` and `GeoDataFrame` to allow nulls, and test for the feature with sqlite.\r\n\r\nShould [`create_sqlite`][1] get a GIS-oriented rewrite?\r\nThough [`create_sqlite`][1] seemed to have been written for SQLite tests, its original design assumes data isn't stored to perform geospatial analysis within SQLite, which I find questionable.\r\nWhile comments under [`create_postgis`][2] remind the tester to load a GIS extension in their database, [`create_sqlite`][1] lacks such comments and instead stores geometries as opaque blobs that SQLite's GIS extension, [SpatiaLite][3], wouldn't store.\r\nI would think anyone seriously using GeoPandas and SQLite for GIS analysis would load and store geometries with [SpatiaLite][3] and want that tested much as they would with PostgreSQL and PostGIS.\r\nNonetheless, I preserved that questionable design in [`create_sqlite`][1] and used it as its name would suggest.\r\n\r\n[1]: https://github.com/geopandas/geopandas/pull/856/files#diff-a69da126b34c78887116607be6f68b3cL52\r\n[2]: https://github.com/geopandas/geopandas/pull/856/files#diff-a69da126b34c78887116607be6f68b3cL77\r\n[3]: https://www.gaia-gis.it/fossil/libspatialite/index",
    "head_branch": "feature-sql",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix from_postgis to accept nullable geometry (#856)\n\n* TST: test read_postgis with NULL geometry\r\n\r\nThough GIS databases permit NULL values in the geometry field, read_postgis throws exceptions when it encounters them.\r\ntest_read_postgis_null_geom defines this test case with sqlite3 database, and support functions are revised to support it.\r\ncreate_sqlite is revised to loosen data type restrictions and follow [recommendations from the python manual](https://docs.python.org/3/library/sqlite3.html)\r\n- connection parameter instead of filename to allow for in-memory database\r\n- 'with' statement for transaction management\r\n- parameter substitution instead of string operations\r\nvalidate_boro_df strips NULL values before checking geometry type.\r\n\r\n* TST: replace sqlite test with spatialite test\r\n\r\nThe original SQLite test reflected unlikely usage for geospatial analysis.\r\nIn parity with PostGIS, the new test runs against SQLite with SpatiaLite enabled.\r\nFor coverage, test geometries read as text and binary.\r\n\r\n* TST: add libspatialite as a test dependency\r\n\r\n* TST: add conda-forge testing environment for Python 2.7\r\n\r\nadd this environment to continuous integration\r\nconda-forge Python 2.7 enables loadable SQLite extensions with conda-forge/python-feedstock#227\r\nadding this environment enables SpatiaLite tests\r\n\r\n* BUG: fix read_postgis & GeoDataFrame to accept NULL geometry values\r\n\r\nread_postgis failed to load nullable binary geometry data while GeoDataFrame raised exceptions on NULL in the geometry field.\r\nThis fixes both issues.\r\nIt moreover adds logic to detect python version & load geometries from\r\npython 2 buffers as necessary.\r\n\r\n* ENH DOC: drop hex_encoded parameter from read_postgis & from_postgis\r\n\r\ndrop hex_encoded, since sqlite3 represents binary & text as distinct Python data types\r\nadjust names to clarify this distinction\r\nadjust documentation to clarify geometry is expected in WKB representation (which was implicit)\r\nadd example SpatiaLite usage reflecting this expectation"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d828ac254a19ac29e328",
    "number": 855,
    "body": "Related to https://github.com/geopandas/geopandas/issues/437, again passing through 'bool' type if fiona >= 1.8.",
    "head_branch": "fiona-io-bool",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: support writing bool dtype with fiona>=1.8 (#855)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d829ac254a19ac29e329",
    "number": 854,
    "body": "Closes #845",
    "head_branch": "fiona-18-warning",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Use fiona.Env() for new versions to avoid warning (#854)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d82aac254a19ac29e32a",
    "number": 853,
    "body": "Hello\r\nThis is my first attempt to contribute to this project. \r\nThe purpose is to implement a relate method which has not been implemented yet.\r\n\r\nI am not good at English, so I'm sorry if my intention is not communicated.\r\n",
    "head_branch": "relate-method",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Implementation of relate method (#853)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d82aac254a19ac29e32b",
    "number": 851,
    "body": "@jorisvandenbossche  @jdmcbr  here is a first stab at updating the contrib file based upon discussion [here](https://github.com/geopandas/geopandas/issues/848).\r\n\r\nPlease note that I also removed the double spaces after each period! if you don't like that I can undo it.  I am open to any and all modifications as well - please just say the word!",
    "head_branch": "contrib-edits",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Contributing file updates python 2.7 instead of 2.6 + a few other syntax consistency edits (#851)\n\n* Fixing minor misspelling in Contributing.md file\r\n\r\n* Updating CONTRIBUTING file to reflect python 3.x\r\n\r\n* Support for Python v 2.7 edits\r\n\r\n* Consistent capitalization  of Python\r\n\r\n* Adjust python support version"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d82bac254a19ac29e32c",
    "number": 849,
    "body": "",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fixing minor misspelling in Contributing.md file (#849)\n\nCloses #848"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d82cac254a19ac29e32d",
    "number": 847,
    "body": "Part of https://github.com/geopandas/geopandas/pull/835 that is unrelated to ExtensionArrays, so split off.\r\n\r\nHarmonized the helper functions for binary/unary spatial ops + some PEP8 clean-up.",
    "head_branch": "cleanup-base",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CLN: clean-up base.py (#847)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d82dac254a19ac29e32e",
    "number": 844,
    "body": "",
    "head_branch": "test-fiona",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Test fiona 1.8b1 (#844)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d82eac254a19ac29e32f",
    "number": 843,
    "body": "This refactors the travis CI setup using an environment file for each travis build (similarly to how it is done in pandas).\r\n\r\nProblems with the current set-up was that it was not easy to fix certain dependencies such as shapely. For example, we pinned shapely in some builds, but then a subsequent install of fiona updates the shapely version, so we were not actually testing it (eg https://travis-ci.org/geopandas/geopandas/jobs/433952235#L736).\r\n\r\nThis approach here gives a bit more redundancy in the other deps in the environment files (but we can later always see if we can reduce this, eg automatically inject the other deps that do no vary)",
    "head_branch": "refactor-travis",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST/CI: refactor travis using fixed environment files (#843)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d82eac254a19ac29e330",
    "number": 842,
    "body": "Fix for #841. Also added some more information to the warning raised for mismatching CRS.\r\n\r\nSeems like my autopep8 format on save also touched a few more lines in the sjoin test.",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Raise exception from sjoin if inputs are not GeoDataFrames (#842)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d82fac254a19ac29e331",
    "number": 835,
    "body": "Implementing the ExtensionArray interface (for current master, not the geopandas-cython branch, as I want that we actually support the EA interface already now)\r\n\r\nWork in progress: \r\nFor now only targeting pandas master / 0.23.0, need to add compatibility layer for older pandas versions later. \r\nStarted with implementing a GeometryArray, and dispatching to that for the spatial methods (this will also work for older pandas versions), now integrating in the rest of the code base.\r\n\r\nTODO:\r\n\r\n- [x] add compatibility layer with pandas 0.23 ",
    "head_branch": "master-extension-array",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Refactor internals based on ExtensionArray interface (#835)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d830ac254a19ac29e332",
    "number": 833,
    "body": ".set_geometry() now takes keywords x, y[, z] as an alternative to the `col` argument to construct the geometry column directly from coordinates.\r\n\r\nMost of the code here was taken from PR #75 which is superseded by this PR.",
    "head_branch": "set-geometry-by-coords",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d831ac254a19ac29e333",
    "number": 829,
    "body": "The crs was not preserved when aligning GeoSeries objects + added some more thorough test for align",
    "head_branch": "align-preserve-crs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG/TST: fix align to preserve metadata + more tests (#829)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d832ac254a19ac29e334",
    "number": 828,
    "body": "",
    "head_branch": "assert-equal-nan",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: handle missing values in testing functionality (#828)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d833ac254a19ac29e335",
    "number": 827,
    "body": "Per https://github.com/Toblerity/Fiona/pull/539 this seems like the right way to handle this case.\r\n\r\n```\r\nimport os\r\nimport geopandas as gpd\r\nfrom shapely.geometry import Polygon, MultiPolygon\r\n\r\np = Polygon([(0., 0.), (0., 1.), (1., 1.), (1., 0.), (0., 0.)])\r\ngdf = gpd.GeoDataFrame({'a':[1,2]}, geometry=[p, MultiPolygon([p])])\r\n\r\ntry:\r\n    os.remove('/tmp/test.geojson')\r\nexcept:\r\n    pass\r\ngdf.to_file('/tmp/test.geojson', driver='GeoJSON')\r\n```\r\n\r\nThe above works on Fiona==1.7.13 but on Fiona==1.8a2 gives\r\n```\r\nGeometryTypeValidationError: Record's geometry type does not match collection schema's geometry type: 'MultiPolygon' != 'Polygon'\r\n```\r\n\r\nSetting the schema like in this PR works with both versions:\r\n```\r\ngdf.to_file('/tmp/test.geojson', driver='GeoJSON', schema={**gpd.io.file.infer_schema(gdf), 'geometry': 'Unknown'})\r\n```",
    "head_branch": "patch-2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Default to `'Unknown'` geometry schema (#827)\n\n* Default to `'Unknown'` geometry schema\r\n\r\n* Add GeoJSON to_file test\r\n\r\n* Add comment to test"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d833ac254a19ac29e336",
    "number": 822,
    "body": "Hi, \r\n\r\nThis is my first attempt to contribute to this project. The goal is to seamlessly ingest a `GeoDataFrame` object into a PostGIS database in a similar way that `pandas` interacts with PostgreSQL. \r\nI inspired from #457  and #761 to come up with this method that \r\n\r\n1. Uses `geoalchemy2` as a requirement (only added to `requirements.test.txt`) \r\n2. Make a copy of the original gdf\r\n3. Infer the PostGiS geom type from `geopandas.GeoDataFrame.geom_type()` \r\n4. Convert the CRS to a PostGIS SRID format\r\n5. Pass arguments to all arguments to `pandas.to_sql()` \r\n\r\n### Notes\r\n* Unlike #457, this does not attempt to parse converts shapely objects from another column that the geometry.  Geopandas is designed to work off-the shell with only one geometry column, is then up to the user to change the types. \r\n* It does a full copy of the frame in the first place because the geometry has to be converted and one shall not mutate the object. This can be heavy in memory for large frames with large shapes. One could add a copy argument default to `True` or maybe you have another \r\n\r\nOfc this is a WIP and If you like it I can continue documenting it and writing some tests. \r\n\r\nCheers!\r\n\r\n (Ping @jdmcbr )\r\n\r\nPS : I found that the way tests are handled is complicated as it requires to have a PostGIS instance running on the same machine. I came up with a `docker-compose` setup of a PostGIS image to emulate that - look at the `ci` branch. \r\n",
    "head_branch": "postgis_api",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d834ac254a19ac29e337",
    "number": 816,
    "body": "Starts addressing #750 \r\n\r\nGives a warning when doing operations on two GeoSeries that are not aligned to each other.\r\n\r\nCurrently the warning is quite terse. We should also add a page in the documentation that explains how the user can do what he/she really wants to do (reindexing, spatial join, etc), and then reference that page in the warning.",
    "head_branch": "750-warn-about-alignment",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Warn about automatic alignment of GeoSeries (#816)\n\n* Add test for warnings about misaligned Geoseries\r\n\r\n* Add warning if geoseries are not aligned\r\n\r\n* Do fillna explicitly (was done by align)\r\n\r\n* Explicitly expect warnings in non-aligned tests\r\n\r\n* Add test that no warning is given when series are aligned\r\n\r\n* fixup merge\r\n\r\n* Improve text in warning\r\n\r\n* apply black\r\n\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d835ac254a19ac29e338",
    "number": 815,
    "body": "Added a list of available datasets to the error raised when trying to get a path of a dataset that does not exist.\r\n\r\nExample:\r\n\r\n    >>> import geopandas\r\n    >>> geopandas.datasets.get_path(\"naturalearth\")\r\n    ValueError: The dataset 'naturalearth' is not available. Available datasets are naturalearth_lowres, naturalearth_cities, nybb\r\n",
    "head_branch": "available-datasets",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "List available datasets if dataset is not found (#815)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d836ac254a19ac29e339",
    "number": 814,
    "body": "There are some warnings issued by Sphinx when building the docs.\r\n\r\nThis PR fixes most of the warnings. There are four outstanding warnings about missing `source/reference/geopandas.<smth>.examples` files. These warnings should probably be fixed by creating examples :blush: \r\n\r\n",
    "head_branch": "docs-update-warnings",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Remove warnings when building docs (#814)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d836ac254a19ac29e33a",
    "number": 813,
    "body": "Removes warnings emitted from tests:\r\n\r\n- crs mismatch because of unnecessary crs on `self.empty` series\r\n- downstream warning from `scipy.stats`\r\n- future warning for `.select()`",
    "head_branch": "tests-remove-warnings",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Clean output from tests by removing warnings (#813)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d837ac254a19ac29e33b",
    "number": 810,
    "body": "I just tracked down this bug when using geopandas.testing.assert_geodataframe_equal. I kept being confused as to why my test was succeeding when it shouldn't. This appears to be a typo. I didn't see any other mistakes.\r\n\r\nThis is my first commit to geopandas. Let me know if you need anything else. Thanks for all your hard work!",
    "head_branch": "fix_assert_geodataframe_equals",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix assert_geodataframe_equal to correctly compare left and right (#810)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d838ac254a19ac29e33c",
    "number": 808,
    "body": "fix for issue #804 \r\nnew shapefiles downloaded from http://www.naturalearthdata.com/downloads/110m-cultural-vectors/110m-admin-0-countries/",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "updated the demo dataset (#808)\n\n* updated the demo dataset\r\n\r\nnew shapefiles from http://www.naturalearthdata.com/downloads/110m-cultural-vectors/110m-admin-0-countries/\r\n\r\n* script to create example dataset\r\n\r\nReads the earth data from naturalearth.com as a geojson and selects the 6 columns used to create the example datasets.\r\n\r\n* changed shapefile source\r\n\r\nadded the .zip file from naturalearth.com with version 4.1.0 shapefiles. Also added a line that changes column names to lowercase to match the example dataset\r\n\r\n* removed .zip shapefile\r\n\r\nI wasn't sure if I should include the .zip or not. It's removed now. Thank you for clarifying.\r\n\r\n* added module docstring\r\n\r\n* Make small revisions to demo dataset creation file"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d839ac254a19ac29e33d",
    "number": 807,
    "body": "Working with some rather brightly colored labelled data, I noticed that the legend styling can be very visually discordant for some colormaps. \r\n![2018-08-24-101118_1347x1677_scrot](https://user-images.githubusercontent.com/2250995/44576280-0f5cdb00-a786-11e8-802b-2e520452e6bc.png)\r\n\r\nThis errs in the same direction as the other cartography, using no boundaries on patches by default:\r\n![2018-08-24-101512_1491x1484_scrot](https://user-images.githubusercontent.com/2250995/44576510-aa55b500-a786-11e8-822c-f957e03f52b7.png)\r\n\r\nIf there's anything else we'd like to see from legend symbology here, I'm very OK with keeping this open and adding that functionality (@lwasser #735), so long as it's agreed. \r\n\r\nFor instance, we could align `geom_types` and `categories` and check during the`(value,cat)` loop at line 497 if `cat` is all of one geometry type. If it is, we could set the marker style intelligently based that type (e.g. polygons get `marker='s'`, points get `marker='o'`, and lines get `marker='-'` or something via `markeredgewidth`).",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "VIS: remove marker edge from legend"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d83aac254a19ac29e33e",
    "number": 802,
    "body": "First attempt to fix [issue#801](https://github.com/geopandas/geopandas/issues/801).\r\n\r\nI'm not sure that the test is valid, now the method accept the crs parameter and check that the original crs is equal to the read one. To pass the test I had to add these two lines:\r\n\r\n```python\r\n        df.crs[\"x_0\"] = int(df.crs[\"x_0\"])\r\n        df.crs['wktext'] = True\r\n```\r\nOtherwise the two dictionary are different as highlight by `pytest`:\r\n\r\n```diff\r\n>       assert self.df.crs == df.crs\r\nE       AssertionError: assert {'datum': 'NA...33333333, ...} == {'datum': 'NAD...33333333, ...}\r\nE         Common items:\r\nE         {'datum': 'NAD83',\r\nE          'lat_0': 40.16666666666666,\r\nE          'lat_1': 40.66666666666666,\r\nE          'lat_2': 41.03333333333333,\r\nE          'lon_0': -74,\r\nE          'no_defs': True,\r\nE          'proj': 'lcc',\r\nE          'units': 'us-ft',\r\nE          'y_0': 0}\r\nE         Differing items:\r\nE         {'x_0': 300000} != {'x_0': 300000.0000000001}\r\nE         Left contains more items:\r\nE         {'wktext': True}\r\nE         Full diff:\r\nE         {'datum': 'NAD83',\r\nE         'lat_0': 40.16666666666666,\r\nE         'lat_1': 40.66666666666666,\r\nE         'lat_2': 41.03333333333333,\r\nE         'lon_0': -74,\r\nE         'no_defs': True,\r\nE         'proj': 'lcc',\r\nE         'units': 'us-ft',\r\nE         +  'x_0': 300000.0000000001,\r\nE         -  'wktext': True,\r\nE         -  'x_0': 300000,\r\nE         'y_0': 0}\r\n```\r\nDo you think that with the two lines above the test is cheating or do you think it is correct?",
    "head_branch": "issue801",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: allow explicit CRS setting in to_file (#802)\n\n* Fix issue#801: add crs parameter and docstring\r\n\r\n* Add test for issue#801\r\n\r\n* update for pyproj.CRS\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d83bac254a19ac29e33f",
    "number": 800,
    "body": "This PR addresses #799 ",
    "head_branch": "correct-overlay",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Correct overlay empty intersection (#800)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d83bac254a19ac29e340",
    "number": 796,
    "body": "All tests are currently failing due to installation problems with conda-forge (see also https://github.com/conda-forge/geopandas-feedstock/pull/43#issuecomment-412686051). \r\n\r\nThis PR will not solve this for the conda-forge builds, but does correct the mixing of conda-forge and defaults (I added a channel flag and added the channel if it was specified, but then hard-coded the use of conda-forge for the first install command). \r\nNow we explicitly run some builds with conda-forge channel added, and the others without conda-forge",
    "head_branch": "travis-conda-forge",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: fix usage of conda-forge in travis.yml (#796)\n\n Now we explicitly run some builds with conda-forge channel added, and the others without conda-forge"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d83cac254a19ac29e341",
    "number": 795,
    "body": "@jorisvandenbossche this will ensure that the license is packaged with the source.",
    "head_branch": "add_license",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Ensure to package license file (#795)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d83dac254a19ac29e342",
    "number": 789,
    "body": "I realized that `sjoin` wasn't using `base.sindex` which meant that new spatial indexes were being generated every time. Now pre-built spatial indexes can be re-used!\r\n\r\n~~Defaulted to using the left dataframe's sindex if neither already have one, with the thought that (at least in my use cases) the left dataframe is more likely to be re-used later.~~ If neither dataframe already has a spatial index, the shorter dataframe's spatial index is generated and used. \r\n\r\nThe only drawback is that this modifies the original dataframes (adds the spatial index), but only using a property. Call 'heresy!' if you don't like this.\r\n\r\nNote that this did not appear to need new tests, but please tell me if I am wrong there.\r\n\r\nHere's a quick script to demonstrate the improvement:\r\n```python\r\nimport geopandas as gpd\r\nimport pandas as pd\r\nfrom shapely.geometry import Point, Polygon\r\nimport timeit\r\n\r\n# 100 circles on a diagonal\r\ndf1 = gpd.GeoDataFrame(geometry=[Point(x, x).buffer(45) for x in range(0, 10000, 100)], crs={'init': '3395'})\r\n# 2 squares\r\ndf2 = gpd.GeoDataFrame(geometry=[Polygon([(0, 0), (5000, 0), (5000, 5000), (0, 5000)]),\r\n                                 Polygon([(9000, 9000), (10000, 9000), (10000, 10000), (9000, 10000)])],\r\n                       crs={'init': '3395'})\r\n\r\ndf3 = gpd.sjoin(df1, df2)\r\n\r\n# insane mode!!\r\ndf4 = pd.concat([df1 for i in range(0,200)])\r\n\r\nstart_time = timeit.default_timer()\r\ndf5 = gpd.sjoin(df4, df2)\r\nelapsed = timeit.default_timer() - start_time\r\nprint(\"first run: {:0.2f}\".format(elapsed))\r\n\r\nstart_time = timeit.default_timer()\r\ndf5 = gpd.sjoin(df4, df2)\r\nelapsed = timeit.default_timer() - start_time\r\nprint(\"second run: {:0.2f}\".format(elapsed))\r\n\r\nstart_time = timeit.default_timer()\r\ndf5 = gpd.sjoin(df4, df2)\r\nelapsed = timeit.default_timer() - start_time\r\nprint(\"third run: {:0.2f}\".format(elapsed))\r\n```",
    "head_branch": "sjoin_sindex",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "PERF: Repeated sjoins using the same dataframes re-use spatial indexes (#789)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d83eac254a19ac29e343",
    "number": 786,
    "body": "I think GeoPandas needs a logo, so I drew one:\r\n\r\n![image](https://user-images.githubusercontent.com/41756119/43279837-c88c20b8-90d4-11e8-8b4e-9fd26cb1aabe.png)\r\n\r\nIt's all hand drawn, and all rights to it are hereby assigned to the GeoPandas maintainers.  logo.svg is the master source, but currently only the PNG-exported version is used.",
    "head_branch": "logo",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d83fac254a19ac29e344",
    "number": 785,
    "body": "Resolves #698.\r\n\r\nAdded check in `_flatten_multi_geoms` to see if there are multi-geometries and whether the flattening is needed.",
    "head_branch": "patch-4",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "PERF: added check for multi-geometries (#785)\n\nThis PR is related to Issue #698.\r\n\r\nAdded check in `_flatten_multi_geoms` to see if there are multi-geometries and whether the flattening is needed."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d840ac254a19ac29e345",
    "number": 784,
    "body": "",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Update CONTRIBUTING.md (#784)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d840ac254a19ac29e346",
    "number": 783,
    "body": "Corrected mapping scheme options from percentiles to fisher_jenks.\r\n\"Options are 'Equal_interval', 'Quantiles', 'Fisher_Jenks'\"\r\nSee: https://github.com/geopandas/geopandas/blob/master/geopandas/plotting.py#L522",
    "head_branch": "patch-2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Corrected Mapping Tools scheme options (#783)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d841ac254a19ac29e347",
    "number": 782,
    "body": "Correcting the changelog date for Release 0.4.0 from 2017 to 2018",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Correcting the changelog date for Release 0.4.0 from 2017 to 2018 (#782)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d842ac254a19ac29e348",
    "number": 781,
    "body": "This PR allow to use a `np.ndarray` or a `pd.Series` as `distance` argument for the `buffer` and `interpolate` methods of GeoSeries and should closes #767 if merged.",
    "head_branch": "ENH_767",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: allow to specify varying distances for buffer and interpolate (#781)\n\n* Allow to specify varying distances for buffer and interpolate\r\n\r\n* Minor fixes in interpolate method and its test\r\n\r\n* Verify geoseries and distance indexes are the same\r\n\r\n* Comparison of GeoSerie and distance indexes"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d843ac254a19ac29e349",
    "number": 780,
    "body": "A minor refactoring to use generators instead of lists in built-in Python functions. Please feel free to reject this, if it's unnecessary. ",
    "head_branch": "refcln",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CLN: Use generators inplace of lists (#780)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d844ac254a19ac29e34a",
    "number": 778,
    "body": "",
    "head_branch": "doc-install",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: update install instructions (#778)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d844ac254a19ac29e34b",
    "number": 777,
    "body": "After further investigation, it seems like the current `read_postgis`\r\ncommand would not support a spatialite database in the wild (as compared\r\nto the one I'd created using ogr2ogr that had made me optimistic that we\r\nhad spatialite read capabilities in place). So long as it is not likely\r\nto work for more use cases, let's leave it as `read_postgis`, since that\r\nis all we think it is likely able to do.",
    "head_branch": "remove-sql-alias",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Remove read_sql alias (#777)\n\nAfter further investigation, it seems like the current `read_postgis`\r\ncommand would not support a spatialite database in the wild (as compared\r\nto the one I'd created using ogr2ogr that had made me optimistic that we\r\nhad spatialite read capabilities in place). So long as it is not likely\r\nto work for more use cases, let's leave it as `read_postgis`, since that\r\nis all we think it is likely able to do."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d845ac254a19ac29e34c",
    "number": 775,
    "body": "",
    "head_branch": "doc-geoplot-dep",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add geoplot to doc environment (#775)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d846ac254a19ac29e34d",
    "number": 774,
    "body": "Closes https://github.com/geopandas/geopandas/issues/716",
    "head_branch": "doc-imports",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: change imports to use geopandas (#774)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d847ac254a19ac29e34e",
    "number": 773,
    "body": "Structured the sidebar with some subtitles + removed the outdated about page",
    "head_branch": "doc-sidebar",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      " DOC: update doc sidebar + remove about (#773)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d847ac254a19ac29e34f",
    "number": 772,
    "body": "This should fix the warnings about concat sorting for pandas >= 0.23",
    "head_branch": "overlay-warnings",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix warnings with overlay and pandas >= 0.23 (#772)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d848ac254a19ac29e350",
    "number": 771,
    "body": "@jdmcbr I also had some updates, merged it with your update",
    "head_branch": "update-changelog",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: update changelog (#771)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d849ac254a19ac29e351",
    "number": 770,
    "body": "Closes https://github.com/geopandas/geopandas/issues/768\r\n\r\n1) Check if color and column are defined. Original assumption was\r\nthat both are strings. This is no longer the case, now we check if\r\nthey are not None (if they exist).\r\n\r\n2) The docstring was updated to state that now column accepts np.array or\r\npd.Series\r\n\r\n3) Added conditional statement to check if:\r\n\ta) The passed column is a pd.Series or a np.array\r\n\tb) The passed column has the same number of elements as df has rows\r\n\r\n4) Added instruction to assign the column to variable values:\r\n\tif it is an array (pd.Series or np.array)\r\n\tor if it is a column in the df",
    "head_branch": "ENH_768",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: pass array/series of values to column argument in plot (#770)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d84aac254a19ac29e352",
    "number": 769,
    "body": "",
    "head_branch": "travis-conda",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: use conda for travis (#769)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d84bac254a19ac29e353",
    "number": 765,
    "body": "@jorisvandenbossche @slumnitz Does this seem sufficient to resolve #764? It does seem reasonable that a downstream test of geopandas install from the test requirements file, in which descartes is included.",
    "head_branch": "764",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add error message if descartes import missing (#765)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d84bac254a19ac29e354",
    "number": 762,
    "body": "Closes #731\r\n\r\nThis makes sure that the key dtype in empty spatial joins is `float`, addressing but #731. ",
    "head_branch": "empty-sjoin",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix empty sjoin (#762)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d84cac254a19ac29e355",
    "number": 761,
    "body": "This is the reboot of #440, which I seem to have screwed up in deleting my original fork and then recloning. I preserved the very messy commit history in this PR for posterity. :smile: \r\n\r\nThis gets writes to postgis databases working, including CRS setting in the call. There's still the question of going the GeoAlchemy2 route (#457), but I personally remain disinclined to add an extra dependency and a lot of extra code to maintain. In my latest commits, I did adapt a couple of pieces of that PR that were useful here too, `get_srid`, and, not consciously, `connect_sqlalchemy`, which originally I had named oppositely and placed differently. \r\n\r\nThere's also the question of making the base method name `to_sql` and creating `to_postgis` aliases, which probably makes sense to do.",
    "head_branch": "440",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d84dac254a19ac29e356",
    "number": 759,
    "body": "",
    "head_branch": "fix-testing",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      " TST: fix the tests for >= python 3.6  (#759)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d84eac254a19ac29e357",
    "number": 747,
    "body": "Implements `.set_crs()` for GeoSeries and GeoDataFrame as described in #245 .\r\n\r\n(Also: This is my first time using git / using Github / contributing to an open source project. I think I followed the instructions correctly, but I'm not sure---it looks as if there's a commit that shows up twice?)",
    "head_branch": "issue-245-set-crs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Setting the CRS of naive geometries (#747)\n\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d84fac254a19ac29e358",
    "number": 745,
    "body": "Add encoding argument to the method to_file. It adds better visibility to avoid encoding problem when writing geojson from geopandas dataframe for example.",
    "head_branch": "mauryaland-patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d84fac254a19ac29e359",
    "number": 742,
    "body": "test",
    "head_branch": "patch-2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d850ac254a19ac29e35a",
    "number": 741,
    "body": "Allows for a dictionary of keyword arguments to be passed when creating the colorbar for a plot.",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d851ac254a19ac29e35b",
    "number": 740,
    "body": "This would allow a user to pass a dictionary of keyword arguments to the .plot() method for a DataFrame that would be used when creating the colorbar.",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d852ac254a19ac29e35c",
    "number": 734,
    "body": "",
    "head_branch": "rutgerhofste-patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d853ac254a19ac29e35d",
    "number": 733,
    "body": "This is a followup PR to \r\nhttps://github.com/geopandas/geopandas/issues/732\r\n\r\nI am updating the documentation for gpd.sjoin() to be a bit more explicit. \r\n\r\nPlease bare with me as this is my first actual contribution to an OS repo (i've submitted issues but never contributed content). I've directly edited the `.rst` files and welcome comments wherever you'd like changes. \r\n\r\nOnce i understand how to best suggest changes I will update other parts of the docs as i create lessons for my python class! :) ",
    "head_branch": "sjoin-doc",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC updating spatial merge docs with argument details (#733)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d853ac254a19ac29e35e",
    "number": 728,
    "body": "Fixes #196 \r\n\r\nRan into the issue where an export from geopandas with a datetime field fails with a ValueError (also see https://gis.stackexchange.com/questions/281895/changing-shapefiles-field-type-using-fiona/281941#281941). The numpy dtype object has a name attribute, and for datetime objects the data type will be `datetime64[ns]` (or some other frequency than `ns`). This fix grabs the start of this string and returns the string `datetime` as per the fiona schema.",
    "head_branch": "datetime_export_fix",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: support datetime in to_file (#728)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d854ac254a19ac29e35f",
    "number": 723,
    "body": "",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix incorrect parameters in translate (#723)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d855ac254a19ac29e360",
    "number": 719,
    "body": "In #405 I proposed adding `geoplot` to `geopandas` as its visualization module. After some thought and some growth, my opinion now is that `geoplot` is better staying separate from the `geopandas` plotting functions. This mirrors the relationship that `seaborn` has with `pandas`: simple data tools are in `pandas`, more complex tools are in `seaborn`.\r\n\r\n@jorisvandenbossche reached out a month ago to rekindle this issue. I've just released a new version of `geoplot`, after a long absence from the code-base, so this is an ideal time to work on the minimum of we came up with:\r\n\r\n> I would personally do: 1) adding an example to the gallery using some of the geoplot plotting types, and 2) mentioning this on the user guide page about plotting (http://geopandas.readthedocs.io/en/latest/mapping.html). \r\nIf you would have time for this, that would be great, but I would also already open some issues to track this.\r\n\r\nFor now this is a null commit just intended to get the ball rolling, because I have to ask @choldgraf, can you sketch out how the Sphinx gallery work? I'm scratching my head a bit as to the connections between the Sphinx gallery code and the resultant documentation pages in #463.\r\n\r\n(would be nice to add a few words on the matter to `CONTRIBUTING.md` as well BTW)",
    "head_branch": "geoplot-docs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Mix geoplot into the geopandas docs (#719)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d856ac254a19ac29e361",
    "number": 718,
    "body": "This is one way to address #715 \r\n\r\nAnother way is to push this on users, to suggest that every time a multi-axis figure is built using:\r\n\r\n`f,ax = plt.subplots(2,2,figsize=(10,10), subplot_kw=dict(aspect='equal'))`\r\n\r\nIf it's better to not set `aspect=equal` by default, then maybe just showing the way to set all axes in a subplot to equal aspect in docs would help it be recognized.",
    "head_branch": "aspects",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Plotting: always set equal aspect on active axis (#718)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d857ac254a19ac29e362",
    "number": 717,
    "body": "",
    "head_branch": "example-contextily",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add example to add basemap with contextily (#717)\n\n* DOC: add example to add basemap with contextily\r\n\r\n* add contextily to readthedocs environment"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d857ac254a19ac29e363",
    "number": 709,
    "body": "Mimicked the existing `serialize` function, but writing to an object array instead of a single bytearray.\r\n",
    "head_branch": "cython-to-wkb",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add vectorized to_wkb function to convert to object arrays of bytes  (#709)"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d858ac254a19ac29e364",
    "number": 708,
    "body": "Clean-up of the travis yaml file. \r\n(could maybe even more aggressively remove more old versions)",
    "head_branch": "travis-matrix-update",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST/DEP: remove support for pandas <0.19 (#708)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d859ac254a19ac29e365",
    "number": 707,
    "body": "This moves the testing functionality from `geopandas.tests.util` to `geopandas.testing`, as this is generally useful functionality. \r\nAnd also adds a `assert_geodataframe_equal` method that uses `assert_geoseries_equal` for the geometry column, to ensure correct comparison of that column.",
    "head_branch": "testing-module",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      " Add assert_geodataframe_equal function + expose testing functions in geopandas.testing module (#707)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d85aac254a19ac29e366",
    "number": 704,
    "body": "This PR is related to https://github.com/geopandas/geopandas/issues/702. \r\n\r\nThe PR changes the behavior of colobars in Geopandas. With this PR, the colorbars have the same height as the map area. \r\n\r\nThe following example demonstrates the change. The used dataset can be downloaded from [https://opendata.swiss/en/dataset/swissboundaries3d-gemeindegrenzen](url).\r\n\r\nCode:\r\n\r\n\r\n    import geopandas as gpd\r\n    import matplotlib.pyplot as plt\r\n    df = gpd.read_file(r\"swissBOUNDARIES3D_1_3_TLM_HOHEITSGEBIET.shp\")\r\n    print(df)\r\n\r\n    df.plot(column='GEM_FLAECH',\r\n            linewidth=0.1,\r\n            edgecolor='face',\r\n            legend=True)\r\n\r\n    plt.tight_layout()\r\n\r\n    plt.savefig('test.png')\r\n\r\nWith the master branch, the results looks like this:\r\n![test_org](https://user-images.githubusercontent.com/259530/38356721-c2308680-38c0-11e8-9a49-bb67a33a7e0b.png)\r\n\r\nWith the PR like this:\r\n\r\n![test_mod](https://user-images.githubusercontent.com/259530/38356732-cd3c4ed8-38c0-11e8-8b6e-a00fad862f4b.png)\r\n\r\nThe PR is not ready to be included.  Further changes might be necessary regarding the hardcoded \"5%\" size parameter.  For example the ones proposed in the answer from Matthias in https://stackoverflow.com/questions/18195758/set-matplotlib-colorbar-size-to-match-graph/33505522#33505522. ",
    "head_branch": "colorbar_height",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d85bac254a19ac29e367",
    "number": 701,
    "body": "First pass to implement the extension array interface. All interface tests are passing except the ones that rely on sorting. \r\nStill need to better integrate with block code to support released version of pandas as well.\r\n\r\nSome other tests are still failing: https://github.com/pandas-dev/pandas/issues/20576, https://github.com/pandas-dev/pandas/issues/20578",
    "head_branch": "extension-array",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d85cac254a19ac29e368",
    "number": 700,
    "body": "Currently the `cast=True` in cython leads to silently wrong data (`points_from_xy` requires float64 data):\r\n\r\n```\r\nIn [12]: a = geopandas.array.points_from_xy(np.array([0, 1]), np.array([0, 1]))\r\n\r\nIn [13]: [p.wkt for p in a]\r\nOut[13]: ['POINT (0 0)', 'POINT (4.940656458412465e-324 4.940656458412465e-324)']\r\n\r\nIn [14]: a = geopandas.array.points_from_xy(np.array([0, 1], dtype='float64'), np.array([0, 1], dtype='float64'))\r\n\r\nIn [16]: [p.wkt for p in a]\r\nOut[16]: ['POINT (0 0)', 'POINT (1 1)']\r\n```",
    "head_branch": "fix-points-xy",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix points_from_xy for non-float data (#700)"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d85cac254a19ac29e369",
    "number": 699,
    "body": "New round of cherry-picks of commits to master since last round (#642)\r\n\r\n+ some extra commits to fix new failures",
    "head_branch": "cython-update-from-master3",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix construction of GeoDataFrame with only geometry"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d85dac254a19ac29e36a",
    "number": 693,
    "body": "I noticed some differences between the docs and the source code. By default scheme is ``None`` and ``equal_interval`` mustn't end with an s otherwise an exception is raised. I also changed the link because the current URL resolves to a 404 error.",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Adjust the scheme option docs to reflect the source code (#693)\n\nI noticed some differences between the docs and the source code. By default scheme is ``None`` and ``equal_interval`` mustn't end with an s otherwise an exception is raised. I also changed the link because the current URL resolves to a 404 error."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d85eac254a19ac29e36b",
    "number": 692,
    "body": "Should fix the failing tests on pandas master (xref https://github.com/pandas-dev/pandas/issues/20391)",
    "head_branch": "bug-series-scalar",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix GeoSeries construction from scalar on pandas master (#692)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d85fac254a19ac29e36c",
    "number": 690,
    "body": "First attempt to address #689 \r\n\r\nCloses #689  \r\n\r\n",
    "head_branch": "simple_examples",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Building a GeoDataFrame from DataFrame (#690)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d860ac254a19ac29e36d",
    "number": 686,
    "body": "Not doing so resulted in incorrect dtypes when the\r\nresult was empty since numpy could not automatically\r\ndetermine the dtype. This then had the effect of\r\nindexing dropping columns unexpectedly.\r\nCloses #685",
    "head_branch": "force_bool_dtype",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Explicitly set the dtype for geometry operations (#686)\n\nNot doing so resulted in incorrect dtypes when the\r\nresult was empty since numpy could not automatically\r\ndetermine the dtype. This then had the effect of\r\nindexing dropping columns unexpectedly.\r\nCloses #685"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d860ac254a19ac29e36e",
    "number": 683,
    "body": "Resolves #664.\r\n\r\nI think this looks right, mostly just re-used the methods & tests for plotting MultiPolygons.",
    "head_branch": "plot-multipoints",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: add support for plotting MultiPoints (#683)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d861ac254a19ac29e36f",
    "number": 682,
    "body": "As of https://github.com/matplotlib/matplotlib/commit/c36902c19622aae8102e12d6ffb4b65f84211465#diff-2eeaed663bd0d25b7e608891384b7298, matplotlib master no longer supports python 2.7. Given the impending deprecation plans for 2.7 across the scientific python stack, it seems reasonable to drop the python2.7 build check for pandas/matplotlib master. Currently, the travis build check is failing everywhere because matplotlib master cannot install with python 2.7.",
    "head_branch": "py2-build",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "BLD: remove matplotlib master from 2.7 (#682)\n\nMatplotlib master no longer supports python 2"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d862ac254a19ac29e370",
    "number": 678,
    "body": "Gets full/explicit CRS from EPSG code provided. This provides useful logic for #245 when used like `gdf.to_crs(crs=explicit_crs_from_epsg(other_gdf.crs))`. Additionally this could provide a 90% solution for not performing `to_crs` unnecessarily by checking `if explicit_crs_from_epsg(gdf.crs) == explicit_crs_from_epsg(other_gdf.crs)` prior to running `to_crs` could then be used as part of a resolving #65.\r\n\r\nNote, I didn't know where this should go (in code or in the docs) so I created the file you see, however I leave it at the discretion of the maintainers as to where it best fits and what documentation it needs (and I'm happy to revise once given direction).",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: get explicit CRS from EPSG code (#678)\n\n* added method for getting long-definition of epsg codes\r\n\r\n* more testing for explicit_crs_from_epsg\r\n\r\n* more testing for explicit_crs_from_epsg\r\n\r\n* added new function `epsg_from_crs`"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d863ac254a19ac29e371",
    "number": 675,
    "body": "It was not clear what the integer in the multi-index represented",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: clarify MultiIndex of explode() return value (#675)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d864ac254a19ac29e372",
    "number": 674,
    "body": "",
    "head_branch": "doc-distance",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: remove ambiguous 'minimum' in distance docstring (#674)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d864ac254a19ac29e373",
    "number": 671,
    "body": "Related to #667 .\r\n@jorisvandenbossche not sure what the desired behaviour for the resulting GeoDataFrame index is? Left it as suggested in the example, could also be fully reset?\r\n",
    "head_branch": "feature/explode_dataframe",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: explode() method for geodataframe (#671)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d865ac254a19ac29e374",
    "number": 668,
    "body": "",
    "head_branch": "move-block",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Move block construction logic to block.py (#668)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d866ac254a19ac29e375",
    "number": 663,
    "body": "Closes #657 ",
    "head_branch": "empty_df_error",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ERR: Better error message for writing empty dataframe to file (#663)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d867ac254a19ac29e376",
    "number": 662,
    "body": "",
    "head_branch": "refactor_array",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "REF: split cython code in vectorized.pyx and array.py (#662)"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d868ac254a19ac29e377",
    "number": 661,
    "body": "The assert_seq_equal test was not used, and was written in such a\r\nway that it would never fail.",
    "head_branch": "remove-unused-test",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG/CLN: remove unused and broken test utility (#661)\n\nThe assert_seq_equal test was not used, and was written in such a\r\nway that it would never fail."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d869ac254a19ac29e378",
    "number": 659,
    "body": "@jorisvandenbossche started work on test_geocode.py, just wondering how you think the best way to deal with the  ForwardMock and ReverseMock classes is with regards to pytest?",
    "head_branch": "test_geocode",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: test_geocode.py pytest conversion (#659)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d869ac254a19ac29e379",
    "number": 656,
    "body": "Given the methods for plotting points, polygons, and linestrings only work with `GeoSeries`, which have their own `plot` method that internally calls those as appropriate, it is hard to see a use case for an external calls to those separate plotting methods. And, so long as they are really intended only for internal consumption, I think prepending function names with underscores is a good move to indicate that intent more clearly.\r\n\r\nThis PR is at the conversation starter level now though; probably we ought to include a deprecation warning for the old method names without underscores, just in case someone is using them.\r\n\r\nCloses #635.",
    "head_branch": "issue635",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "API: Suggest privacy for internal plotting methods (#656)\n\n* API: Suggest privacy for internal plotting methods\r\n\r\n* Add deprecation warning to plot functions\r\n\r\n* tests\r\n\r\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d86aac254a19ac29e37a",
    "number": 655,
    "body": "Vectorized function to create GeometryArray from array of WKB bytes objects. Can add a `from_wkt` as well (and maybe also the `to_` versions).\r\n\r\n",
    "head_branch": "from_wkb",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add vectorized from_wkb / from_wkt functions (#655)"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d86bac254a19ac29e37b",
    "number": 654,
    "body": "Removed testing class in `test_dissolve.py`, using fixtures instead.",
    "head_branch": "test_dissolve",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Fixtures and test clean up for test_dissolve.py (#654)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d86cac254a19ac29e37c",
    "number": 653,
    "body": "Closes https://github.com/geopandas/geopandas/issues/649",
    "head_branch": "read-empty",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: read empty files correctly (#653)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d86dac254a19ac29e37d",
    "number": 652,
    "body": "In so doing, add the has_z attribute to series. The check in determining\r\nthe geometry type is pretty simplistic. Given how fiona is thinking\r\nabout geometry types now (https://github.com/Toblerity/Fiona/issues/465)\r\nI didn't see a clearly better way.\r\n\r\nCloses #612.",
    "head_branch": "issue612",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Save z dimension in file writes (#652)\n\n* BUG: Save z dimension in file writes\r\n\r\nIn so doing, add the has_z attribute to series. The check in determining\r\nthe geometry type is pretty simplistic. Given how fiona is thinking\r\nabout geometry types now (https://github.com/Toblerity/Fiona/issues/465)\r\nI didn't see a clearly better way.\r\n\r\n* Add test for a 3d polygon, too\r\n\r\n* TST: Add has_z test\r\n\r\n* TST: Mix 2D/3D polygons in file writes\r\n\r\nRemoved the pandas assert_frame_equal test because it will no longer\r\npass anywhere due to the 2D/3D handling, which doesn't look like\r\nsomething there's any way around without changes to fiona (or possibly\r\nGDAL?)."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d86dac254a19ac29e37e",
    "number": 650,
    "body": "Fixes #647 ",
    "head_branch": "remove-descartes-install-dependency",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d86eac254a19ac29e37f",
    "number": 648,
    "body": "The descartes import in plotting is hidden, so it is not a hard\r\ndependency, and should not be required for installation.\r\n\r\nCloses #647.",
    "head_branch": "issue647",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Remove descartes from install requirements (#648)\n\n* Remove descartes from install requirements\r\n\r\nThe descartes import in plotting is hidden, so it is not a hard\r\ndependency, and should not be required for installation.\r\n\r\n* Update install reqs in README.md"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d86fac254a19ac29e380",
    "number": 646,
    "body": "Parametrized test for test_dataset.py\r\nRelated to: #644 ",
    "head_branch": "feature/pytest-parametrize",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: parametrized test_datasets.py tests (#646)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d870ac254a19ac29e381",
    "number": 645,
    "body": "in theory:\r\n-  added a link to formats supported by gdal for `read_file` - because `fiona` does not mention topojson.\r\n- added `to_topojson` function that requires @calvinmetcalf's topojson.py to store a topojson out of polygonal geodataframe.\r\n\r\nin practice - messed with git a little :-/",
    "head_branch": "topojson",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d871ac254a19ac29e382",
    "number": 643,
    "body": "Fiona doesn't support writing to files with boolean type. There was some\r\ndiscussion of converting to int and writing to file anyway, but at a\r\nminimum seems useful to raise a clearer message about the problem.\r\n\r\nCloses #437.",
    "head_branch": "issue437",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Raise ValueError using to_file with bool column (#643)\n\n* Raise ValueError using to_file with bool column\r\n\r\nFiona doesn't support writing to files with boolean type. There was some\r\ndiscussion of converting to int and writing to file anyway, but at a\r\nminimum seems useful to raise a clearer message about the problem.\r\n\r\n* Improve warning with to_file on bool column"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d872ac254a19ac29e383",
    "number": 642,
    "body": "New round of cherry-picks of commits to master since last round (https://github.com/geopandas/geopandas/pull/587)",
    "head_branch": "cython-update-from-master2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Update .gitignore (#628)\n\n(cherry picked from commit 8cad410ebdae4303c70ecc09852e1989f296afd5)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d872ac254a19ac29e384",
    "number": 641,
    "body": "Apparently by having defaults as the first channel, problems are fixed at the moment (you don't get a downgrade of a lot of packages in the second conda install step invoked by readthedocs)",
    "head_branch": "readthedocs_test",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "DOC: fix readthedocs problems with conda (#641)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d873ac254a19ac29e385",
    "number": 639,
    "body": "This essentially copies relevant components of the fiona travis build\r\ninstructions, in an effort to test/reproduce #637.\r\n\r\nI'll be surprised if I got this right on the first attempt.",
    "head_branch": "test-against-gdal",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d874ac254a19ac29e386",
    "number": 638,
    "body": "Looking to test out issue raised in #637.",
    "head_branch": "sjoin-naturalearth",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Add test of naturalearth spatial join (#638)\n\nLooking to test out issue raised in #637."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d875ac254a19ac29e387",
    "number": 633,
    "body": "Can optionally set the size of points in a scatter plot of point\r\ngeometries to be specified by the value of a column in the frame. Note\r\nthat it does not perform any normalization at present, so very small or\r\nvery large values in the column specified lead to less than desirable\r\nresults. Also no checks on user, so if a user specifies a column with a\r\nnon numeric type, it does throw a slightly less than clear error.\r\n\r\nI can see addressing either of those potential shortcomings as useful. Though\r\nunlike the `column`/`colormap` case, there isn't really a natural range by which\r\n`markersize` values should be normalized, and adding options for that seems\r\ntoo much. \r\n\r\nCloses #624. cc @h4k1m0u ",
    "head_branch": "plot-markersize",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Set point markersize with column values (#633)\n\nCan optionally set the size of points in a scatter plot of point\r\ngeometries to be specified by the value of a column in the frame. Note\r\nthat it does not perform any normalization at present, so very small or\r\nvery large values in the column specified lead to less than desirable\r\nresults. Also no checks on user, so if a user specifies a column with a\r\nnon numeric type, it does throw a slightly less than clear error."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d876ac254a19ac29e388",
    "number": 631,
    "body": "This PR:\r\n1. Adds a MyBinder icon to run the example notebooks on mybinder.org (part of JupyterHub)\r\n2. Fixes the example Jupyter notebooks:\r\n    - Standardizes the way geopandas is invoked, specifically, `import geopandas as gpd`\r\n    - Loads the `nybb.zip` dataset in the new manner, see #384 \r\n    - Fixes a TODO in `spatial-joins.ipynb`",
    "head_branch": "fix-examples",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add link to JupyterHub's MyBinder, and fix example notebooks (#631)\n\n* fixed nybb\r\n\r\n* rearrange chloropleths example\r\n\r\n* added badge to MyBinder\r\n\r\n* extra formatting on README\r\n\r\n* add extra info in chrolopleths.ipynb\r\n\r\n* Update choropleths example"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d876ac254a19ac29e389",
    "number": 628,
    "body": "Wanted to add `.asv`, and at once updated it to include much of the default python gitignore from github",
    "head_branch": "update-gitignore",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Update .gitignore (#628)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d877ac254a19ac29e38a",
    "number": 627,
    "body": "As currently implemented, this is relying on string parsing from the sql\r\nstring passed in by the user. An API change could achieve this without\r\nthe string parsing. Specifically thinking that since a `geom_col` is already\r\nrequired, it would be easy to form a valid sql query if the user also passed in\r\na table name. As is, this looked like a string replace that is relatively unlikely\r\nto cause weird issues, but still doesn't feel great.\r\n\r\nAside from questions of whether this is the right approach at all, I'm wondering\r\nwhether the `crs` behavior should be modified. Right now, this would only set `crs`\r\nfrom the SRID if the user does not specify a `crs` in the `read_postgis` call.\r\n\r\ncc @adamboche @kuanb @emiliom \r\n",
    "head_branch": "read-srid",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: get SRID from postgis read (#627)\n\n* ENH: get SRID from postgis read\r\n\r\nAs currently implemented, this is relying on string parsing from the sql\r\nstring passed in by the user. An API change could achieve this without\r\nthe string parsing. Or something else I'm not seeing?\r\n\r\n* Fix polygons -> geometries in comment\r\n\r\n* Remove brittle SRID postgis extraction\r\n\r\nChange previous test to xfail, add test of \"select geom as the_geom\".\r\n\r\n* Use GEOSGetSRID to return SRID from postgis\r\n\r\nPer @jorisvandenbossche suggestion. Also simplifies wkb loading using\r\nthe shapely.skb.loads argument hex=True. Add the argument hex_encoded to\r\nread_postgis so that non hex geometries might also be read.\r\n\r\n* Un-xfail test for SRID read\r\n\r\nWith SRID read from geodatabase support, can now set CRS automatically\r\nso that user does not need to.\r\n\r\n* Remove check for unique SRID in sql read\r\n\r\nAssume the CRS for frame from SRID in first geometry.\r\n\r\n* Add test of sqlite database read\r\n\r\n* Add type check in sql geometry read\r\n\r\nI think this both addresses python2 failures for sqlite and WKBElement\r\nreads.\r\n\r\n* Rename read_postgis to read_sql\r\n\r\nCreate wrappers read_postgis and read_sqlite\r\n\r\n* Add read_sqlite to __init__\r\n\r\n* Add test to create sqlite database for testing\r\n\r\nRename the function for postgis from create_db to create_postgis. This\r\npermits not shipping the sqlite table as part of the datasets.\r\n\r\n* Amend read_sql docs per Joris's comments\r\n\r\n* Remove nybb.sqlite dataset\r\n\r\n* Clean up sqlite db creation/execution\r\n\r\n* Remove explicit sqlite support\r\n\r\n* Remove read_sqlite command from __init__ too\r\n\r\n* Fix sqlite read tests\r\n\r\n* Fix failures in merge conflict resolution"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d878ac254a19ac29e38b",
    "number": 619,
    "body": "Continuing #618 ",
    "head_branch": "vc9",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BLD: enable to build for Python 2.7 on Windows (vc9) (#619)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d879ac254a19ac29e38c",
    "number": 618,
    "body": "@jorisvandenbossche I am not sure what exceptions are raised by `get_geos_config` but we could wrap that in a try/except clause and re-raise with a custom message explaining to the user that s/he can use the environment variables instead.\r\n\r\nPS: Python 2.7, vc 9, will fail due to the lack of `stdint.h` and `stdbool.h`. I'll can fix those like I did in https://github.com/conda-forge/geopandas-feedstock/commit/5c2e8e43b44c037e6ff860c08ff84205e35be5bc but in two separate commits so you can have the AppVeyor logs to go back and look.",
    "head_branch": "find_geos",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI/BLD: Find geos headers and library on Windows (#618)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d87aac254a19ac29e38d",
    "number": 617,
    "body": "Should fix #616",
    "head_branch": "appveyor",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CI: build env in one go (#617)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d87aac254a19ac29e38e",
    "number": 615,
    "body": "",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Correct spelling mistakes. (#615)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d87bac254a19ac29e38f",
    "number": 614,
    "body": "Shows the location of borough centers accessed through Google geocoding\r\nAPI, along with the boundaries in the shapefile included in geopandas.",
    "head_branch": "geocoding-doc",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Add minimal geocoding example for docs (#614)\n\nShows the location of borough centers accessed through Google geocoding\r\nAPI, along with the boundaries in the shapefile included in geopandas."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d87cac254a19ac29e390",
    "number": 613,
    "body": "Adds support for passing a GeoDataFrame in place of a bbox tuple which allows us to resolve crs mis-matches between bbox and the target file's crs.",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: accept bbox of geoseries for filtered read_file (#613)\n\n* Fix for when read_file bbox crs does not match target file crs\r\n\r\n* added tests for read_file with GeoSeries/GeoDataFrame boundary\r\n\r\n* Group related tests in test_io\r\n\r\n* Make adjustment to read_file bounding box doc"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d87dac254a19ac29e391",
    "number": 611,
    "body": "Closes https://github.com/geopandas/geopandas/issues/598\r\n\r\nAs this PR stands, it at least addresses the individual specific issue raised in #598; `geom_equals` already avoids densifying, so just need to override `__eq__` on a `GeoSeries` to use `geom_equals`. That said, it is not clear to me if there was any particular reason why this behavior was not already in place on master. I would have assumed it was, so the fact that it was not makes me wonder if I'm missing something.\r\n\r\nIf this is the right way to go, I at least need to add `__ne__` as well. I'm not sure if there's anything else of that sort that makes sense to add.",
    "head_branch": "cython-eq-geom-equals",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Override __eq__ with geom_equals for GeoSeries (#611)\n\n\r\n* Add __ne__ method for geoseries and test\r\n\r\n* Raise clearer TypeError on GeoSeries eq check"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d87eac254a19ac29e392",
    "number": 608,
    "body": "Real PITA .. (but this occurred in the concat with axis=1 PR)",
    "head_branch": "cython-fix-setitem",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fix cornercase in __setitem__ when column already exist but is non-geometry (#608)"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d87eac254a19ac29e393",
    "number": 605,
    "body": "closes #557",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "PERF: writing mutliple records at once to increase speed in GeoPackage (#605)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d87fac254a19ac29e394",
    "number": 604,
    "body": "Closes https://github.com/geopandas/geopandas/issues/602\r\n\r\nLogic: if we specify a `geometry` keyword that is not a string, drop any columns in the passed data that have the same name (the default 'geometry' or the derived geometry name if a Series is passed to `geometry`)",
    "head_branch": "cython-bug-overwrite-geometry",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: let geometry kwarg override geometry in data in GeoDataFrame constructor (#604)"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d880ac254a19ac29e395",
    "number": 600,
    "body": "@jorisvandenbossche ",
    "head_branch": "isna",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d881ac254a19ac29e396",
    "number": 597,
    "body": "Previously we called a Cython function that obtained the handle at every\r\nfunction call.  We inherited this behavior from Shapely and they\r\npresumably had some reason to do it.  We are trying this change to avoid\r\nan error around get_geos_context_handle during tests.",
    "head_branch": "get-handle-once",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Get GEOS Handle using C-API (#597)\n\nPreviously we depended on Shapely's handling of a global GEOS handle.\r\nNow we create and destroy this handle within every function call."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d882ac254a19ac29e397",
    "number": 596,
    "body": "Closes https://github.com/geopandas/geopandas/issues/528",
    "head_branch": "cython-setitem",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Do not densify geometries in __setitem__ (#596)"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d882ac254a19ac29e398",
    "number": 593,
    "body": "Simple test effectively replicating the test on a not-inplace transform.",
    "head_branch": "test-inplace-transform",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Test inplace transform on geodataframe (#593)\n\nSimple test effectively replicating the test on a not-inplace transform."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d883ac254a19ac29e399",
    "number": 592,
    "body": "",
    "head_branch": "cython-concat-axis1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Support axis=1 in the custom geopandas.concat function (#592)"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d884ac254a19ac29e39a",
    "number": 591,
    "body": "Closes #590",
    "head_branch": "cython-reindex",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: correct filling logic for GeoSeries.reindex (#591)\n\n* BUG: correct filling logic for GeoSeries.reindex\r\n\r\n* temp fix geom_equals to work on missing data"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d885ac254a19ac29e39b",
    "number": 589,
    "body": "Related to https://github.com/geopandas/geopandas/pull/587#issuecomment-337393467 (but this only fixes align to preserve the metadata, does not yet add the warning to `binary_geo`)",
    "head_branch": "align-crs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix align to preserve metadata (#589)"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d886ac254a19ac29e39c",
    "number": 587,
    "body": "New round of cherry-picks of commits to master since last round.",
    "head_branch": "cython-update-from-master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: xfail crs warning test for now"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d887ac254a19ac29e39d",
    "number": 586,
    "body": "Work in progress to allow for an easy pip based install directly from git (with or without pre-installing Cython?).\r\n\r\n``pip install --upgrade git+https://github.com/geopandas/geopandas.git@geopandas-cython``\r\n\r\nMakes it easier for people wanting to develop/try-out geopandas-cython branch!\r\n\r\nTODO ensure 'test cases' below work (and find a proper place to put those test cases):\r\n\r\n- [x] `pip install git+https://github.com/weiji14/geopandas.git@geopandas.cython`\r\n- [ ] `git clone https://github.com/weiji14/geopandas.git && git checkout geopandas-cython && pip install .`\r\n- [ ] `git clone https://github.com/weiji14/geopandas.git && git checkout geopandas-cython && python setup.py build_ext --inplace --with-cython`\r\n\r\n\r\nSome references:\r\n- https://stackoverflow.com/questions/24923003/organizing-a-package-with-cython\r\n- https://github.com/pandas-dev/pandas/blob/f18378dc5af59c137e3579ff83806296c2222321/setup.py#L79\r\n- https://github.com/h5py/h5py/blob/28e1e2bb68df60a3f3a42177dd2e7b3a0edfcc6e/setup.py#L35\r\n- https://groups.google.com/forum/?_escaped_fragment_=topic/cython-users/n5UpJmWUzag#!topic/cython-users/n5UpJmWUzag\r\n- https://docs.cython.org/en/latest/src/reference/compilation.html#compiling-with-distutils",
    "head_branch": "geopandas-cython",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d887ac254a19ac29e39e",
    "number": 585,
    "body": "Put both under [tools:pytest] section to silence warnings.",
    "head_branch": "pytest-setup",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CLN: Consolidate pytest sections in setup.cfg (#585)\n\nPut both under [tools:pytest] section to silence warnings."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d888ac254a19ac29e39f",
    "number": 584,
    "body": "Analog of #577 for cython branch. ",
    "head_branch": "cython-crs-warn",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Add CRS mismatch warning to cython branch (#584)"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d889ac254a19ac29e3a0",
    "number": 583,
    "body": "",
    "head_branch": "cython-concat-pandas",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Support pd.concat for pandas master (#583)"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d88aac254a19ac29e3a1",
    "number": 582,
    "body": "This fixes a few of the xfailing tests.  Going through this commit-by-commit probably makes sense.",
    "head_branch": "fix-tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix missing data handling (#582)\n\n* Add _concatenator method to GeometryBlock\r\n\r\nFollowing on https://github.com/pandas-dev/pandas/pull/17728\r\n\r\n* Use None for missing values\r\n\r\nPreviously we used `Empty Polygon` for missing values.  Now we revert to\r\nusing NULL in GeometryArray (as before) and Python None when we convert\r\nto shapely objects.\r\n\r\n* fix align and fillna tests\r\n\r\n* implement dropna\r\n\r\n* remove comments\r\n\r\n* Redefine isna\r\n\r\nThis makes it so that only Nones and NaNs are considered missing.\r\n\r\n* clean up tests\r\n\r\n* respond to comments\r\n\r\n* remove unsupported kwargs"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d88bac254a19ac29e3a2",
    "number": 581,
    "body": "Following on https://github.com/pandas-dev/pandas/pull/17728",
    "head_branch": "concatenator",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d88bac254a19ac29e3a3",
    "number": 580,
    "body": "All current overlay tests have indices for which `loc`/`iloc` give the same\r\nresult. Since `ix` will be deprecated (and #579 would remove use of `ix`), add a test to\r\ndistinguish behavior between the two indexers. ",
    "head_branch": "overlay-index-test",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Add test of overlay with non-integer index (#580)\n\nAll current overlay tests have indices for which loc/iloc give the same\r\nresult. Since ix will be deprecated, add a test to distinguish behavior\r\nbetween the two."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d88cac254a19ac29e3a4",
    "number": 579,
    "body": "As of 0.20.0, pandas .ix is deprecated (http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated). This switches all such instances\r\nto the label based .loc indexer. (In searching for usage, I also noticed\r\nthe CHANGELOG contained an error in describing the introduction of the\r\n.cx indexer.)",
    "head_branch": "remove-ix",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "COMPAT: Remove deprecated usage if ix (#579)\n\nAs of 0.20.0, pandas .ix is deprecated. This switches all such instances\r\nto the label based .loc indexer. (In searching for usage, I also noticed\r\nthe CHANGELOG contained an error in describing the introduction of the\r\n.cx indexer.)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d88dac254a19ac29e3a5",
    "number": 578,
    "body": "Inspired by possibility of switch to `fiona` as basis of transform, rather than `pyproj` (#564). I just replicated the NYBB dataset by 10x since ~1 second runtime seemed like a good baseline amount of time for the test. ",
    "head_branch": "asv-transform",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add asv benchmark for to_crs (#578)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d88eac254a19ac29e3a6",
    "number": 577,
    "body": "",
    "head_branch": "sjoin-crs-warning",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Warning for sjoin CRS mismatch, and test (#577)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d88fac254a19ac29e3a7",
    "number": 576,
    "body": "Handling for a bug discussed in\r\nhttps://github.com/Toblerity/Shapely/issues/47#issuecomment-18506767\r\nseems no likely necessary, given the issue was fixed 4 years ago.\r\n\r\nOf course, not a big deal to leave this in place if there's concern about removal, I've just been looking around the code and seeing some references to fixes required for old versions of libraries geopandas depends upon. ",
    "head_branch": "remove-old-geos-try",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CLN: Remove try/except for old GEOS bug (#576)\n\nHandling for a bug discussed in\r\nhttps://github.com/Toblerity/Shapely/issues/47#issuecomment-18506767\r\nseems no likely necessary, given the issue was fixed 4 years ago."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d88fac254a19ac29e3a8",
    "number": 575,
    "body": "We switch the sides of the join and use the complementary predicate.\r\nThis seems to be significantly faster in the common case.\r\n\r\nFixes https://github.com/geopandas/geopandas/issues/563\r\n\r\n@andreas-h if you have a chance to try your code on this branch I would be very grateful.\r\n\r\n@brendancol may also have run into this",
    "head_branch": "sjoin-within",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Implement sjoin within with contains (#575)\n\nWe switch the sides of the join and use the complementary predicate.\r\nThis seems to be significantly faster in the common case."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d890ac254a19ac29e3a9",
    "number": 574,
    "body": "",
    "head_branch": "fix-xfailed-tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix a few xfailed tests (#574)\n\n* Fix some tests in geodataframe\r\n\r\n* fix GeoSeries.astype(str)\r\n\r\n* respond to comments"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d891ac254a19ac29e3aa",
    "number": 573,
    "body": "",
    "head_branch": "py27",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Support Python 2.7 (#573)"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d892ac254a19ac29e3ab",
    "number": 572,
    "body": "@mrocklin I would like an eye on this to see if this is what you had in mind (I am not too familiar with `__new__`, and it also feels a bit messy with the need to define a dummy `__init__`)",
    "head_branch": "cython-geoseries-fallback",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "GeoSeries to return Series when non-geometry data are passed (#572)"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d893ac254a19ac29e3ac",
    "number": 571,
    "body": "This PR fixes #565 by introducing a check in `plot_dataframe`  to make sure the table is not empty. If `df.shape[0] > 0`, it proceeds; otherwise, it issues a warning and returns the original `ax` (if nothing's passed, the `None` is returned).",
    "head_branch": "fix565",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix error on plot empty GeoDataFrame (#571)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d894ac254a19ac29e3ad",
    "number": 570,
    "body": "",
    "head_branch": "appveyor-cython",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d894ac254a19ac29e3ae",
    "number": 569,
    "body": "`_array_input` was not used anywhere, and has been sitting around unused\r\nfor ~4 years, so far as I can tell.\r\n\r\nIf this has a clear purpose I'm missing, I'm happy to close this. I just noticed it, tried to figure out what it was used for, couldn't discern any function it was currently serving, and making a PR to remove it was as easy as creating an issue to ask about it. ",
    "head_branch": "remove-unused-internal",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CLN: Remove unused internal function (#569)\n\n_array_input was not used anywhere, and has been sitting around unused\r\nfor ~4 years, so far as I can tell."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d895ac254a19ac29e3af",
    "number": 568,
    "body": "Basic tests of `centroid` and `convex_hull` methods that were not previously covered.",
    "head_branch": "add-geom-tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Add tests for centroid and convex_hull (#568)\n\nBasic tests of methods that were not previously covered."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d896ac254a19ac29e3b0",
    "number": 567,
    "body": "The symmetric difference test compared a frame with a crs to one\r\nwithout. It didn't seem that this was intentional, so set the second\r\nframe crs to the first so that the tests run without warnings.\r\n\r\nWarning below:\r\n```\r\ngeopandas/tests/test_geom_methods.py::TestGeomMethods::()::test_symmetric_difference_series\r\n  /home/james/python/geopandas/geopandas/base.py:29: UserWarning: GeoSeries crs mismatch: {'init': 'epsg:4326', 'no_defs': True} and None\r\n    other.crs))\r\n\r\ngeopandas/tests/test_geom_methods.py::TestGeomMethods::()::test_symmetric_difference_operator\r\n  /home/james/python/geopandas/geopandas/base.py:29: UserWarning: GeoSeries crs mismatch: {'init': 'epsg:4326', 'no_defs': True} and None\r\n    other.crs))\r\n```",
    "head_branch": "test-crs-warning",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Set test gdf crs to silence crs warning (#567)\n\n* TST: Set test gdf crs to silence crs warning\r\n\r\nThe symmetric difference test compared a frame with a crs to one\r\nwithout. It didn't seem that this was intentional, so set the second\r\nframe crs to the first so that the tests run without warnings.\r\n\r\nWarning below:\r\ngeopandas/tests/test_geom_methods.py::TestGeomMethods::()::test_symmetric_difference_series\r\n  /home/james/python/geopandas/geopandas/base.py:29: UserWarning: GeoSeries crs mismatch: {'init': 'epsg:4326', 'no_defs': True} and None\r\n    other.crs))\r\n\r\ngeopandas/tests/test_geom_methods.py::TestGeomMethods::()::test_symmetric_difference_operator\r\n  /home/james/python/geopandas/geopandas/base.py:29: UserWarning: GeoSeries crs mismatch: {'init': 'epsg:4326', 'no_defs': True} and None\r\n    other.crs))\r\n\r\n* Add test intended to catch CRS warning"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d897ac254a19ac29e3b1",
    "number": 566,
    "body": "Marking the remaining failures as `xfail`, so we can start relying on travis for further developing of the geopandas-cython branch.\r\n\r\nI also marked the same tests with a cython mark, so you can do:\r\n\r\n```\r\npytest geopandas -v --runxfail -m cython\r\n```\r\n\r\nto run all those tests in no-xfail mode to see the actual remaining failures.\r\n\r\nFurther trimmed down the travis build matrix (trying 0.19 for now)",
    "head_branch": "update-tests-travis-matrix",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: mark geopandas-cython failures and update travis matrix (#566)\n\n* TST: mark geopandas-cython failures and update travis matrix\r\n* Use miniconda in travis.yml\r\n* remove apt packages"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d898ac254a19ac29e3b2",
    "number": 564,
    "body": "This is experimental for the moment.  It is more to start a discussion.  It is regarding #315.\r\n\r\nI don't even know if this is a good idea.\r\n\r\nA benchmark would be nice to show if there is a performance difference.  In very limited testing, I found fiona.transform to be a bit faster.\r\n\r\nMy branch had one test fail.",
    "head_branch": "coordinate_transform",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d898ac254a19ac29e3b3",
    "number": 561,
    "body": "fixes #559",
    "head_branch": "nodata",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d899ac254a19ac29e3b4",
    "number": 555,
    "body": " I think the documentation here is outdated. As a first-time user of Geopandas, I could only find the geocode function in the tools module. Is this correct?",
    "head_branch": "patch-2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Update geocoding.rst (#555)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d89aac254a19ac29e3b5",
    "number": 554,
    "body": "`validate_boro_df` had been used primarily for testing reads from a postgis database, and so was checking against lower case column names. In the one other place that `validate_boro_df` was used, it was changing column names prior to testing in order to use the existing functionality. I think this is a little more transparent functionality for any future situations in which `validate_boro_df` might be used.",
    "head_branch": "validate-boro",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Add case sensitivity flag to validate_boro_df (#554)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d89bac254a19ac29e3b6",
    "number": 553,
    "body": "There might be a better and more generic way of accomplishing this.",
    "head_branch": "drop-pandas",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d89cac254a19ac29e3b7",
    "number": 551,
    "body": "A few things changed between 2.0.0 and 2.0.1, causing tests to not pass against 2.0.0.",
    "head_branch": "mpl2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "COMPAT: fix tests of Matplotlib 2.0.0 (#551)\n\n* Fix default cmap for Matplotlib 2.0.0.\r\n\r\n* TST: Fix determination of expected dash style.\r\n\r\nIn Matplotlib 2.0.0, there was a minimum dash length that was eventually\r\nremoved because it was problematic. The expected line style does not\r\napply this minimum."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d89dac254a19ac29e3b8",
    "number": 550,
    "body": "This uses geopy's `get_geocoder_for_service` to map strings to the proper class\r\nto use, so a geopandas user can use any available geopy Geocoder. This also\r\nprovides the option to use a Geocoder instance, rather than the string\r\nmapping, which is potentially more transparent. I'll add a couple inline notes on\r\npotentially questionable changes.\r\n\r\nCloses #468 and closes #539.",
    "head_branch": "issue539",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Expose all geopy services (#550)\n\nUse geopy's get_geocoder_for_service to map strings to the proper class\r\nto use, so a geopandas user can use any available geopy Geocoder. Also\r\nprovide option to use a Geocoder instance, rather than the string\r\nmapping, which is potentially more transparent."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d89eac254a19ac29e3b9",
    "number": 549,
    "body": "(WIP: will further add the commits of master to this PR)\r\n\r\nAfter those cherry picks, I ran the tests but currently they segfault on this test (did not yet investigate why):\r\n\r\ngeopandas/tests/test_geoseries.py::TestSeries::test_coord_slice_with_zero Segmentation fault (core dumped)\r\n",
    "head_branch": "geopandas-cython-update-with-master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: correct column order in tests"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d89eac254a19ac29e3ba",
    "number": 548,
    "body": "A quick update to note the use of `conda-forge` when installing on OSX/Windows",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: update installation instructions in README (#548)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d89fac254a19ac29e3bb",
    "number": 547,
    "body": "- fix tests for changed order of columns (geometry column is now last column)\r\n- add tolist to GeometryArray (for iteration in pandas)",
    "head_branch": "geopandas-cython-failing-tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix failing tests (#547)\n\n- fix tests for changed order of columns (geometry column is now last column)\r\n- add tolist to GeometryArray (for iteration in pandas)"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d8a0ac254a19ac29e3bc",
    "number": 546,
    "body": "When using geoalchemy2 accessing postgis for tables with geography type, the returned geometries are WKBElement objects. The object does not have `x.encode()` but rather a `desc` property for stringifying the underlying wkt data. This PR is trying to make it easy to work with such scenario.",
    "head_branch": "wkbelement_from_postgis",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8a1ac254a19ac29e3bd",
    "number": 545,
    "body": "a fix and some unit tests for issue #525. Original panda dataframe's index names are no longer changed by sjoin() call.\r\n\r\nThis pull request follows on from request #538 (I reorganised my github fork and broke things)\r\n\r\nMy original code didn't work for pandas 0.16.2 and so I've found the following way to make the code work across pandas version 0.16.0 - 0.20.0\r\n\r\n    left_df = left_df.copy(deep=True)\r\n    left_df.index = left_df.index.rename(index_left)\r\n    left_df = left_df.reset_index()\r\n\r\nI wanted to do copy(deep=False) in order to save a copy but the geopandas code for the copy method is different from the pandas method code and so it didn't work (but works for a pandas dataframe). Is there a reason for that?\r\npandas code is\r\n\r\n    data = self._data.copy(deep=deep)\r\n    return self._constructor(data).__finalize__(self)\r\n\r\ngeopandas code is\r\n\r\n    data = self._data\r\n    if deep:\r\n        data = data.copy()\r\n    return GeoDataFrame(data).__finalize__(self)\r\n",
    "head_branch": "issue525",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: retain index names of input frames to sjoin (#545)\n\n* BUG: sjoin modifies original frame (#525)\r\n\r\nOriginal pandas table's index names are no\r\nlonger changed by sjoin() call. Includes\r\nsome unit-tests. Fixes issue #525\r\n\r\n* New code to fix issue that is compatible with pandas 0.16.2 - 0.20.3\r\n\r\n* applied suggested changes to test_sjoin.py"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8a2ac254a19ac29e3be",
    "number": 542,
    "body": "",
    "head_branch": "fix-choropleth-in-doc",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix choropleth typo in doc (#542)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8a3ac254a19ac29e3bf",
    "number": 538,
    "body": "a fix and some unit tests for issue #525. Original panda dataframe's index names are no longer changed by sjoin() call.",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8a3ac254a19ac29e3c0",
    "number": 537,
    "body": "cc @jorisvandenbossche thoughts on the best way to solve problems like this?",
    "head_branch": "reset-index-tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8a4ac254a19ac29e3c1",
    "number": 535,
    "body": "Fixes #532 ",
    "head_branch": "532-buffer-arguments",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Pass through kwargs for GeoSeries.buffer (#535)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8a5ac254a19ac29e3c2",
    "number": 534,
    "body": "Fixes #530 \r\n\r\nUses sphinx autodoc for the reference documentation to pick out the docstrings of the corresponding attributes and methods.\r\n\r\nThe documentation originally in `reference.rst` has been merged with the docstrings inside the `.py`-files. An attempt has been made to make the documentation more consistent.",
    "head_branch": "530-improve-api-docs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Improve API reference docs (#534)\n\n* Add autodoc to sphinx configuration\r\n\r\n* Add support for numpy docstring to sphinx configuration\r\n\r\n* Use autodoc for reference documentation, reading documentation from docstrings\r\n\r\n* Improve docstrings of properties and methods listed in Reference documentation\r\n\r\n* Pass through kwargs for GeoSeries.buffer (#535)\r\n\r\n* Fix choropleth typo in doc (#542)\r\n\r\n* Remove warnings from numpydoc when generating docs\r\n\r\n* Add autodoc to sphinx configuration\r\n\r\n* Add support for numpy docstring to sphinx configuration\r\n\r\n* Use autodoc for reference documentation, reading documentation from docstrings\r\n\r\n* Improve docstrings of properties and methods listed in Reference documentation\r\n\r\n* Remove warnings from numpydoc when generating docs\r\n\r\n* Add GeoSeries-subsection for consistency\r\n\r\n* Consistently only add parameters for functions passing through args/kwargs\r\n\r\n* Clarify how contains and within are inverses of each other\r\n\r\n* remove plot signature in reference"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8a6ac254a19ac29e3c3",
    "number": 531,
    "body": "Tested with GeoJSON files.",
    "head_branch": "remote-geojson",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add basic support for remote resources to `read_file` (#531)\n\n* Add basic support for remote resources to `read_file`\r\n\r\nTested with GeoJSON files.\r\n\r\n* TST: Use GeoJSON file from GeoPandas repo\r\n\r\n* Switch to numpydoc style\r\n\r\n* Fix syntax in docs\r\n\r\n* Formatting and rename test marker"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8a7ac254a19ac29e3c4",
    "number": 523,
    "body": "closes https://github.com/geopandas/geopandas/issues/522\r\n\r\nThis results in the colorbar getting drawn on `ax` referred to in the `ax.get_figure().colorbar` call. The axis doesn't propagate downwards after `get_figure`, so the current version will always plot the colorbar on the last axis in a figure with more than one axis. \r\n\r\nI did this locally and it behaves as I expect:\r\n```python\r\nimport geopandas as gpd\r\nimport pysal as ps\r\ntest_data = gpd.read_file(ps.examples.get_path('columbus.shp'))\r\nf,ax = plt.subplots(1,2,figsize=(5*2.1,5))\r\nax[0] = test_data.plot('CRIME', ax=ax[0], legend=True)\r\nax[1] = test_data.plot('INC', legend=False, ax=ax[1])\r\nplt.show()\r\n``` \r\ngives\r\n![test_a](https://user-images.githubusercontent.com/2250995/29848437-66fda8e8-8cd5-11e7-86bd-d1904383abdc.png)\r\n",
    "head_branch": "dev",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: ensure that the colorbar gets plotted to the right axis (#523)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8a7ac254a19ac29e3c5",
    "number": 520,
    "body": "",
    "head_branch": "update-copyright",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: Update copyright date range in sphinx docs (#520)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8a8ac254a19ac29e3c6",
    "number": 518,
    "body": "",
    "head_branch": "docs-update",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: make figures a bit larger in the docs (#518)\n\n* DOC: make figures a bit larger in the docs\r\n\r\n* update some plot styles in docs to look nicer with new defaults"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8a9ac254a19ac29e3c7",
    "number": 517,
    "body": "Add same alias for notnull -> notna, and add tests of empty geometries\r\nto ensure that the check is working for the case it is supposed to\r\ncatch.\r\n\r\nQuestions: \r\n- Are the docs sufficient? \r\n- I don't think what I've added is incompatible with changes in #512, but maybe I've missed something?\r\n- This doesn't cover `isna` or `notna` on `GeoDataFrames`, which is consistent with existing behavior of `isnull`, where the override only occurs for `GeoSeries`. Should that change? ",
    "head_branch": "issue503",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "COMPAT: Alias isnull -> isna, following pandas (#517)\n\n* COMPAT: Alias isnull -> isna, following pandas\r\n\r\nAdd same alias for notnull -> notna, and add tests of empty geometries\r\nto ensure that the check is working for the case it is supposed to\r\ncatch."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8aaac254a19ac29e3c8",
    "number": 516,
    "body": "Something that came up is how to handle this case:\r\n\r\n```python\r\nGeoSeries([1, 2, 3])\r\n```\r\n\r\nShould we use `__new__` to create a Series?  Should it be legal to have non-geometries in a GeoSeries?\r\n\r\ncc @jorisvandenbossche ",
    "head_branch": "fix-misc-tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8abac254a19ac29e3c9",
    "number": 515,
    "body": "We unpack the geometry and normal pandas data and then repack in setstate\r\n\r\n",
    "head_branch": "cython-pickle",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix GeoDataFrame pickling (#515)\n\nWe unpack the geometry and normal pandas data and then repack in setstate"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8acac254a19ac29e3ca",
    "number": 514,
    "body": "",
    "head_branch": "cython-concat",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add concat that respects GeometryArrays (#514)\n\n* Add concat that respects GeometryArrays\r\n\r\n* Handle errors in gpd.concat\r\n\r\n* test ignore_index\r\n\r\n* clean up concat(series) code\r\n\r\n* test crs support"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d8acac254a19ac29e3cb",
    "number": 513,
    "body": "I find linter warnings about imports useful, but they were a little less useful in some geopandas modules because of older no-longer-used imports. ",
    "head_branch": "clean-imports",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CLN: Remove unused imports (#513)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8adac254a19ac29e3cc",
    "number": 512,
    "body": "This should for now close #509 (although I am not really satisfied with the fix -> still relies on the fact that the array interface for Polygon won't change).",
    "head_branch": "shapely-compat2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG/COMPAT: fix fillna by filling with Polygon instead of Point (#512)\n\nSee #509. Polygon cannot be converted to an array, and therefore\r\nfillna works (starting with shapely 1.6, an empty Point can be\r\nconverted to an aray -> broke fillna).\r\nHowever, we should find a better fix for this in the long term.\r\n\r\n* unpin shapely, add test builds with older shapely\r\n\r\n* adapt test\r\n\r\n* change to BaseGeometry"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8aeac254a19ac29e3cd",
    "number": 510,
    "body": "Closes https://github.com/geopandas/geopandas/issues/318 (also closes #269) \r\n\r\nSee https://github.com/geopandas/geopandas/issues/318#issuecomment-324141739, this removed all hard coded defaults (only switching from viridis to tab10 for the color map when we have categorical data)\r\n\r\nI didn't yet add the removal of the axes by default. If we do that, do we want to add a new keyword to control that ?",
    "head_branch": "plotting-defaults",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "VIS: updated plotting defaults (#510)\n\n* remove hardcoded defaults\r\n\r\n* use uniform color by default\r\n\r\n* for categorical data use default cmap tab10 instead of Set1\r\n\r\n* forgot to remove hardcoded markersize\r\n\r\n* remove no longer used gencolor function\r\n\r\n* update MultiPolygons test\r\n\r\n* fix some tests + mixed geom case with cmap\r\n\r\n* enable more tests\r\n\r\n* fix for matplotlib 1.4.3\r\n\r\n* skip one for 1.4.3\r\n\r\n* fix some collection tests\r\n\r\n* small updates to docstring\r\n\r\n* undo take squaring of the markersize"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8afac254a19ac29e3ce",
    "number": 508,
    "body": "Some tests are failing since shapely 1.6 is used on CI (see eg https://travis-ci.org/geopandas/geopandas/jobs/267360623)\r\n(reported to shapely: https://github.com/Toblerity/Shapely/issues/510)",
    "head_branch": "travis-shapely",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: temporary pin shapely to < 1.6 (#508)\n\nxref #509"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8b0ac254a19ac29e3cf",
    "number": 507,
    "body": "Closes https://github.com/geopandas/geopandas/issues/225\r\nSee [jupyter notebook with usage examples](https://gist.github.com/emiliom/bde588461f816a0f0b5e4ae47ffbcc20)",
    "head_branch": "fromgeo_fc",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: GeoDataFrame.from_features to accept FeatureCollection as well (#507)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8b1ac254a19ac29e3d0",
    "number": 506,
    "body": "",
    "head_branch": "try-except-from-shapely",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add try-except check aroung geom.__geom__ in from_shapely (#506)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8b2ac254a19ac29e3d1",
    "number": 505,
    "body": "",
    "head_branch": "cython-failing-tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "fix set_geometry accept GeometryArray"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8b2ac254a19ac29e3d2",
    "number": 504,
    "body": "",
    "head_branch": "clean-ci",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: clean requirements.txt, add pysal on travis, omit _versions.py from coverage (#504)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8b3ac254a19ac29e3d3",
    "number": 502,
    "body": "I went through the plotting code and did some clean-up (builds further upon the work of @IamJeffG):\r\n\r\n- Changed the signature of the `plot_*_collection` functions. They now just have an optional `values=None` argument (instead of `colors_or_values, plot_values` combo where `plot_values` indicated whether `color_or_values` should be interpreted as colors or as values\r\n  - This makes the implementation IMO a bit cleaner\r\n  - This simplifies the code as I leave all handling of the color kwargs to matplotlib collection constructors (no need to set them manually)\r\n- I removed the legacy handling of `alpha` for plotting polygons:\r\n  - Currently polygons were plotted twice to be able to apply alpha to fill color, but not to edge. Removed this hack, which implies of course a behavioural change that the alpha is now applied on both edge and fill.\r\n  - This cleaned up the code a lot, and also improves the performance for plotting polygons\r\n- Some other clean-up, eg not re-computing the `geometry.types` will improve performance a little bit (will also do a PEP8)\r\n\r\nResult from the benchmarks also indicate that their is some speed improvement, mainly for polygons:\r\n\r\n```\r\n       before           after         ratio\r\n     [baa1601c]       [a951e68c]\r\n-        73.1±2ms         64.9±1ms     0.89  plotting.Bench.time_plot_values('mixed')\r\n-        99.4±3ms         87.8±3ms     0.88  plotting.Bench.time_plot_values('Point')\r\n-        71.4±3ms         62.2±2ms     0.87  plotting.Bench.time_plot_series('LineString')\r\n-         105±1ms         87.8±1ms     0.83  plotting.Bench.time_plot_series('mixed')\r\n-        82.5±3ms       62.9±0.8ms     0.76  plotting.Bench.time_plot_values('MultiPolygon')\r\n-         104±2ms         73.4±1ms     0.71  plotting.Bench.time_plot_values('Polygon')\r\n-        174±30ms         96.7±8ms     0.56  plotting.Bench.time_plot_series('Polygon')\r\n-         122±2ms         65.3±1ms     0.54  plotting.Bench.time_plot_series('MultiPolygon')\r\n```\r\n\r\nThose changes should mainly be back compatible (apart from the alpha change, the only other behavioural change (based on the tests) is that now color overrules facecolor instead of the other way around for polygons (this follows matplotlib behaviour). \r\nFurther, there is one test that is not yet passing for MultiPolygons. I can fix this one, but if we decide in https://github.com/geopandas/geopandas/issues/318 to switch to uniform colors by default, this fix is not needed (so will wait on that)\r\n\r\nBut of course, not everything will probably be covered in the tests, so feedback / testing welcome!\r\n\r\ncc @IamJeffG @jdmcbr \r\n\r\n(it might be easier to digest if you look at the diff commit by commit, there is also some explanation in the commit message) \r\nAnd sorry for doing this so close to the release (want to release next week)\r\n\r\ncc @darribas @emiliom always welcome to run some tutorial material with this branch to see if there are problems.\r\n\r\n",
    "head_branch": "plotting-cleanup",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Clean-up / simplify plotting code (#502)\n\n* Simplify plot_point_collection\r\n\r\nPass values or colors separately to c / color kwargs\r\nMatplotlib automatically handles them well\r\n\r\n* Simplify plot_linestring_collection\r\n\r\nHandle values or colors separately.\r\nColors are then handles by the constructor of\r\nLineCollection itself and don't need to be set\r\nafterwards\r\n\r\n* Simplify plot_polygon_collection\r\n\r\nHandle values or colors separately.\r\nColors are then handles by the constructor of\r\nPatchCollection itself and don't need to be set\r\nafterwards\r\n\r\nDifference is that color sets both face and edgecolor\r\n\r\n* Update (and remove legacy support for alpha) plot_series/plot_frame\r\n\r\nget plot_series and plot_frame working with the new plot_*_collection functions\r\nremoved the workaround to keep old alpha behaviour for polygons\r\n(no longer apply alpha only on fill and not on edge)\r\n\r\nchanges in behaviour:\r\n- color has now priority over facecolor, not the other way around\r\n\r\nMutliPolygons without specifying values don't work yet\r\n\r\n* compute s.geometry.type only once\r\n\r\n* address review comments\r\n\r\n* try to fix tests for older matplotlib versions\r\n\r\n* PEP8 clean-up\r\n\r\n* skip more tests with older matplotlib\r\n\r\n* merge two testing functions"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8b4ac254a19ac29e3d4",
    "number": 501,
    "body": "This isn't optimally fast, but might be faster than current methods of densification\r\n\r\ncc @jorisvandenbossche \r\n\r\nThis currently depends on #500 \r\n\r\n```python\r\nIn [1]: from shapely.geometry import Polygon\r\n\r\nIn [2]: coords = [((0, 0), (1, 1), (1, 0), (0, 0)),\r\n   ...:           ((0, 0), (0, 10), (10, 10), (10, 0), (0, 0))]\r\n   ...: polys = [Polygon(c) for c in coords] + [None]\r\n   ...:           \r\n\r\nIn [3]: import geopandas as gpd\r\n\r\nIn [4]: s = gpd.GeoSeries(polys)\r\n\r\nIn [5]: s.exterior.coords()\r\nOut[5]: \r\n[((0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0)),\r\n ((0.0, 0.0), (0.0, 10.0), (10.0, 10.0), (10.0, 0.0), (0.0, 0.0)),\r\n ()]\r\n```",
    "head_branch": "get-coordinates",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Cythonize get coordinates (#501)\n\n* Add cythonized get_coordinates function\r\n\r\n* add test for points.coords\r\n\r\n* Coords return series\r\n\r\n* test z coordinate\r\n\r\n* rename get_coordinates to coords\r\n\r\n* Remove unnecessary import"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d8b5ac254a19ac29e3d5",
    "number": 500,
    "body": "",
    "head_branch": "exterior",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Cythonize exterior  (#500)"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d8b6ac254a19ac29e3d6",
    "number": 499,
    "body": "",
    "head_branch": "unary-union",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Cythonize unary union (#499)\n\n* Add Cythonized unary_union implementation"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d8b6ac254a19ac29e3d7",
    "number": 497,
    "body": "",
    "head_branch": "asv-benchmarks",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Start adding an asv benchmark suite (#497)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8b7ac254a19ac29e3d8",
    "number": 496,
    "body": "This intercepts GDAL error and warnings so that they go to the Python logger instead of directly to stderr, solving confusing error messages like the one reported at https://github.com/Toblerity/Fiona/issues/468.",
    "head_branch": "with-fiona-context",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Open output file in a GDAL error-handling context (#496)\n\nThis solves confusing error messages like the one reported at https://github.com/Toblerity/Fiona/issues/468."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8b8ac254a19ac29e3d9",
    "number": 495,
    "body": "Adding some more tests for constructing a GeoDataFrame\r\n\r\n(will do a cleanup of the imports once https://github.com/geopandas/geopandas/pull/494 is merged, like this is will be easier to rebase)",
    "head_branch": "test-constructors",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: addexrGeoDataFrame constructor tests (#495)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8b9ac254a19ac29e3da",
    "number": 494,
    "body": "Some general clean-up of the tests to be able to use more pytest features (therefore removed the subclassing from `unittest.TestCase`, but fore now kept the structuring in classes). At the same time also did some PEP8)",
    "head_branch": "cleanup-tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: clean-up tests (remove unittest.TestCase subclassing, more pytest usage, PEP8) (#494)\n\n* Remove no longer used baseline images\r\n\r\n* Remove dependency on unittest.TestCase (to be able to use pytest functionality) in test_geodataframe.py\r\n\r\n* also remove unittest TestCase usage in other test files (+ PEP8 cleaning)\r\n\r\n* remove check for old pandas version (not supported anymore)\r\n\r\n* automatically close figures after plotting tests\r\n\r\n* further cleanup tests/util.py\r\n\r\n* ensure recent version of pytest is used"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8baac254a19ac29e3db",
    "number": 493,
    "body": "I reversed the way the test was applied for simpler handling between matplotlib versions, but I think the basic logic is the same.\r\n\r\nCloses #278",
    "head_branch": "fix-linestyle-test",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Fix test of LineString style in mpl>=2.0 (#493)\n\n* Fix test of LineString style in mpl>=2.0\r\n\r\n* Do not allow matplotlib>2.0 failures in travis"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8bbac254a19ac29e3dc",
    "number": 492,
    "body": "",
    "head_branch": "distance-project",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Cython refactor: add distance and project (#492)"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d8bbac254a19ac29e3dd",
    "number": 489,
    "body": "Hopefully this will allow `make inplace` to work for more people and under more circumstances.  This gets the paths with system calls to `geos-config`.  XREF #473",
    "head_branch": "cython-geos_config",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Get include and library paths for GEOS from `shapely._buildcfg.get_geos_config` (#489)\n\nHopefully this will allow `make inplace` to work for more people and under\r\nmore circumstances.  This gets the paths with system calls to `get-geos`."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d8bcac254a19ac29e3de",
    "number": 487,
    "body": "This adds tests of desired behavior of drop_duplicates as applied to\r\ngeoseries and geodataframes, with currently failing tests for both.",
    "head_branch": "duplicates-tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Add (failing) tests of drop_duplicates (#487)\n\nThis adds tests of desired behavior of drop_duplicates as applied to\r\ngeoseries and geodataframes, with currently failing tests for both."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8bdac254a19ac29e3df",
    "number": 486,
    "body": "Instead of specifying the name of the default color table, verify that default geopandas plots have color schemes that match the mpl defaults, which as far as I can tell, still captures the spirit of the original tests. This addresses a couple of the testing failures introduced with matplotlib 2.0, and is a first step towards #278.",
    "head_branch": "issue278a",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: fix tests of color in mpl 2.0 (#486)\n\nInstead of specifying the name of the default color table, verify that\r\ndefault geopandas plots have color schemes that match the mpl defaults."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8beac254a19ac29e3e0",
    "number": 484,
    "body": "The inclusion of tests as part of the coverage seems a little distracting to me. Of course, if there's a good reason to keep them, it isn't that big a deal, but the projects with which I'm most familiar all seem to exclude tests.",
    "head_branch": "omit-test-coverage",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Omit tests from coverage report"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8bfac254a19ac29e3e1",
    "number": 482,
    "body": "In addition to applying the existing cx slicing functionality for `GeoSeries` to `GeoDataFrame` objects, I added a minimal page to the docs on indexing geodataframes, which includes an example of using the `cx` method.",
    "head_branch": "issue471",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: add cx indexer to GeoDataFrame (#471) (#482)\n\n* Add coordinate indexing method cx to geodataframes\r\n\r\nAdd a few basic tests that it works on a geodataframe as it does for a\r\ngeoseries.\r\n\r\n* Add docs on indexing, including slicing with cx\r\n\r\n* Use consistent assert in gdf coord slice test\r\n\r\n* Move _CoordinateIndexer to base module\r\n\r\nWith both geoseries and geodataframe modules using the class, base.py is\r\na better place to define the _CoordinateIndexer class.\r\n\r\nAlso add docs to the _CoordinateIndexer class."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8c0ac254a19ac29e3e2",
    "number": 481,
    "body": "`merge` was already kind of working, but only did not preserve the geometry block (it resulted in a GeoDataFrame but with ObjectBlock / `_geometry_array` of shapely objects.\r\n\r\n@mrocklin possibly relevant for https://github.com/geopandas/geopandas/pull/475",
    "head_branch": "geopandas-cython-merge",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8c0ac254a19ac29e3e3",
    "number": 480,
    "body": "",
    "head_branch": "remove-download-nybb",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC/TST: use datasets.get_path('nybb') in docs and tests (#480)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8c1ac254a19ac29e3e4",
    "number": 479,
    "body": "This cythonizes the current overlay operation.  I thought I needed this for Dask work, but after looking at the performance this operation is still really quite slow.  I'll probably try to get by with spatial joins.  Still, I thought I'd leave this up here for now.\r\n\r\nThis includes the changes in the spatial join PR",
    "head_branch": "overlay",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8c2ac254a19ac29e3e5",
    "number": 478,
    "body": "With the previous tests of the style `xs.start or xmin`, if `xs.start`\r\nequalled 0, `xmin` was taken, ignoring the user specified slice boundary.\r\nThis fixes that issue, and adds miminal testing around slices with\r\nboundaries at 0.\r\n\r\nCloses #477",
    "head_branch": "issue477",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: Fix handling of 0 slice in cx method (#477) (#478)\n\nWith the previous tests of the style xs.start or xmin, if xs.start\r\nequalled 0, xmin was taken, ignoring the user specified slice boundary.\r\nThis fixes that issue, and adds miminal testing around slices with\r\nboundaries at 0."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8c3ac254a19ac29e3e6",
    "number": 476,
    "body": "I followed the example in `rasterio` (whose change logs I like) and labeled the changes with \"next\", to be updated to `0.3.0` once we merge everything we want to include and release. I also changed the extension since it is written with markdown already, and improves the readability when browsing on github, but happy to change back if there is some reason I'm not seeing for it not having an extension.",
    "head_branch": "pre-0.3.0-changelog",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "RLS: add pre-0.3.0 changelog (#476)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8c4ac254a19ac29e3e7",
    "number": 475,
    "body": "This uses GEOS's STRTree to implement a spatial join.",
    "head_branch": "sjoin2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Cython refactor: Add spatial-join algorithm (#475)\n\n* add sjoin algorithm (c/cythonized)\r\n\r\n* Fix constructor logic when geometry and columns both provided"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d8c4ac254a19ac29e3e8",
    "number": 474,
    "body": "",
    "head_branch": "cleanup",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge pull request #474 from mrocklin/cleanup\n\nAdd missing import"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8c5ac254a19ac29e3e9",
    "number": 472,
    "body": "This is a partially squashed, rebased on master, cleaned-up (removed sjoin for now) version of https://github.com/geopandas/geopandas/pull/467.\r\n\r\nI will merge this into a geopandas-cython branch in the geopandas repo. So subsequent PRs to further work on this can target that branch.",
    "head_branch": "geopandas-cython-PR",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "add types to GeometryArray\n\ntypes -> geom_type\n\nconnect geom_type to base\n\ngeom_type returns a string\n\nThis follows shapely behavior"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d8c6ac254a19ac29e3ea",
    "number": 469,
    "body": "For refactoring the internals, to have some more tests with pandas interaction (how pandas methods currently behave)",
    "head_branch": "more-tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: add more extensive tests of pandas functionality (#469)\n\n* TST: add more extensive tests of pandas functionality\r\n\r\n* add first groupby methods\r\n\r\n* add get_group and select_dtypes\r\n\r\n* ensure array input to where\r\n\r\n* fix select dtypes test\r\n\r\n* fix max test for python 2 (on python 2 objects are orderable, so max works)\r\n\r\n* skip test for pandas 0.16\r\n\r\n* windows fix int64\r\n\r\n* fix skipif"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8c7ac254a19ac29e3eb",
    "number": 467,
    "body": "This cythonizes a class of geometry operations within geoseries.  It builds off of @jorisvandenbossche notebook in #430 by extending the set of operations and setting up a proper build environment.\r\n\r\nSome things to note\r\n\r\n1.  There is a Cython build setup provided by @eriknw\r\n2.  Cython code is only used if available, falling back on the previous Python solution\r\n3.  @wmay has another attempt at https://github.com/Toblerity/Shapely/issues/501\r\n4.  I get around a 50-100x speedup on a simple comparison\r\n5.  There are some inconsistencies between this and what shapely does that I haven't yet tracked won\r\n6.  There are still plenty of operations to do.  This just expands on @jorisvandenbossche 's work",
    "head_branch": "cythonize",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8c8ac254a19ac29e3ec",
    "number": 464,
    "body": "Added method to GeoDataFrame for ingesting GeoJSON files that are hosted online (for example https://data.cityofnewyork.us/resource/kk4q-3rt2.geojson). This is intended to provide similar functionality to `pandas.read_json()`. Included a somewhat trivial test against the url for `geopandas/examples/null_geom.geojson` on Github.\r\n\r\nThere's a bunch of unrelated deletions/insertions where my editor changed things w/ automatic PEP8 adjustments – sorry.",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8c9ac254a19ac29e3ed",
    "number": 463,
    "body": "This PR converts some of the documentation to examples using the sphinx-gallery plugin. This does a couple of things:\r\n\r\n0. Converts many of the examples in `.rst` files (that were using `.. ipython::` blocks) into proper python files with `rst` embedded as comments\r\n1. Generates a gallery of images showing off example outputs\r\n2. Converts python files with embedded rST into a rendered HTML output\r\n3. Creates jupyter notebooks for each example as well, to go along with the python file\r\n4. Embeds examples in documentation stub pages\r\n5. Makes (some) methods/classes/etc clickable links in the rendered examples.\r\n\r\nThis PR is still somewhat WIP, but this is a general idea of what it'd look like:\r\n\r\nhttp://predictablynoisy.com/geopandas/gallery/index.html\r\n\r\nAnd here's an example of the examples listed in an API stub page:\r\n\r\nhttp://predictablynoisy.com/geopandas/api/_as_gen/geopandas.datasets.get_path.html#geopandas.datasets.get_path\r\n\r\nLet me know what folks think and/or if this is worth me spending more time to refine. I think it'd be a nice step towards making the documentation more user-friendly! Comments welcome!\r\n\r\n Note: In general this does **not** change the content of any examples, it only converts them to python. I think that changing the example content itself should be done in another PR if folks want this.",
    "head_branch": "sphinx_gallery",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add sphinx gallery for examples (#463)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8c9ac254a19ac29e3ee",
    "number": 459,
    "body": "Wraps `total_bounds` as a numpy array. I don't *think* this should change any of the tests etc...let's see :-)\r\n\r\nCloses #458",
    "head_branch": "total_bounds_array",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Change total_bounds to return an array (#459)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8caac254a19ac29e3ef",
    "number": 457,
    "body": "I implemented the 'write_postgis' and the 'to_postgis' (same as write_postgis but called on a GeoDataFrame object) methods. They behave very similarly to the original 'to_sql' method of pandas. In fact, I subclassed the SQLDatabase and SQLTable from pandas.io.sql to GeoSQLDatabase and GeoSQLTable to use original pandas logic as much as possible.\r\n\r\nI relied on GeoAlchemy2 (https://github.com/geoalchemy/geoalchemy2) and on SQLAlchemy. I added them to the requirements because it was easier, but if it is a problem to have new dependencies I think it could be possible to only allow this feature when GeoAlchemy2 and SQLAlchemy are installed.\r\n\r\nI added a test case for both methods. I'm also willing to write doc later for this new feature, it it gets accepted.\r\n\r\nLet me know if you need more details or some modifications.",
    "head_branch": "dev",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8cbac254a19ac29e3f0",
    "number": 454,
    "body": "Update newest tested matplotlib to version 1.5.3",
    "head_branch": "patch-2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: Add Pandas version 0.20.2 to travis matrix (#454)\n\nUpdate newest tested matplotlib to version 1.5.3"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8ccac254a19ac29e3f1",
    "number": 453,
    "body": "I wanted to use affine_transform from shapely, so I added it to the affine transformations in GeoPandasBase. I added the function and the description in the docs.\r\n\r\nSince the shapely function had a [bug recently](https://github.com/Toblerity/Shapely/pull/494) I'm not sure what to do for testing until that fix makes it into the shapely package. I'd be happy to add a test though, if that helps.",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8cdac254a19ac29e3f2",
    "number": 450,
    "body": "When adding `legend=True` and `scheme` to `plot_dataframe` the values of the range where being miscalculated.\r\n\r\nFor example doing this:\r\n\r\n```python\r\nimport geopandas as gpd\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\n\r\ndf = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\r\ndf['data'] = np.linspace(-10, 10, df.count()[0])\r\ndf.plot(column='data', cmap='RdBu_r', scheme='quantiles', legend=True)\r\nplt.savefig('before.png')\r\n```\r\nWould result in:\r\n![before](https://user-images.githubusercontent.com/2049010/27263036-da225b96-5438-11e7-9393-6bdc0dace9b9.png)\r\n\r\nNotice the `0 - -6` range of the first color., which makes no sense.\r\n\r\nWith the fix it looks like this:\r\n![after](https://user-images.githubusercontent.com/2049010/27263038-daf8d810-5438-11e7-95e9-1e7b00093bb8.png)",
    "head_branch": "fix_legend_bins",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fixing a problem with bins in choropleth legend (#450)\n\n* fixing a problem with bins in choropleth legend\r\n\r\n* adding a test for it"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8cdac254a19ac29e3f3",
    "number": 445,
    "body": "The series being an array subclass (`OLD_PANDAS` checks) dates from pandas <= 0.12, which we don't support anymore.\r\n\r\nAlso closes #443 (remove cache_readonly import, was not used)",
    "head_branch": "compat",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CLN: clean up old compat code (#445)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8ceac254a19ac29e3f4",
    "number": 442,
    "body": "Per @jorisvandenbossche comments in #440, remove the statements in database testing functions designed to handle pandas version <0.14.",
    "head_branch": "new-sql-api-check",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CLN: Remove deprecated PANDAS_NEW_SQL_API check (#442)\n\nWas necessary to support pandas version <0.14, which is no longer\r\nsupported by geopandas."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8cfac254a19ac29e3f5",
    "number": 440,
    "body": "I'm interested in having the ability to write to a postgis database (see #189). So far, I've just inverted the existing `read_postgis` function, and put in place a very basic test thereof. I've tested more exhaustively on my own, and it looks like it is behaving almost as expected, though somewhere in writing/reading, the table order is getting changed. \r\n\r\nI had to remove the `if PANDAS_NEW_SQL_API` check; when in, it was causing my tests to hang indefinitely. I couldn't figure out what was going on, or quite understand the rationale behind that check in the first place. I'm sure there is a good reason, and hopefully someone has an idea why it was hanging on my end so I can restore those checks.\r\n\r\nOne difference between the `read_postgis` function is that `to_postgis` requires an `sqlalchemy.engine` instance, rather than a db connection object. \r\n\r\nAt this point, I'm wondering whether the basic direction I'm taking is reasonable, and just get general feedback. I'd like to put in place a better test than what I added (which simply writes the dataframe to the database without checking anything at all), but I'm not totally sure what that would look like.\r\n\r\nFinally, my upstream merges continue to show up in my pull requests, ever since I merged the changes from @IamJeffG to get improved plotting functionality before it was merged to master. Does anyone have any idea what might be causing that?",
    "head_branch": "to_postgis",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8d0ac254a19ac29e3f6",
    "number": 434,
    "body": "closes https://github.com/geopandas/geopandas/issues/377 and https://github.com/geopandas/geopandas/issues/355\r\n\r\nI know you guys are considering overhauling the plotting methods (https://github.com/geopandas/geopandas/issues/405), so I won't mind if you'd rather not merge without a clear concept for geopandas' plottin API. \r\n\r\nthe ``*_kwarg={}`` strategy is the one we follow in xarray, until now without too much trouble (the drawback is the high number of kwargs of course).",
    "head_branch": "legend_kw",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add legend_kwds to plot() (#434)\n\n`plot_dataframe` now accepts a `legend_kwds` argument, through which a user can pass keyword arguments accepted by the call to matplotlib's legend function (if `legend=True`)."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8d1ac254a19ac29e3f7",
    "number": 433,
    "body": "",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8d2ac254a19ac29e3f8",
    "number": 429,
    "body": "This PR addresses #338, #400 and #343 (related also to #330, #233, #404)\r\n\r\nI changed the overlay function, but kept the old one as ``overlay_slow``. Additionally, I added ``test_overlay2`` and some ``qgis`` generated files in datasets for testing. There is an issue with ``union`` and ``ident``, which fail in the tests in ``test_overlay``, which uses the ``Borrows`` shapefile, while it passes the same tests in ``test_overlay2`` when creating basic polygons. It seems the ``qgis`` generated union for the borrows data is not too clean (e.g., missing geometries), so ``test_overlay2`` seems to be correct and shows the function performing correctly. \r\n\r\nCloses #338, closes #400, closes #666",
    "head_branch": "overlay-performance",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "PERF/ENH: new overlay implementation (#429)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8d2ac254a19ac29e3f9",
    "number": 428,
    "body": "xref https://github.com/pandas-dev/pandas/pull/10458 and https://github.com/pandas-dev/pandas/pull/15652",
    "head_branch": "assert-isinstance",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CLN/TST: remove usage of assert_isinstance from pandas (deprecated/removed) (#428)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8d3ac254a19ac29e3fa",
    "number": 427,
    "body": "`pytest` creates a `.cache/` file when it runs, so let's add that to the `.gitignore` to avoid having to delete it when we want to commit (`pandas` already has this).",
    "head_branch": "cache",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "add pytest cache to gitignore (#427)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8d4ac254a19ac29e3fb",
    "number": 425,
    "body": "Closes #423\r\n\r\nFrom the notebook http://nbviewer.jupyter.org/gist/jorisvandenbossche/751809b631f30579b9859e6bf75d2657",
    "head_branch": "test-sjoin",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: add more robust tests for sjoin (GH423) (#425)\n\n* TST: add more robust tests for sjoin (GH423)\r\n* fix right join test\r\n* fix windows test\r\n* use parametrized test + add tests (xfail) for non-default index"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8d5ac254a19ac29e3fc",
    "number": 422,
    "body": "Fixes #352.\r\n\r\n`rtree` allows fewer things in its index than `pandas` does, causing errors when you use a non-int index and try to do an `sjoin` with it. This PR attempts to fix this issue by stashing the actual index in favor of an `int` index and only reattaching The Real Thing at the end of the operation.\r\n\r\n@jorisvandenbossche wanted to get your feedback on this...what do you think of this approach? ",
    "head_branch": "sjoin-index",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: Enable non-integer-indexed GeoDataFrame sjoin operations (#422)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8d6ac254a19ac29e3fd",
    "number": 421,
    "body": "#390 asks that exporting an ID when exporting to GeoJSON be made an optional thing, per the specification. However, @sgillies (who is actually on the spec committee) stepped in and pointed out that this was due to a lack of consensus regarding an error correction in the previous spec and that actually having a meaningful ID is part of best practices.\r\n\r\nIn light of that I'm opposed to making exporting an ID optional, and in favor of making the ID exported meaningful. This PR is a tiny change that does the latter by replacing `str(i)` (the column number) with `str(row.name)` (the column index entry) in the export.",
    "head_branch": "meaningful-id",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "CLN: more explicitly use row name as id in features (#421)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8d7ac254a19ac29e3fe",
    "number": 418,
    "body": "to make .dropna() drop na.\r\nSee https://github.com/geopandas/geopandas/issues/314#issuecomment-284180090\r\nTested, it works now:\r\n```\r\nIn [4]: a = gpd.GeoSeries([Point(1,1), Point(2,2), gpd.np.nan, Point(3,3)])\r\nIn [5]: a.dropna()\r\nOut[5]: \r\n0    POINT (1 1)\r\n1    POINT (2 2)\r\n3    POINT (3 3)\r\ndtype: object\r\n```",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8d7ac254a19ac29e3ff",
    "number": 416,
    "body": "Convert coordinates to wgs84 on export, see issue #412 \r\n\r\nTests pass on py 2 and 3, updated docstring",
    "head_branch": "convert_to_wgs84_for_geojson",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: to_json converts to wgs84 as per 2016 geojson spec (#416)\n\nCo-authored-by: Martin Fleischmann <martin@martinfleischmann.net>\r\nCo-authored-by: Joris Van den Bossche <jorisvandenbossche@gmail.com>\r\nCo-authored-by: Brendan Ward <bcward@astutespruce.com>"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8d8ac254a19ac29e400",
    "number": 415,
    "body": "This uses the pandas json libraries for df.to_json.\r\n\r\nAdvantages:\r\n- pandas datetime series can be exported as timestamps or isoformat\r\n- float precision can be set\r\n\r\nDisadvantages:\r\n- can no longer set na='keep' to keep nan's, instead they are converted to null\r\n\r\nI tested it on py2 and 3, added tests, updated docstring (although not iterating each new option)\r\n\r\nWant to add it?",
    "head_branch": "pandas.io.json",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8d9ac254a19ac29e401",
    "number": 414,
    "body": "Closes #381",
    "head_branch": "codecov",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: switch to codecov for coverage testing (#414)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8daac254a19ac29e402",
    "number": 413,
    "body": "Closes https://github.com/geopandas/geopandas/issues/407\r\n\r\nDrop support (at least testing) for python 2.6 and 3.3, pandas 0.15 (and added 019.2 in test matrix) and matplotlib < 1.4\r\n\r\nAlso changed the main test matrix to use python 3.6 instead of 3.5",
    "head_branch": "drop-old",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Drop python 2.6/3.3, pandas 0.15, matplotlib 1.2/1.3 (#413)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8dbac254a19ac29e403",
    "number": 411,
    "body": "This PR uses pandas.io.json.dump for to_json. That means it handles pandas datetimes (see [here](https://github.com/pandas-dev/pandas/blob/v0.19.2/pandas/io/json.py#L22))",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8dbac254a19ac29e404",
    "number": 409,
    "body": "Our tests are still failing for the newest matplotlib 2.0 due to the style changes, so until that is fixed, pin matplotlib to 1.5 on appveyor.",
    "head_branch": "appveyor-mpl",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: fix matplotlib to 1.5.3 on appveyor (#409)\n\nOur tests are still failing for the newest matplotlib 2.0 due to the style changes, so until that is fixed, pin matplotlib to 1.5 on appveyor."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8dcac254a19ac29e405",
    "number": 408,
    "body": "Alternative to #406, and also a simplification of the travis.yml file: remove pip wheel commands (for the more recent versions, wheels are already available on PyPI, for the other ones pip nowadays automatically builds wheels the first time and then use pip cache).",
    "head_branch": "travis-pip-install",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: remove explicit building wheels - wheels are now available on PyPI - use pip cache (#408)\n\n* TST: remove building wheels - wheels are now available on PyPI\r\n\r\n* add pip cache\r\n\r\n* also remove pip wheel for pandas/matplotlib\r\n\r\n* don't remove cython for master builds"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8ddac254a19ac29e406",
    "number": 406,
    "body": "Travis (pip) is automatically downloading the latest numpy (0.12), which does not support python 2.6 and 3.3 anymore, therefore travis is failing. \r\nWill open an issue to remove support for those python versions, but in the meantime a fix.",
    "head_branch": "travis-old-versions",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8deac254a19ac29e407",
    "number": 403,
    "body": "",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix some sindex issue (#403)\n\nrename _sindex_valid to _sindex_generated to make it more understandable"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8dfac254a19ac29e408",
    "number": 394,
    "body": "Maybe since `cascaded_union` is deprecated, this does not really\r\nmatter, but `gdf.unary_union` works, while `gdf.cascaded_union`\r\ndid not, and I thought as long as both are supported they should\r\nbehave the same way.\r\n\r\nBTW, I'm seeing three test failures on plotting, but they are evidently\r\nunrelated to this pull request. I'm guessing it is due to having\r\nupgraded to matplotlib 2.0.0, but I'll look into it a bit more.",
    "head_branch": "cascade-property",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Match property behavior of cascaded_union to match unary_union (#394)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8dfac254a19ac29e409",
    "number": 389,
    "body": "",
    "head_branch": "fix-dissolve-looses-crs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix dissolve retains crs (#389)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8e0ac254a19ac29e40a",
    "number": 386,
    "body": "So we also test on windows",
    "head_branch": "appveyor",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: skip sindex tests on appveyor for now"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8e1ac254a19ac29e40b",
    "number": 385,
    "body": "Fix link to pandas contribution guidelines. Though they are fairly extensive, and perhaps overkill, so perhaps the line should be removed?",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Update CONTRIBUTING.md (#385)\n\nFix link to pandas contribution guidelines."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8e2ac254a19ac29e40c",
    "number": 384,
    "body": "Closes https://github.com/geopandas/geopandas/issues/295, closes https://github.com/geopandas/geopandas/issues/368\r\n\r\nxref https://github.com/geopandas/geopandas/pull/373\r\n\r\nTo avoid changing geometries or changing download links with future updates, and to have the dataset more easily available as example dataset, I included the zip file in the source and made it available through `geopandas.datasets`",
    "head_branch": "nybb-datasets",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add NYC borough boundaries as included dataset (#384)\n\n* Add NYC borough boundaries as included dataset\r\n\r\n* TST: add tests for the datasets\r\n\r\n* Add readme for datasets directory with attribution\r\n\r\n* add description to README"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8e3ac254a19ac29e40d",
    "number": 383,
    "body": "@jorisvandenbossche brought up the possibility of adding x/y as attributes for point geoseries in #246. It seemed there was enthusiasm there for this functionality, if not consensus on what exactly the behavior should be. This is a first crack at providing that functionality for points, with sensible behavior for polygons.",
    "head_branch": "xy-attr-246",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: add access to x/y coordinates of point geoseries (#246) (#383)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8e4ac254a19ac29e40e",
    "number": 382,
    "body": "I just set up the two new classes, one each for point and polygon testing, that inherit the tests for the x/y cases, but instead test points/polygons that are x/y/z. Possibly slight overkill, but it doesn't add too much time to testing.\r\n\r\nAlso, I'm not sure what happened with the commit history so that it is including all my recent merges. I can try to clean that up if that is an issue.\r\n\r\nLet me know if more would be useful to close #268.",
    "head_branch": "test-z-plot",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Add tests for plotting points/polys with z coord. (#382)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8e4ac254a19ac29e40f",
    "number": 380,
    "body": "Alternative for #347 from @perrygeo. \r\nSince travis is already using pytest, I just removed the remaining usage of nose.\r\n\r\nCloses #347",
    "head_branch": "pytest",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: switch remaining nose to pytest (#380)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8e5ac254a19ac29e410",
    "number": 379,
    "body": "Closes #378 \r\n\r\nUse ordered dict from meta[\"schema\"][\"properties\"] with column order, as suggested by @jorisvandenbossche.\r\n\r\nI added a couple of lines to `TestIO.test_read_file` verifying that the column order matches. In doing so, I needed to convert the fiona column names to lower case to match a conversion happening to the geodataframe. I see that `validate_boro_df` has the columns in lower case, presumably motivating that lower case transformation in `test_read_file`, but it wasn't clear to me why it was necessary in `validate_boro_df`.",
    "head_branch": "issue-378v2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "ENH: preserve column order in read_file (#378) (#379)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8e6ac254a19ac29e411",
    "number": 374,
    "body": "The geometry columns were hardcoded in the sjoin operation, meaning if a user renamed their geometry column, the function would fail. Or worse yet, if a second geometry column were generated with a different name and set as the default geometry column, the sjoin operation would still run on the column named \"geometry,\" unbeknownst to the user.\n\nThis PR ensures the actual default geometry column is called during sjoin operations.\n",
    "head_branch": "sjoin-use-true-geom-column",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Changes hard-coded reference to geometry column in sjoin operation (#374)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8e7ac254a19ac29e412",
    "number": 373,
    "body": "I was able to find what appears to be the updated and only available zip file that is consistent with what the nybb_16a.zip file contained.\n\nUnfortunately, the number of fields in the shapefiles appear to be different, and the hardcoded shapes that are used for verifying geodataframe shapes are no longer valid.\n\nFor example, the test below fails because the number of fields in the shapefile differs from the hardcoded reference tuple:\n\n```\nFAIL: test_intersection (geopandas.tests.test_overlay.TestDataFrame)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/Users/nickg/geopandas/geopandas/tests/test_overlay.py\", line 62, in test_intersection\n    self.assertEquals(df.shape, (68, 7))\nAssertionError: Tuples differ: (67, 7) != (68, 7)\n```\n\nIt seems more work is needed to make the tests valid again given the new shapefile.\n",
    "head_branch": "fix-nybb-download",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: nybb zip file no longer exists. (#373)\n\n* Referencing the new nybb file uploaded to the geopandas repo seems to do the trick"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8e8ac254a19ac29e413",
    "number": 372,
    "body": "Closes #371\n\nThis is a quick fix that ensures filtered results from Fiona's `filter` function are used to populate the `GeoDataFrame`. Previously, the entire selection of features were returned whether or not the `bbox` keyword argument was passed in while using `geopandas.read_file`.\n",
    "head_branch": "fiona-bbox-filter-fix",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: fixed fiona filter results where bbox is not None (#372)\n\n* fixed fiona filter resulsts where bbox is not None\r\n\r\n* adds test to ensure bbox used in read_file returns a filtered subset of features"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8e9ac254a19ac29e414",
    "number": 364,
    "body": "separate spatial_index function might be of use for \"millions_to_hundreds\" sjoint, where we split data into chunks and don't want to generate a rtree.Index for each chunk once again\n",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8e9ac254a19ac29e415",
    "number": 362,
    "body": "xref https://github.com/geopandas/geopandas/issues/361\n\nSeems I forgot the `cmdclass` in setup.py \nTested it, and now it generates the correct version in the packaged source.\n",
    "head_branch": "fix-versioneer",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix usage of versioneer in setup.py (#362)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8eaac254a19ac29e416",
    "number": 360,
    "body": "Closes #359 \n",
    "head_branch": "359-invalid-scheme-exception",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "VIS: rraise ValuError on unsupported scheme, fixes #359: (#360)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8ebac254a19ac29e417",
    "number": 358,
    "body": "Closes #356 \n",
    "head_branch": "356-k-inrange",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "VIS: let PySAL use its own logic for k, fixes #356 (#358)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8ecac254a19ac29e418",
    "number": 349,
    "body": "Tests were using 0.18.0, while 0.18.1 is the latest release.\n",
    "head_branch": "testing-pd0181",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: test with latest 0.18.x pandas release (#349)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8ecac254a19ac29e419",
    "number": 347,
    "body": "Looks like nose is needed to run the tests.\n\nAlso note that [nose is in maintenance mode](http://nose.readthedocs.io/en/latest/#note-to-users) and no longer recommended. Moving to py.test would be a solid alternative.\n",
    "head_branch": "nose-test-requirement",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8edac254a19ac29e41a",
    "number": 344,
    "body": "Remove outdated TODO section and add links to docs.\n",
    "head_branch": "readme-update",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge pull request #344 from geopandas/readme-update\n\nupdate README and setup.py"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8eeac254a19ac29e41b",
    "number": 343,
    "body": "Added some more tests for `overlay` comparing to actual output (so using simple example dataframe like in docs, and not only checking shape). \nWanted to do this before #338 to ensure the perf improvements do not change the output.\n",
    "head_branch": "overlay-tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: more thorough testing of overlay (#343)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8efac254a19ac29e41c",
    "number": 342,
    "body": "This changes the behavior of `set_geometry()` in the case of a geometry column not named `geometry`, but I believe the previous behavior was incorrect. Previously, passing in a column to `set_geometry()` would always create a column called `geometry`, and leave the existing geometry column if it had a different name. This change will honor the geometry column name, and overwrite the existing one (as it already did in the case of a column actually called `geometry`).\n\nFix #339.\n",
    "head_branch": "bug/set_geometry",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "BUG: Use _geometry_column_name in set_geometry() (#342)\n\n* BUG: Use _geometry_column_name rather than default name\r\n\r\n* TST: Add a test for to_crs() with different geometry column name\r\n\r\n* TST: Remove assertions that no longer hold for set_geometry()\r\n\r\n* TST CLN: simpler to use rename()\r\n\r\n* TST: comment instead of docstring for test method"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8f0ac254a19ac29e41d",
    "number": 341,
    "body": "Forgot to change this in #331 (switch to versioneer). \nAn installed geopandas version is needed in any case to build the docs (the example are run during doc build), so this should not be a problem.\n",
    "head_branch": "version-doc",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge pull request #341 from jorisvandenbossche/version-doc\n\nDOC: remove hardcoded version (leftover after #331)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8f1ac254a19ac29e41e",
    "number": 340,
    "body": "This should solve #333 for now. \nI don't think the pdf and epub versions of the documentation are really essential.\n",
    "head_branch": "readthedocs-formats",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: disable other formats on readthedocs (for faster build) (#340)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8f1ac254a19ac29e41f",
    "number": 338,
    "body": "This improves the performance of the overlay on the countries/capitals dataset from 25.9 s to 12.5 s on my computer.\n\nI did not change the logic of the implementation (looking at that could maybe also give some additional performance reduction opportunities), but just optimized the current logic, including:\n- not concatting inside the for loop, but collecting the row labels and concatting once after the for loop\n- using `iat` instead of `ix`\n\nTested with (example from the docs):\n\n```\nimport geopandas as gpd\nworld = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\ncapitals = gpd.read_file(gpd.datasets.get_path('naturalearth_cities'))\ncountries = world[['geometry', 'name']]\ncountries = countries.to_crs('+init=epsg:3395')[countries.name!=\"Antarctica\"]\ncapitals = capitals.to_crs('+init=epsg:3395')\ncapitals['geometry']= capitals.buffer(500000)\n\ngpd.overlay(countries, capitals, how='intersection')\n```\n\nTODO:\n- [ ] add some more tests (including tests for dataframes with non default (0,1,2, ...) row indices)\n",
    "head_branch": "perf-overlay",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8f2ac254a19ac29e420",
    "number": 337,
    "body": "I added examples of the different overlay 'how' methods using the same dummy/simple example GeoDataFrame. \n\nUsing a simple example makes it easier to see what the different methods do, I think, and it also helps to reduce the time to build the docs.\n\nSimilar output can be seen at http://nbviewer.ipython.org/d993c25e0ea8111778599990fb2da2bd\n",
    "head_branch": "doc-overlay-simple",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add overview of overlay methods (#337)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8f3ac254a19ac29e421",
    "number": 336,
    "body": "",
    "head_branch": "docstrig-tools",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: update docstrings of overlay and sjoin (#336)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8f4ac254a19ac29e422",
    "number": 335,
    "body": "This is a fix for issue https://github.com/geopandas/geopandas/issues/251 \n\nThe problem is an obscure error when performing an sjoin where the result of sjoin has no overlapping geometries. Now instead of an error it returns an empty GeoDataFrame on inner join as well as left_df and right_df when performing respectively left and right joins.\n\nThe only pieces of code are the added if, else part with handling of empty results.\n",
    "head_branch": "issues251",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fix for issue 251  (#335)\n\n* Fixes problem with obscure error when performing an sjoin and the result of sjoin has no overlapping geometries. Now returns an empty GeoDataFrame.\r\n\r\n* Added tests for sjoin correctly returning the GeoDataFrame when join result is empty. The test verifies whether the output GeoDataFrames correspond to those who would result in a Pandas join.\r\n\r\n* Indention of test, as it was erronously placed outside class\r\n\r\n* Added new tests for verifying correct merge when no overlapping geometries.\r\n\r\n* Updated tests so they test whether the outputed GeoDataFrames equal the inteded ones.\r\n\r\n* Updated tests again to include import of pandas.\r\n\r\n* Skip the test if version of Pandas is below 0.17\r\n\r\n* Minor changes for style and simplicity suggested by jorisvandenbossche.\r\n\r\n* Added functionality to handle new output for more recent version of Pandas (i.e. from > 0.18.1). This is relevant for the output of right sided merges when there are no overlapping geometries.\r\n\r\n* Fixed test for sjoin where right_idxs were constructed erroneously.\r\n\r\n* Additional fix in test for sjoin where right_idxs for inner and left join were constructed erroneously."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8f5ac254a19ac29e423",
    "number": 332,
    "body": "Needed for new mapping and merging docs (currently the build was failing on readthedocs)\n",
    "head_branch": "doc-fix",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: add rtree and pysal to doc requirements (needed for new mapping and merging docs) (#332)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8f6ac254a19ac29e424",
    "number": 331,
    "body": "",
    "head_branch": "versioneer",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge pull request #331 from jorisvandenbossche/versioneer\n\nMNT/BLD: use versioneer"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8f6ac254a19ac29e425",
    "number": 328,
    "body": "Closes  #281?\n- Updates tool import paths -- `sjoin` and `overlay` now in root path. \n- Adds dissolve docs\n",
    "head_branch": "final_doc_upates",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "final doc updates (#328)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8f7ac254a19ac29e426",
    "number": 327,
    "body": "Related to https://github.com/geopandas/geopandas/issues/278. Deliberatly skipping the tests until #278 is resolved has the advantage that if other tests start failing in a PR for pandas/matplotlib master, this gets noticed (because now the tests fail anyway).\n",
    "head_branch": "travis-skip-mpl-dev",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "TST: explicitly skip tests that fail with master version of matplotlib (#327)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8f8ac254a19ac29e427",
    "number": 323,
    "body": "Continuation (and resolution?) of #311 \n",
    "head_branch": "dissolve_tweaks",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "dissolve bug fixes (#323)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8f9ac254a19ac29e428",
    "number": 322,
    "body": "Closes #247 \n\nTODO for this PR:\n- [ ] do the same for GeoSeries\n\nTODO for later PR:\n- I now use the metadata of the left/first object, but in the right/other objects can also be GeoDataFrames/Series, with possibly conflicting metadata\n- Eg when concatting with `axis=0`, I think we should check that the metadata are equal and otherwise raise (on different crs or different geometry column) -> https://github.com/geopandas/geopandas/issues/326\n",
    "head_branch": "merge-bug",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "BUG: preserve metadata on merge/concat (#247, #320) (#322)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8faac254a19ac29e429",
    "number": 321,
    "body": "ref #281, docs examples were broken since #312, so fixing references to example data\n",
    "head_branch": "doc-datasets",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: loading example datasets with new method (#321)\n\n* API: provide datasets submodule in top-level namespace\r\n\r\n* DOC: loading example datasets with new method"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8faac254a19ac29e42a",
    "number": 319,
    "body": "Updated the version to the minimum one we are using in the tests (older version we cannot (and do not want) guarantee I think since we are not testing those).\n\n(also removed a notion of the `--pre` tag, as I don't think development versions are uploaded to PyPI\n",
    "head_branch": "doc-pandas-version",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "DOC: update minimum pandas version in install docs (#319)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8fbac254a19ac29e42b",
    "number": 316,
    "body": "Currently, CRS validity isn't checked unless a user attempts to use `to_crs`. This way it's checked when run.\n\nIn addition, if https://github.com/jswhit/pyproj/pull/78 gets integrated, this offers scaffolding to convert all CRS strings to informative CRS strings, so if someone uses an EPSG code, the CRS will be converted to a string with actual parameters. \n\n@micahcochran Here's my interest in keeping `pyproj` #315 \n\n(as evidence of value, note several updates to tests with improper syntax!)\n",
    "head_branch": "crs_as_property",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8fcac254a19ac29e42c",
    "number": 313,
    "body": "Started with a small overview of changes for 0.2\n",
    "head_branch": "changelog",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge pull request #313 from jorisvandenbossche/changelog\n\nAdd changelog for v0.2.0"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8fdac254a19ac29e42d",
    "number": 312,
    "body": "Continuation of #285, closes #282\n\nI think it would be good to have the datasets that are currently used in the documentation easily available to the users, so the documentation is reproducible (users can test out the code snippets easily). \nFor now, I just took the data that @nickeubank included in the docs and put it in a new `datasets` module. The way to use would be like:\n\n```\ncities_shapefile = geopandas.datasets.get_path('naturalearth_cities')\ncities = gpd.read_file(cities_shapefile)\n```\n\nOther option would be to directly return the dataframe, but I like this approach of returning the path, so it is clear this is just reading in a shapefile with the geopandas tools as a user would do with a file of its own. \nThe above approach is similar to `pysal` (they have a much larger set of data included).\n\n@kjordahl \n",
    "head_branch": "sample_data",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge pull request #312 from jorisvandenbossche/sample_data\n\nExpose example datasets through API geopandas.datasets"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8feac254a19ac29e42e",
    "number": 311,
    "body": "Sketch of implementation for  #310. \n\n(Open issues: clean up; catch errors; handle string aggfuncs) \n",
    "head_branch": "add_dissolve",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge pull request #311 from nickeubank/add_dissolve\n\nAdd dissolve method to GeoDataFrame"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8feac254a19ac29e42f",
    "number": 309,
    "body": "Rebase of #253\n",
    "head_branch": "pr/253",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge pull request #309 from geopandas/pr/253\n\nRebase of PR #253 (refactor tests)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d8ffac254a19ac29e430",
    "number": 308,
    "body": "For #281 \n",
    "head_branch": "geometric_docs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Docs for geometric manipulations and overlay (#308)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d900ac254a19ac29e431",
    "number": 307,
    "body": "Closes #305 (by adding informative error for when overlay passed a GeoSeries) and #306 (overlay fixed for geometry columns not named geometry). \n",
    "head_branch": "bug_306",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Fixes 305 and 306 (#307)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d901ac254a19ac29e432",
    "number": 303,
    "body": "Implementation of #302 \n",
    "head_branch": "move_up_sjoin",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge pull request #303 from nickeubank/move_up_sjoin\n\nmove sjoin to top-level namespace"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d902ac254a19ac29e433",
    "number": 301,
    "body": "",
    "head_branch": "join_docs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "updated joining docs (#301)"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d903ac254a19ac29e434",
    "number": 300,
    "body": "Closes #264\n\nDoc strings for plotting were not accessible to the user. This moves them up to associate them with the appropriate methods. \n",
    "head_branch": "move_doc_for_plot",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "moved docs for plotting to more accessible location (#300)\n\n* moved docs for plotting to more accessible location\r\n\r\n* more supportable docs"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d903ac254a19ac29e435",
    "number": 299,
    "body": "Working on improving mapping doc. Part of #281\n\nAnyone have advice on layering maps? Never done myself. \n",
    "head_branch": "improve_mapping_doc",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "updated mapping doc (#299)\n\n* updated maps\r\n\r\n* add cities\r\n\r\n* overlapping layers added\r\n\r\n* tweak to docs\r\n\r\n* both layering options"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d904ac254a19ac29e436",
    "number": 298,
    "body": "Starting with #283 PR from @nickeubank, the docs require a usable installed version of geopandas, because the examples are being built at doc build runtime. Installing these dependencies on read the docs is not done at the moment, and was also somewhat problematic, but they recently added conda support: http://docs.readthedocs.org/en/latest/conda.html\n\nThis PR adds therefore a readthedocs.yml config file and a conda environment file for installing all doc dependencies on read the docs using conda. \nThis is currently working: http://readthedocs.org/projects/geopandas/builds/3894807/, only the docs are not yet fully correct because the example data used in the docs are not available in the installed version (but will open a separate issue for that): http://geopandas.readthedocs.org/en/doc-readthedocs-requirements/index.html\n\n@kjordahl \n",
    "head_branch": "doc/readthedocs-requirements",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge pull request #298 from geopandas/doc/readthedocs-requirements\n\nDOC: add readthedocs yaml config file + use conda for doc deps"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d905ac254a19ac29e437",
    "number": 297,
    "body": "Addresses my remaining comments in PR #283 of @nickeubank \n",
    "head_branch": "doc-cleanup",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge pull request #297 from jorisvandenbossche/doc-cleanup\n\nDOC: some clean-up after #283"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d906ac254a19ac29e438",
    "number": 296,
    "body": "Change download_nybb() to return shapefile name and path within the zip file.   Fix for issue #295   A few changes to make the code a little more maintainable. \n",
    "head_branch": "nybb-fix",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge pull request #296 from micahcochran/nybb-fix\n\nUpdate nybb url."
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d907ac254a19ac29e439",
    "number": 293,
    "body": "Closes #291 \n",
    "head_branch": "add_get_geometry",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d908ac254a19ac29e43a",
    "number": 289,
    "body": "Subject says it all!\n",
    "head_branch": "fixreaddocs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge pull request #289 from nickeubank/fixreaddocs\n\nimprove read_file docstring"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d908ac254a19ac29e43b",
    "number": 288,
    "body": "Closes #292\n\nRight now, the CRS tools won't accept a proj4 string -- it requires they be broken out into a dictionary. But behind the scenes is the pyproj library which can parse proj4 strings. This just adjusts the call to pyproj slightly so `to_crs()` can take proj4 strings in addition to full dictionaries. Dictionaries still work!\n",
    "head_branch": "tweak_crs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge pull request #288 from nickeubank/tweak_crs\n\nmake crs more flexible"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d909ac254a19ac29e43c",
    "number": 287,
    "body": "... has the potential to make geopandas slightly easier to install.  Since geopandas itself it pure python, this should be an extra step during release: `python setup.py sdist bdist_wheel upload`\n\nSee: http://pythonwheels.com/\n",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge pull request #287 from micahcochran/patch-1\n\nUniversal Python Wheel"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d90aac254a19ac29e43d",
    "number": 285,
    "body": "Closes #282\n\nSimple implementation of included shapefiles. In this case, just simple (low-resolution) country map. I think it'll really help writing the updated docs to just be able to import a dataset the user can also just open.\n",
    "head_branch": "correct_embedded_data",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d90bac254a19ac29e43e",
    "number": 284,
    "body": "Closes #282 \n\nSimple implementation of included shapefiles. In this case, just simple (low-resolution) country map. I think it'll really help writing the updated docs to just be able to import a dataset the user can also just open. \n",
    "head_branch": "embed_data",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d90cac254a19ac29e43f",
    "number": 283,
    "body": "Just getting started -- feel free to look, but will ping when in better shape. \n\nNote I'm building off `sphinx_rtd_theme`. To build these docs, first run `pip install sphinx_rtd_theme`. Not sure how to add to library. \n",
    "head_branch": "docs_02",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge pull request #283 from nickeubank/docs_02\n\nUpdated Docs for 0.2 Release"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d90cac254a19ac29e440",
    "number": 277,
    "body": "Add the [pandas 0.18 release](http://pandas.pydata.org/pandas-docs/version/0.18.0/whatsnew.html#v0-18-0-march-13-2016) to the test matrix (for python 2.7 and 3.5 only).\n",
    "head_branch": "pandas-0.18",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d90dac254a19ac29e441",
    "number": 275,
    "body": "matplotlib testing was proposed in PR #243.   Add Pandas 0.18.0 to testing.  Have one requirements.txt file for all versions (remove .requirements-2.6.txt).  Allow MATPLOTLIB=master tests\nto fail (which a few of the tests currently fail).\n",
    "head_branch": "travis-matplotlib",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge 1489a9e8b076e02fdc860c078189d0cde0b922da into 77b9b3b7e87456bb75f569725aa38285ea4e35d0"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d90eac254a19ac29e442",
    "number": 273,
    "body": "This patch calls setUpClass and tearDownClass once. (setUp and tearDown were called once for each test fixture [3-4 times]).  This is very minor change.\n",
    "head_branch": "test-setup-class",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d90fac254a19ac29e443",
    "number": 272,
    "body": "This is not the most beautiful way to change the Travis builds, but it is an attempt at resolving issues raised in PR #243 and Issue #271.  \n\nThis results in 11 test and removes the test combinations aspect of the matrix.  Eight (8) tests focused on testing Python 2.7 and 3.5 with many versions of Pandas.\n\nI did not attempt to add multiple versions of matplotlib to the travis tests.  (I've made a similar travis test \"suite\" for basemap.) I'm not trying to avoid doing that, but I am trying to make sure that this is acceptable before spending too much time on it.\n",
    "head_branch": "travis-changes",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge db68f18bb10f17e5f84e28ee8b9b7e08f6e3f6be into 1451292060fd4d788b6950530040e0712b2f08e6"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d910ac254a19ac29e444",
    "number": 267,
    "body": "~~This doesn't use `Collection.set_array()` because I can't find a way to share\nthe same colorscale across different collection types (i.e. geometry types). To\nkeep different collections in sync with the same colorbar, we must resolve every\ngeometry's colors globally.~~ (Fixed below in 17313dc) But we still gain the performance benefit from\nusing collections.\n\n~~This also adds a legend for noncategorical dataframes. However I deprecated\n`facecolor` kwarg because it conflicts with `color`; discussion for this is at #204.~~\n\nGiven that `TestImageComparisons` caused us so much trouble in Travis, and the\nnew plotting mechanism requires re-generating these plots, I dropped this method\nof testing.  If there are objections, let's discuss the options.\n- [x] ~~Fix plotting Polygon holes. (I've no idea how to do this in a PolygonPatch...)~~ (broken on master too, so deferring to a different PR)\n- [x] Replace a test for `plot(figsize=(...))`, which I removed when removing TestImageComparisons.\n- [x] Smoketest PySAL support\n- [x] Add tests for heterogeneous geometry types in a single GeoSeries.\n- [x] Compatibility with mpl < 1.5\n\nFixes #172 (except for #266 which existed even before this PR)\nFixes #259\nFixes #204 \n",
    "head_branch": "259-plotting-collections",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge pull request #267 from IamJeffG/259-plotting-collections\n\nImplement plotting using matplotlib Collections"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d910ac254a19ac29e445",
    "number": 263,
    "body": "See #262 \n",
    "head_branch": "geoseries_tojson",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge pull request #263 from BibMartin/geoseries_tojson\n\nFix GeoSeries.to_json"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d911ac254a19ac29e446",
    "number": 261,
    "body": "Since rtree is now an optional requirement,  I removed rtree from requirements.txt and put it into requirements.test.txt.  retree is needed for testing, otherwise some unit tests are skipped.\n\n**Edit**: Created contraints.txt and added rtree to it.\n",
    "head_branch": "rtree-req",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge a7753616081a68ee7cd5c6653fbaf0f236160d40 into b49991ef79985fb14665295177a33258b358bd7e"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d912ac254a19ac29e447",
    "number": 260,
    "body": "By passing through the `color_kwds`, you can eg also adapt the markersize for point plots, or the linestyle for line plots. \nAdded a test for those two example cases.\n",
    "head_branch": "plot-point-kwargs",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d913ac254a19ac29e448",
    "number": 258,
    "body": "### geopandas/geopandas now has a Chat Room on Gitter\n\n@jorisvandenbossche has just created a chat room. You can visit it here: [https://gitter.im/geopandas/geopandas](https://gitter.im/geopandas/geopandas?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&content=body_link).\n\nThis pull-request adds this badge to your README.md:\n\n[![Gitter](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/geopandas/geopandas?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=body_badge)\n\nIf my aim is a little off, please [let me know](https://github.com/gitterHQ/readme-badger/issues).\n\nHappy chatting.\n\nPS: [Click here](https://gitter.im/settings/badger/opt-out) if you would prefer not to receive automatic pull-requests from Gitter in future.\n",
    "head_branch": "gitter-badge",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d913ac254a19ac29e449",
    "number": 256,
    "body": "An small update to the install section (correct the the requirements), remove the hard coded version number, added conda with mention of ioos channel, ..)\n",
    "head_branch": "doc-install",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge b11403e62953a2fb6d5e686c7c35e99362c1058e into a304931eba058fe128d5a8775803e429c57ea2c7"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d914ac254a19ac29e44a",
    "number": 255,
    "body": "Let's get the RTD build working again.\n\nThis skips installing requirements when installing on readthedocs. Otherwise it fails on the binary libraries. I did try mocking out the libraries instead of skipping them, as listed [here](http://docs.readthedocs.org/en/latest/faq.html#i-get-import-errors-on-libraries-that-depend-on-c-modules), but that didn't work for me (I must be doing something wrong).\n\nLink for the build associated with this branch: http://geopandas.readthedocs.org/en/doc-readthedocs-requirements\n",
    "head_branch": "doc/readthedocs-requirements",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge c4a41bc0f917bf9dd3cea117f6995de7f4236804 into b3d07f351871f6715cbef006bf88a141004f335f"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d915ac254a19ac29e44b",
    "number": 253,
    "body": "This puts the tests in the main geopandas package, instead of the root level of the repository.\n\nIncludes a few minor additional test cleanups.\n\nFixes #168\n",
    "head_branch": "test/refactor-tests",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d916ac254a19ac29e44c",
    "number": 248,
    "body": "Previously, a value of min=0 was interpreted as False and ignored.\nI added a new test case that failed before and passes now.\n\nI also removed some duplicated entries in the docstring.\n",
    "head_branch": "bugfix-vmin-vmax-zero",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d917ac254a19ac29e44d",
    "number": 244,
    "body": "Drops 0.15.2, adds 0.17.0.\n\ncloses #243\n",
    "head_branch": "test/pandas-0.17",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d917ac254a19ac29e44e",
    "number": 241,
    "body": "Trying to revive #172, which had fallen out of sync with master.  This pull request merges the good work of @ianalis with master.\n\nI had to tell Travis CI to skip the `compare_images` tests (as others have done before me).\n\nThere is one new warning in the test log, emitted from matplotlib and which has been fixed in future versions of matplotlib:\n    https://github.com/matplotlib/matplotlib/issues/5209\n",
    "head_branch": "noncategorical-legend",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d918ac254a19ac29e44f",
    "number": 240,
    "body": "See #208\n",
    "head_branch": "deprecation",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d919ac254a19ac29e450",
    "number": 239,
    "body": "Fix tests after #228\n\n(see also comments here: https://github.com/geopandas/geopandas/pull/186#discussion_r43541233)\n",
    "head_branch": "fix-test-colormap",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d91aac254a19ac29e451",
    "number": 238,
    "body": "Add the ability to specify `color` in `plot()` to plot all points/lines/polygons in a single color.\n\nYou can see it at work in this notebook: http://nbviewer.ipython.org/gist/jorisvandenbossche/47e6d587eec39a8357f0#\n",
    "head_branch": "plot-full-color",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge 9c2d84c8949e7feccada63dfa40b84fc16f0432c into 3489dcee24f40821f185c2347f133fb0465a7dc3"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d91bac254a19ac29e452",
    "number": 231,
    "body": "This commit relates to #230 \n\nNeed to work on test coverage.\n",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d91cac254a19ac29e453",
    "number": 229,
    "body": "This PR fixes the problem mentioned in Issue #204 where one cannot pass a fixed color to `plot_series` or `plot_dataframe`. Before the PR, the following line:\n\n``` python\ndf.plot(facecolor='white')\n```\n\nReturns the error that `facecolor` is referenced twice. This is solved with the patch.\n\nIn addition, the patch also allows related problems also mentioned in the issue, where arguments for `plot_linestring` and `plot_point` are not passed properly.\n\nAfter the patch, all the tests continue passing locally.\n",
    "head_branch": "fix_facecolor_conflict",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d91dac254a19ac29e454",
    "number": 228,
    "body": "This PR is an easy fix for #208 which replaces every instance of `axes` for `ax` and every `colormap` for `cmap` in the `plot_series` and `plot_dataframe` methods. This makes the plotting interface for geo objects much more inline with that of `pandas` for non-spatial plots. The PR includes an adaptation of the tests, and everything passes locally.\n",
    "head_branch": "fix208",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d91dac254a19ac29e455",
    "number": 224,
    "body": "Added a test case for to_file function in the tests/test_io.py.\n",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d91eac254a19ac29e456",
    "number": 222,
    "body": "When Shapely geometries become unhashable, this behavior is no longer\nsupported.\n\nSee #221.\n",
    "head_branch": "unhashable_geometries",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d91fac254a19ac29e457",
    "number": 220,
    "body": "Inspired by the speedups achieved [in rasterio](https://github.com/mapbox/rasterio/pull/474), these changes run the Travis builds on the new container-based infrastructure and build wheels for the dependencies. The wheels are cached so that subsequent builds will be much faster.\n\nWith the addition of [libspatialindex-dev](https://github.com/travis-ci/apt-package-whitelist/issues/1100) to the travis apt package whitelist, all of the system deps are available in the containers.\n\nPandas master still requires a build but the pandas stable releases use pypi and build cacheable wheels.\n\nAfter the initial build, I'm seeing travis runs completing 2-4x faster. \n\nResolves #125 \n",
    "head_branch": "travis_container",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d920ac254a19ac29e458",
    "number": 218,
    "body": "Closes #217\n\nMost things were already inplace to have this optional, and I think with this it should be ok.\n",
    "head_branch": "rtree",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d921ac254a19ac29e459",
    "number": 216,
    "body": "Sync the document with the currently used version of `geopy`, as referenced\nin the `requirements.test.txt` document. The 1.10.0 is immune to the Python 3\nissue originally reported, remove the note.\n",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge dcaf2794147295eb4bca4c0d99b109228deec9d6 into 533d80419039eeaa702680636a6a49fdb1019dbf"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d921ac254a19ac29e45a",
    "number": 213,
    "body": "I'm using spatial joins again, after dropping it abruptly last winter. Thanks again for adding this great functionality!\n\nThere are a few things here. I find that there's an import missing from the `tools` module's `__init__.py`. This works for me.\n\nI updated the notebook about spatial joins... but I'm on Jupyter 4.0, so that notebook is now updated. Don't know if that's a problem? In the notebook, I removed a missing link, and added a missing file. \n\nI see #203 and assume that's [this file](https://github.com/geopandas/geopandas/blob/master/doc/source/user.rst)? I think I could add something there.\n\nPS Sorry for PR'ing on master... I'm new at this :) I trust you know how to deal with it. If you need me to put this on another branch, just let me know.\n",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d922ac254a19ac29e45b",
    "number": 212,
    "body": "Currently if you try to geocode `['123 Valid Address ...', 'n/a', ...]` the `geopandas.geocode.geocode` command will throw a `TypeError` when it tries to unpack the result for the `n/a` row. This causes the whole thing to fail. I would rather it just skipped that in the output.\n",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d923ac254a19ac29e45c",
    "number": 211,
    "body": "I added this because descartes does not accept polygons with a z coordinate. I could imagine wanting to do something a bit more sophisticated when the z coordinate contains interesting information, but in the meantime, this is nicer behavior than raising an exception.\n\nI would not ordinarily have put the shapely import inside the if statement, but from the descartes import within the function, I guessed there was some desire to limit global imports. \n",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d924ac254a19ac29e45d",
    "number": 210,
    "body": "Based on a SO question, I added the ability to create a legend for choropleth figures based on PySAL schemes (see my answer: http://stackoverflow.com/questions/31755886/choropleth-map-from-geopandas-geodatafame?noredirect=1#comment51555293_31755886 and the notebook: http://nbviewer.ipython.org/gist/jorisvandenbossche/d4e6efedfa1e4e91ab65)\n\nThis lets you obtain something like:\n\n![index](https://cloud.githubusercontent.com/assets/1020496/9069130/dce6287e-3ae7-11e5-8151-4b8d74c415d5.png)\n",
    "head_branch": "plotting-pysal-legend",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d925ac254a19ac29e45e",
    "number": 209,
    "body": "",
    "head_branch": "support_figsize",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d926ac254a19ac29e45f",
    "number": 207,
    "body": "These allow adjusting the min/max value used for the colormap.\n",
    "head_branch": "colormap_vmin_vmax",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d926ac254a19ac29e460",
    "number": 206,
    "body": "Fixes #199 to correctly serialize/deserialize `crs` attribute. Not implemented for `GeoSeries` here, only for `GeoDataFrame`. A cleaner fix will be to do this upstream, as submitted in pydata/pandas#10557.\n",
    "head_branch": "bug/pickle-crs",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge ddf08b7b82af25b1cd9d545abe2911654623e824 into 327e84e676b75f8dc2eb130f61bb201e58c736ee"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d927ac254a19ac29e461",
    "number": 202,
    "body": "Use most recent geopy release and fix API accordingly.\n\nCloses #200  \n",
    "head_branch": "geopy-version",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge c785db02250e7a7ebf8792af1e66772c7bbad47b into 6163bc92ab501c571e98bde737d80c464a9f50cc"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d928ac254a19ac29e462",
    "number": 201,
    "body": "Use the latest pandas release in tests.\n",
    "head_branch": "test/update-pandas-version",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d929ac254a19ac29e463",
    "number": 194,
    "body": "Small cleanup to address my [comment](https://github.com/geopandas/geopandas/pull/193#discussion_r29402616) on #193.\n",
    "head_branch": "clean/add-kwarg-null-value",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d929ac254a19ac29e464",
    "number": 193,
    "body": "This copy includes commits in stale P.R. #156.  I'm re-posting under my account to be able to iterate and get it merged, toward issue #139.\n\nI'm not 100% acquainted with all these commits quite yet, but I am willing to figure it out, discuss the design, and iterate as necessary.\n",
    "head_branch": "139-missing-geoms",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d92aac254a19ac29e465",
    "number": 192,
    "body": "The test versions of pandas used on Travis were out of date. This updates `travis.yml` to use 0.15.2 and 0.16.0, the latest 2 major releases, as well as master.\n",
    "head_branch": "test/pandas-ci-versions",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 9d6f81bdb6f130920b9ef109284f9a8187924a25 into c4d56a309331daee2cd91057763998814b4978ab"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d92bac254a19ac29e466",
    "number": 191,
    "body": "Fix for second issue mentioned in #190.\n",
    "head_branch": "bug/sjoin-index",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 15b2b450d077f80b1d11a7401a2556d329bcecef into 1cc916cc9490faa6ec914b0efd39fae685d132df"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d92cac254a19ac29e467",
    "number": 188,
    "body": "This PR increases the performance of geopandas' spatial join function (sjoin.py). The work is based largely on @perrygeo's original work, but introduces a number of optimizations that (a) improve the speed of the join, and (b) reduce memory consumption, allowing the function to handle larger datasets.\n\nPerformance increases are primarily achieved by vectorizing operations that were previously handled through iteration (e.g. querying the Rtree index, checking binary predicates). Performance increases are also obtained by generating 'prepared geometry' instances using the `shapely.prepared` package.\n\nSample speed tests are shown below. The original sjoin function is indicated by `tools.sjoin` while the new sjoin function is indicated by `fast_sjoin`. Join speed is increased by about an order of magnitude for a small dataset (23,000 polygons), by about 14x for a medium dataset (200,000 polygons) and by almost 20x for a large dataset (600,000 polygons).\n#### Test 1: ~23000x1500 polygons\n\n```\nIn [2]: (l_df.shape, r_df.shape)\nOut[2]: ((1526, 10), (22669, 9))\n\nIn [3]: %timeit fast_sjoin(l_df, r_df, op='contains')\n1 loops, best of 3: 4.13 s per loop\n\nIn [4]: %timeit tools.sjoin(l_df, r_df, op='contains')\n1 loops, best of 3: 53.9 s per loop\n\n```\n#### Test 2: ~200000x1500 polygons\n\n```\nIn [2]: (l_df.shape, r_df.shape)\nOut[2]: ((1526, 10), (201853, 9))\n\nIn [3]: %timeit fast_sjoin(l_df, r_df, op='contains')\n1 loops, best of 3: 31.8 s per loop\n\nIn [4]: %timeit tools.sjoin(l_df, r_df, op='contains')\n1 loops, best of 3: 7min 27s per loop\n\n```\n#### Test 3: ~600000x1500 polygons\n\n```\nIn [2]: (l_df.shape, r_df.shape)\nOut[2]: ((1526, 10), (598502, 9))\n\nIn [3]: %timeit fast_sjoin(l_df, r_df, op='contains')\n1 loops, best of 3: 2min 9s per loop\n\nIn [4]: %timeit tools.sjoin(l_df, r_df, op='contains')\n1 loops, best of 3: 37min 12s per loop\n```\n\nLet me know what you think!\n\nThanks,\nMDB\n\nNote: special cases (namely, point-in-polygon joins) can probably be optimized further using the `shapely.vectorized` module. However, I haven't implemented these special cases yet.\n",
    "head_branch": "spatial_join",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d92dac254a19ac29e468",
    "number": 187,
    "body": "This PR increases the performance of geopandas' spatial join function (sjoin.py). The work is based largely on @perrygeo's original work, but introduces a number of optimizations that (a) improve the speed of the join, and (b) reduce memory consumption, allowing the function to handle larger datasets.\n\nPerformance increases are primarily achieved by vectorizing operations that were previously handled through iteration (e.g. querying the Rtree index, checking binary predicates). Performance increases are also obtained by generating 'prepared geometry' instances using the `shapely.prepared` package.\n\nSample speed tests are shown below. The original sjoin function is indicated by `tools.sjoin` while the new sjoin function is indicated by `fast_sjoin`. Join speed is increased by about an order of magnitude for a small dataset (23,000 polygons), by about 14x for a medium dataset (200,000 polygons) and by almost 20x for a large dataset (600,000 polygons).\n#### Test 1: ~23000x1500 polygons\n\n```\nIn [2]: (l_df.shape, r_df.shape)\nOut[2]: ((1526, 10), (22669, 9))\n\nIn [3]: %timeit fast_sjoin(l_df, r_df, op='contains')\n1 loops, best of 3: 4.13 s per loop\n\nIn [4]: %timeit tools.sjoin(l_df, r_df, op='contains')\n1 loops, best of 3: 53.9 s per loop\n\n```\n#### Test 2: ~200000x1500 polygons\n\n```\nIn [2]: (l_df.shape, r_df.shape)\nOut[2]: ((1526, 10), (201853, 9))\n\nIn [3]: %timeit fast_sjoin(l_df, r_df, op='contains')\n1 loops, best of 3: 31.8 s per loop\n\nIn [4]: %timeit tools.sjoin(l_df, r_df, op='contains')\n1 loops, best of 3: 7min 27s per loop\n\n```\n#### Test 3: ~600000x1500 polygons\n\n```\nIn [2]: (l_df.shape, r_df.shape)\nOut[2]: ((1526, 10), (598502, 9))\n\nIn [3]: %timeit fast_sjoin(l_df, r_df, op='contains')\n1 loops, best of 3: 2min 9s per loop\n\nIn [4]: %timeit tools.sjoin(l_df, r_df, op='contains')\n1 loops, best of 3: 37min 12s per loop\n```\n\nLet me know what you think!\n\nThanks,\nMDB\n\nNote: special cases (namely, point-in-polygon joins) can probably be optimized further using the `shapely.vectorized` module. However, I haven't implemented these special cases yet.\n\nAlso note: I am in the process of tweaking the spatial join tests because the output format is currently a little bit different than in the previous implementation.\n",
    "head_branch": "spatial_join",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d92dac254a19ac29e469",
    "number": 186,
    "body": "This PR let's you specify a colormap for `Point` plots.\n\nSome questions:\n- this changes the default colors: now it are the colors from the default matplotlib color cycle. Is this a problem? (I rather think this makes it more consistent with Linestrings/Polygons)\n- the docstring of `plot_dataframe` says that the default for `colormap` is 'Set1', but the actual signature uses `None` -> therefore the default matplotlib colormap 'jet' is used\n- how should this be tested? Adding an image to compare with? Or I can also just check the actual color on the `ax` object\n",
    "head_branch": "plot-colorbar",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d92eac254a19ac29e46a",
    "number": 183,
    "body": "Added `linewidth` and `vmin`, `vmax` arguments to `plot_dataframe`. The latter are especially important when generating a series of subplots so that the scales can be standardized across plots.\n",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d92fac254a19ac29e46b",
    "number": 180,
    "body": "This is mostly to be able to turn off lines by setting `linewidth=0`\n",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d930ac254a19ac29e46c",
    "number": 178,
    "body": "Add a schema argument in GeoDataFrame.to_file to pass in to Fiona.\nAllows for finer control over how the data gets written.\n\nRefactor to_file into geopandas.io.file.\n\nAddresses #177 \n",
    "head_branch": "write_schema",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d931ac254a19ac29e46d",
    "number": 173,
    "body": "add the ability to pass `edgecolor` to `plot_dataframe`, `plot_series`\n",
    "head_branch": "plot-edge-options",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d931ac254a19ac29e46e",
    "number": 172,
    "body": "This PR implements the `legend` option for noncategorical dataframes which, up to now, returns a `NotImplementedError`. Since there is no easy method of accessing the legend of an axes that I'm aware of, `plot_dataframe()` will also return the colorbar aside from the axes. Additional tests and appropriate changes in the documentation were also added.\n",
    "head_branch": "noncategorical-legend",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d932ac254a19ac29e46f",
    "number": 170,
    "body": "Replaces #163 - now with 4 small commits. Tests pass now that 3.2 is no longer supported.\n- Fixes a few tests to assign to subset of rows using `.loc[...]` instead of trying to assign to a view or copy\n- Use `if pd.notnull(item)` instead of `if item` when generating the rtree stream input. `if item(np.nan)` returns True!!\n- The `interiors` property returns a `Series` instead of a `GeoSeries` as it's not really a proper `geometry` and caused issues when the index was being generated.\n- Fix `unary_union` to work on `GeoDataFrame`.\n",
    "head_branch": "four_fixes",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge be618726af51729b0ae10a6e058d917511d29b84 into a4a88c7e96c758f2d50e7af907b3616ceb376a4d"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d933ac254a19ac29e470",
    "number": 169,
    "body": "Is anyone using GeoPandas with 3.2? And would anyone object to dropping support for it? We'll still support 3.3 and up.\n\nWe've been having problems with geopy and now Fiona on 3.2 (https://travis-ci.org/jwass/geopandas/jobs/37751221#L544). Those libraries don't try to support 3.2. The errors are due to 3.2 not supporting unicode literals, e.g. `u'blah'` is `SyntaxError` in 3.2. Unicode literals were reintroduced in 3.3. \n\nAlso, dropping some Travis runs wouldn't be so terrible either :)\n\nOtherwise we need the dependencies to support 3.2, which seems to be less common.\n",
    "head_branch": "no3.2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge 01763d35db72fc00afe646adde8835dbc5c13951 into 35c2f5b74ce8d0684670467cfd94b3adba239f27"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d934ac254a19ac29e471",
    "number": 163,
    "body": "There are 3 small commits here. For whatever reason, the 3.2 builds in Travis are all hanging on the matplotlib install right now but are not failing...\n- Fixes a few tests to assign to subset of rows using `.loc[...]` instead of trying to assign to a view or copy\n- Use `if pd.notnull(item)` instead of `if item` when generating the rtree stream input. `if item(np.nan)` returns True!!\n- The `interiors` property returns a `Series` instead of a `GeoSeries` as it's not really a proper `geometry` and caused issues when the index was being generated.\n",
    "head_branch": "small_fixes",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d935ac254a19ac29e472",
    "number": 159,
    "body": "I've been burned enough times by the `GeocoderTimedOut` errors, which cause us to restart the Travis builds This makes each Travis run to take at least 15 minutes longer. See #143.\n\nUse the `mock` library to mock geopy's geocoding calls for our round-trip tests. The mocked methods are the `geocode` and `reverse` methods of one of the geocoders, which is GeoPandas interface to geopy.\n",
    "head_branch": "mock_geocode_tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d935ac254a19ac29e473",
    "number": 158,
    "body": "Before this commit, a new rtree is generated with each new GeoPandas object even though it might not be needed. For example:\n\n```\ndf = gpd.read_file(...)\ndf.to_crs(epsg=4326, inplace=True)\ndf_filtered = df[df['column'] == 'value']\n```\n\nThe above code would re-create the rtree 3 times even though we never use it. This can be fairly expensive. Instead, don't compute it until it's first requested, then cache it and re-use.\n\nWe'll have to be careful to call `_reset_sindex()` on any inplace geometry updates (only implemented with `set_geometry` for now). See also #128.\n\nThe downside of this approach is that it could seem like inconsistent runtime performance since it may not be obvious where/when the index is created. Another option would be to decide whether a spatial index should be generated on a per-GeoSeries/GeoDataFrame level. This would be more like PostGIS where we can default to off and then create the index only when explicitly told.\n",
    "head_branch": "lazy_build_sindex",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge 02a05376a13cbaeb59e4d867fe3fcafe9f6fb43d into cb62e9f80bbd5e3cf695898ca01e2a1009e73a5d"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d936ac254a19ac29e474",
    "number": 157,
    "body": "Fix the tests and Travis build.\n\nThis builds on @kjordahl's #150. It re-enables the tests on Pandas master and fixes the failing tests. (#155).\n\nIn the latest Pandas, `Index` no longer subclasses `ndarray` so some of the arithmetic methods were dropped, particularly `__mod__` which caused the failed test.\n",
    "head_branch": "fix_travis",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d937ac254a19ac29e475",
    "number": 156,
    "body": "This PR allows for more graceful handling of null geometries; as mentioned in https://github.com/geopandas/geopandas/issues/138 and https://github.com/geopandas/geopandas/issues/139.\n\nMain improvements include:\n- to_file and from_file handle read/write of null geometries\n- Various geometric operations return nan, None or False.\n",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d938ac254a19ac29e476",
    "number": 154,
    "body": "Just make sure to add `libgdal1h` to the packages installed to make sure that it's finding the ubuntugis version ([reference](http://lists.osgeo.org/pipermail/ubuntu/2014-August/001141.html)).\n\nFixes #150.\n",
    "head_branch": "bug/install-libgdal1h-first",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 95d2e20fe59af0ace72c3ab2faef1e0157a4735e into cbf604a34b2fffd1126fa7d91e30f754ca8199fb"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d939ac254a19ac29e477",
    "number": 153,
    "body": "",
    "head_branch": "152-debian",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d939ac254a19ac29e478",
    "number": 151,
    "body": "```\ntools.geocoding delegates finding a geocoder to geopy.\n\nGeocoding results are handled as geopy.location.Location objects,\nand altitude is added to shapely.geometry.Point objects.\n\nNone results from geocoding results are handled better.\n\ngeopy is upgraded to >=1.1.0.\n```\n\nI saw this is being used, and thought I'd provide a better interface. Let me know if I've misunderstood something about the use or you have other feedback.\n",
    "head_branch": "geopy_interface",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d93aac254a19ac29e479",
    "number": 149,
    "body": "This PR uses the `imp` library to dynamically load the requested PySAL map classification scheme, which no longer restricts users to the three hard-coded classification methods previously provided. It'll default to 'Quantiles' as before if the requested method isn't found.\n\nCaveat:\n\n`imp` is pending deprecation (though included) as of Python 3.5, and the use of `importlib` is recommended instead, but Python 2.6 doesn't include `importlib`, though it's available to be installed from PyPI, and _could_ be provided as a conditional requirement based on the python version.\n\nMore generally: should this functionality be moved to `geopandas.tools` (if only to discourage the proliferation of choropleth maps?)\n",
    "head_branch": "simple_choro",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d93bac254a19ac29e47a",
    "number": 148,
    "body": "Move geocoding capability into the tools module.\n\nMoves `geocode.py` to `geocoding.py` and exposes `geocode()` and `reverse_geocode()` in the `tools` module. I think this is the last piece to close #135.\n",
    "head_branch": "geocoding_tools",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge e453940b3f106f4d5e8075557d7467ecef85a1e7 into 5219026c99e21058e96dd6949d0d98ebc190f3b3"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d93cac254a19ac29e47b",
    "number": 146,
    "body": "A couple of additional tools here:\nexplode() expands multi-part geometries into multiple rows, and into\ntheir single part geometries. This returns a `GeoSeries` with a `MultiIndex`.\n\ncollect() - take multiple single geometries and combine them into their\nMulti\\* counterparts.\n\n`explode()` is a new member of `GeoPandasBase`, but could also be a separate function in `tools` like `collect()` is. These are similar to PostGIS `ST_Dump` and `ST_Collect` functions.\n\nTo use `MultiIndex` you can use `.loc` on the first level to get back:\n\n```\n>>> singles = df.explode()\n0  0     POLYGON ((970217.0223999023 145643.3322143555,...\n   1     POLYGON ((969488.1658325195 149753.5946044922,...\n   2     POLYGON ((939997.0946044922 173013.5794067383,...\n   3     POLYGON ((961436.3049926758 175473.0296020508,...\n1  0     POLYGON ((1021176.479003906 151374.7969970703,...\n   1     POLYGON ((1020482.590393066 157430.9501953125,...\n   2     POLYGON ((1006493.460205078 157737.2102050781,...\n...\n\n>>> singles.loc[0]\n0    POLYGON ((970217.0223999023 145643.3322143555,...\n1    POLYGON ((969488.1658325195 149753.5946044922,...\n2    POLYGON ((939997.0946044922 173013.5794067383,...\n3    POLYGON ((961436.3049926758 175473.0296020508,...\ndtype: object\n```\n\nUsing the NYC boros examples you can do some neat things quickly:\n\nTake the polygon with the greatest area from each multipolygon, preserving the index:\n\n```\n>>> df.explode().groupby(level=0).apply(lambda x: x.loc[x.area.argmax()])\n0    POLYGON ((961436.3049926758 175473.0296020508,...\n1    POLYGON ((996887.8187866211 208559.3403930664,...\n2    POLYGON ((1033946.682983398 231157.9963989258,...\n3    POLYGON ((1004601.953430176 259027.5151977539,...\n4    POLYGON ((1019370.870605469 268815.8876342773,...\ndtype: object\n```\n\nRemove any polygons with small perimeters from each multipolygon, recombine to MultiPolygon:\n\n```\n>>> df.explode().groupby(level=0).apply(lambda x: collect(x[x.exterior.length >= 3000]))\n0    (POLYGON ((969488.1658325195 149753.5946044922...\n1    (POLYGON ((1021176.479003906 151374.7969970703...\n2    (POLYGON ((1029606.076599121 156073.8142089844...\n3    (POLYGON ((972081.7882080078 190733.4674072266...\n4    (POLYGON ((1015023.713439941 230286.7592163086...\ndtype: object\n```\n",
    "head_branch": "explode_collect",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d93dac254a19ac29e47c",
    "number": 145,
    "body": "Implement spatial joins; closes #115\n\nExamples found in the [notebook](http://nbviewer.ipython.org/github/geopandas/geopandas/blob/sjoin/examples/spatial_joins.ipynb)\n",
    "head_branch": "sjoin",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge c707e1f36bd9f363c0806e1901761d0babefb7b9 into b90fce6bd48874844e789d955de4b613635cb162"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d93dac254a19ac29e47d",
    "number": 144,
    "body": "Use the pandas 0.14.1 bugfix release in the Travis test matrix.\n\nAlso allow geopy to use future versions > 0.99, when released.  Given how often the geopy API changes with minor releases, this may be a pain, but at least we'll catch API changes that affect geopandas.\n",
    "head_branch": "test/updates",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d93eac254a19ac29e47e",
    "number": 142,
    "body": "This branch implements polygon spatial overlays as discussed at the scipy 2014 sprints.\n\nIt leverages the work of the new spatial indexing to speed things up ... but it is still quite slow. The tests take ~40 seconds on my laptop and I'm sure we can do better. Profiling didn't reveal any low hanging fruit as most of the time was spent in shapely doing the union, polygonize and intersects.\n\nThere is an [example ipython notebook](http://nbviewer.ipython.org/github/geopandas/geopandas/blob/3384c82f80f8a099193aa0a74d9ff1c8d98e775d/examples/overlays.ipynb) to show the usage but no sphinx docs yet.\n\nNote that this fixes #112 and lays the ground work for #135 \n",
    "head_branch": "overlay",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 7480560c6e339cf4b38c1abfb4bd39c24c444fc0 into df6ba0afa7d3fa68bc2aa4d623a9f58eab1ae777"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d93fac254a19ac29e47f",
    "number": 141,
    "body": "See #140. An R-tree for series and frames, with tests. It's ready to be merged @kjordahl.\n",
    "head_branch": "issue140",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge fd7ce725742a7b3091ad6aafab8936efc8cd61db into f42d049ae9b83c5c0ab9fe1a5b227653db259b55"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d940ac254a19ac29e480",
    "number": 137,
    "body": "",
    "head_branch": "geojson_bbox",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 66ac9b973dbda7f4f9839aae83272b2e0946308a into 5724e578828ad5843123e3d44a537ad2866cbde2"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d941ac254a19ac29e481",
    "number": 133,
    "body": "I'd like to get this back to master and continue to work on it from there. It can't be rebased because I've pushed and @cfarmer has based commits on it. And I think it's not going to be a smooth merge because I've got 739d04e in the spatial_index branch's history. There's no sign of that code in the next version, 0ee9f4d.\n\n@kjordahl I've never run into this before. Will we need to remove 739d04e from the spatial_index branch's history?\n",
    "head_branch": "spatial_index",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d941ac254a19ac29e482",
    "number": 132,
    "body": "This bumps the version numbers following the 0.1.0 release so that master continues as the development branch.\n\nNew features can be merged into master following the merge of this PR.\n",
    "head_branch": "bld/0.2.0-dev",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge ddec2d3690c937d546b1598a78fc63ad84583f72 into 310b37ec165de752a8d4527e06e030d5a8a7db91"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d942ac254a19ac29e483",
    "number": 130,
    "body": "Simple documentation update for release.\n",
    "head_branch": "doc/release-0.1.0-fix",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 055ed0e674869d196c949e70596df288419f0a27 into 8b5477faf74027d2038456feca213fd20e7e8b58"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d943ac254a19ac29e484",
    "number": 129,
    "body": "The GitHub repo is now [geopandas/geopandas](https://github.com/geopandas/geopandas).\n",
    "head_branch": "doc/new-repo-name",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge db012775181a5492f267ec50e04035a41f779b57 into c82ba65cf32f4badcc5dd76f86ff22799f6aca0c"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": true,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d944ac254a19ac29e485",
    "number": 127,
    "body": "This will pull metadata from the correct place when the finalize\noperation is from a merge.\n\nThis partly addresses Issue #118, but it's a bug in Pandas that hardcodes `DataFrame` as the result of a merge.\n\nThe new test is skipped here until Pandas [PR#7737](https://github.com/pydata/pandas/pull/7737) is merged.\nNot yet ready to merge.\n",
    "head_branch": "merge_fix",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d945ac254a19ac29e486",
    "number": 123,
    "body": "Updated version of #109.  Uses SQLAlchemy if running on pandas 0.14 or later, otherwise the DB API for connecting to postGIS.\n\nCloses #98.\n",
    "head_branch": "bug/pandas-sqlalchemy-no-travis",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 04d263ae66cc3c7c2bf9489c85e3676b080df671 into 3697d6b52dc294dd007aa918d5f82ab8bdb91c32"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d945ac254a19ac29e487",
    "number": 121,
    "body": "Take a bunch of points and turn them into addresses.\n\nAddresses #111.\n\nThis turned out to be pretty easy as the the forward and reverse geocode functions return the same thing.\nPossible future enhancement would be to allow coordinate tuples instead of Shapely `Point` objects.\n\nIt would be nice if the reverse geocoding split out administrative levels, but it doesn't look like most of them do it now.\n",
    "head_branch": "reverse_geocode",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d946ac254a19ac29e488",
    "number": 119,
    "body": "This addresses #52, fleshing out skipped tests of shapely geometry methods. \n",
    "head_branch": "enh/series-geometry-tests",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 0061fb8df9cc609d51d1196c5afeae221734aff9 into d0a1c70de613e3f09b09a7b55df15387d727c995"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d947ac254a19ac29e489",
    "number": 116,
    "body": "Closes #113 , Implements a `__geo_interface__` property on `GeoDataFrames` and `GeoSeries`. Both are represented as geojson-like dicts with type = `FeatureCollection` ... this is inconsistent with the [current spec](https://gist.github.com/sgillies/2217756) which expects features or geometries. As discussed with @sgillies , this is probably an acceptable extension to the interface (which should be updated accordingly)\n",
    "head_branch": "geo_interface",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge e1da927134b4204df7d43ad8ccb0b7d59b23d77c into 028b8644cb3cd56e05ce319f0f22b486863e0a72"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d948ac254a19ac29e48a",
    "number": 109,
    "body": "Uses SQLAlchemy if running on pandas 0.14 or later, otherwise the DB API for connecting to postGIS.\n\nCloses #98.\n",
    "head_branch": "bug/pandas-sqlalchemy",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d949ac254a19ac29e48b",
    "number": 108,
    "body": "Includes the fix from #104 and updates test requirements to use the current latest version of geopy.\n\nUnfortunately, this will break with previous versions of geopy.\n\nReplaces #104.\n",
    "head_branch": "pr-104-rebased",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge e9755b6332eca05d1cda9d270863c94b8144a736 into 407d6c07f23a992418d049baaea183cc67b6bdc5"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d949ac254a19ac29e48c",
    "number": 106,
    "body": "It's about time we cut a release!\n\nAs we're using some of the same infrastructure as pandas, their [release checklist](https://github.com/pydata/pandas/wiki/Release-Checklist) is useful as a reference, though GeoPandas should be rather simpler.\n\nOne difference is that I will plan on tagging the merge commit of this pull request as the release candidate, and then as 0.1.0 if all goes well.\n\nI'll open a couple remaining issues on [this milestone](https://github.com/kjordahl/geopandas/issues?milestone=1&state=open) and see if we can clear them up in the next day or so, in time for my [SciPy talk](https://conference.scipy.org/scipy2014/schedule/presentation/1674/) on Tuesday.\n",
    "head_branch": "release/0.1.0",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d94aac254a19ac29e48d",
    "number": 104,
    "body": "GeocoderResultError no longer exists in GeocoderQueryError.  Thank you for making geopandas!\n",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d94bac254a19ac29e48e",
    "number": 103,
    "body": "",
    "head_branch": "patch-1",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d94cac254a19ac29e48f",
    "number": 101,
    "body": "Adds support for sqlite db with geometry column stored as WKB. This PR\ndoes not (yet) contain additional tests for sqlite tables (but should\nstill pass postgis tests).\n",
    "head_branch": "sqlite_support",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d94dac254a19ac29e490",
    "number": 100,
    "body": "Python 3.4 is [now available on Travis](http://blog.travis-ci.com/2014-04-28-upcoming-build-environment-updates).\n",
    "head_branch": "test/python34",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 9bd4f59b46c121dd0849ee2e5957a02583879a32 into 761b5c6c0e03324dfc705d30eaacedf21768d7e1"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": true,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d94dac254a19ac29e491",
    "number": 99,
    "body": "The `install.rst` file needs a space before a list, and minor rewording of plotting requirements there as well.\n",
    "head_branch": "doc/plotting-reqs",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge d9e7f81dee9c5ecdc1bb1fd83931fdd675339b6d into a7b594e79fec746f03a8d2f27844b81a17427d61"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d94eac254a19ac29e492",
    "number": 97,
    "body": "Finally finish python 3 support and start running tests on Travis CI.\n\nUses `six` where necessary to smooth over the differences between major python versions and keep a single codebase.\n\nThe test matrix is getting rather large now, with 4 python versions and 3 pandas versions.  The 12 tests take a while to run on Travis.  In testing this I saw corner cases in both python and pandas, though, so it's hard to say we should drop something.\n",
    "head_branch": "feature/py34",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge cf2d13c5cc98c1c4c98e92d9e619105f3fdf0a35 into 120d5eebe5be252d3cc8935307a3b598ae1faea6"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": true,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d94fac254a19ac29e493",
    "number": 96,
    "body": "This fixes a longstanding bug starting in read_file() that was migrated to\nGeoDataFrame.from_features() which wouldn't align properties with their\nassociated rows.\n",
    "head_branch": "from_features_fix",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge 02cab384bd9a865fb705ee719b1d0b05003dd13b into 01a179e6f8483eb1023e6e57d2b20365a0d6d7c1"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d950ac254a19ac29e494",
    "number": 95,
    "body": "Cherry picked from #91.\n",
    "head_branch": "bug/unhexify",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 5ef391198a1291883ce9858e055d6aeac960581c into 11a6992e673b42a8d2525555840e0010346bd90a"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d950ac254a19ac29e495",
    "number": 94,
    "body": "Make sure that when creating a Fiona schema, we always use type `int` instead of `long`.\n\nCloses #93.\n",
    "head_branch": "bug/no-long-type",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge f443cc7d78d34ff4abfc82505fda28ab6e68dc6f into 6a7d59b1b1f3174a01c93ac6974f98fbe114d13a"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d951ac254a19ac29e496",
    "number": 92,
    "body": "If DataFrame's set_geometry() is called with a Series, align\nthe index.\n\nBefore this fix, these could have different results because `set_geometry` didn't use the index:\n\n```\ndf = DataFrame(...)\ng = GeoSeries(...)\ndf.set_geometry(g)  # Unaligned\n```\n\nvs.\n\n```\ndf = DataFrame(...)\ng = GeoSeries(...)\ndf['geometry'] = g  # Aligned\ndf = GeoDataFrame(df)\n```\n",
    "head_branch": "set_geometry_align",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge 04dfaf9a10f1a45a566db7f949d8b7337d0f5dce into 1edddada8ff54a94d35342df2dadc8f8aaf67600"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d952ac254a19ac29e497",
    "number": 91,
    "body": "1. Support Py3K build with automatic 2to3 run. This was tested with Python 3.3. Note, the changeset is about build and installation only (not running geopandas yet).\n2. When running read_postgis function, I am getting\n\n```\nTraceback (most recent call last):\n  File \"script.py\", line 51, in <module>\n    data = GeoDataFrame.from_postgis(QUERY, db, geom_col='location', index_col='timestamp')\n  File \"/home/user/.local/lib/python3.3/site-packages/geopandas-0.1.0.dev_1edddad-py3.3.egg/geopandas/geodataframe.py\", line 211, in from_postgis\n  File \"/home/user/.local/lib/python3.3/site-packages/geopandas-0.1.0.dev_1edddad-py3.3.egg/geopandas/io/sql.py\", line 39, in read_postgis\n  File \"/home/user/.local/lib/python3.3/site-packages/pandas-0.13.1-py3.3-linux-x86_64.egg/pandas/core/series.py\", line 2023, in apply\n    mapped = lib.map_infer(values, f, convert=convert_dtype)\n  File \"inference.pyx\", line 920, in pandas.lib.map_infer (pandas/lib.c:43334)\n  File \"/home/user/.local/lib/python3.3/site-packages/geopandas-0.1.0.dev_1edddad-py3.3.egg/geopandas/io/sql.py\", line 39, in <lambda>\nAttributeError: 'str' object has no attribute 'decode'\n```\n\nThe 2nd commit replaces str.decode('hex') call with unhexlify function call, which should make geopandas work on both Python 2.6 and Python 3.3.\n",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d953ac254a19ac29e498",
    "number": 90,
    "body": "The first two of these commits fix the tests against pandas master.\nThe first removes the GeoSeries override of `__getslice__`. It's handled by `__getitem__`.\nThe second fixes the call to `read_sql`. Pandas overhauled the SQL interface. The fix here was to use keyword arguments and everything passes down correctly now.\n\nThose fixes work in back to Pandas 0.12.0.\n\nThe third fixes a GeoPandas bug where converting the GeoDataFrame to GeoJSON would fail if the geometry column was not named 'geometry'.\n",
    "head_branch": "pd_master_fixes",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge f0108b922b677d9d07272780a9ac836f3da7d409 into a91e8ab7bf724c5d27045ba8a9776de2cd0b40b2"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d954ac254a19ac29e499",
    "number": 88,
    "body": "Pandas [0.13.1](http://pandas.pydata.org/pandas-docs/stable/whatsnew.html#v0-13-1-february-3-2014) has been released.  Using that for testing, along with 0.12 and master.\n",
    "head_branch": "test/pandas-0.13.1",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge b1b3614ed8ebe1a503f4d582b2b78ba813b9d7d0 into 4ee1432b07238337a8a7734f2f6506db0cf486a4"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d954ac254a19ac29e49a",
    "number": 87,
    "body": "Fixes a bug introduced in 72f236.\n\nMakes a few tests more robust.\n",
    "head_branch": "crs_fix",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge 47f25eea93fc3ad1129f972848d14b8c71828c77 into 3b92577f847ff836dd727fd1d671de525c633c94"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d955ac254a19ac29e49b",
    "number": 86,
    "body": "Display test coverage for all to see.\n",
    "head_branch": "test/coveralls_badge",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d956ac254a19ac29e49c",
    "number": 85,
    "body": "Run tests on Travis CI with test coverage, and enable [Coveralls](https://coveralls.io) to track and report coverage.\n\nThis also required switching to py.test from nosetests for running the tests on Travis.  The tests can still be run locally with `python -m unittest discover`, `nosetest` or `py.test`.\n",
    "head_branch": "test/coveralls",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d957ac254a19ac29e49d",
    "number": 84,
    "body": "Pandas 0.13 [has now been released](http://pandas.pydata.org/pandas-docs/stable/whatsnew.html#v0-13-0-january-1-2014), so added the pandas 0.13 tag to the matrix of tests on Travis CI.  Now running 3 different pandas versions, 0.12, 0.13 and master.\n",
    "head_branch": "test/pandas-0.13",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge b649c0a0e0667729f7a6f933c99d69a95951e911 into 19862aa3462ceef17324bf9731aceb716858a38b"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d957ac254a19ac29e49e",
    "number": 83,
    "body": "Allows passing a list of features or objects that implement\n**geo_interface** for easier GeoDataFrame construction.\n\nThis makes it easy to create a GeoDataFrame if you have features or feature dicts already in memory.\n",
    "head_branch": "from_features",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d958ac254a19ac29e49f",
    "number": 82,
    "body": "Over-riding shift on GeoSeries and GeoDataFrame clobbered shift\nin Pandas. Get rid of it and just use translate\n\nAlthough this breaks the public API for `GeoSeries` and `GeoDataFrame`, the Pandas `shift` function is pretty important to have. It plays a role in many common patterns.\n",
    "head_branch": "no_shift",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge 2343ee3ddc4ce858b81a5d09834fd1982eaf7a38 into 9a507b429845dbd03fd8e302119f48ce6ce84746"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d959ac254a19ac29e4a0",
    "number": 80,
    "body": "Changes in 0.97 break GeoPandas error detection. Until this is properly\nhandled, this fixes the Travis build.\n\nThe newest version of geopy, 0.97, removes the `GeocoderResultError` which we're using. This just requires the latest 0.96 in `requirements.test.txt` to get the Travis build passing.\n",
    "head_branch": "geopy096",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge 6bcffef99fd10e56e59f8345680403c9ed8bc55f into 6dab7f60516a49a4fe51f2489d60e6e590eaf37a"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d95aac254a19ac29e4a1",
    "number": 79,
    "body": "--pre is required to install with pip when using pre-release version numbers\n\nSee http://www.pip-installer.org/en/1.4.1/logic.html#pre-release-versions\n",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d95bac254a19ac29e4a2",
    "number": 78,
    "body": "`geopy` 0.96 [removed support](https://github.com/geopy/geopy/blob/master/RELEASES) for the Google Maps v2 API, which removed the `geopy.geocoders.Google` attribute and broke things, causing tests to fail.  The Yahoo API has also changed to [`YahooPlaceFinder`](http://geopy.readthedocs.org/en/latest/#geopy.geocoders.YahooPlaceFinder).\n\nAlso added support for the OpenStreetMaps [Nominatim](http://geopy.readthedocs.org/en/latest/#geopy.geocoders.Nominatim) geocoder which is now in `geopy`.  To honor their [usage policy](https://wiki.openstreetmap.org/wiki/Nominatim_usage_policy), requests are throttled to 1 request per second.\n\nAdded a few explicit geocoder tests as well (these require network access, of course).  There are still no tests for APIs that require a key.\n",
    "head_branch": "bug/geopy_0.96",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d95bac254a19ac29e4a3",
    "number": 77,
    "body": "This is a start at Python 3 support, fixing some of the obvious things.  I can get some simple `GeoSeries` objects defined, but much isn't yet working, including tests.\n\nIntroduces a dependency on `six`.  It would be nice to use `pandas.compat` instead to avoid a new dependency, but I don't think we can if we want to keep pandas 0.12 support (@jtratner please correct me if I'm wrong about that).\n",
    "head_branch": "feature/py3",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d95cac254a19ac29e4a4",
    "number": 76,
    "body": "This is an example of possible use of [PySAL classification schemes](http://pysal.readthedocs.org/en/v1.6/library/esda/mapclassify.html) for choropleth mapping on geopandas GeoDataFrames. \n\nThere are other classifiers available that could be used, this is just to give an idea of one possible approach.\n\nNote it requires pysal.\n",
    "head_branch": "choro",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d95dac254a19ac29e4a5",
    "number": 75,
    "body": "This PR allows the user to specify two columns (X and Y) to the `set_geometry` method. This will allow a DataFrame with Lat, Lon, fields to be easily converted to a GeoDataFrame.\n\n``` python\ndf = GeoDataFrame({\"A\": [1,2,3,4,5,6],\n                               \"B\": [6,5,4,3,2,1],\n                               \"X\": [1,2,3,4,5,6],\n                               \"Y\": [1,2,3,4,5,6]})\ndf.set_geometry([\"X\", \"Y\"], inplace=True, drop=False)\n```\n",
    "head_branch": "set_by_coords",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d95eac254a19ac29e4a6",
    "number": 74,
    "body": "Without this check, it is possible to do the following:\n\n``` python\ndf = GeoDataFrame({\"A\":[1,2,3,4,5,6], \"B\":[6,5,4,3,2,1]})\ndf.set_geometry(\"A\")\n```\n\nThis might not be the most efficient way to check, as it goes through the whole iterable item by item:\n\n``` python\nall(isinstance(item, BaseGeometry) for item in level)\n```\n",
    "head_branch": "check_for_geo",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d95fac254a19ac29e4a7",
    "number": 72,
    "body": "Part of #62. Looks like we're good on this for now.\n\nClearly in the future it would be nice if a column with geometry in it\ncame out as GeoSeries, but I wanted to specify current behavior in the\ntests so we could be sure we were choosing to change it.\n",
    "head_branch": "geo-setitem-tests",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge f33d8859a70962010aa17fd3a440b85b0eb04ca0 into 06c335efe30ff4b6ed577b3d2f2ce244b22a326e"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d960ac254a19ac29e4a8",
    "number": 70,
    "body": "Because Multi\\* geometries are iterable, they get expanded when passed into\nnp.array(). Protect against this by passing in all base geometries as a\nsingle element list. They will not be expanded into their individual\nparts.\n\nIt actually would crash on a `MultiPoint`.\n\nThis would happen before:\n\n```\nIn [3]: df = gpd.read_file('/nybb_13a/nybb.shp', vfs='zip://examples/nybb_13a.zip')\n\nIn [4]: multipoly = df.iloc[0].geometry\n\nIn [5]: type(multipoly)\nOut[5]: shapely.geometry.multipolygon.MultiPolygon\n\nIn [6]: gs = gpd.GeoSeries(multipoly)\n\nIn [7]: gs\nOut[7]:\n0    POLYGON ((970217.0223999023437500 145643.33221...\n1    POLYGON ((969488.1658325195312500 149753.59460...\n2    POLYGON ((939997.0946044921875000 173013.57940...\n3    POLYGON ((961436.3049926757812500 175473.02960...\ndtype: object\n```\n\nHere's the output with this patch:\n\n```\nIn [2]: df = gpd.read_file('/nybb_13a/nybb.shp', vfs='zip://examples/nybb_13a.zip')\n\nIn [3]: multipoly = df.iloc[0].geometry\n\nIn [4]: type(multipoly)\nOut[4]: shapely.geometry.multipolygon.MultiPolygon\n\nIn [5]: gs = gpd.GeoSeries(multipoly)\n\nIn [6]: gs\nOut[6]:\n0    (POLYGON ((970217.0223999023437500 145643.3322...\ndtype: object\n```\n",
    "head_branch": "singlegeomfix",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d960ac254a19ac29e4a9",
    "number": 69,
    "body": "This is an alternate implementation for Pull Request #68 that also changes the way `GeoSeries` works.\n\nIt introduces the idea of a `geo` namespace where all the geometry methods reside. @jtratner has suggested it multiple times and I figured I'd give it a shot. The tests are completely broken, I didn't want to spend the time to fix them before discussing this.\n\nBoth `GeoSeries` and `GeoDataFrame` have a `geo` property that's analogous to `Series.str` for performing the Shapely operations.\n\nAll geometry operations take the form:\n\n```\ns = GeoSeries(...)\ns2 = GeoSeries(...)\n\ns.geo.intersects(s2)\n```\n\nThe advantages of this approach are:\n- Avoid any name collisions with Series/DataFrame methods\n- No multiple inheritance\n- Could make it easier to monkey patch `geo` on `Series` or `DataFrame`, although there would be a bunch of other issues to sort out.\n- @jtratner, others?\n\nThe main disadvantage is you have to type `geo` all over the place. Here's a good example for testing bounding box overlaps:\n\n```\ngdf1 = GeoDataFrame(...)\ngdf2 = GeoDataFrame(...)\n\ngdf1.geo.envelope.geo.intersects(gdf2.geo.envelope)\n```\n\ninstead of\n\n```\ngdf1.envelope.intersects(gdf2.envelope)\n```\n\nAny thoughts of this over the original implementation in Pull Request #68?\n",
    "head_branch": "geons",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d961ac254a19ac29e4aa",
    "number": 68,
    "body": "Add geometry operations to `GeoDataFrame`. It enables:\n\n```\ngdf1 = GeoDataFrame(...)\ngdf2 = GeoDataFrame(...)\n\ngdf1.intersection(gdf2)\ngdf1.intersection(gdf2.geometry)\ngdf1.geometry.intersection(gdf2)\n...\n```\n\nThis addresses Issue #44.\n\nI'm not sure it's ready to be merged just yet. I'd like to get everyone's feedback.\n\nA few things are happening here:\n- A new `GeoPandasBase` class is introduced. It implements all the geometry operations which get removed from `GeoSeries`. `GeoPandasBase` has no instance variables.\n- Both `GeoSeries` and `GeoDataFrame` inherit from `GeoPandasBase`.\n- The `GeoPandasBase` geometry operations grab the `geometry` property of their inputs to use for the underlying Shapely operations\n- `GeoSeries` now has a `geometry` property which returns `self` (in order to get the `GeoPandasBase` operations functioning)\n- All the geometry tests are moved to `test_geom_methods` which tests all possible combinations of input types when necessary. So the binary topological operations will be tested with: (GeoSeries, GeoSeries), (GeoDataFrame, GeoSeries), (GeoSeries, GeoDataFrame), (GeoDataFrame, GeoDataFrame) input types.\n\nAll the geometry operations return a `GeoSeries`.\n\nHow do you feel about the multiple inheritance? We could also bind the geom methods dynamically without the extra class.\n",
    "head_branch": "gdfops",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge aab741e4e39faa63f7fd4d57289508fbe8f2f164 into 237af0e6341647198d8ad94f2389911ec6f9b293"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d962ac254a19ac29e4ab",
    "number": 67,
    "body": "This PR supports Python 2.6 and adds it to Travis CI tests.\n\ngeopy still doesn't work, that should be fixed (or at least test skipped) before merging.\n\nRelated: #30.\n",
    "head_branch": "test/python_2.6_support",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge b1ced78b16383294e54a98ea04b4fe203382c663 into d080911c045dfcdfbfd84f617905d82425db3859"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d963ac254a19ac29e4ac",
    "number": 66,
    "body": "Using index lookups is ~20% slower (and less pythonic) than unpacking with\ncomprehension (there's a bit of variability). Plus it makes it more\nreadable too.\n\nSnippet:\n\n``` python\nIn [1]: def index_unpack(): return [(s[0], s[1]) for s in lst]\n\nIn [2]: def pythonic_unpack(): return [(a, b) for a, b in lst]\n\nIn [3]: lst = zip(range(100000), range(100000))\n\nIn [10]: %timeit -n 100 index_unpack()\n100 loops, best of 3: 26.2 ms per loop\n\nIn [12]: %timeit -n 100 pythonic_unpack()\n100 loops, best of 3: 22 ms per loop\n```\n",
    "head_branch": "fix-perf-issue",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge 0dc6f9e826395353059b5d695c5957f4d52d790a into 40b32dbe5d8f0e2a71e08f65853fee8477453d6c"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d964ac254a19ac29e4ad",
    "number": 64,
    "body": "Check the crs in assert_geoseries_equal.\n\nLeaves the ability to compare the crs optional with a 'check_crs' flag that defaults to True. Also sets the crs of some inputs when using assert_geoseries_equal.\n",
    "head_branch": "crstest",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge b557e44c3cdc8252146c388d414ca3d3cc6a456b into f6e545cdde88b234055ba042de13d81938f0f929"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d964ac254a19ac29e4ae",
    "number": 63,
    "body": "Use ubuntugis stable.\n\nShould get rid of any issues that were due to using gis unstable.\n",
    "head_branch": "travis-fix",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge b94e805b0a7293f08380fdac6db7059a1f1251e1 into 2883bea1271df2f2e41036d7ef0f97f85696bff5"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d965ac254a19ac29e4af",
    "number": 61,
    "body": "`geopandas.io` should be in the packages list in `setup.py`.\n",
    "head_branch": "bug/setup_package_io",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d966ac254a19ac29e4b0",
    "number": 60,
    "body": "There are a bunch of changes here, but in sum they make it so that the\nGeoDataFrame isn't bound to the name `geometry` for dealing with\ngeometric data. It also changes the default for drop to False.\n- GeoDataFrame constructor accepts a 'geometry' kwarg that can be either a\n  column name (in which case that column is set as geometry) or a\n  compatible array (in which case the array is set as the geometry on the\n  object).\n- GeoDataFrame gets a `_geometry_column_name` which is set to the\n  current geometry column.\n- By default, set_geometry doesn't drop if you specify a column (just\n  swaps the geometry). If you pass `drop=True`, it renames the column to\n  geometry and resets the internal name for geometry column.\n- `set_geometry` accepts a crs so you can pass the crs that matches your\n  the new geometry.\n- binds `set_geometry` method to `pandas.DataFrame` that allows\n  conversion of a DataFrame to a GeoDataFrame. E.g.:\n  `gf = df.set_geometry('location', crs=some_crs)`  though this could\n  potentially let you do something like load data from a file with\n  pandas methods, then load another set of data with geometries, merge\n  them on something, then use set_geometry() to get to GeoDataFrame.\n\nFuture TODO based on this: have some way to keep track of geometry\ncolumns, because once you change the geometry name only that column\ncomes out as GeoSeries.\n\nUsing a GeoSeries with non-matching index in the constructor\nmay lead to weird results, but I don't think it's worth getting into\nyet.\n\nCloses #45\n",
    "head_branch": "be-flexible-with-geometry-column",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d967ac254a19ac29e4b1",
    "number": 59,
    "body": "Might make sense to add a test suite example with no geopy? Passes on my\ntest environment (which doesn't have geopy) and now you can import the\ngeocode module without a problem.\n",
    "head_branch": "skip-and-guard-geopy",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d968ac254a19ac29e4b2",
    "number": 58,
    "body": "Addresses issue #56.\n\nJust disabling the cache for now, could re-enable if the cache is properly invalidated on change.\n",
    "head_branch": "bug/cached_total_bounds",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d968ac254a19ac29e4b3",
    "number": 57,
    "body": "Minor fixup to use absolute imports (necessary for Python 3). Added pd,\nnp, and gpd to namespace because I've found having np (and now pd) makes\nit much easier to quickly test something out, rather than always having\nto type out the import.\n",
    "head_branch": "use-absolute-imports",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge d5add6cbc42d35888b5a32de8b6e18d7b6b88cd7 into 120828c6a05d786c2899ca64282cdaae723d3a8b"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d969ac254a19ac29e4b4",
    "number": 55,
    "body": "This is a new API for slicing `GeoSeries` objects by coordinates.  This implements a new indexer that uses the `cx` attribute for slicing by coordinates, analogous to `ix` for slicing by index.  Slices on `cx` will return all geometries that intersect the bounding box defined by the sliced coordinates.\n\nExamples:\n\n```\n>>> g = GeoSeries([Point(1.0, 1.0), Point(2.0, 1.0), Point(1.0, 2.0), Point(2.0, 2.0)])\n>>> g\n0    POINT (1.0000000000000000 1.0000000000000000)\n1    POINT (2.0000000000000000 1.0000000000000000)\n2    POINT (1.0000000000000000 2.0000000000000000)\n3    POINT (2.0000000000000000 2.0000000000000000)\ndtype: object\n>>> g.cx[:, :1.0]\n0    POINT (1.0000000000000000 1.0000000000000000)\n1    POINT (2.0000000000000000 1.0000000000000000)\ndtype: object\n>>> g.cx[2:, 2:]\n3    POINT (2.0000000000000000 2.0000000000000000)\n```\n\nA `step` (stride) is not handled, since coordinate intervals are continuous.\n\nThis is a preliminary implementation, open for discussion on the interface.\n",
    "head_branch": "feature/coordinate_index",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 11b3ad07f04dc46423daeb313f31782e972e42cf into 3b7afba679387b6363bdc9da5f0499392c64c33d"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d96aac254a19ac29e4b5",
    "number": 54,
    "body": "Setting a property adds some tricky issues with DataFrame, this fixes it\nby catching the KeyError as AttributeError. I still think\nit has some useful possibilities (especially in terms of allowing\ndifferent column names to draw on for 'geometry'), but I haven't added\nany of that yet.\n- Allows for clearer errors when a GeoDataFrame is created but has no\n  geometry.\n- TST: Add test util for comparing sequence (b/c assert_almost_equal seems\n  to not work with shapely.\n",
    "head_branch": "change-geometry-v2",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d96bac254a19ac29e4b6",
    "number": 50,
    "body": "When omitna is true, any properties that are NaN will not be written out.\nThis means that different features can have different numbers of properties,\nwhich is okay for GeoJSON. Writing out NaN values is not valid JSON and causes\nproblems for some parsers.\n\nThis introduces a new flag, `omitna`, to `GeoDataFrame.to_json()`. Each feature's properties are evaluated independently and null values are removed before serializing to JSON. I originally wanted to call this `dropna` but thought that could be confusing as `dropna` typically removes whole rows or columns, whereas `omitna` effectively removes single elements from the output.\n",
    "head_branch": "geojson_omitna",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge 0e671667b073ee8cfddc4a2633a14dbf44728802 into 65c2e0d99c17918cfb9072e0a8b7ee25cd730dd0"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d96cac254a19ac29e4b7",
    "number": 49,
    "body": "Define the new `__finalize__()` method (see #36) and `_constructor` attributes.  A few other changes were necessary, and it revealed a bug in the custom `fillna`, which I removed since it isn't necessary in pandas master.\n\nThere are now 3 failing tests on pandas 0.12, however.  It looks like they are all related to fillna, so that might have to be reimplemented to keep 0.12 support.  I won't merge until this is fixed, I don't think we need to abandon 0.12 quite yet.\n\nThis has the `loc`, `iloc`, `head` and `tail` tests are passing again.\n",
    "head_branch": "feature/update_pandas_api",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d96cac254a19ac29e4b8",
    "number": 48,
    "body": "",
    "head_branch": "bounds",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge 3e33e27642922f82d50f3942a7fcaf1297714e25 into 5ca153c582069c0b97beaafd8c292892d54c65ce"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d96dac254a19ac29e4b9",
    "number": 47,
    "body": "Adds a geometry property and set_geometry() method to GeoDataFrame. This was\nsuggested in Issue #45. The implementation mimics that of DataFrame's\nset_index in that it returns a copy of the GeoDataFrame by default with the\nnew geometry. You can specify a column or give a list/ndarray of geometries.\n\nThis addresses the discussion in Issue #45. The new `set_geometry()` method in `GeoDataFrame` more explicitly sets the geometry instead of just operating on the geometry column. The interface is modeled on `DataFrame.set_index()` including the `drop` and `inplace` options, as well the ability to use an existing column. (Most of its code comes from `set_index` as well). The geometry should be accessed using the `geometry` property instead of as a column.\n\nSoon, we might also want to remove the geometry column altogether soon and just access it through the property and `set_geometry` method. I didn't want to go that far before getting feedback.\n\nThe Travis build on this fails on Pandas master due to the new implementation of head and tail. Pull request #46 takes care of that.\n",
    "head_branch": "set_geometry",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d96eac254a19ac29e4ba",
    "number": 46,
    "body": "Pandas commit c6d07a8 uses iloc for head and tail, which cause these\ntests to fail. Skip them. The test for iloc is already being skipped.\n",
    "head_branch": "skip_head_tail_test",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge ae27e9775a611c5d2890096b1df6019dc3c6c27c into 9a6f6c5e6066ea48be702b577e8b846c3cf33ee7"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d96fac254a19ac29e4bb",
    "number": 43,
    "body": "Finally a way to test plotting functions, using matplotlib's testing function `compare_images`.\n",
    "head_branch": "feature/plot_testing",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d96fac254a19ac29e4bc",
    "number": 42,
    "body": "Use the new default theme on [Read the Docs](https://readthedocs.org/), but `nature` theme for docs built elsewhere.\n",
    "head_branch": "doc/read_the_docs_theme",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d970ac254a19ac29e4bd",
    "number": 41,
    "body": "- Shift the location of the documentation source files and make it a little easier to build.\n- Started bringing the User's guide into sync with the current code.\n- Added a CONTRIBUTING file.\n- Copyright notices to \"GeoPandas developers\"\n",
    "head_branch": "doc/revamp_docs",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 4f39771ea8221303c708d7a5f10ed2cca494b1e6 into 8144a45ed88a55f8eb8d4fcefafc00749bff737a"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": true,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d971ac254a19ac29e4be",
    "number": 40,
    "body": "A few minor updates to the matplotlib plotting functions.\n- Parameters weren't being passed to `plot_series`\n- Better handling of existing figures.\n- Use colormaps for plotting `LineString`s as well\n",
    "head_branch": "feature/plotting_updates",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d972ac254a19ac29e4bf",
    "number": 39,
    "body": "Geocode a Series or list of strings and get back a GeoDataFrame with the\nPoint objects and a full geocoded address.\n\nUses `geopy` to geocode strings. This allows something like this:\n\n``` python\n>>> from geopandas.geocode import geocode\n>>> df = geocode(['cambridge, ma', '1600 pennsylvania avenue washington dc'])\n                                             address                                          geometry\n0                                 Cambridge, MA, USA  POINT (-71.1097334999999902 42.3736158000000032)\n1  1600 Pennsylvania Avenue Northwest, President'...  POINT (-77.0365122999999983 38.8978377999999978)\n```\n\nFor fun you can save the output of `df.to_json()` and upload to Github to quickly see a map:\n![screen shot 2013-10-16 at 12 47 33 am](https://f.cloud.github.com/assets/1214350/1340040/273e0df4-361e-11e3-8be1-7bf58440ffe1.png)\n\nI'm not sure if a `geocode` module at the top-level is the right place, but I didn't think it belonged in `io`.\nThere's also some questions about what to do when the geocoder returns no result or has errors, the whole thing will error out now. We could fill those rows with nan, or possibly add an error string column which will be nan for successes, but have the appropriate error when there are problems.\n\nAlso, I've only tested this using the GoogleV3 geocoder and OpenMapQuest. It could also use more documentation on the options for the different geocoders.\n\nWould like to hear what others think... I think this is a great complement to Pandas use-cases where you'd be extracting addresses out of some data.\n\nI'm also unsure of the best way to test the part of the geocoder that hits the different APIs. I have testing now on handling the results.\n",
    "head_branch": "geocode",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge e3f99438876226d0bf53b8fbc4e11911d573545e into 189a35c9e75626d0f6196a3bdc32ffeee2814695"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d973ac254a19ac29e4c0",
    "number": 37,
    "body": "This PR is more of a conversation starter than anything. In some of the work I'm doing, it is useful to have a GeoSeries return the same thing as a similar call to a shapely BaseGeometry object. For example, future spatial operations will likely utilize bounding boxes to filter out non-overlapping geometies. Since the user might want to overlay a single BaseGeometry, or another GeoSeries, it would be useful to have `obj.bounds` return a bounding box tuple, regardless or what that object is. This would avoid having to write something like this every time:\n\n``` python\nif isinstance(other, BaseGeometry):\n    other = other.bounds\nelif isinstance(other, GeoSeries):\n    aggregator = dict(minx=np.nanmin, miny=np.nanmin,\n                             maxx=np.nanmax, maxy=np.nanmax)\n    bbox = other.bounds.groupby(lambda x: 1).agg(aggregator)\n    other = tuple(bbox.values[0].tolist())\n```\n\nI could see this coming up in other contexts as well. For instance, the user might want `area` to return the area of the _entire_ GeoSeries, or they may want `buffer` to return a single buffered geometry for the whole GeoSeries. While both can be accomplished by a single additional call, it may be nice to provide shortcuts to these common operations, or provide an API that is closer to what one would expect from using shapely?\n\n``` python\ntot_area = obj.area.sum()\nsing_buff = obj.buffer(.5).unary_union()\n```\n\nWhat about exposing the individual methods in addition to the property (with a `geo_` prefix for all methods):\n\n``` python\ndef geo_buffer(self, distance, resolution=16, by_geom=False):\n    geom = GeoSeries([geom.buffer(distance, resolution) for geom in self],\n                         index=self.index, crs=self.crs)\n    if by_geom:\n        return geom\n    return geom.unary_union()\n\nbuffer = property(geo_buffer) # Similar to shapely (return single geometry)\n```\n\nNote: the naming conventions I've used here are not necessarily ideal. Perhaps something like `element_*` or `geom_*`  for the element-wise operations (and the short names for the Series operations). Conversely, maybe we want to do the 'opposite' to shapely, and have element-wise operations take on the short names, and the Series-based operations take on a `all_*` or `series_*` prefix?\n",
    "head_branch": "bounds",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d973ac254a19ac29e4c1",
    "number": 35,
    "body": "This pull request addresses Issue #34.\n- Moves functionality of GeoDataFrame's `from_file` and `from_postgis` into a new `io` sub-package.\n- The functions are renamed to `read_file` and `read_postgis` to be consistent with `pandas` naming conventions.\n- The functions are exposed at the top-level `geopandas` module.\n- Introduces a `util` module in `tests` for performing some common operations across the tests, e.g., downloading the shapefile, connecting to the test database, etc.\n\nI kept the name `read_file` since I'm not sure any of the options are better.\n",
    "head_branch": "io",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge ee02c69420e57f017eea9939279b39e4ecb486b7 into abb4137e879f7aa39a305f0b98c083231f43142e"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d974ac254a19ac29e4c2",
    "number": 33,
    "body": "Some additions and clean up in tests.\n\nAlso fixes two bugs: in `copy` and the output `crs` when using the `to_crs` method.\n",
    "head_branch": "test/test-coverage",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge a693228fb4ffcff11891bf39c3bf522cdb48ecd3 into dbf15b21a77a82fa56d0f23ee03bd3cae030c7bc"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d975ac254a19ac29e4c3",
    "number": 32,
    "body": "All tests on Travis CI will now run explicitly on pandas 0.12.0 and pandas master.\n\nThe downside is that pull requests may show a failing test due to a pandas change that broke something unrelated.\n\nThe benefits are that we will quickly catch pandas changes that will affect things that GeoPandas depends on, and also it will be clearer what will break in pandas release versions if we start using the improved typing and subclassing available in pandas master (see #26).\n",
    "head_branch": "feature/travis-pandas-versions",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge c0565df397edb7f06d5a6d0f4d3b692d669d48ad into 2be7de81d2a12054f7c6ed05927b4383df565fc8"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d976ac254a19ac29e4c4",
    "number": 31,
    "body": "Clean up some imports, using absolute imports for GeoPandas modules, alphabetizing and grouping imports, and lazily importing plotting libraries.\n\nRemoves the Travis CI dependencies on matplotlib and descartes, which makes the test suite considerably faster.  These would need to be put back in if we actually had some plotting tests, though.\n",
    "head_branch": "cleanup/imports",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 8caaadc423c1fd9fb8355380fa74217b692e2363 into 9db47e8f7a95cc0b7dafc8904d02ee505cddfced"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d977ac254a19ac29e4c5",
    "number": 29,
    "body": "I have stuck with a pretty simple API for the new functions, similar to the way `buffer` currently works. As such, the functions only accept one value for each parameter for the whole `GeoSeries`, rather than index-specific parameters such as a different rotation value for each geometry (i.e., users must use a float rather than `Series` of floats). This keeps things simpler and consistent, and if a user really wants index-specific parameters, they can use the shapely functions directly inside `Series.apply`. This PR also contains a few other minor adjustments/fixes.\n",
    "head_branch": "transform",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge fd58437ea311b6ea106ce8299f31d6017ff8a686 into 1c6f8a3fc6fa613c8611799bb6728ec73d304b2e"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d977ac254a19ac29e4c6",
    "number": 28,
    "body": "Operations on a GeoSeries that return a non-geometry series should be Series type (as it already said in the docstring).\n\nCloses #27.\n",
    "head_branch": "bug/series_unary_op",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 4eccd048a3455619cd57e97ea336e61934785f7f into c770a5cc424192e37d0ba4eb0c5ffa9f1b3a7ec2"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d978ac254a19ac29e4c7",
    "number": 26,
    "body": "These changes implement a GeoSeries-specific `_constructor` property that propagates the correct type to many pandas methods.  A check had to be added to the `__init__` method to ensure that objects with no geometries in them (e.g. booleans from tests) are actually returned as Series instead of GeoSeries.\n\nThis will close #19, at least for the set of methods mentioned there.  Some of the ugly boilerplate wrapping is probably unnecessary now as well.  Some more testing is needed to see that `groupby` and other methods actually return reasonable results, but they seem to return the correct types now.\n",
    "head_branch": "feature/groupby",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d979ac254a19ac29e4c8",
    "number": 25,
    "body": "Wraps read_sql() and looks for the specified geometry column which gets\nconverted to shapely geometries. It returns a GeoDataFrame.\n\nExample:\n\n```\ndf = GeoDataFrame.read_sql(\"SELECT id, geom, highway, oneway FROM roads LIMIT 5\", con)\ndf\n           id highway oneway                                           geometry\n0   4317678        5  False  LINESTRING (-92.0983609999999970 31.4399659999...\n1  11803224        3  False  LINESTRING (-92.3248040000000003 30.5609140000...\n2   4285654        5  False  LINESTRING (-90.8962089999999989 30.9225339999...\n3   4286812        5  False  LINESTRING (-90.9428329999999931 30.7880220000...\n4  12057238        3   True  LINESTRING (-91.5078129999999987 30.3997999999...\n\n```\n\n`df` is a GeoDataFrame.\n\nNot sure the best way to test this with travis.\n",
    "head_branch": "postgis",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge c404f83d14e2a3a579e36417aa6d510c12890337 into fea5c40ac67b2e4e1497e061b8b6c6a524d67204"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d97aac254a19ac29e4c9",
    "number": 24,
    "body": "The `crs` keyword parameter was just being thrown away instead of setting the attribute on a new `GeoDataFrame`.\n",
    "head_branch": "bug/df-init-crs",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 019029c60f74b21abab4111534716bc92b6ea5cf into 74b2666efdec4ad1ffe59926371896291f29d25f"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d97bac254a19ac29e4ca",
    "number": 23,
    "body": "Fixes boolean indexing on GeoDataFrame\n\nFixes a crash on statements like:\n\n``` python\ndf[df['col'] == 'match']\n```\n\nwhere `df` is a GeoDataFrame\n",
    "head_branch": "fix_bool_index",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge 983c3ad798790bc5250a3409d201a5bf0fa9c495 into 3ebcae071ddc8faa44a1ecb541154b6399af14a8"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d97cac254a19ac29e4cb",
    "number": 22,
    "body": "Starting on #19. This PR gets slicing working for `GeoSeries`, as well as a number of other pandas methods ([`head`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.head.html#pandas.Series.head), [`tail`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.tail.html#pandas.Series.tail), [`order`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.order.html#pandas.Series.order), [`sort_index`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.sort_index.html#pandas.Series.sort_index), [`take`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.take.html#pandas.Series.take), and [`select`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.select.html#pandas.Series.select), at least).\n\nFixing `.loc`, `.iloc`, and `.groupby` are rather more involved, and this PR does not attempt to start implementing them.  There are tests for those in this PR, currently explicitly skipped.\n",
    "head_branch": "pandas-methods",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 8ca8a85e5b021789738653eec2cf9cd44544c7c0 into c4dcd95d61a77f61c07917799ce102a5be3b1402"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d97cac254a19ac29e4cc",
    "number": 21,
    "body": "Set up to run continuous integration tests on [Travis-CI](https://travis-ci.org/kjordahl/geopandas).\n",
    "head_branch": "feature-travis-ci",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge ae040f62766a97e24e7a1816ad3211b9551c8310 into 553da148bcf1ac678fd0991a3fe0a470e95b0d98"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": true,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d97dac254a19ac29e4cd",
    "number": 20,
    "body": "Recent changes  (particularly [#3482](https://github.com/pydata/pandas/pull/3482)) in [pandas/master](https://github.com/pydata/pandas) broke a couple things in GeoPandas.\n\nA workaround for forcing the constructor to return a `GeoSeries` object is no longer necessary, and in fact now leads to inifinite recursion.  A call to `numpy.putmask` was failing because `pandas.core.Series` no longer inherits from `numpy.ndarray`.  Also added a more specific test for the `fillna()` method.\n",
    "head_branch": "fix-pandas-master",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 0757777eefc949df1cd504ad502dc9dd75e217ad into c67c07bc0ca22660c72110d74a8eda7133b2b926"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d97eac254a19ac29e4ce",
    "number": 18,
    "body": "tempfile.NamedTemporaryFile was failing for me, so reimplemented the to_file test in a temp directory.  Requires a tearDown function to clean up.\n",
    "head_branch": "test-tempfile",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 0856a8e9e236bc8d113ef7cbeb907f825b2adb7c into e3006bcf5638bdf89c846936a9ce5d21c5d76674"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d97fac254a19ac29e4cf",
    "number": 17,
    "body": "As per #16, the current release of Shapely (2.1.17) doesn't include the\nops.transform method, requiring GeoPandas users to install\na bleeding-edge version from Github.\n",
    "head_branch": "shapely_import",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d97fac254a19ac29e4d0",
    "number": 15,
    "body": "Initial support for writing geodataframe to geospatial data formats via fiona.\n",
    "head_branch": "writing",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge d015688d2758f3ed0082aaace915755a9ca6d01c into ea042e3dabde8aed7950f0238ad727f80513b96b"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d980ac254a19ac29e4d1",
    "number": 14,
    "body": "Use osr.CoordinateTransformation instead of pyproj for transforming between coordinate reference systems. Warning: creating a SpatialReference (osr) is less flexible than a Proj (pyproj)\n",
    "head_branch": "faster_transform",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d981ac254a19ac29e4d2",
    "number": 12,
    "body": "This fix ensures that projections work for coordinate systems with units other than meters.\n",
    "head_branch": "fix-units",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge e557dc76ad681d882cbe925b4e3984872aab3ecc into ebf5eb2bce0c8377da60e7e1e3a804bcbda0872f"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d982ac254a19ac29e4d3",
    "number": 11,
    "body": "Add `to_crs()` method to GeoSeries and GeoDataFrame objects to allow transformation to new coordinate reference systems.\n",
    "head_branch": "feature-transform",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 018c71c32bd4905e595bed850d16b9d8e936560b into e4a9d5482e1cffb033b3c887289a416167ffa00d"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d983ac254a19ac29e4d4",
    "number": 10,
    "body": "- Preserves crs attribute through operations\n- Clean up and improve docstrings\n- Fix a couple tests and streamline others\n",
    "head_branch": "feature-pandas-fixes",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge d085838e6fbd558b48c4809585282e7bf193cdf0 into 620b8d887d050fe0851f5162504d9eb84d95153d"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d983ac254a19ac29e4d5",
    "number": 9,
    "body": "Give this a try, i didn't want to make a mess by trying to merge in my branch, but i hope it wont be too much trouble. Should just include the axes and filter commits, i reverted the linestring plot commit that occurred earlier in the tree.\n\nCheers,\nAlex\n",
    "head_branch": "temp",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge 9fe1fd274f41579e58e042366682b813300b865b into 62ab34a16763d38362c2b97b98d80cfd6b937e6f"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d985ac254a19ac29e4d6",
    "number": 8,
    "body": "Make tests more consistent.\n\nAlso adds a LICENSE.txt file.\n",
    "head_branch": "enh-testing",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 2a5ff391284132b6072fa7b429061e8f8994f4d9 into 282180fbdb1c7ba18277fb7c367505ec272ff533"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": true,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d985ac254a19ac29e4d7",
    "number": 7,
    "body": "Additions to plotting, including points and lines, and plotting a GeoDataFrame by column value.\n",
    "head_branch": "feature-plotting",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 9dc1f8b7539ed3833489698f01c24e960b984d54 into 2e3f4b83bba019031a269435f13a319db70c0710"
    ],
    "has_test_file": false,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d986ac254a19ac29e4d8",
    "number": 6,
    "body": "I decided to jump in and try and use GeoPandas for some litigation work I am doing. To get done what I needed end-to-end, I added the following things to GeoPandas that will probably be useful in some form to others in the long run:\n- Plotting for points and lines (I have not tested the geopandas/shapely operations on these geometries)\n- Labeling scheme so that legends can be used in plots (should probably also add an option that uses the GeoDataFrame or GeoSeries index (or other column) if the user desires)\n- Support for the Fiona collection filter by bbox in the GeoDataFrame.from_file open call\n- Ability to specify axes to use in the .plot() calls, instead of creating new automatically\n\nAs part of this work I also was starting with some Pandas DataFrames that we're really trajectories, so I wrote some middlewear that converts each DataFrame into an individual shapely geometry (lines in this case, but points is probably also useful) and then packs them all into GeoSeries and GeoDataFrames. Would it be useful in GeoPandas to include some kind of utility methods that converts a sequence of DataFrames into geometries or GeoPandas objects given some user inputs with regard to what columns to use for x, y[, z]?\n\nCheers,\nAlex\n",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [],
    "has_test_file": false,
    "was_merged": false,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": false
  },
  {
    "_id": "6621d987ac254a19ac29e4d9",
    "number": 5,
    "body": "I've added a to_json method to GeoDataFrame. Next thing for me is a demo/recipe: figure out how to load a GeoJSON file, join data from another table, write out another GeoJSON file. Classic GIS, but all in Pandas instead of ArcMap or QGIS :)\n\nI couldn't resist regrouping and sorting imports in geodataframe.py: standard libs, then dependencies, then the local modules (Zope habits die hard). Is that okay?\n",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge 2a84b92ee495b712c0af0cae6a5baf1d346ad7ff into 6380fb599214f649bc9a1af4443bbde982c209fa"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d988ac254a19ac29e4da",
    "number": 4,
    "body": "What do you think? The test uses the NYC shapefiles, zipped. And nose.\n\nAlso try to import setup from setuptools to get the 'develop' feature.\n",
    "head_branch": "master",
    "is_a_fork": true,
    "comments": [],
    "commit_messages": [
      "Merge 7782f6a00fbfb46d660f23e0ae8228fa2e4f3451 into eb15f97b37cc3da6c0b7382258ce0dc12b66a9c5"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d989ac254a19ac29e4db",
    "number": 3,
    "body": "A first cut at documenting the methods available for GeoSeries and GeoDataFrame objects.  Also a new example.\n",
    "head_branch": "docs",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 728580099f0538a13e85a8cdb9c09af2915c9fc4 into d7fc01140319bfbef14bc79d30e1acf27b5b4d09"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d989ac254a19ac29e4dc",
    "number": 2,
    "body": "",
    "head_branch": "feature-operators",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 299803a547b088c3ca2cacbf68d1de563c43a561 into e3d608b23f147419a881119f5fbc36b75a054d83"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  },
  {
    "_id": "6621d98aac254a19ac29e4dd",
    "number": 1,
    "body": "Implement alignment of GeoSeries and some basic pandas methods to support it.\n",
    "head_branch": "feature-align",
    "is_a_fork": false,
    "comments": [],
    "commit_messages": [
      "Merge 86aeeb659908d6c2fe0b294e309bd67526c89e7e into 307fe2989f3eefbfec1abb7102f76b20d3368c3d"
    ],
    "has_test_file": true,
    "was_merged": true,
    "documentation_file_was_changed": false,
    "documentation_or_comments_in_code_were_changed": true
  }
]